{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Set CUDA device order and visible devices\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7,8,9\"\n",
    "\n",
    "# # Set the device\n",
    "# device = '/cpu:0'\n",
    "# if tf.config.experimental.list_physical_devices('GPU'):\n",
    "#     try:\n",
    "#         # Restrict TensorFlow to only use the second GPU\n",
    "#         gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#         if gpus:\n",
    "#             tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "#             device = '/gpu:0'\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "\n",
    "# print(\"device\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 22:38:19.327526: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-09 22:38:19.343044: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-09 22:38:19.356748: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-09 22:38:19.360918: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-09 22:38:19.374115: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-09 22:38:20.009884: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 22:38:21.652805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79194 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:45:00.0, compute capability: 8.0\n",
      "2024-10-09 22:38:21.654318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 77691 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:46:00.0, compute capability: 8.0\n",
      "2024-10-09 22:38:21.655688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79194 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:49:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # Only GPUs 0 and 1 will be visible to TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\",\"/gpu:2\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# DataLoader Class Definition\n",
    "# -----------------------------\n",
    "class DataLoader:\n",
    "    def __init__(self, h5_filename):\n",
    "        self.h5_filename = h5_filename\n",
    "        self.images, self.centers = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with h5py.File(self.h5_filename, 'r') as f:\n",
    "            images = np.array(f['images'])\n",
    "            centers = np.array(f['centers_training'])\n",
    "        return images, centers\n",
    "\n",
    "    def plot_image_with_centers(self, image_index=None):\n",
    "        if image_index is None:\n",
    "            image_index = np.random.randint(0, len(self.images))\n",
    "\n",
    "        image = self.images[image_index]\n",
    "        centers = self.centers[image_index]\n",
    "\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        valid_centers = centers[centers[:, 0] == 1]\n",
    "        for center in valid_centers:\n",
    "            plt.scatter(center[1], center[2], c='red', marker='o',s=5)  # center[1] is x and center[2] is y\n",
    "        plt.title('Image with Valid Centers Marked')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_centers(centers):\n",
    "        return centers[np.lexsort((centers[:, 0], centers[:, 1]))]\n",
    "\n",
    "    def normalize_data(self):\n",
    "        normalized_images = self.images / np.max(self.images)\n",
    "        sorted_centers = np.array([self.sort_centers(image_centers[:, 1:]) for image_centers in self.centers])\n",
    "        normalized_centers = sorted_centers / 64\n",
    "\n",
    "        normalized_midpoints = tf.expand_dims(normalized_centers, axis=1)\n",
    "        return normalized_images, normalized_midpoints.numpy()\n",
    "\n",
    "    def split_data(self, train_size=0.8, random_state=42):\n",
    "        normalized_images, normalized_midpoints_np = self.normalize_data()\n",
    "        return train_test_split(normalized_images, normalized_midpoints_np, train_size=train_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Utility Function Definition\n",
    "# -----------------------------\n",
    "def plot_transposed_images_with_midpoints(dataset, image_indices=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Extracts multiple images and their midpoints from the given dataset, transposes the images, \n",
    "    corrects the midpoints, and plots the transposed images with the corrected midpoints.\n",
    "\n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The dataset from which to extract the images and midpoints.\n",
    "    - image_indices (list): The indices of the images in the batch to visualize. Default is [0, 1, 2, 3].\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract a sample image batch and its corresponding midpoints from the dataset\n",
    "    sample_image_batch, sample_midpoints_batch = next(iter(dataset))\n",
    "\n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(image_indices):\n",
    "            # Select the specified image and corresponding midpoints from the batch\n",
    "            sample_image = np.array(sample_image_batch[image_indices[i]])\n",
    "            sample_midpoints = np.array(sample_midpoints_batch[image_indices[i]])\n",
    "\n",
    "            # Transpose the image\n",
    "            transposed_image = sample_image.T\n",
    "\n",
    "            # Correct the midpoints by swapping the x and y coordinates\n",
    "            transposed_midpoints_corrected = sample_midpoints[:, :, [1, 0]]\n",
    "\n",
    "            # Plot the transposed image with corrected midpoints\n",
    "            ax.imshow(transposed_image, cmap='gray')\n",
    "            ax.scatter(\n",
    "                transposed_midpoints_corrected[:, :, 0] * 64, \n",
    "                transposed_midpoints_corrected[:, :, 1] * 64, \n",
    "                c='red', marker='o', s=5\n",
    "            )\n",
    "            ax.set_title(f'Image {image_indices[i]} for this batch')\n",
    "        else:\n",
    "            ax.axis('off')  # If fewer than 4 images are requested, hide the unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Loss and Callback Definitions\n",
    "# -----------------------------\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(exponent):\n",
    "    def loss(y_true, y_pred):\n",
    "        diff = tf.abs(y_true - y_pred)\n",
    "        powered_diff = tf.pow(diff, exponent)\n",
    "        return tf.reduce_mean(powered_diff)\n",
    "    return loss\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DynamicExponentCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_exponent, increment, update_frequency):\n",
    "        super().__init__()\n",
    "        self.exponent = initial_exponent\n",
    "        self.increment = increment\n",
    "        self.update_frequency = update_frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.update_frequency == 0:\n",
    "            self.exponent += self.increment\n",
    "            print(f\"\\nEpoch {epoch + 1}: Increasing exponent to {self.exponent}\")\n",
    "            self.model.loss = self.custom_loss(self.exponent)\n",
    "\n",
    "    def custom_loss(self, exponent):\n",
    "        def loss(y_true, y_pred):\n",
    "            diff = tf.abs(y_true - y_pred)\n",
    "            powered_diff = tf.pow(diff, exponent)\n",
    "            return tf.reduce_mean(powered_diff)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'initial_exponent': self.exponent,\n",
    "            'increment': self.increment,\n",
    "            'update_frequency': self.update_frequency,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my NEW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# class ModelBuilder:\n",
    "#     def __init__(self, input_shape=(64, 64, 1), num_classes=3, num_coordinates=2, learning_rate=3e-5, weights_path=None, l2_reg=0.001):\n",
    "#         self.input_shape = input_shape\n",
    "#         self.num_classes = num_classes\n",
    "#         self.num_coordinates = num_coordinates\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.l2_reg = l2_reg\n",
    "#         self.model = self.build_model()\n",
    "\n",
    "#         # Load weights if a path is provided\n",
    "#         if weights_path is not None:\n",
    "#             self.model.load_weights(weights_path)\n",
    "\n",
    "#         self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "#         # self.optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "#     def build_model(self):\n",
    "#         l2 = regularizers.l2(self.l2_reg)\n",
    "        \n",
    "#         x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "#         # First branch\n",
    "#         x_1 = layers.Conv2D(64, kernel_size=6, strides=1, padding='same', activation='relu')(x_input)\n",
    "#         x_1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=3, padding='same', activation='relu', kernel_regularizer=l2)(x_1)\n",
    "#         # x_1 = layers.Dropout(0.1)(x_1)\n",
    "#         # x_1 = layers.BatchNormalization()(x_1)\n",
    "\n",
    "#         # Second branch\n",
    "#         x_2 = layers.Conv2D(32, kernel_size=8, strides=3, padding='same', activation='relu')(x_input)\n",
    "#         x_2 = layers.Conv2D(64, kernel_size=4, strides=1, padding='same', activation='relu')(x_2)\n",
    "#         x_2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_2)\n",
    "#         # x_2 = layers.Dropout(0.1)(x_2)\n",
    "#         # x_2 = layers.BatchNormalization()(x_2)\n",
    "\n",
    "#         # Concatenate branches\n",
    "#         x_3 = layers.concatenate([x_1, x_2])\n",
    "#         x_3 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_3)\n",
    "#         # x_3 = layers.Dropout(0.1)(x_3)\n",
    "#         # x_3 = layers.BatchNormalization()(x_3)\n",
    "\n",
    "#         # Third branch\n",
    "#         x_4 = layers.Conv2D(64, kernel_size=19, strides=5, padding='same', activation='relu', kernel_regularizer=l2)(x_input)\n",
    "        \n",
    "#         # Flatten and concatenate\n",
    "#         x_3 = layers.Flatten()(x_3)\n",
    "#         x_4 = layers.Flatten()(x_4)\n",
    "#         x = layers.Concatenate()([x_3, x_4])\n",
    "\n",
    "#         # Dense layers with L2 regularization\n",
    "#         x = layers.Dense(256, activation='relu', kernel_regularizer=l2)(x)\n",
    "#         # x = layers.Dropout(0.1)(x)\n",
    "\n",
    "#         # Output layer for midpoints\n",
    "#         x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "#         x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "#         return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "#     def compile_model(self, loss_function):\n",
    "#         self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "#     def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "#         history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "#         return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, input_shape=(64, 64, 1), num_classes=13, num_coordinates=2, learning_rate=1e-3, weights_path=None,l1_reg=0.001,l2_reg =0.01):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_coordinates = num_coordinates\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # Load weights if a path is provided\n",
    "        if weights_path is not None:\n",
    "            self.model.load_weights(weights_path)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        # self.optimizer =tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        l1 = regularizers.l1(self.l1_reg)\n",
    "        l2 = regularizers.l2(self.l2_reg)\n",
    "\n",
    "    \n",
    "        x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(128, kernel_size=5, padding='same', activation='relu')(x)\n",
    "        # x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='linear', name='x_midpoints')(x)\n",
    "        x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "        return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "    def compile_model(self, loss_function):\n",
    "        self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "    def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "        history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Main Script Execution\n",
    "# -----------------------------\n",
    "\n",
    "# Load data\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_Mixed_13.h5'             \n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KNoFalsePositivesFixed-index84_13.h5'\n",
    "h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_13_Sparsespots.h5'\n",
    "data_loader = DataLoader(h5_filename)\n",
    "images, centers = data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, 12276)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=np.random.randint(0,len(centers))\n",
    "data_loader.plot_image_with_centers(l)\n",
    "plt.imshow(images[l]),l\n",
    "plt.grid(True),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[l]),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_midpoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m n \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(images))\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_midpoints\u001b[49m[n]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_midpoints' is not defined"
     ]
    }
   ],
   "source": [
    "n = np.random.randint(0, len(images))\n",
    "train_midpoints[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data and split it into training and validation sets\n",
    "train_images, val_images, train_midpoints, val_midpoints = data_loader.split_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: (24000, 64, 64), Train Midpoints: (24000, 1, 13, 2)\n",
      "Validation Images: (6000, 64, 64), Validation Midpoints: (6000, 1, 13, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 400\n",
    "train_dataset = train_dataset.shuffle(buffer_size=8000, reshuffle_each_iteration=True).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=8000).batch(batch_size)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f'Train Images: {train_images.shape}, Train Midpoints: {train_midpoints.shape}')\n",
    "print(f'Validation Images: {val_images.shape}, Validation Midpoints: {val_midpoints.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_transposed_images_with_midpoints(train_dataset, image_indices=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=10, verbose=1, mode='min', min_lr=7e-6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">819,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,338</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m819,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │        \u001b[38;5;34m13,338\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m2\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,059,162</span> (34.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,059,162\u001b[0m (34.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,057,882</span> (34.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,057,882\u001b[0m (34.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# dynamic_exponent_callback = DynamicExponentCallback(2, 1, 400)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # Instantiate the model builder\n",
    "    # model_builder = ModelBuilder(weights_path= \"/home/da886/Weights from Josh's model/Josh's5fixedMSE45overfit-1.keras\")\n",
    "    model_builder = ModelBuilder()\n",
    "\n",
    "    # Build the model\n",
    "    model_builder.build_model()\n",
    "\n",
    "    # Display the model architecture\n",
    "    model_builder.model.summary()\n",
    "\n",
    "    # Compile the model using the custom loss function\n",
    "    # model_builder.compile_model(loss_function=dynamic_exponent_callback.custom_loss(2))\n",
    "    model_builder.compile_model(loss_function=tf.keras.losses.MeanSquaredError()) \n",
    "    \n",
    "    # model_builder.compile_model(loss_function=custom_loss(3))e\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 22:38:56.758348: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-09 22:38:56.767948: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-09 22:38:56.804823: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1728513536.883717 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.886335 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.886449 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.948500 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.948607 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.948683 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.949109 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.949296 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.949372 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.955783 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.956133 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.956236 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.981827 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.981832 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.981870 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.984364 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.984522 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.984896 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.985254 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.985377 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.985653 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.985902 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.986102 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.986327 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.988085 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.988750 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513536.988816 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.009507 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.009555 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.009582 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.010437 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.010508 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.010602 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.011262 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.011334 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.011426 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.012251 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.012269 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.012367 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.013092 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.013244 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.013253 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.013948 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.014186 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.014200 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.016407 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.016527 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.016903 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.018604 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.018878 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.019078 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.021364 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.021573 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.021583 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.024611 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.024620 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.024733 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.027734 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.027897 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.027906 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.031811 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.032079 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.032104 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.033791 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.034136 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.034283 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.034963 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.042968 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.043176 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.043186 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.045728 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.045938 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.045947 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.145487 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.145523 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.146149 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.146153 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.146784 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.146863 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.147381 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.147458 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.148040 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.148120 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.148868 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.148941 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.149807 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.149890 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.150656 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.150747 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.151575 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.151648 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.152545 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.152620 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.153990 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.154068 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.155348 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.155756 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.163009 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.163501 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.163504 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.164008 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.164083 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.164549 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.164627 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.165089 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.165167 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.165643 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.165725 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.166211 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.166288 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.166710 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.166814 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.167208 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.168227 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.168299 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.168869 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.168948 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.169521 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.169598 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.170150 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.170223 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.170783 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.170863 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.172124 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.172200 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.179160 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.179159 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.179860 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.179932 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.180505 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.180580 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.182250 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.182327 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.184112 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.184185 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.186667 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.186746 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.187348 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.187662 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.188253 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.188688 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.189288 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.189799 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.190408 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.200348 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.200441 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.201049 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.201119 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.201713 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.201793 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.202417 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.202499 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.203061 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.203140 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.203941 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.204019 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.205406 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.205486 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.206779 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.206870 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.208121 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.208287 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.209504 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.209670 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.210843 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.211018 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.212319 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.212496 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.227387 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.227460 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.227959 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.228040 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.228559 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.228646 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.229232 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.229305 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.229944 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.230024 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.230628 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.230709 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.231353 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.231433 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.232178 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.232249 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.232902 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.232983 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.233644 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.233725 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.235470 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.235546 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.236295 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.236369 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.237104 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.237179 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.237947 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.238021 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.238911 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.238988 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.240567 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.240641 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.241464 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.241542 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.242532 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.242607 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.243549 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.243628 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.244494 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.244572 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.245589 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.246499 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.247520 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.249124 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.250156 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.250646 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.251688 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.252469 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.253509 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.254441 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.255480 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.264836 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.264860 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.265641 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.265717 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.266346 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.266570 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.267054 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.267296 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.267839 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.268006 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.268618 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.269161 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.269419 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.270270 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.271190 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.271540 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.272016 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.272861 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.273834 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.274006 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.274819 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.275809 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.276446 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.276807 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.277957 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.278831 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.279178 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.280812 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.281292 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.282044 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.283359 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.283958 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.284837 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.286197 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.287839 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.291023 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.293524 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.297808 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.300478 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.303197 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.306514 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.313403 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.314044 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.314780 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.315549 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.316328 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.317130 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.317980 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.318439 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.318905 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.319603 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.319767 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.320653 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.320735 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.321802 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.321875 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.322794 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.323211 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.323779 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.324327 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.324787 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.325411 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.326027 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.326636 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.327690 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.327881 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.328948 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.329122 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.330335 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.330412 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.331908 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.333261 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.334948 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.336439 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.339619 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.340710 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.343418 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.344298 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.346758 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.348860 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.353416 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.358400 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.358409 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.359556 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.360499 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.361617 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.362941 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.363318 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.364061 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.365152 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.367368 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.368619 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.369724 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.370949 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.375542 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.380196 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.384883 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.389423 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.393950 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.398969 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.403854 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.421293 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.422382 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.423587 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.424834 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.426184 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.427475 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.428921 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.428951 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.429520 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.430109 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.430273 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.430624 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.431176 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.431644 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.431907 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.432753 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.433213 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.433591 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.434417 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.434852 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.435306 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.436582 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.436753 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.438147 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.438329 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.441236 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.443334 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.445652 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.445916 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.446325 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.446768 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.447212 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.447748 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.447856 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.448224 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.448692 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.449192 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.449908 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.450174 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.450718 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.451273 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.451818 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.452360 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.452974 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.454264 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.454872 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.455413 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.456202 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.457025 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.457615 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.458798 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.459716 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.460250 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.460759 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.461880 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.462339 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.462717 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.463493 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.464718 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.465587 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.465937 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.467301 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.468605 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.470088 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.470748 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.471358 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.471891 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.472505 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.472749 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.473071 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.473671 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.474270 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.474452 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.475078 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.476097 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.476478 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.476679 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.477927 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.478023 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.479350 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.479609 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.480731 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.482062 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.482547 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.483553 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.484690 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.487012 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.489147 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.491040 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.491458 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.493278 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.494865 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.496654 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.498419 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.498820 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.498906 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.499304 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.499811 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.500389 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.500662 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.501005 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.501709 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.501798 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.502493 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.502562 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.503230 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.503846 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.504279 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.504628 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.504826 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.505519 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.506250 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.506880 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.507052 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.507811 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.508684 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.508882 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.509367 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.510269 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.510631 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.511072 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.512039 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.512964 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.513802 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.515195 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.515750 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.518397 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.519835 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.520005 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.521861 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.523868 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.528869 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.529773 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.531565 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.533140 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.533718 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.534496 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.534920 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.535355 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.536085 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.536845 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.536938 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.538203 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.538278 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.539085 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.540763 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.540862 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.542839 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.543226 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.544856 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.545714 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.546590 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.547170 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.548132 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.548583 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.550631 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.553333 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.556157 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.557619 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.565951 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.566527 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.575496 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.575664 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.583141 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.583796 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.584575 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.584666 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.585442 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.586223 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.587023 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.587874 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.588810 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.589636 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.590498 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.591463 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.592461 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.593494 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.593593 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.594617 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.595859 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.597524 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.598770 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.600101 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.601600 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.602906 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.603004 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.606211 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.610524 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.612682 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.613278 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.616644 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.628410 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.629574 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.630523 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.631645 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.632986 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.634113 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.635203 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.636437 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.637694 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.638805 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.640040 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.644680 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.649381 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.654106 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.658686 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.663248 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.668317 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.673243 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.691158 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.692965 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.694903 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.696778 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.698870 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.700919 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.703097 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.705141 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.707340 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.709612 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.712240 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.714893 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.717725 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.721870 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.725430 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.728761 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.729255 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.730570 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.732188 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.732504 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.733203 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.733378 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.734393 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.734620 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.735837 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.736640 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.736721 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.737223 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.738534 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.738796 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.740046 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.741004 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.741318 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.742695 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.743055 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.744279 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.745270 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.745942 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.747789 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.747800 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.749481 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.750429 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.750702 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.752439 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.753177 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.754572 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.755608 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.756055 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.756925 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.759067 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.760505 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.760524 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.760983 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.764220 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.765709 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.768131 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.768703 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.771355 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.772049 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.773859 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.775291 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.778990 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.783247 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.784854 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.786428 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.789150 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.789597 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.792500 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.794006 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.796576 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.798664 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.799661 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.799660 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.801476 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.803053 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.803295 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.804845 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.806439 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.806647 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.808868 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.809667 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.810595 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.812579 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.813322 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.814594 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.815926 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.816324 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.817001 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.818329 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.819059 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.822194 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.824941 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.827461 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.829004 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.832044 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.835375 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.835673 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.836521 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.838860 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.841965 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.845568 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.845792 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.849307 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.854120 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.854759 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.863736 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.867958 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.872451 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.873235 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.883195 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.886133 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.890206 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.904704 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.907785 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.922788 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.926423 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.941615 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.945476 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.960661 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513537.979886 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.000634 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.002436 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.004367 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.006245 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.008353 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.010417 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.012620 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.014659 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.016865 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.019163 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.021793 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.024467 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.027279 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.031454 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.035082 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.038929 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.042859 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.046128 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.060105 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.065005 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.069702 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.087053 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.090221 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.093377 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.096129 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.100194 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.103250 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.106851 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.110016 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.113138 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.116796 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.120495 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.138785 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.156778 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.175007 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.175160 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.178508 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.181621 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.185051 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.188980 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.192549 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.192748 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.196601 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.200738 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.204493 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.208549 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.210623 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.211266 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.213799 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.214631 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.217733 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.219119 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.221178 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.224760 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.225099 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.228773 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.229211 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.231134 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.232590 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.236669 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.238507 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.240532 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.244710 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.246320 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.248507 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.249825 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.253769 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.255037 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.260536 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.263235 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.266708 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.273429 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.274060 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.281731 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.282805 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.289072 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.298535 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.304323 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.307734 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.328698 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.480354 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.483723 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.486836 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.490280 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.494227 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.498075 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.502021 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.506262 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.510067 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.514211 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.519381 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.524660 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.530233 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.536457 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.543793 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.551594 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.559099 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.568667 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.579225 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.600763 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.608413 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.610126 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.611642 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.613210 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.614840 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.616889 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.618450 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.620233 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.621797 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.623626 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.625424 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.634447 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.634540 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.636139 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.637626 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.639181 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.640788 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.642824 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.643636 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.644370 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.646146 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.647686 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.649494 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.651298 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.652689 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.660250 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.661927 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.669158 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.671258 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.678016 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.680728 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.687165 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.690587 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.696394 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.705761 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.715756 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.817713 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.819612 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.821467 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.823399 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.825455 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.827482 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.829521 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.831518 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.833432 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.835460 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.837818 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.840191 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.842797 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.844442 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.845774 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.846193 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.847853 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.849036 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.849610 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.851504 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.852406 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.853382 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.855254 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.856256 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.857225 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.859122 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.860820 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.861139 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.863587 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.865744 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.866069 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.868716 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.870431 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.871687 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.875061 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.878553 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.881403 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.882392 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.886966 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.891585 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.900007 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.900729 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.901001 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.901373 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.902021 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.902368 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.902745 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.902916 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.903569 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.904366 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.904445 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.905141 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.905965 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.906084 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.906850 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.907698 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.907802 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.909856 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.910329 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.911414 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.912930 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.913288 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.914851 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.915654 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.916690 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.918614 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.918689 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.920351 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.921068 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.921702 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.921926 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.922352 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.923179 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.923812 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.924466 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.924845 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.925219 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.925973 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.926820 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.927695 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.927821 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.927995 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.930290 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.932848 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.935531 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.936695 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.938430 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.941671 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.944605 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.945521 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.947677 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.954612 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.961211 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.961856 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.962487 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.963165 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.963923 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.963996 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.964653 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.965321 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.965977 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.966672 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.967369 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.968153 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.968941 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.969881 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.970885 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.971922 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.973317 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.973389 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.974376 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.975672 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.977033 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.979431 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.981642 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.982292 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.982913 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.983398 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.983541 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.983713 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.984411 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.985068 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.985739 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.986395 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.987090 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.987795 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.988583 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.989372 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.990304 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.991318 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.992360 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.993620 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.994062 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.994665 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.995965 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513538.998364 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.002317 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.004453 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.004891 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.005268 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.005750 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.006515 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.008279 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.009060 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.009967 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.010930 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.012069 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.012792 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.013265 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.017994 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.018321 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.018640 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.018971 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.019307 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.019634 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.019971 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.020298 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.020645 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.020984 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.021337 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.021728 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.022077 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.022458 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.022809 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.023061 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.023227 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.023514 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.023681 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.023904 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.024383 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.025053 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.025214 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.025631 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.026166 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.026269 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.026768 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.026955 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.027512 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.027856 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.028756 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.028865 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.030184 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.030200 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.031292 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.035642 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.035947 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.036273 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.036596 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.036924 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.037295 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.037654 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.037988 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.038316 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.038670 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.039012 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.039362 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.039751 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.040107 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.040487 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.040850 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.041267 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.041699 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.042997 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.043489 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.043584 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.044117 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.044125 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.044394 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.044891 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.045084 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.045752 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.046026 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.046698 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.047262 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.048054 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.049059 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.050096 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.051940 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.052748 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.052900 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.053196 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.053459 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.053747 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.054034 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.054287 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.054668 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.054949 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.055218 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.055487 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.055802 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.056111 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.056529 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.056903 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.057287 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.057679 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.058082 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.058537 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.059049 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.059782 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.060343 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.060625 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.061090 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.061146 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.061386 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.062043 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.062285 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.062710 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.063644 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.065025 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.066031 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.067069 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.068906 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.069758 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.070052 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.070316 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.070600 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.070897 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.071149 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.071440 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.071725 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.071988 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.072258 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.072575 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.072889 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.073309 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.073681 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.074059 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.074454 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.074869 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.075326 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.076394 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.077129 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.077702 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.078339 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.080130 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.111921 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.113640 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.115305 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.117056 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.118955 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.120824 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.122692 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.124653 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.126548 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.128556 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.130999 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.133420 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.136039 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.138985 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.142301 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.145835 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.149730 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.154365 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.159086 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.170152 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.188588 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.189311 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.189948 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.190596 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.191449 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.192100 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.192768 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.193527 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.194302 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.195168 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.195929 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.198560 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.201167 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.203903 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.206797 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.210023 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.212958 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.216025 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.249978 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.250623 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.251242 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.251932 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.252640 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.253301 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.253976 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.254640 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.255333 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.256030 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.256825 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.257625 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.258564 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.259590 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.260633 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.261904 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.262955 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.264265 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.266682 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.270712 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.281536 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.292173 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.292591 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.292969 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.293463 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.294233 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.295067 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.295829 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.296740 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.297715 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.298856 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.299973 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.304701 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.305024 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.305349 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.305679 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.306003 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.306335 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.306677 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.307011 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.307367 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.307711 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.308062 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.308455 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.308816 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.309203 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.309568 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.309982 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.310413 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.311726 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.312228 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.312714 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.313450 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.314583 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.315816 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.321313 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.329329 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.329634 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.329903 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.330564 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.331228 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.332164 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.333513 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.334518 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.335559 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.337408 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.338266 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.338555 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.338826 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.339111 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.339403 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.339661 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.339957 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.340245 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.340518 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.340792 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.341110 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.341424 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.341847 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.342224 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.342608 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.342998 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.343407 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.343863 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.344378 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.345115 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.345682 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.346336 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513539.347461 4086301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.728037 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.728160 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.728327 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.732304 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.732318 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.732431 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.737249 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.737326 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.737344 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.738014 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.738092 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.738121 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.738964 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.738954 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.739005 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.739671 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.739755 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.739779 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.740242 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.740436 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.740450 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.740906 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.741084 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.741191 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.741417 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.741659 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.741743 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.757094 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.757322 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.757473 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.757901 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.758153 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.758324 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.758679 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.758964 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.759139 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.761744 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.761939 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.761963 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.764600 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.764797 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.764880 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.766758 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.767038 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.767106 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.794262 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.794576 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.794865 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.795132 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.795647 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.795659 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.795641 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.796050 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.796069 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.796471 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.796579 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.796803 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.797015 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.797190 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.798160 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.798574 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.798587 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.799080 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.799104 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.799225 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.799702 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.799723 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.799791 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.800280 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.800301 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.800380 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.800889 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.800969 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.800978 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.801241 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.803811 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.803808 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.803919 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.804296 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.804425 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.804442 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.806705 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.806883 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.806898 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.807193 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.807370 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.807380 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.807678 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.807846 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.807854 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.808141 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.808313 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.808327 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.808618 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.808779 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.808794 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.809117 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.809285 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.809300 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.811147 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.811224 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.811235 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.813173 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.813350 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.813366 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.813641 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.813960 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.813993 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.814154 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.814592 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.814606 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.815882 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.816497 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.816514 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.836867 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.836882 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.836944 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.837518 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.837531 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.837631 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.839519 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.839703 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.839793 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.839990 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.840258 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.840312 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.840538 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.840730 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.840790 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.841017 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.841296 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.841356 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.841579 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.841779 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.841839 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.842066 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.842294 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.842329 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.853069 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.853348 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.853418 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.853571 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.854082 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.854165 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.854174 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.854732 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.854798 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.854811 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.855186 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.855407 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.855450 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.855762 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.856068 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.856084 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.856344 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.856626 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.856642 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.856859 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.857227 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.857266 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.857489 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.857864 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.857899 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.857976 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.858376 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.858484 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.858645 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.858980 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.859064 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.859350 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.859615 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.859668 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.859780 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.859952 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.862530 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.862538 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.862551 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.863211 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.863229 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.863249 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.863815 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.863835 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.863853 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.864450 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.864471 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.864490 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.865056 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.865073 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.865090 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.867104 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.867177 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.867189 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.869352 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.869364 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.869384 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.870669 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.870702 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.870779 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.873397 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.873472 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.873626 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.874262 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.874440 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.874454 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.876395 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.876467 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.876481 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.877019 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.877102 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.877117 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.877632 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.877737 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.877752 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.878385 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.878465 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.878487 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.879024 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.879026 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.879129 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.881127 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.881126 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.881155 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.883216 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.883302 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.883317 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.883936 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.883947 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.883958 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.884596 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.884617 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.884625 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.899456 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.899495 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.899570 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.902019 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.902016 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.902044 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.902637 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.902711 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.902724 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.903333 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.903409 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.903422 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.904014 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.904084 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.904096 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.904704 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.904781 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.904795 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.905381 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.905456 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.905470 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.906083 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.906166 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.906177 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.908820 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.908833 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.908846 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.909474 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.909549 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.909560 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.910214 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.910236 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.910248 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.910942 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.910964 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.910971 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.913486 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.913599 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.913612 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.914112 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.914144 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.914229 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.914746 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.914758 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.914859 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.915436 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.915496 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.915510 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.916147 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.916232 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.916246 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.916896 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.916971 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.916984 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.917642 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.917717 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.917730 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.918386 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.918463 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.918477 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.919074 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.919180 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.919262 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.919565 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.919853 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.919932 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.920289 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.920698 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.920777 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.921003 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.921535 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.921651 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.921835 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.922355 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.922614 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.922704 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.923089 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.923344 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.926718 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.927186 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.927313 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.927696 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.927741 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.927855 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.928416 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.928417 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.928524 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.929085 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.929124 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.929200 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.929742 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.929759 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.929784 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.930399 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.930423 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.930439 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.931090 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.931170 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.931182 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.931785 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.931807 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.931830 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.932436 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.932456 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.932479 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.933185 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.933206 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.933219 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.933836 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.933905 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.933919 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.934314 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.934604 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.934642 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.934758 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.935188 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.935313 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.935495 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.935636 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.936042 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.936065 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.936182 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.936651 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.936674 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.936776 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.937150 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.937229 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.937638 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.937740 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.938164 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.938244 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.939183 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.939273 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.939586 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.940527 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.940850 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.941161 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.942121 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.950941 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.951262 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.951341 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.951823 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.951833 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.952275 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.952425 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.952441 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.952845 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.953002 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.953030 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.953376 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.953550 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.953589 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.953923 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.954090 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.954113 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.954445 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.954763 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.954778 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.954898 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.955229 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.955301 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.955452 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.955977 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.956057 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.956068 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.956621 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.956627 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.956734 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.957182 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.957195 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.957305 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.957814 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.957949 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.957970 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.958325 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.958551 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.958671 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.958806 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.959092 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.959305 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.959466 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.959602 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.959988 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.960031 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.960253 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.960657 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.960731 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.960842 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.961452 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.961487 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.961563 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.962206 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.962209 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.962315 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.962970 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.962982 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.963084 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.963750 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.963764 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.963867 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.964518 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.964600 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.964613 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.964995 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.965111 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.965521 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.965618 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.965934 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.966200 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.966298 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.966674 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.966992 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.967899 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.967937 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.968088 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.969478 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.969603 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.969679 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.970970 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.971153 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.971172 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.972356 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.972653 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.972669 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.974042 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.978710 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.978992 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.979180 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.979562 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.979675 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.979984 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.980152 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.980549 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.980765 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.980804 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.980997 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.981479 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.981514 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.981591 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.982195 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.982227 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.982306 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.982865 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.982900 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.982976 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.983579 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.983604 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.983678 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.984299 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.984302 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.984405 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.985017 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.985063 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.985131 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.985370 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.985924 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.986661 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.986749 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.986760 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.987236 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.987566 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.987641 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.987995 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.988411 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.989079 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.989177 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.989815 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.990537 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.990637 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.991208 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.998681 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.998860 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.998919 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.999408 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.999703 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513541.999809 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.000063 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.000603 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.000648 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.000818 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.001630 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.001644 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.001745 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.002652 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.002733 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.002741 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.003592 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.003594 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.003696 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.004678 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.004713 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.004788 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.005727 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.005761 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.005838 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.006742 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.006821 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.006835 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.007797 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.007873 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.007887 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.008749 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.008850 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.008932 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.009535 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.009711 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.009728 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.010349 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.010531 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.010549 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.011036 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.011374 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.011452 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.011761 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.012105 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.012354 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.012650 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.013003 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.013401 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.013691 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.014052 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.014447 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.014728 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.015100 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.017184 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.017481 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.017893 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.019728 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.020001 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.020448 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.022264 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.022509 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.022987 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.027212 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.027495 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.028030 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.036366 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.036746 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.037371 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.066655 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.066879 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.067286 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.067513 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.067818 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.068072 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.068432 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.068538 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.068750 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.069109 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.069419 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.069526 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.069791 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.070236 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.070336 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.070510 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.071163 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.071188 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.071289 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.072061 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.072186 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.072202 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.072880 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.073052 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.073067 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.073580 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.073852 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.073867 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.074311 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.074749 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.074764 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.075029 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.075850 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.075865 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.075967 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.076932 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.076944 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.077056 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.078099 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.078209 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.078222 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.079110 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.079296 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.079319 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.080139 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.080312 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.080332 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.081526 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.081563 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.081637 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.082624 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.084110 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.084287 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.085187 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.086499 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.086711 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.087594 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.093707 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.094007 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.094475 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.094776 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.094817 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.095203 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.095645 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.095730 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.095979 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.096537 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.096634 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.096805 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.097558 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.097643 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.097747 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.098525 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.098742 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.098750 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.099307 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.099659 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.099757 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.100093 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.100547 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.100652 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.100887 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.101466 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.101602 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.101779 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.102298 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.102582 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.102680 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.103079 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.103384 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.103556 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.103899 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.104182 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.104355 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.104674 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.105155 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.105360 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.105533 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.106164 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.106396 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.106561 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.107059 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.107301 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.107566 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.107947 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.108179 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.108458 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.108793 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.109028 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.109355 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.109745 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.109985 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.110211 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.110633 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.110873 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.111171 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.112166 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.112304 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.112482 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.113296 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.113460 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.113786 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.114236 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.114424 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.114756 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.115662 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.117412 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.117627 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.118868 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.120547 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.120767 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.122016 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.124194 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.124400 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.125701 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.127897 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.128085 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.129420 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.131593 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.131755 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.133137 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.135294 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.135460 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.136857 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.183071 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.183179 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.183801 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.183978 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.184590 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.184701 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.185167 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.185507 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.185522 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.185866 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.186443 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.186476 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.186655 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.187679 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.187756 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.187774 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.188539 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.188864 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.188880 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.189439 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.190055 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.190071 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.190416 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.191370 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.191439 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.191550 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.192821 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.192896 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.192910 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.194181 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.194357 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.194372 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.195402 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.195622 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.195624 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.196511 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.198407 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.198626 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.199541 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.207029 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.207226 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.208192 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.208685 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.208858 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.209806 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.210299 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.210475 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.211382 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.211944 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.212118 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.212989 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.213603 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.213714 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.214540 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.215399 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.215413 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.216125 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.217070 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.217085 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.217715 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.218817 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.218832 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.219382 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.220601 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.220616 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.221087 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.222438 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.222452 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.222836 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.224074 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.224088 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.224388 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.225743 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.225756 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.225986 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.227682 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.227707 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.227912 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.229839 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.230047 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.230117 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.231854 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.232198 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.232280 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.233983 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.234493 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.234574 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.236260 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.236979 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.237068 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.239134 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.240065 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.240082 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.249612 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.251002 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.251075 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.258682 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.260327 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.260515 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.267730 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.269491 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.269847 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.278037 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.279917 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.280240 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.287997 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.289980 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.290261 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.297650 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.299746 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.299972 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.417427 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.419047 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.419421 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.420123 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.420676 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.421077 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.421771 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.422346 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.422706 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.423407 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.424098 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.424367 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.425081 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.425834 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.426137 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.426846 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.427745 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.427921 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.428593 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.429579 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.429802 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.430462 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.431518 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.431691 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.432303 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.433695 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.433792 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.434203 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.435935 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.436032 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.436254 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.438111 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.438440 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.438521 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.440731 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.440851 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.440870 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.443624 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.443636 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.443641 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.446563 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.446638 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.446653 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.449547 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.449562 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.449666 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.452243 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.452422 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.453065 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.455693 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.455957 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.456853 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.459436 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.459773 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.461503 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.464100 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.464445 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.470911 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.473624 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.473884 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.486378 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.488450 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.489136 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.489462 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.490463 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.491218 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.491577 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.492505 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.493241 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.493640 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.494521 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.495285 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.495718 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.496484 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.497286 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.497770 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.498626 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.499239 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.499773 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.500639 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.501363 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.501946 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.502850 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.503370 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.504000 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.505077 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.505559 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.506255 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.507196 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.507758 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.508514 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.509444 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.509852 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.510672 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.512134 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.512314 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.512944 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.514410 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.514822 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.515702 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.516939 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.517108 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.517826 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.519687 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.519789 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.520526 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.522318 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.522574 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.523166 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.525167 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.525266 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.525983 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.527806 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.528313 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.528630 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.530880 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.531109 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.531708 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.533703 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.534537 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.536795 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.539276 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.539674 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.540225 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.542139 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.542717 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.543137 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.545167 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.546208 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.553528 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.556018 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.557201 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.564302 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.566751 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.568233 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.575476 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.577816 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.579597 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.586649 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.588877 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.590844 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.597829 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.599938 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.602090 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.609002 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.611000 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.613335 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.798933 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.799459 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.800619 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.801144 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.802482 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.802995 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.804438 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.804953 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.805409 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.806428 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.807074 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.807187 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.809215 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.809221 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.809626 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.811210 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.812020 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.812414 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.813227 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.815036 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.815425 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.815810 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.818314 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.818765 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.818844 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.821929 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.822033 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.822383 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.825351 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.825967 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.826527 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.828694 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.828891 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.829300 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.833052 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.835832 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.840275 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.840931 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.847541 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.859918 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.860256 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.862988 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.863307 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.865924 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.866044 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.866320 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.869040 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.869209 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.869455 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.872079 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.872423 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.872659 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.875186 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.875710 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.875954 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.878406 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.878717 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.878950 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.881968 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.881986 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.882115 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.885001 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.885214 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.885489 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.888083 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.888560 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.888769 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.891782 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.891818 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.892013 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.895004 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.895983 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.896224 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.898131 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.899146 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.899427 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.902303 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.903257 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.903593 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.905509 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.907011 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.907394 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.909674 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.911280 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.911718 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.913533 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.915945 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.916429 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.917901 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.922025 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.922726 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.922812 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.929017 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.943178 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.944195 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.950545 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.961439 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.962563 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.969091 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.979448 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.980632 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.987233 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513542.999258 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.000259 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.007173 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.018374 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.019168 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.026490 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.038729 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.039226 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.046951 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.274574 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.275625 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.277698 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.278780 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.280825 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.281907 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.284023 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.285106 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.286269 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.287424 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.288504 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.289400 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.290819 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.291878 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.292544 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.294453 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.295687 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.295796 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.298009 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.299312 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.299418 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.301664 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.302705 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.303189 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.305617 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.306330 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.307221 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.310068 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.310148 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.311414 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.313846 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.314522 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.315748 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.318017 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.319564 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.320781 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.322351 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.325102 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.326332 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.326661 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.330589 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.331721 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.331893 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.336133 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.337270 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.337454 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.342679 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.343212 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.344484 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.348187 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.350869 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.352127 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.355198 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.360175 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.361331 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.362836 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.372044 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.379265 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.380112 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.390802 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.406454 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.407282 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.410320 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.411220 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.414175 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.415082 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.417862 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.418019 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.418941 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.421869 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.421973 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.422831 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.425818 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.425996 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.426758 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.429773 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.429945 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.430621 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.433697 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.433954 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.434617 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.437659 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.438106 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.438751 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.441694 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.442645 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.443268 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.445914 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.446867 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.447450 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.450258 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.451412 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.451961 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.454854 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.456445 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.456998 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.458929 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.460104 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.461357 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.463268 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.464407 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.465013 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.467587 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.467975 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.468577 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.471266 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.472078 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.472656 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.475590 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.477037 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.477555 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.479183 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.482580 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.483006 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.483314 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.488351 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.488470 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.488750 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.493904 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.494105 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.494290 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.499507 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.499837 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.499916 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.505418 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.506439 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.506781 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.510838 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.513423 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.513669 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.517795 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.519256 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.519436 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.524751 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.525333 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.525534 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.530561 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.536665 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.545711 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.545726 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.557065 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.567189 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.567451 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.578861 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.588648 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.588986 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.600584 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.609893 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.610457 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.622307 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.631137 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.631925 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.644024 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.658427 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.659509 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513543.672083 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.033952 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.037128 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.037452 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.040818 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.040892 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.044450 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.044626 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.048152 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.048424 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.051969 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.053491 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.053520 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.056788 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.056964 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.059165 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.060420 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.062600 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.064171 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.064578 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.068222 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.068235 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.070365 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.073206 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.073987 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.076648 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.078862 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.080276 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.083582 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.084357 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.087236 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.090220 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.092253 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.095982 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.096609 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.102171 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.103640 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.105883 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.112449 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.122448 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.127117 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.130971 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.146914 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.173696 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.175598 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.177424 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.177434 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.179358 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.179553 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.181172 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.181481 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.183098 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.183330 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.185017 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.185232 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.186817 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.187385 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.188672 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.189296 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.190659 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.191384 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.192507 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.193235 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.193570 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.194557 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.195635 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.195652 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.196782 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.197631 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.197648 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.198593 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.199638 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.200039 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.200452 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.201613 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.202238 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.202783 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.203450 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.204741 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.204944 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.205338 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.207726 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.207811 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.207829 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.209613 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.210426 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.211256 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.211709 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.213758 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.213981 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.215812 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.217682 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.220042 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.222223 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.222653 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.224701 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.224935 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.227365 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.230747 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.232320 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.234358 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.241776 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.242167 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.243672 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.251738 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.252782 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.254477 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.261257 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.263333 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.264993 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.272224 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.273631 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.275238 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.282913 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.293363 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.392753 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.394615 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.395044 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.396459 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.396923 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.398358 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.398775 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.400347 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.400685 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.402287 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.402668 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.404444 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.404647 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.406510 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.406770 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.408623 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.408845 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.410910 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.411084 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.413283 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.413502 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.414642 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.415597 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.415852 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.416532 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.418163 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.418520 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.418544 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.420443 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.420913 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.421883 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.422437 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.424552 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.424560 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.424876 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.426687 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.427552 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.427958 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.428773 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.430664 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.430926 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.431856 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.433211 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.434626 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.435545 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.436669 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.437868 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.439505 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.440635 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.441419 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.443889 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.444276 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.446803 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.449930 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.451050 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.453980 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.454062 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.458963 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.463811 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.468089 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.470314 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.470957 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.472482 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.473172 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.473448 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.474888 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.475346 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.476964 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.477751 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.479588 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.479822 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.482451 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.482720 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.485698 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.485798 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.488651 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.488829 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.490706 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.491570 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.492310 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.492946 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.495297 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.495308 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.495669 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.497736 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.498376 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.498676 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.499829 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.501414 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.502035 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.502510 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.505252 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.505349 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.505691 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.508636 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.508687 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.508796 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.511850 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.511956 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.512372 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.515356 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.515695 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.516082 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.518759 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.519456 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.520169 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.521522 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.522874 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.523606 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.525264 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.525585 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.526307 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.528442 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.529008 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.530229 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.531655 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.533723 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.534879 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.535411 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.538447 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.538948 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.539184 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.542562 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.543348 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.543975 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.546112 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.547644 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.548147 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.548857 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.551861 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.553578 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.558409 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.558488 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.562113 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.562619 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.567695 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.568540 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.571943 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.572258 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.579426 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.582242 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.583137 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.590223 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.592460 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.594010 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.603351 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.604030 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.607953 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.614245 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.617831 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.621935 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.628245 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.642193 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.805170 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.807075 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.809077 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.811133 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.811535 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.813451 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.813565 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.815586 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.816108 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.817664 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.818975 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.819878 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.822027 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.822566 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.825374 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.825542 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.828601 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.830003 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.831904 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.833428 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.834538 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.835384 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.836542 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.837425 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.839515 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.839975 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.841063 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.841755 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.844445 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.846478 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.847355 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.849596 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.850461 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.853790 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.856068 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.858464 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.863003 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.868456 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.870311 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.876862 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.878118 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.883292 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.889658 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.898970 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.905968 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.907127 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.908222 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.909368 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.910504 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.911735 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.911918 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.912263 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.912939 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.913423 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.914050 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.914526 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.915153 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.915673 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.916231 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.916817 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.917571 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.918011 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.918831 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.919213 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.920306 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.920416 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.921508 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.921943 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.922581 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.923600 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.923915 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.924987 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.925174 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.926662 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.926670 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.928287 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.928568 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.929931 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.931293 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.932744 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.934359 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.934625 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.934712 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.935873 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.936972 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.938120 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.939087 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.939282 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.940423 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.940602 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.941804 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.942909 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.943789 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.944032 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.945321 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.945324 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.946667 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.947921 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.949355 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.949424 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.949974 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.951069 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.952714 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.954091 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.954693 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.955547 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.955653 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.957558 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.959936 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.960897 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.963358 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.966163 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.968073 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.972764 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.978269 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.983664 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513544.988968 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.019813 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.020988 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.022125 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.023320 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.024532 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.025797 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.026216 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.027066 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.027394 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.028509 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.028623 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.029945 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.030042 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.031165 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.031428 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.032425 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.032800 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.033699 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.034467 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.035012 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.036057 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.036352 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.037852 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.037950 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.039223 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.039813 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.040871 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.041940 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.042472 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.044167 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.044411 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.046010 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.048164 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.049267 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.049663 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.050593 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.050855 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.051987 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.053186 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.054397 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.055347 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.055669 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.056942 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.058248 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.059584 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.060312 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.060957 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.061719 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.062343 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.063035 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.064011 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.064341 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.065747 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.065835 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.066261 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.067353 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.067599 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.067698 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.068700 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.069004 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.069467 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.070229 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.070400 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.071852 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.072047 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.072069 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.073552 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.073967 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.074303 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.074905 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.076054 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.076408 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.077890 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.078104 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.079068 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.079803 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.080212 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.081718 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.081912 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.083457 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.083812 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.085308 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.085907 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.087547 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.087643 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.089280 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.089534 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.090011 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.091148 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.091396 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.091806 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.092702 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.093347 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.094146 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.094222 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.095248 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.095518 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.096796 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.097034 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.097542 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.098412 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.100044 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.100055 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.100348 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.101507 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.102642 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.103437 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.105589 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.105711 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.106202 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.107537 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.109651 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.111208 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.111407 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.111567 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.112961 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.114812 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.117159 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.117231 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.117339 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.119064 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.121370 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.122898 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.123058 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.123667 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.126255 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.128551 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.128716 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.129830 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.134308 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.135175 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.135702 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.140832 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.141411 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.142845 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.146479 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.148513 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.152090 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.157671 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.164782 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.171902 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.237194 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.238479 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.239759 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.241202 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.242743 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.243567 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.244388 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.244860 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.246297 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.246310 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.247763 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.248158 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.249328 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.250478 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.250980 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.252718 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.252988 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.254576 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.256078 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.256888 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.259394 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.261379 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.262501 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.267109 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.267343 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.267826 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.268408 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.269699 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.271168 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.272737 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.273829 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.274402 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.275750 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.276165 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.278033 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.280371 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.282283 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.282907 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.286040 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.286867 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.291411 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.293543 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.297453 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.301586 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.302363 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.303291 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.304062 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.304835 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.305622 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.305975 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.306439 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.307234 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.308068 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.308895 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.309102 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.309773 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.309948 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.310806 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.310823 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.311601 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.311777 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.312377 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.312656 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.313119 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.313547 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.313862 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.314764 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.314780 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.315578 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.315810 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.316297 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.316938 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.317256 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.317355 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.318224 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.318329 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.319224 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.320070 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.321062 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.321527 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.321952 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.322956 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.322969 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.324111 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.324331 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.326972 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.327306 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.329736 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.329969 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.332163 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.332883 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.332952 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.333683 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.334409 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.335283 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.335387 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.336166 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.337032 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.337800 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.338295 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.338604 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.339399 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.340105 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.340327 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.340914 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.341215 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.341751 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.342127 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.342757 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.343058 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.343611 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.344052 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.344620 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.345110 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.345514 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.346198 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.346452 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.347295 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.347613 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.348485 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.350828 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.353290 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.354887 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.355743 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.356601 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.358919 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.358938 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.361342 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.361977 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.364257 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.367328 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.368156 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.368944 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.369711 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.370494 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.371290 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.371640 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.372129 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.372959 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.373812 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.374677 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.375549 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.376199 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.376442 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.377477 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.378508 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.379608 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.380769 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.381402 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.382129 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.383483 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.385959 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.388983 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.392169 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.393124 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.393910 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.394702 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.395512 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.396344 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.396558 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.397303 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.397326 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.397590 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.398014 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.398216 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.398625 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.398721 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.399103 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.399593 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.399612 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.399995 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.400290 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.400512 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.401003 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.401021 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.401455 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.401707 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.402061 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.402413 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.402528 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.403245 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.403256 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.403519 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.403991 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.404487 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.404619 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.404790 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.405742 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.405863 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.405938 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.406786 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.406802 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.407326 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.407674 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.407921 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.408832 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.408912 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.409129 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.409871 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.410156 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.410836 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.411209 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.411385 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.412265 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.412720 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.413319 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.414091 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.414447 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.414546 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.415447 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.415762 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.417132 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.417218 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.418366 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.418851 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.419763 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.421402 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.423086 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.423529 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.423992 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.424793 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.425310 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.425696 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.426643 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.427596 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.428237 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.428593 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.429583 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.430496 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.431163 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.431460 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.432585 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.434078 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.434158 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.434250 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.434765 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.435122 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.435375 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.435978 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.436164 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.436597 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.437533 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.437570 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.437668 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.438379 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.438662 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.439088 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.439720 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.439882 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.440620 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.441077 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.441321 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.441422 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.442241 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.442410 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.442974 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.443699 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.443865 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.444720 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.445186 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.445261 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.445570 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.446673 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.446929 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.447487 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.448878 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.449070 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.449555 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.450554 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.450867 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.453819 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.456756 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.457030 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.457889 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.458674 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.459451 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.459708 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.460243 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.461004 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.461704 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.462411 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.462656 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.463229 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.463943 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.464761 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.465594 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.466494 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.466571 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.467322 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.468163 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.469063 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.470167 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.470275 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.471229 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.472541 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.473669 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.474687 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.474856 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.476044 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.477615 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.479190 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.480760 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.482330 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.484287 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.486241 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.488706 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.490979 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.497354 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.498297 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.499226 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.500218 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.501267 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.502350 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.503455 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.504641 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.511150 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.512849 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.515119 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.515220 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.515828 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.516510 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.517216 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.517555 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.518014 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.518746 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.519391 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.520149 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.520657 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.522977 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.523991 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.524066 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.525032 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.525191 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.525677 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.526056 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.527115 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.527647 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.528217 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.529323 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.530023 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.530677 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.530685 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.532082 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.537174 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.538893 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.540677 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.541141 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.541310 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.541802 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.542244 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.542692 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.543173 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.543733 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.543805 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.544301 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.544803 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.545277 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.545809 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.546377 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.546395 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.547026 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.547227 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.547301 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.548019 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.548116 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.548688 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.549441 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.549454 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.550171 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.550340 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.550849 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.551147 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.551490 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.551657 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.552088 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.552192 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.553020 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.553115 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.553797 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.553961 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.554517 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.555394 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.555494 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.556227 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.557152 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.557240 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.557340 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.558398 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.559346 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.560290 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.560600 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.562167 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.563515 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.564855 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.566503 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.568167 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.568361 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.568830 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.569292 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.569749 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.570215 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.570739 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.571286 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.571814 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.572355 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.572865 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.572909 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.573612 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.573695 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.574187 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.574384 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.574774 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.575062 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.575378 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.575784 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.575948 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.576526 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.576694 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.577223 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.577946 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.578019 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.578562 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.579363 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.579449 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.580195 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.581050 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.581820 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.582654 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.583320 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.583551 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.583945 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.584775 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.584787 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.585161 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.585396 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.585794 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.586124 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.586134 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.586988 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.587067 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.587079 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.587774 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.587885 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.588453 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.588616 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.589010 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.589202 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.589374 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.589849 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.590122 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.590436 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.590606 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.590873 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.591264 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.591684 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.591938 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.592042 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.592432 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.592610 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.593402 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.593549 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.593659 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.594200 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.594384 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.594811 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.595467 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.595480 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.595604 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.596243 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.596608 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.597442 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.597604 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.598750 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.598842 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.600001 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.600509 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.601116 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.601875 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.603415 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.604945 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.606478 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.606980 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.607824 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.608141 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.608630 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.609421 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.610204 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.610792 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.610994 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.611425 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.611705 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.612045 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.612425 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.612659 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.613497 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.613505 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.614323 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.614420 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.615050 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.615258 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.615767 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.616102 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.616495 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.616931 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.617253 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.617696 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.618007 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.618557 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.618793 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.619698 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.619709 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.620545 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.620663 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.620834 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.621088 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.621675 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.621839 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.621951 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.622450 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.622634 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.623007 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.623315 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.623599 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.623801 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.624219 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.624573 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.624684 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.624919 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.625620 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.625776 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.626081 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.626657 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.626985 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.627763 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.628602 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.628914 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.630257 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.630526 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.631865 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.632069 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.633477 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.633694 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.634180 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.635031 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.635442 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.635716 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.635878 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.636672 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.637636 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.637646 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.638431 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.639172 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.639876 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.640104 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.640701 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.641420 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.642347 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.642438 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.643200 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.643208 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.644077 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.644255 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.644771 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.644931 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.645777 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.646066 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.646809 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.646883 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.647525 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.647882 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.648235 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.648955 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.649254 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.650386 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.650463 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.651208 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.651617 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.652754 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.653957 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.655198 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.655588 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.657209 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.658370 4086304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.658836 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.660460 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.662435 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.664409 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.666636 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.666907 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.667248 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.667927 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.668627 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.669221 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.669422 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.670154 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.670800 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.671557 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.675353 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.677003 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.678944 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.681367 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.683462 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.692026 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.692535 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.693021 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.693520 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.693696 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.694023 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.694446 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.694546 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.695176 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.695283 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.695675 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.696123 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.696229 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.696710 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.696930 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.697262 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.697697 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.697888 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.698479 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.698578 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.699431 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.699435 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.700593 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.701400 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.702185 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.703015 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.703220 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.703903 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.704743 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.704929 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.706088 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.706926 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.707530 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.709335 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.710291 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.711423 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.718000 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.718470 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.718936 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.719399 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.719866 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.719890 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.720560 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.720577 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.721230 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.721240 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.721928 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.721938 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.722664 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.722675 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.723363 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.723374 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.724098 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.724108 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.724836 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.724846 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.725593 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.725606 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.726203 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.726311 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.726790 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.726966 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.727402 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.727622 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.728052 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.728737 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.728912 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.729918 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.730138 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.730752 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.731549 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.732371 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.733265 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.734085 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.735434 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.735748 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.736473 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.736883 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.737201 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.737862 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.738490 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.739148 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.739772 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.739867 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.740502 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.741161 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.741833 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.742389 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.743068 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.743664 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.744262 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.744903 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.745546 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.746831 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.747578 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.748278 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.748287 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.748758 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.749246 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.749420 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.749730 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.750253 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.750539 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.750810 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.751535 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.751545 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.752089 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.752644 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.753353 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.753365 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.753936 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.754509 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.755038 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.755149 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.755691 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.756353 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.756622 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.757547 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.758311 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.758772 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.764407 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.765139 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.765777 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.766438 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.767067 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.767729 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.768370 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.769014 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.769669 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.770340 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.770665 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.770910 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.771200 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.771705 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.771804 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.772531 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.772540 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.773202 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.773298 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.773786 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.773958 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.774406 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.774624 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.775107 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.775872 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.775963 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.776909 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.777248 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.778363 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.779188 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.779489 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.780247 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.780920 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.781848 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.782505 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.783436 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.784143 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.785030 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.786113 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.786706 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.791367 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.792316 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.792758 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.794062 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.794675 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.795318 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.796021 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.797030 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.798046 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.798834 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.801232 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.801805 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.801898 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.802410 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.802978 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.803527 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.804094 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.804703 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.805038 4086296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.805408 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.806130 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.807168 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.809429 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.811024 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.812605 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.814234 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.816223 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.821448 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.822393 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.822878 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.824139 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.824762 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.825405 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.826108 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.827114 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.828135 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.828933 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.831740 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513545.834940 4086298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.2241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 22:39:09.026872: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-09 22:39:09.027022: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-09 22:39:09.027176: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "W0000 00:00:1728513551.504598 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.504676 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.504826 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.505572 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.505613 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.505686 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.506490 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.506490 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.506535 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.507348 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.507478 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.507562 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.508068 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.508294 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.508324 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.508676 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.509113 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.509126 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.509352 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.509966 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.510058 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.510176 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.510819 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.511003 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.511017 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.511478 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.511817 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.511898 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.512129 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.512544 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.517003 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.517240 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.517308 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.517801 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.518081 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.518221 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.518483 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.518819 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.518985 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.519233 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.519661 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.519860 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.520133 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.520570 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.520917 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.520927 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.521259 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.521721 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.521925 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.522091 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.522469 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.522769 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.522978 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.523296 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.523580 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.523808 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.524121 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.524430 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.524702 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.524995 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.525271 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.525519 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.525820 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.526117 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.526380 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.526707 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.527656 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.528072 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.528311 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.528446 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.528665 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.528955 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.529105 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.529288 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.529691 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.529826 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.530022 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.530590 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.530808 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.530930 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.531395 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.531969 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.532092 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.532491 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.532764 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.532879 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.533174 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.533603 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.533862 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.534044 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.534404 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.534764 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.535014 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.535201 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.535500 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.535734 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.536094 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.536420 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.537359 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.537795 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.538315 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.538405 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.539376 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.540015 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.540230 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.540407 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.541065 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.541469 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.541833 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.542139 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.542970 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.543049 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.543524 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.544035 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.545369 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.562121 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.562551 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.562647 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.563179 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.563248 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.563689 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.563779 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.563796 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.564431 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.564452 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.564468 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.565057 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.565162 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.565244 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.565650 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.565823 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.565841 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.566226 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.566335 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.566667 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.567167 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.567243 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.567594 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.568511 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.568852 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.569314 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.570217 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.570824 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.571326 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.572194 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.572841 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.573355 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.574210 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.574516 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.575063 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.575892 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.576388 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.576958 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.577764 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.578216 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.578809 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.579594 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.612240 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.612655 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.613100 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.613488 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.613668 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.613969 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.614107 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.614227 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.614422 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.614644 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.614913 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.615002 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.615173 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.615588 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.615804 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.615815 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.616138 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.616534 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.616561 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.616728 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.617402 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.617420 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.617484 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.618167 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.618202 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.618228 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.618985 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.619003 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.619082 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.619798 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.619818 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.619896 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.620532 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.620570 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.620679 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.621215 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.621355 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.621457 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.621899 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.622064 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.622174 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.622476 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.622870 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.622951 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.623137 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.623495 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.623764 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.623938 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.624154 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.624411 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.624842 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.625026 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.625127 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.625722 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.626269 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.626281 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.627409 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.627427 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.627530 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.628676 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.629268 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.629277 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.630537 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.630639 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.635935 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.636464 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.636935 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.637452 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.637688 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.637914 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.638190 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.638188 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.638435 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.638821 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.638958 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.639069 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.639519 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.639652 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.639758 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.640014 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.640342 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.640424 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.640593 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.640825 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.641176 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.641274 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.641458 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.641727 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.642027 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.642213 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.642306 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.642826 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.642999 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.643094 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.643533 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.643724 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.644320 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.644427 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.645014 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.645090 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.645762 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.646484 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.646943 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.647839 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.648407 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.648798 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.649791 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.650258 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.651662 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.652465 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.653946 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.655405 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.656147 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.657676 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.658526 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.659179 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.660071 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.660943 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.661606 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.662494 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.664030 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.728684 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.729212 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.729747 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.730381 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.730448 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.730897 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.731064 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.731434 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.731620 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.731980 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.732175 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.732571 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.732910 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.733068 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.733167 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.733475 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.733811 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.733908 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.734084 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.734625 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.734833 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.734846 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.735477 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.735685 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.735695 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.736313 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.736435 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.736519 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.737242 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.737430 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.737619 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.737863 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.738335 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.738629 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.738743 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.739265 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.739399 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.739587 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.740243 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.740338 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.740519 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.740934 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.741468 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.741507 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.741714 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.742605 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.742724 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.742803 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.743810 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.743828 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.744010 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.744865 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.744966 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.745473 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.745840 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.746420 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.746822 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.747436 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.748357 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.748459 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.749492 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.750381 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.750555 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.752469 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.758236 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.758939 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.759358 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.759664 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.760053 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.760407 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.760722 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.761066 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.761115 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.761479 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.761916 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.761986 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.762252 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.762632 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.762838 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.763016 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.763395 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.763836 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.763851 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.764179 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.764524 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.764734 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.764915 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.765268 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.765567 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.765739 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.766636 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.766676 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.766748 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.767525 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.767654 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.767828 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.768713 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.768945 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.769021 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.769651 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.769968 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.770732 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.770934 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.772132 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.772318 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.773391 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.774119 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.774714 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.775882 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.776133 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.777705 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.777948 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.779364 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.779538 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.781191 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.782911 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.783711 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.785666 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.785687 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.790141 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.790810 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.792854 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.793625 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.798041 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.800144 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.802454 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.802738 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.803744 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.804774 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.804853 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.805934 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.806866 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.808050 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.809014 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.810178 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.811218 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.812173 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.813247 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.814352 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.820437 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.825774 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.832598 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.839210 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.846268 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.853441 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.867514 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.937498 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.938244 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.938982 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.939674 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.940425 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.941223 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.941997 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.942058 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.942922 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.943008 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.943672 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.943911 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.944385 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.944941 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.945171 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.945985 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.946084 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.947107 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.947118 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.948013 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.948121 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.948940 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.949305 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.949981 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.950559 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.950926 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.952114 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.952126 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.953058 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.953563 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.954245 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.955103 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.955536 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.956864 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.957753 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.958310 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.959842 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.962216 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.962527 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.965721 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.967022 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.970552 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.975331 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.976336 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.977303 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.978375 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.979308 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.980149 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.980487 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.981171 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.981464 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.982158 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.982639 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.983249 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.983698 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.984195 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.984660 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.985402 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.985743 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.986378 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.986854 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.987559 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.988617 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.989577 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.990653 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.991766 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.992946 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.997882 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513551.998256 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.003257 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.005077 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.010131 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.011704 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.016796 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.018870 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.024033 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.026130 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.031397 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.040072 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.045581 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.137161 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.138255 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.139373 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.140417 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.141565 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.142811 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.144015 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.145225 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.146642 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.148293 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.149769 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.151297 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.152802 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.154763 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.156935 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.159210 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.161677 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.164770 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.167468 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.172415 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.180354 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.193229 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.194900 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.196599 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.198436 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.200086 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.202081 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.203694 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.205773 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.207350 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.208938 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.210781 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.212683 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.223831 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.234360 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.247998 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.261182 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.275008 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.289341 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.310717 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.311819 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.312930 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.313977 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.315124 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.316366 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.317575 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.318140 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.318803 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.320429 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.320455 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.321587 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.322102 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.322734 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.323593 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.323800 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.324979 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.325161 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.326248 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.326677 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.327471 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.328887 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.328902 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.330344 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.331085 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.332030 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.333490 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.333596 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.335129 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.335983 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.336658 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.338884 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.338895 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.341076 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.343378 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.343822 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.345877 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.348620 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.351764 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.353588 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.361576 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.364572 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.366223 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.367923 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.369757 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.371383 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.373363 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.374413 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.374958 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.376088 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.377021 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.377809 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.378593 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.379659 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.380175 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.381314 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.382019 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.383328 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.383927 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.384953 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.387032 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.388606 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.390198 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.392040 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.393953 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.394841 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.405080 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.405249 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.415643 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.418635 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.429277 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.431630 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.442443 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.445573 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.456506 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.459824 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.471105 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.488566 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.499989 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.855105 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.856904 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.858686 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.860463 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.862371 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.864325 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.866286 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.868336 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.870476 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.872855 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.875324 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.877829 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.880497 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.884204 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.887848 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.891616 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.896281 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.901751 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.906918 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.926792 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.929652 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.932532 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.936204 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.939153 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.942039 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.944803 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.948140 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.951921 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.954742 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.958068 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.961587 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513552.983722 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.004993 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.031887 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.032030 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.033816 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.035577 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.037345 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.039265 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.041215 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.043184 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.044623 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.045254 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.046433 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.047396 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.048223 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.049794 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.050023 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.051960 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.052291 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.053935 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.054847 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.055930 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.057691 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.057691 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.058023 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.060194 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.061382 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.062607 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.065263 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.065276 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.067814 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.069072 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.070500 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.073733 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.074224 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.077870 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.078698 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.081635 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.082686 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.086288 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.091270 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.098227 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.101027 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.103835 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.107414 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.109291 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.110351 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.110876 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.113190 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.113709 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.115907 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.116553 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.119163 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.120171 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.122882 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.123135 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.125672 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.125997 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.128732 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.129042 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.132023 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.132573 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.135779 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.138557 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.141831 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.145255 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.154406 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.167466 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.171570 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.175433 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.188717 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.202212 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.215672 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.227832 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.241598 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.253099 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.266982 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.279696 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.294521 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.341387 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513553.356123 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.247339 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.250392 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.253486 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.256601 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.259947 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.263387 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.266846 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.270509 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.274339 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.278749 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.283412 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.288126 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.293168 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.300240 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.307463 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.314890 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.323947 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.334513 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.344265 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.377381 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.378975 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.380559 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.382133 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.383644 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.385575 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.387313 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.388803 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.390813 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.392294 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.394104 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.396003 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.407003 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.421078 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.427593 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.430651 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.433727 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.434636 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.436850 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.440217 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.443664 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.445663 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.446710 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.447167 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.449790 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.450859 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.452896 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.454782 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.456039 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.458674 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.459228 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.459451 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.462923 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.463972 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.466429 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.468775 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.470147 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.471802 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.473876 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.474063 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.478507 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.480929 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.483281 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.488118 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.488297 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.493253 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.495810 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.498997 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.500320 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.504889 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.507603 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.514587 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.515093 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.524114 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.533796 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.547438 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.549005 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.550578 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.552126 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.553639 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.555554 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.557288 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.558748 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.560885 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.562381 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.564125 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.565949 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.566703 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.568291 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.569874 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.571431 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.572945 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.574881 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.576595 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.576689 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.578170 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.580180 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.581669 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.583426 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.585267 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.590498 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.595783 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.603795 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.609717 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.614723 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.623171 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.627716 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.634206 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.641015 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.647377 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.660920 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.669491 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513554.689673 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.014581 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.016307 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.017917 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.019513 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.021290 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.023066 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.024994 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.026772 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.028638 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.030911 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.033210 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.035170 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.037685 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.041347 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.052695 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.056123 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.059592 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.064077 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.068966 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.079895 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.080588 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.081199 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.081938 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.082667 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.083444 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.084212 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.087760 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.092132 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.095850 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.099421 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.103038 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.106393 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.113275 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.188967 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.190665 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.192262 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.193831 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.195608 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.197379 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.199287 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.201032 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.202905 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.205190 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.207505 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.209485 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.210848 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.211994 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.212577 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.214178 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.215783 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.215884 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.217673 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.219454 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.221408 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.223167 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.225062 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.226987 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.227396 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.229871 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.230600 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.232042 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.234308 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.234435 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.234745 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.235128 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.235939 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.236729 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.237422 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.238266 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.238610 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.239219 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.239337 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.240130 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.240924 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.241776 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.242582 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.243448 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.244502 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.245433 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.246368 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.247374 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.248399 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.249665 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.249872 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.250018 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.250716 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.250947 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.251335 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.252070 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.252373 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.252808 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.253318 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.253594 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.254366 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.254835 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.256819 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.257859 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.258110 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.261343 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.261910 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.262144 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.265729 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.269225 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.271909 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.272822 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.272911 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.273447 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.274190 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.274920 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.275694 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.276253 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.276479 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.278797 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.279174 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.279518 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.279892 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.280111 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.280350 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.280757 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.281910 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.282373 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.282885 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.283056 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.283678 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.284566 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.284640 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.285572 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.286487 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.287657 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.288212 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.289219 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.291724 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.295278 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.296452 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.296767 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.297083 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.297400 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.297727 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.298054 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.298383 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.298782 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.298862 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.299204 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.299562 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.299906 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.300278 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.300632 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.301003 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.301413 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.301770 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.302174 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.302602 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.303078 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.304417 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.305007 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.305642 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.306789 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.307513 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.308665 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.319435 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.319739 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.320016 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.320298 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.320827 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.321413 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.321996 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.322662 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.323313 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.324558 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.326179 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.327849 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.328788 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.329054 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.329320 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.329595 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.329860 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.330136 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.330423 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.330713 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.331020 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.331344 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.331627 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.332003 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.332393 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.332778 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.333187 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.333635 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.334056 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.334567 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.335126 4086306 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.403250 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.403886 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.404523 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.405130 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.405715 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.406384 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.407076 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.407701 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.408311 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.408974 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.409632 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.410314 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.411071 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.411827 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.412731 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.413751 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.414782 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.416003 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.417267 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.419700 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.422932 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.426799 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.426920 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.427563 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.428200 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.428786 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.429379 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.430054 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.430744 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.431370 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.431987 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.432653 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.433310 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.433992 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.434754 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.435514 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.436420 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.437450 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.438481 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.439696 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.440963 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.443242 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.443445 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.443661 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.443989 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.444313 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.444676 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.445142 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.445617 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.446392 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.446707 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.447191 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.448103 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.449007 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.450169 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.450504 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.451723 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.452825 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.459974 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.460286 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.460589 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.461037 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.461386 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.461710 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.462025 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.462370 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.462701 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.463059 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.463385 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.463755 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.464118 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.464464 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.464814 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.465234 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.465640 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.466121 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.466480 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.467097 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.467203 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.467484 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.467808 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.468129 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.468469 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.468570 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.469035 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.469503 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.469811 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.470284 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.471075 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.471579 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.472013 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.472927 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.474094 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.475639 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.476737 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.482075 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.482368 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.482645 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.482923 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.483451 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.484023 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.484117 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.484352 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.484892 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.484904 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.485220 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.485744 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.485750 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.486081 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.486604 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.486613 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.486957 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.487285 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.487652 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.487986 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.488097 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.488467 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.488836 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.489182 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.489669 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.489770 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.490096 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.490493 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.490964 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.491428 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.491525 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.492157 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.492466 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.492727 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.492993 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.493401 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.493503 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.493672 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.493951 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.494236 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.494527 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.495069 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.495076 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.495391 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.495678 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.496047 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.496430 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.496957 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.497063 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.497381 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.497829 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.498249 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.498757 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.499327 4086289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.507532 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.507841 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.508119 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.508401 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.508931 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.509520 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.510103 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.510761 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.511409 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.512650 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.514253 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.515920 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.516849 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.517108 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.517376 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.517654 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.517917 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.518200 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.518498 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.518788 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.519097 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.519412 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.519699 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.520073 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.520462 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.520853 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.521256 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.521708 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.522130 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.522636 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728513555.523198 4086288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 169ms/step - loss: 0.2221 - val_loss: 0.2817 - learning_rate: 0.0010\n",
      "Epoch 2/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 22:39:15.753824: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0405"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 22:39:20.907723: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - loss: 0.0405 - val_loss: 0.2827 - learning_rate: 0.0010\n",
      "Epoch 3/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0338 - val_loss: 0.2725 - learning_rate: 0.0010\n",
      "Epoch 4/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 22:39:27.212478: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 0.0314 - val_loss: 0.2666 - learning_rate: 0.0010\n",
      "Epoch 5/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.0300 - val_loss: 0.2551 - learning_rate: 0.0010\n",
      "Epoch 6/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 22:39:42.974978: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0290 - val_loss: 0.2406 - learning_rate: 0.0010\n",
      "Epoch 7/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 0.0282 - val_loss: 0.2158 - learning_rate: 0.0010\n",
      "Epoch 8/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 0.0271 - val_loss: 0.1856 - learning_rate: 0.0010\n",
      "Epoch 9/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0265 - val_loss: 0.1514 - learning_rate: 0.0010\n",
      "Epoch 10/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0258 - val_loss: 0.1145 - learning_rate: 0.0010\n",
      "Epoch 11/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0254 - val_loss: 0.1120 - learning_rate: 0.0010\n",
      "Epoch 12/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 22:40:10.895170: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 0.0248 - val_loss: 0.0697 - learning_rate: 0.0010\n",
      "Epoch 13/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.0245 - val_loss: 0.0676 - learning_rate: 0.0010\n",
      "Epoch 14/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0239 - val_loss: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 15/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 0.0236 - val_loss: 0.0521 - learning_rate: 0.0010\n",
      "Epoch 16/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 0.0233 - val_loss: 1.3909 - learning_rate: 0.0010\n",
      "Epoch 17/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 96ms/step - loss: 0.0229 - val_loss: 0.0519 - learning_rate: 0.0010\n",
      "Epoch 18/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - loss: 0.0225 - val_loss: 0.0412 - learning_rate: 0.0010\n",
      "Epoch 19/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.0221 - val_loss: 0.1151 - learning_rate: 0.0010\n",
      "Epoch 20/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0219 - val_loss: 0.0437 - learning_rate: 0.0010\n",
      "Epoch 21/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0217 - val_loss: 0.1753 - learning_rate: 0.0010\n",
      "Epoch 22/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0214"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 22:41:10.086665: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 0.0214 - val_loss: 0.0381 - learning_rate: 0.0010\n",
      "Epoch 23/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 0.0212 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 24/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0209 - val_loss: 0.3450 - learning_rate: 0.0010\n",
      "Epoch 25/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0207 - val_loss: 0.0236 - learning_rate: 0.0010\n",
      "Epoch 26/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0204 - val_loss: 0.0276 - learning_rate: 0.0010\n",
      "Epoch 27/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0203 - val_loss: 0.2461 - learning_rate: 0.0010\n",
      "Epoch 28/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.0201 - val_loss: 0.0270 - learning_rate: 0.0010\n",
      "Epoch 29/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.0200 - val_loss: 0.0385 - learning_rate: 0.0010\n",
      "Epoch 30/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 98ms/step - loss: 0.0196 - val_loss: 0.0240 - learning_rate: 0.0010\n",
      "Epoch 31/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0195 - val_loss: 1.6248 - learning_rate: 0.0010\n",
      "Epoch 32/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 0.0192 - val_loss: 0.0362 - learning_rate: 0.0010\n",
      "Epoch 33/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0190 - val_loss: 0.0272 - learning_rate: 0.0010\n",
      "Epoch 34/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0189 - val_loss: 0.0336 - learning_rate: 0.0010\n",
      "Epoch 35/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0187\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 0.0187 - val_loss: 0.0279 - learning_rate: 0.0010\n",
      "Epoch 36/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0183 - val_loss: 0.0310 - learning_rate: 9.0000e-04\n",
      "Epoch 37/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 98ms/step - loss: 0.0181 - val_loss: 0.0247 - learning_rate: 9.0000e-04\n",
      "Epoch 38/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0179 - val_loss: 0.0420 - learning_rate: 9.0000e-04\n",
      "Epoch 39/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0178 - val_loss: 0.0220 - learning_rate: 9.0000e-04\n",
      "Epoch 40/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 109ms/step - loss: 0.0176 - val_loss: 0.0274 - learning_rate: 9.0000e-04\n",
      "Epoch 41/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.0175 - val_loss: 0.2837 - learning_rate: 9.0000e-04\n",
      "Epoch 42/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0173 - val_loss: 0.0287 - learning_rate: 9.0000e-04\n",
      "Epoch 43/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0171 - val_loss: 0.0321 - learning_rate: 9.0000e-04\n",
      "Epoch 44/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 22:43:07.650241: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0170 - val_loss: 0.0229 - learning_rate: 9.0000e-04\n",
      "Epoch 45/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.0167 - val_loss: 0.0274 - learning_rate: 9.0000e-04\n",
      "Epoch 46/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 0.0166 - val_loss: 0.0268 - learning_rate: 9.0000e-04\n",
      "Epoch 47/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0163 - val_loss: 0.0313 - learning_rate: 9.0000e-04\n",
      "Epoch 48/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0164 - val_loss: 0.0236 - learning_rate: 9.0000e-04\n",
      "Epoch 49/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0160\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.0160 - val_loss: 0.0293 - learning_rate: 9.0000e-04\n",
      "Epoch 50/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0158 - val_loss: 0.0256 - learning_rate: 8.1000e-04\n",
      "Epoch 51/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - loss: 0.0154 - val_loss: 0.0419 - learning_rate: 8.1000e-04\n",
      "Epoch 52/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 0.0152 - val_loss: 0.0277 - learning_rate: 8.1000e-04\n",
      "Epoch 53/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0149 - val_loss: 0.0268 - learning_rate: 8.1000e-04\n",
      "Epoch 54/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 0.0149 - val_loss: 0.0507 - learning_rate: 8.1000e-04\n",
      "Epoch 55/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0148 - val_loss: 0.0507 - learning_rate: 8.1000e-04\n",
      "Epoch 56/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 0.0145 - val_loss: 0.0391 - learning_rate: 8.1000e-04\n",
      "Epoch 57/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0144 - val_loss: 0.0234 - learning_rate: 8.1000e-04\n",
      "Epoch 58/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0142 - val_loss: 0.1130 - learning_rate: 8.1000e-04\n",
      "Epoch 59/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0139\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0139 - val_loss: 0.0236 - learning_rate: 8.1000e-04\n",
      "Epoch 60/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 98ms/step - loss: 0.0135 - val_loss: 0.0211 - learning_rate: 7.2900e-04\n",
      "Epoch 61/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 0.0132 - val_loss: 0.0366 - learning_rate: 7.2900e-04\n",
      "Epoch 62/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0129 - val_loss: 0.0385 - learning_rate: 7.2900e-04\n",
      "Epoch 63/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0128 - val_loss: 0.0303 - learning_rate: 7.2900e-04\n",
      "Epoch 64/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 109ms/step - loss: 0.0126 - val_loss: 0.0237 - learning_rate: 7.2900e-04\n",
      "Epoch 65/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - loss: 0.0123 - val_loss: 0.0260 - learning_rate: 7.2900e-04\n",
      "Epoch 66/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0122 - val_loss: 0.0315 - learning_rate: 7.2900e-04\n",
      "Epoch 67/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.0119 - val_loss: 0.0369 - learning_rate: 7.2900e-04\n",
      "Epoch 68/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0118 - val_loss: 0.0291 - learning_rate: 7.2900e-04\n",
      "Epoch 69/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0115 - val_loss: 0.0321 - learning_rate: 7.2900e-04\n",
      "Epoch 70/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0112\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0112 - val_loss: 0.0247 - learning_rate: 7.2900e-04\n",
      "Epoch 71/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 0.0109 - val_loss: 0.0240 - learning_rate: 6.5610e-04\n",
      "Epoch 72/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0106 - val_loss: 0.0258 - learning_rate: 6.5610e-04\n",
      "Epoch 73/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 108ms/step - loss: 0.0101 - val_loss: 0.0253 - learning_rate: 6.5610e-04\n",
      "Epoch 74/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - loss: 0.0099 - val_loss: 0.0257 - learning_rate: 6.5610e-04\n",
      "Epoch 75/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0096 - val_loss: 0.0234 - learning_rate: 6.5610e-04\n",
      "Epoch 76/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0096 - val_loss: 0.0388 - learning_rate: 6.5610e-04\n",
      "Epoch 77/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0092 - val_loss: 0.0410 - learning_rate: 6.5610e-04\n",
      "Epoch 78/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0090 - val_loss: 0.0240 - learning_rate: 6.5610e-04\n",
      "Epoch 79/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 0.0089 - val_loss: 0.0242 - learning_rate: 6.5610e-04\n",
      "Epoch 80/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0085\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0086 - val_loss: 0.0295 - learning_rate: 6.5610e-04\n",
      "Epoch 81/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0083 - val_loss: 0.0298 - learning_rate: 5.9049e-04\n",
      "Epoch 82/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0077 - val_loss: 0.0263 - learning_rate: 5.9049e-04\n",
      "Epoch 83/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0077 - val_loss: 0.0282 - learning_rate: 5.9049e-04\n",
      "Epoch 84/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0074 - val_loss: 0.0270 - learning_rate: 5.9049e-04\n",
      "Epoch 85/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0071 - val_loss: 0.0237 - learning_rate: 5.9049e-04\n",
      "Epoch 86/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0070"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 22:47:00.833507: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 0.0071 - val_loss: 0.0268 - learning_rate: 5.9049e-04\n",
      "Epoch 87/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0068 - val_loss: 0.0366 - learning_rate: 5.9049e-04\n",
      "Epoch 88/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 0.0066 - val_loss: 0.0256 - learning_rate: 5.9049e-04\n",
      "Epoch 89/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 0.0065 - val_loss: 0.0251 - learning_rate: 5.9049e-04\n",
      "Epoch 90/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0063\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0064 - val_loss: 0.0243 - learning_rate: 5.9049e-04\n",
      "Epoch 91/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0060 - val_loss: 0.0245 - learning_rate: 5.3144e-04\n",
      "Epoch 92/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0057 - val_loss: 0.0325 - learning_rate: 5.3144e-04\n",
      "Epoch 93/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 0.0055 - val_loss: 0.0288 - learning_rate: 5.3144e-04\n",
      "Epoch 94/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0054 - val_loss: 0.0271 - learning_rate: 5.3144e-04\n",
      "Epoch 95/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0052 - val_loss: 0.0287 - learning_rate: 5.3144e-04\n",
      "Epoch 96/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0050 - val_loss: 0.0257 - learning_rate: 5.3144e-04\n",
      "Epoch 97/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 0.0049 - val_loss: 0.0354 - learning_rate: 5.3144e-04\n",
      "Epoch 98/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0048 - val_loss: 0.0259 - learning_rate: 5.3144e-04\n",
      "Epoch 99/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0047 - val_loss: 0.0257 - learning_rate: 5.3144e-04\n",
      "Epoch 100/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0046\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0046 - val_loss: 0.0324 - learning_rate: 5.3144e-04\n",
      "Epoch 101/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 0.0044 - val_loss: 0.0243 - learning_rate: 4.7830e-04\n",
      "Epoch 102/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0041 - val_loss: 0.0240 - learning_rate: 4.7830e-04\n",
      "Epoch 103/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0040 - val_loss: 0.0322 - learning_rate: 4.7830e-04\n",
      "Epoch 104/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0039 - val_loss: 0.0333 - learning_rate: 4.7830e-04\n",
      "Epoch 105/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0039 - val_loss: 0.0272 - learning_rate: 4.7830e-04\n",
      "Epoch 106/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0038 - val_loss: 0.0247 - learning_rate: 4.7830e-04\n",
      "Epoch 107/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 0.0036 - val_loss: 0.0274 - learning_rate: 4.7830e-04\n",
      "Epoch 108/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 0.0036 - val_loss: 0.0273 - learning_rate: 4.7830e-04\n",
      "Epoch 109/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.0034 - val_loss: 0.0246 - learning_rate: 4.7830e-04\n",
      "Epoch 110/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0034\n",
      "Epoch 110: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0035 - val_loss: 0.0263 - learning_rate: 4.7830e-04\n",
      "Epoch 111/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0033 - val_loss: 0.0258 - learning_rate: 4.3047e-04\n",
      "Epoch 112/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0031 - val_loss: 0.0261 - learning_rate: 4.3047e-04\n",
      "Epoch 113/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 0.0030 - val_loss: 0.0259 - learning_rate: 4.3047e-04\n",
      "Epoch 114/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0030 - val_loss: 0.0256 - learning_rate: 4.3047e-04\n",
      "Epoch 115/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 0.0029 - val_loss: 0.0266 - learning_rate: 4.3047e-04\n",
      "Epoch 116/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0029 - val_loss: 0.0261 - learning_rate: 4.3047e-04\n",
      "Epoch 117/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0028 - val_loss: 0.0292 - learning_rate: 4.3047e-04\n",
      "Epoch 118/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0028 - val_loss: 0.0256 - learning_rate: 4.3047e-04\n",
      "Epoch 119/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0027 - val_loss: 0.0254 - learning_rate: 4.3047e-04\n",
      "Epoch 120/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0027\n",
      "Epoch 120: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0027 - val_loss: 0.0262 - learning_rate: 4.3047e-04\n",
      "Epoch 121/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0026 - val_loss: 0.0272 - learning_rate: 3.8742e-04\n",
      "Epoch 122/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 0.0025 - val_loss: 0.0251 - learning_rate: 3.8742e-04\n",
      "Epoch 123/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0024 - val_loss: 0.0290 - learning_rate: 3.8742e-04\n",
      "Epoch 124/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 0.0023 - val_loss: 0.0266 - learning_rate: 3.8742e-04\n",
      "Epoch 125/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0023 - val_loss: 0.0250 - learning_rate: 3.8742e-04\n",
      "Epoch 126/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0023 - val_loss: 0.0277 - learning_rate: 3.8742e-04\n",
      "Epoch 127/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0023 - val_loss: 0.0297 - learning_rate: 3.8742e-04\n",
      "Epoch 128/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0023 - val_loss: 0.0256 - learning_rate: 3.8742e-04\n",
      "Epoch 129/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0022 - val_loss: 0.0244 - learning_rate: 3.8742e-04\n",
      "Epoch 130/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0022\n",
      "Epoch 130: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0022 - val_loss: 0.0277 - learning_rate: 3.8742e-04\n",
      "Epoch 131/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 98ms/step - loss: 0.0021 - val_loss: 0.0256 - learning_rate: 3.4868e-04\n",
      "Epoch 132/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0020 - val_loss: 0.0254 - learning_rate: 3.4868e-04\n",
      "Epoch 133/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 0.0020 - val_loss: 0.0271 - learning_rate: 3.4868e-04\n",
      "Epoch 134/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 0.0019 - val_loss: 0.0268 - learning_rate: 3.4868e-04\n",
      "Epoch 135/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0019 - val_loss: 0.0289 - learning_rate: 3.4868e-04\n",
      "Epoch 136/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 98ms/step - loss: 0.0019 - val_loss: 0.0267 - learning_rate: 3.4868e-04\n",
      "Epoch 137/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0018 - val_loss: 0.0254 - learning_rate: 3.4868e-04\n",
      "Epoch 138/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0019 - val_loss: 0.0265 - learning_rate: 3.4868e-04\n",
      "Epoch 139/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.0018 - val_loss: 0.0259 - learning_rate: 3.4868e-04\n",
      "Epoch 140/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0018\n",
      "Epoch 140: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0018 - val_loss: 0.0258 - learning_rate: 3.4868e-04\n",
      "Epoch 141/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0018 - val_loss: 0.0273 - learning_rate: 3.1381e-04\n",
      "Epoch 142/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 0.0017 - val_loss: 0.0253 - learning_rate: 3.1381e-04\n",
      "Epoch 143/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0017 - val_loss: 0.0262 - learning_rate: 3.1381e-04\n",
      "Epoch 144/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0016 - val_loss: 0.0265 - learning_rate: 3.1381e-04\n",
      "Epoch 145/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - loss: 0.0016 - val_loss: 0.0267 - learning_rate: 3.1381e-04\n",
      "Epoch 146/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0016 - val_loss: 0.0341 - learning_rate: 3.1381e-04\n",
      "Epoch 147/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 0.0016 - val_loss: 0.0257 - learning_rate: 3.1381e-04\n",
      "Epoch 148/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0016 - val_loss: 0.0269 - learning_rate: 3.1381e-04\n",
      "Epoch 149/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0016 - val_loss: 0.0264 - learning_rate: 3.1381e-04\n",
      "Epoch 150/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0015\n",
      "Epoch 150: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0015 - val_loss: 0.0257 - learning_rate: 3.1381e-04\n",
      "Epoch 151/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0015 - val_loss: 0.0265 - learning_rate: 2.8243e-04\n",
      "Epoch 152/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 0.0015 - val_loss: 0.0294 - learning_rate: 2.8243e-04\n",
      "Epoch 153/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0014 - val_loss: 0.0248 - learning_rate: 2.8243e-04\n",
      "Epoch 154/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0014 - val_loss: 0.0273 - learning_rate: 2.8243e-04\n",
      "Epoch 155/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 0.0014 - val_loss: 0.0268 - learning_rate: 2.8243e-04\n",
      "Epoch 156/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0014 - val_loss: 0.0259 - learning_rate: 2.8243e-04\n",
      "Epoch 157/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0014 - val_loss: 0.0267 - learning_rate: 2.8243e-04\n",
      "Epoch 158/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 0.0014 - val_loss: 0.0258 - learning_rate: 2.8243e-04\n",
      "Epoch 159/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0014 - val_loss: 0.0254 - learning_rate: 2.8243e-04\n",
      "Epoch 160/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0013\n",
      "Epoch 160: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 0.0014 - val_loss: 0.0281 - learning_rate: 2.8243e-04\n",
      "Epoch 161/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0013 - val_loss: 0.0274 - learning_rate: 2.5419e-04\n",
      "Epoch 162/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0013 - val_loss: 0.0261 - learning_rate: 2.5419e-04\n",
      "Epoch 163/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.0013 - val_loss: 0.0253 - learning_rate: 2.5419e-04\n",
      "Epoch 164/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0012 - val_loss: 0.0261 - learning_rate: 2.5419e-04\n",
      "Epoch 165/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0012 - val_loss: 0.0262 - learning_rate: 2.5419e-04\n",
      "Epoch 166/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 97ms/step - loss: 0.0012 - val_loss: 0.0252 - learning_rate: 2.5419e-04\n",
      "Epoch 167/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 0.0012 - val_loss: 0.0275 - learning_rate: 2.5419e-04\n",
      "Epoch 168/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 0.0012 - val_loss: 0.0287 - learning_rate: 2.5419e-04\n",
      "Epoch 169/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 0.0012 - val_loss: 0.0262 - learning_rate: 2.5419e-04\n",
      "Epoch 170/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0012\n",
      "Epoch 170: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 97ms/step - loss: 0.0012 - val_loss: 0.0261 - learning_rate: 2.5419e-04\n",
      "Epoch 171/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 0.0012 - val_loss: 0.0253 - learning_rate: 2.2877e-04\n",
      "Epoch 172/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 22:54:48.877091: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0011 - val_loss: 0.0258 - learning_rate: 2.2877e-04\n",
      "Epoch 173/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0011 - val_loss: 0.0289 - learning_rate: 2.2877e-04\n",
      "Epoch 174/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0011 - val_loss: 0.0251 - learning_rate: 2.2877e-04\n",
      "Epoch 175/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0011 - val_loss: 0.0278 - learning_rate: 2.2877e-04\n",
      "Epoch 176/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 96ms/step - loss: 0.0011 - val_loss: 0.0257 - learning_rate: 2.2877e-04\n",
      "Epoch 177/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0010 - val_loss: 0.0255 - learning_rate: 2.2877e-04\n",
      "Epoch 178/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 99ms/step - loss: 0.0011 - val_loss: 0.0272 - learning_rate: 2.2877e-04\n",
      "Epoch 179/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0011 - val_loss: 0.0270 - learning_rate: 2.2877e-04\n",
      "Epoch 180/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0011\n",
      "Epoch 180: ReduceLROnPlateau reducing learning rate to 0.00020589114428730683.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0011 - val_loss: 0.0276 - learning_rate: 2.2877e-04\n",
      "Epoch 181/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - loss: 0.0010 - val_loss: 0.0255 - learning_rate: 2.0589e-04\n",
      "Epoch 182/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 9.8984e-04 - val_loss: 0.0270 - learning_rate: 2.0589e-04\n",
      "Epoch 183/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 9.7331e-04 - val_loss: 0.0264 - learning_rate: 2.0589e-04\n",
      "Epoch 184/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 9.6066e-04 - val_loss: 0.0262 - learning_rate: 2.0589e-04\n",
      "Epoch 185/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 9.6121e-04 - val_loss: 0.0257 - learning_rate: 2.0589e-04\n",
      "Epoch 186/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 9.5485e-04 - val_loss: 0.0255 - learning_rate: 2.0589e-04\n",
      "Epoch 187/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 9.4884e-04 - val_loss: 0.0262 - learning_rate: 2.0589e-04\n",
      "Epoch 188/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 9.7240e-04 - val_loss: 0.0260 - learning_rate: 2.0589e-04\n",
      "Epoch 189/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 9.4977e-04 - val_loss: 0.0268 - learning_rate: 2.0589e-04\n",
      "Epoch 190/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 9.3537e-04\n",
      "Epoch 190: ReduceLROnPlateau reducing learning rate to 0.00018530203378759326.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 9.3870e-04 - val_loss: 0.0251 - learning_rate: 2.0589e-04\n",
      "Epoch 191/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 9.2137e-04 - val_loss: 0.0251 - learning_rate: 1.8530e-04\n",
      "Epoch 192/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 8.9878e-04 - val_loss: 0.0263 - learning_rate: 1.8530e-04\n",
      "Epoch 193/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 8.7616e-04 - val_loss: 0.0284 - learning_rate: 1.8530e-04\n",
      "Epoch 194/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 8.8178e-04 - val_loss: 0.0284 - learning_rate: 1.8530e-04\n",
      "Epoch 195/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 8.7515e-04 - val_loss: 0.0261 - learning_rate: 1.8530e-04\n",
      "Epoch 196/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 8.7366e-04 - val_loss: 0.0275 - learning_rate: 1.8530e-04\n",
      "Epoch 197/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 8.6751e-04 - val_loss: 0.0255 - learning_rate: 1.8530e-04\n",
      "Epoch 198/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - loss: 8.6361e-04 - val_loss: 0.0254 - learning_rate: 1.8530e-04\n",
      "Epoch 199/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 8.6612e-04 - val_loss: 0.0267 - learning_rate: 1.8530e-04\n",
      "Epoch 200/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8.5746e-04\n",
      "Epoch 200: ReduceLROnPlateau reducing learning rate to 0.00016677183302817866.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 8.6051e-04 - val_loss: 0.0259 - learning_rate: 1.8530e-04\n",
      "Epoch 201/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 8.4871e-04 - val_loss: 0.0260 - learning_rate: 1.6677e-04\n",
      "Epoch 202/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 8.2851e-04 - val_loss: 0.0259 - learning_rate: 1.6677e-04\n",
      "Epoch 203/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 8.0277e-04 - val_loss: 0.0256 - learning_rate: 1.6677e-04\n",
      "Epoch 204/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 7.9915e-04 - val_loss: 0.0255 - learning_rate: 1.6677e-04\n",
      "Epoch 205/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 7.8671e-04 - val_loss: 0.0261 - learning_rate: 1.6677e-04\n",
      "Epoch 206/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 7.8166e-04 - val_loss: 0.0254 - learning_rate: 1.6677e-04\n",
      "Epoch 207/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 7.7243e-04 - val_loss: 0.0261 - learning_rate: 1.6677e-04\n",
      "Epoch 208/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 7.7183e-04 - val_loss: 0.0256 - learning_rate: 1.6677e-04\n",
      "Epoch 209/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 7.8054e-04 - val_loss: 0.0265 - learning_rate: 1.6677e-04\n",
      "Epoch 210/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 7.8487e-04\n",
      "Epoch 210: ReduceLROnPlateau reducing learning rate to 0.00015009464841568844.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 7.8748e-04 - val_loss: 0.0255 - learning_rate: 1.6677e-04\n",
      "Epoch 211/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 7.6788e-04 - val_loss: 0.0260 - learning_rate: 1.5009e-04\n",
      "Epoch 212/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 105ms/step - loss: 7.4082e-04 - val_loss: 0.0258 - learning_rate: 1.5009e-04\n",
      "Epoch 213/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 7.2870e-04 - val_loss: 0.0265 - learning_rate: 1.5009e-04\n",
      "Epoch 214/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 7.3332e-04 - val_loss: 0.0255 - learning_rate: 1.5009e-04\n",
      "Epoch 215/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 7.1706e-04 - val_loss: 0.0262 - learning_rate: 1.5009e-04\n",
      "Epoch 216/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 7.0833e-04 - val_loss: 0.0260 - learning_rate: 1.5009e-04\n",
      "Epoch 217/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - loss: 7.1556e-04 - val_loss: 0.0255 - learning_rate: 1.5009e-04\n",
      "Epoch 218/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 7.0613e-04 - val_loss: 0.0262 - learning_rate: 1.5009e-04\n",
      "Epoch 219/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 7.1444e-04 - val_loss: 0.0261 - learning_rate: 1.5009e-04\n",
      "Epoch 220/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 7.0754e-04\n",
      "Epoch 220: ReduceLROnPlateau reducing learning rate to 0.0001350851875031367.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 7.1041e-04 - val_loss: 0.0260 - learning_rate: 1.5009e-04\n",
      "Epoch 221/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 6.9986e-04 - val_loss: 0.0256 - learning_rate: 1.3509e-04\n",
      "Epoch 222/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - loss: 6.7637e-04 - val_loss: 0.0258 - learning_rate: 1.3509e-04\n",
      "Epoch 223/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 6.7854e-04 - val_loss: 0.0252 - learning_rate: 1.3509e-04\n",
      "Epoch 224/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 6.7316e-04 - val_loss: 0.0263 - learning_rate: 1.3509e-04\n",
      "Epoch 225/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 6.5592e-04 - val_loss: 0.0267 - learning_rate: 1.3509e-04\n",
      "Epoch 226/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 6.6536e-04 - val_loss: 0.0261 - learning_rate: 1.3509e-04\n",
      "Epoch 227/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 6.6832e-04 - val_loss: 0.0258 - learning_rate: 1.3509e-04\n",
      "Epoch 228/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 6.6688e-04 - val_loss: 0.0260 - learning_rate: 1.3509e-04\n",
      "Epoch 229/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 6.5539e-04 - val_loss: 0.0268 - learning_rate: 1.3509e-04\n",
      "Epoch 230/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6.5057e-04\n",
      "Epoch 230: ReduceLROnPlateau reducing learning rate to 0.00012157666351413355.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 6.5303e-04 - val_loss: 0.0261 - learning_rate: 1.3509e-04\n",
      "Epoch 231/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 6.4557e-04 - val_loss: 0.0260 - learning_rate: 1.2158e-04\n",
      "Epoch 232/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 6.3239e-04 - val_loss: 0.0259 - learning_rate: 1.2158e-04\n",
      "Epoch 233/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 6.2044e-04 - val_loss: 0.0261 - learning_rate: 1.2158e-04\n",
      "Epoch 234/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 6.1276e-04 - val_loss: 0.0255 - learning_rate: 1.2158e-04\n",
      "Epoch 235/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 6.2002e-04 - val_loss: 0.0253 - learning_rate: 1.2158e-04\n",
      "Epoch 236/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 6.2058e-04 - val_loss: 0.0258 - learning_rate: 1.2158e-04\n",
      "Epoch 237/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 6.0725e-04 - val_loss: 0.0262 - learning_rate: 1.2158e-04\n",
      "Epoch 238/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 6.1478e-04 - val_loss: 0.0265 - learning_rate: 1.2158e-04\n",
      "Epoch 239/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 6.0668e-04 - val_loss: 0.0272 - learning_rate: 1.2158e-04\n",
      "Epoch 240/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6.0605e-04\n",
      "Epoch 240: ReduceLROnPlateau reducing learning rate to 0.00010941899454337544.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 6.0835e-04 - val_loss: 0.0256 - learning_rate: 1.2158e-04\n",
      "Epoch 241/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 6.0372e-04 - val_loss: 0.0256 - learning_rate: 1.0942e-04\n",
      "Epoch 242/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 5.8972e-04 - val_loss: 0.0261 - learning_rate: 1.0942e-04\n",
      "Epoch 243/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 5.8091e-04 - val_loss: 0.0256 - learning_rate: 1.0942e-04\n",
      "Epoch 244/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 5.8036e-04 - val_loss: 0.0262 - learning_rate: 1.0942e-04\n",
      "Epoch 245/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 5.8563e-04 - val_loss: 0.0260 - learning_rate: 1.0942e-04\n",
      "Epoch 246/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 5.8045e-04 - val_loss: 0.0256 - learning_rate: 1.0942e-04\n",
      "Epoch 247/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - loss: 5.7713e-04 - val_loss: 0.0261 - learning_rate: 1.0942e-04\n",
      "Epoch 248/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 5.7566e-04 - val_loss: 0.0259 - learning_rate: 1.0942e-04\n",
      "Epoch 249/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 5.8569e-04 - val_loss: 0.0261 - learning_rate: 1.0942e-04\n",
      "Epoch 250/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 5.7043e-04\n",
      "Epoch 250: ReduceLROnPlateau reducing learning rate to 9.847709443420172e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 5.7254e-04 - val_loss: 0.0255 - learning_rate: 1.0942e-04\n",
      "Epoch 251/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 5.6542e-04 - val_loss: 0.0257 - learning_rate: 9.8477e-05\n",
      "Epoch 252/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 5.6327e-04 - val_loss: 0.0257 - learning_rate: 9.8477e-05\n",
      "Epoch 253/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 5.5487e-04 - val_loss: 0.0257 - learning_rate: 9.8477e-05\n",
      "Epoch 254/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 5.4335e-04 - val_loss: 0.0256 - learning_rate: 9.8477e-05\n",
      "Epoch 255/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 5.3952e-04 - val_loss: 0.0263 - learning_rate: 9.8477e-05\n",
      "Epoch 256/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 5.4703e-04 - val_loss: 0.0253 - learning_rate: 9.8477e-05\n",
      "Epoch 257/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 5.3159e-04 - val_loss: 0.0262 - learning_rate: 9.8477e-05\n",
      "Epoch 258/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - loss: 5.3858e-04 - val_loss: 0.0260 - learning_rate: 9.8477e-05\n",
      "Epoch 259/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 5.3693e-04 - val_loss: 0.0255 - learning_rate: 9.8477e-05\n",
      "Epoch 260/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 5.3253e-04\n",
      "Epoch 260: ReduceLROnPlateau reducing learning rate to 8.862938630045391e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 5.3435e-04 - val_loss: 0.0256 - learning_rate: 9.8477e-05\n",
      "Epoch 261/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 5.3223e-04 - val_loss: 0.0257 - learning_rate: 8.8629e-05\n",
      "Epoch 262/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 5.1446e-04 - val_loss: 0.0252 - learning_rate: 8.8629e-05\n",
      "Epoch 263/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 5.1529e-04 - val_loss: 0.0254 - learning_rate: 8.8629e-05\n",
      "Epoch 264/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - loss: 5.1786e-04 - val_loss: 0.0249 - learning_rate: 8.8629e-05\n",
      "Epoch 265/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 5.1686e-04 - val_loss: 0.0262 - learning_rate: 8.8629e-05\n",
      "Epoch 266/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 5.0711e-04 - val_loss: 0.0263 - learning_rate: 8.8629e-05\n",
      "Epoch 267/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 5.0286e-04 - val_loss: 0.0262 - learning_rate: 8.8629e-05\n",
      "Epoch 268/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 5.1111e-04 - val_loss: 0.0263 - learning_rate: 8.8629e-05\n",
      "Epoch 269/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 4.9445e-04 - val_loss: 0.0259 - learning_rate: 8.8629e-05\n",
      "Epoch 270/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 4.9956e-04\n",
      "Epoch 270: ReduceLROnPlateau reducing learning rate to 7.976644701557234e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 5.0132e-04 - val_loss: 0.0259 - learning_rate: 8.8629e-05\n",
      "Epoch 271/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 4.8976e-04 - val_loss: 0.0253 - learning_rate: 7.9766e-05\n",
      "Epoch 272/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 4.8196e-04 - val_loss: 0.0261 - learning_rate: 7.9766e-05\n",
      "Epoch 273/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 4.7477e-04 - val_loss: 0.0256 - learning_rate: 7.9766e-05\n",
      "Epoch 274/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 4.7382e-04 - val_loss: 0.0255 - learning_rate: 7.9766e-05\n",
      "Epoch 275/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 4.8167e-04 - val_loss: 0.0259 - learning_rate: 7.9766e-05\n",
      "Epoch 276/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 4.8340e-04 - val_loss: 0.0255 - learning_rate: 7.9766e-05\n",
      "Epoch 277/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 4.8301e-04 - val_loss: 0.0255 - learning_rate: 7.9766e-05\n",
      "Epoch 278/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 4.8924e-04 - val_loss: 0.0268 - learning_rate: 7.9766e-05\n",
      "Epoch 279/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 4.7769e-04 - val_loss: 0.0265 - learning_rate: 7.9766e-05\n",
      "Epoch 280/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 4.7162e-04\n",
      "Epoch 280: ReduceLROnPlateau reducing learning rate to 7.178980231401511e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 4.7330e-04 - val_loss: 0.0261 - learning_rate: 7.9766e-05\n",
      "Epoch 281/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 4.7581e-04 - val_loss: 0.0255 - learning_rate: 7.1790e-05\n",
      "Epoch 282/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 4.7114e-04 - val_loss: 0.0255 - learning_rate: 7.1790e-05\n",
      "Epoch 283/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 4.5735e-04 - val_loss: 0.0256 - learning_rate: 7.1790e-05\n",
      "Epoch 284/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 4.5952e-04 - val_loss: 0.0262 - learning_rate: 7.1790e-05\n",
      "Epoch 285/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 4.7127e-04 - val_loss: 0.0259 - learning_rate: 7.1790e-05\n",
      "Epoch 286/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 4.6132e-04 - val_loss: 0.0266 - learning_rate: 7.1790e-05\n",
      "Epoch 287/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 4.5564e-04 - val_loss: 0.0256 - learning_rate: 7.1790e-05\n",
      "Epoch 288/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 4.5434e-04 - val_loss: 0.0265 - learning_rate: 7.1790e-05\n",
      "Epoch 289/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 4.6089e-04 - val_loss: 0.0259 - learning_rate: 7.1790e-05\n",
      "Epoch 290/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 4.5153e-04\n",
      "Epoch 290: ReduceLROnPlateau reducing learning rate to 6.461082011810504e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 4.5325e-04 - val_loss: 0.0256 - learning_rate: 7.1790e-05\n",
      "Epoch 291/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - loss: 4.4936e-04 - val_loss: 0.0259 - learning_rate: 6.4611e-05\n",
      "Epoch 292/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 4.4299e-04 - val_loss: 0.0259 - learning_rate: 6.4611e-05\n",
      "Epoch 293/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - loss: 4.3481e-04 - val_loss: 0.0259 - learning_rate: 6.4611e-05\n",
      "Epoch 294/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 4.3245e-04 - val_loss: 0.0262 - learning_rate: 6.4611e-05\n",
      "Epoch 295/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 4.3481e-04 - val_loss: 0.0255 - learning_rate: 6.4611e-05\n",
      "Epoch 296/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 4.3907e-04 - val_loss: 0.0252 - learning_rate: 6.4611e-05\n",
      "Epoch 297/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 4.3385e-04 - val_loss: 0.0261 - learning_rate: 6.4611e-05\n",
      "Epoch 298/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 4.3486e-04 - val_loss: 0.0266 - learning_rate: 6.4611e-05\n",
      "Epoch 299/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 4.3339e-04 - val_loss: 0.0261 - learning_rate: 6.4611e-05\n",
      "Epoch 300/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 4.2358e-04\n",
      "Epoch 300: ReduceLROnPlateau reducing learning rate to 5.8149741380475466e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 4.2512e-04 - val_loss: 0.0262 - learning_rate: 6.4611e-05\n",
      "Epoch 301/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 4.3140e-04 - val_loss: 0.0263 - learning_rate: 5.8150e-05\n",
      "Epoch 302/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - loss: 4.2668e-04 - val_loss: 0.0259 - learning_rate: 5.8150e-05\n",
      "Epoch 303/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 4.2307e-04 - val_loss: 0.0259 - learning_rate: 5.8150e-05\n",
      "Epoch 304/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 4.1928e-04 - val_loss: 0.0257 - learning_rate: 5.8150e-05\n",
      "Epoch 305/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 4.1703e-04 - val_loss: 0.0258 - learning_rate: 5.8150e-05\n",
      "Epoch 306/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 4.1339e-04 - val_loss: 0.0261 - learning_rate: 5.8150e-05\n",
      "Epoch 307/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 4.1320e-04 - val_loss: 0.0265 - learning_rate: 5.8150e-05\n",
      "Epoch 308/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 4.1545e-04 - val_loss: 0.0260 - learning_rate: 5.8150e-05\n",
      "Epoch 309/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 4.1584e-04 - val_loss: 0.0252 - learning_rate: 5.8150e-05\n",
      "Epoch 310/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 4.0982e-04\n",
      "Epoch 310: ReduceLROnPlateau reducing learning rate to 5.233476658759173e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - loss: 4.1148e-04 - val_loss: 0.0259 - learning_rate: 5.8150e-05\n",
      "Epoch 311/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 4.1179e-04 - val_loss: 0.0259 - learning_rate: 5.2335e-05\n",
      "Epoch 312/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 4.0658e-04 - val_loss: 0.0256 - learning_rate: 5.2335e-05\n",
      "Epoch 313/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 4.0220e-04 - val_loss: 0.0257 - learning_rate: 5.2335e-05\n",
      "Epoch 314/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 4.0148e-04 - val_loss: 0.0259 - learning_rate: 5.2335e-05\n",
      "Epoch 315/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 3.9494e-04 - val_loss: 0.0262 - learning_rate: 5.2335e-05\n",
      "Epoch 316/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 3.9663e-04 - val_loss: 0.0258 - learning_rate: 5.2335e-05\n",
      "Epoch 317/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 4.0045e-04 - val_loss: 0.0267 - learning_rate: 5.2335e-05\n",
      "Epoch 318/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 4.0425e-04 - val_loss: 0.0266 - learning_rate: 5.2335e-05\n",
      "Epoch 319/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 4.0110e-04 - val_loss: 0.0258 - learning_rate: 5.2335e-05\n",
      "Epoch 320/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 3.9500e-04\n",
      "Epoch 320: ReduceLROnPlateau reducing learning rate to 4.7101289601414466e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 99ms/step - loss: 3.9647e-04 - val_loss: 0.0255 - learning_rate: 5.2335e-05\n",
      "Epoch 321/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 3.8920e-04 - val_loss: 0.0259 - learning_rate: 4.7101e-05\n",
      "Epoch 322/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 3.8998e-04 - val_loss: 0.0257 - learning_rate: 4.7101e-05\n",
      "Epoch 323/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 3.8745e-04 - val_loss: 0.0261 - learning_rate: 4.7101e-05\n",
      "Epoch 324/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 3.8076e-04 - val_loss: 0.0259 - learning_rate: 4.7101e-05\n",
      "Epoch 325/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - loss: 3.8585e-04 - val_loss: 0.0257 - learning_rate: 4.7101e-05\n",
      "Epoch 326/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 3.8407e-04 - val_loss: 0.0259 - learning_rate: 4.7101e-05\n",
      "Epoch 327/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 3.8342e-04 - val_loss: 0.0259 - learning_rate: 4.7101e-05\n",
      "Epoch 328/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 3.8025e-04 - val_loss: 0.0257 - learning_rate: 4.7101e-05\n",
      "Epoch 329/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 3.8407e-04 - val_loss: 0.0260 - learning_rate: 4.7101e-05\n",
      "Epoch 330/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.7895e-04\n",
      "Epoch 330: ReduceLROnPlateau reducing learning rate to 4.239116096869111e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 3.8028e-04 - val_loss: 0.0262 - learning_rate: 4.7101e-05\n",
      "Epoch 331/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - loss: 3.7946e-04 - val_loss: 0.0260 - learning_rate: 4.2391e-05\n",
      "Epoch 332/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 3.8286e-04 - val_loss: 0.0258 - learning_rate: 4.2391e-05\n",
      "Epoch 333/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 3.7614e-04 - val_loss: 0.0263 - learning_rate: 4.2391e-05\n",
      "Epoch 334/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 3.7712e-04 - val_loss: 0.0260 - learning_rate: 4.2391e-05\n",
      "Epoch 335/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 3.8021e-04 - val_loss: 0.0255 - learning_rate: 4.2391e-05\n",
      "Epoch 336/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 3.7321e-04 - val_loss: 0.0262 - learning_rate: 4.2391e-05\n",
      "Epoch 337/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 3.6901e-04 - val_loss: 0.0260 - learning_rate: 4.2391e-05\n",
      "Epoch 338/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - loss: 3.7528e-04 - val_loss: 0.0256 - learning_rate: 4.2391e-05\n",
      "Epoch 339/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 3.7295e-04 - val_loss: 0.0257 - learning_rate: 4.2391e-05\n",
      "Epoch 340/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.6356e-04\n",
      "Epoch 340: ReduceLROnPlateau reducing learning rate to 3.815204618149437e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 3.6493e-04 - val_loss: 0.0264 - learning_rate: 4.2391e-05\n",
      "Epoch 341/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 3.7298e-04 - val_loss: 0.0254 - learning_rate: 3.8152e-05\n",
      "Epoch 342/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 3.6903e-04 - val_loss: 0.0257 - learning_rate: 3.8152e-05\n",
      "Epoch 343/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.5854e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 23:09:48.012896: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.5990e-04 - val_loss: 0.0261 - learning_rate: 3.8152e-05\n",
      "Epoch 344/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 3.6709e-04 - val_loss: 0.0260 - learning_rate: 3.8152e-05\n",
      "Epoch 345/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 3.5853e-04 - val_loss: 0.0256 - learning_rate: 3.8152e-05\n",
      "Epoch 346/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 3.6633e-04 - val_loss: 0.0261 - learning_rate: 3.8152e-05\n",
      "Epoch 347/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 94ms/step - loss: 3.5910e-04 - val_loss: 0.0260 - learning_rate: 3.8152e-05\n",
      "Epoch 348/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 3.6489e-04 - val_loss: 0.0257 - learning_rate: 3.8152e-05\n",
      "Epoch 349/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.6126e-04 - val_loss: 0.0256 - learning_rate: 3.8152e-05\n",
      "Epoch 350/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.6098e-04\n",
      "Epoch 350: ReduceLROnPlateau reducing learning rate to 3.4336842873017304e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.6232e-04 - val_loss: 0.0258 - learning_rate: 3.8152e-05\n",
      "Epoch 351/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 3.6039e-04 - val_loss: 0.0256 - learning_rate: 3.4337e-05\n",
      "Epoch 352/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 3.5833e-04 - val_loss: 0.0260 - learning_rate: 3.4337e-05\n",
      "Epoch 353/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.5767e-04 - val_loss: 0.0256 - learning_rate: 3.4337e-05\n",
      "Epoch 354/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 3.4940e-04 - val_loss: 0.0258 - learning_rate: 3.4337e-05\n",
      "Epoch 355/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 3.5368e-04 - val_loss: 0.0264 - learning_rate: 3.4337e-05\n",
      "Epoch 356/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 3.5084e-04 - val_loss: 0.0261 - learning_rate: 3.4337e-05\n",
      "Epoch 357/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 94ms/step - loss: 3.5206e-04 - val_loss: 0.0260 - learning_rate: 3.4337e-05\n",
      "Epoch 358/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 3.4721e-04 - val_loss: 0.0262 - learning_rate: 3.4337e-05\n",
      "Epoch 359/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 3.4789e-04 - val_loss: 0.0258 - learning_rate: 3.4337e-05\n",
      "Epoch 360/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 3.4907e-04\n",
      "Epoch 360: ReduceLROnPlateau reducing learning rate to 3.0903160222806036e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 3.5046e-04 - val_loss: 0.0260 - learning_rate: 3.4337e-05\n",
      "Epoch 361/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 3.5869e-04 - val_loss: 0.0258 - learning_rate: 3.0903e-05\n",
      "Epoch 362/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.5071e-04 - val_loss: 0.0257 - learning_rate: 3.0903e-05\n",
      "Epoch 363/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.4193e-04 - val_loss: 0.0258 - learning_rate: 3.0903e-05\n",
      "Epoch 364/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.4200e-04 - val_loss: 0.0253 - learning_rate: 3.0903e-05\n",
      "Epoch 365/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 3.4339e-04 - val_loss: 0.0258 - learning_rate: 3.0903e-05\n",
      "Epoch 366/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 108ms/step - loss: 3.4292e-04 - val_loss: 0.0262 - learning_rate: 3.0903e-05\n",
      "Epoch 367/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 3.4282e-04 - val_loss: 0.0261 - learning_rate: 3.0903e-05\n",
      "Epoch 368/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.4629e-04 - val_loss: 0.0257 - learning_rate: 3.0903e-05\n",
      "Epoch 369/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 3.4402e-04 - val_loss: 0.0261 - learning_rate: 3.0903e-05\n",
      "Epoch 370/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.3929e-04\n",
      "Epoch 370: ReduceLROnPlateau reducing learning rate to 2.7812844200525434e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 3.4066e-04 - val_loss: 0.0262 - learning_rate: 3.0903e-05\n",
      "Epoch 371/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 3.4444e-04 - val_loss: 0.0263 - learning_rate: 2.7813e-05\n",
      "Epoch 372/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 3.3936e-04 - val_loss: 0.0266 - learning_rate: 2.7813e-05\n",
      "Epoch 373/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 3.3638e-04 - val_loss: 0.0261 - learning_rate: 2.7813e-05\n",
      "Epoch 374/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 3.3281e-04 - val_loss: 0.0259 - learning_rate: 2.7813e-05\n",
      "Epoch 375/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.3386e-04 - val_loss: 0.0260 - learning_rate: 2.7813e-05\n",
      "Epoch 376/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 3.3176e-04 - val_loss: 0.0258 - learning_rate: 2.7813e-05\n",
      "Epoch 377/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 3.3321e-04 - val_loss: 0.0268 - learning_rate: 2.7813e-05\n",
      "Epoch 378/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 94ms/step - loss: 3.3519e-04 - val_loss: 0.0265 - learning_rate: 2.7813e-05\n",
      "Epoch 379/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 3.3571e-04 - val_loss: 0.0261 - learning_rate: 2.7813e-05\n",
      "Epoch 380/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 3.3515e-04\n",
      "Epoch 380: ReduceLROnPlateau reducing learning rate to 2.5031560107890984e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - loss: 3.3644e-04 - val_loss: 0.0262 - learning_rate: 2.7813e-05\n",
      "Epoch 381/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.3020e-04 - val_loss: 0.0264 - learning_rate: 2.5032e-05\n",
      "Epoch 382/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.2607e-04 - val_loss: 0.0261 - learning_rate: 2.5032e-05\n",
      "Epoch 383/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 3.2877e-04 - val_loss: 0.0261 - learning_rate: 2.5032e-05\n",
      "Epoch 384/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 3.2646e-04 - val_loss: 0.0261 - learning_rate: 2.5032e-05\n",
      "Epoch 385/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 98ms/step - loss: 3.3423e-04 - val_loss: 0.0268 - learning_rate: 2.5032e-05\n",
      "Epoch 386/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 3.2989e-04 - val_loss: 0.0270 - learning_rate: 2.5032e-05\n",
      "Epoch 387/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 3.2783e-04 - val_loss: 0.0260 - learning_rate: 2.5032e-05\n",
      "Epoch 388/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.2761e-04 - val_loss: 0.0262 - learning_rate: 2.5032e-05\n",
      "Epoch 389/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 3.3109e-04 - val_loss: 0.0257 - learning_rate: 2.5032e-05\n",
      "Epoch 390/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.2563e-04\n",
      "Epoch 390: ReduceLROnPlateau reducing learning rate to 2.2528404588229024e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.2679e-04 - val_loss: 0.0261 - learning_rate: 2.5032e-05\n",
      "Epoch 391/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 3.2694e-04 - val_loss: 0.0255 - learning_rate: 2.2528e-05\n",
      "Epoch 392/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - loss: 3.2248e-04 - val_loss: 0.0259 - learning_rate: 2.2528e-05\n",
      "Epoch 393/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.2120e-04 - val_loss: 0.0262 - learning_rate: 2.2528e-05\n",
      "Epoch 394/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.2056e-04 - val_loss: 0.0265 - learning_rate: 2.2528e-05\n",
      "Epoch 395/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 3.2350e-04 - val_loss: 0.0264 - learning_rate: 2.2528e-05\n",
      "Epoch 396/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 98ms/step - loss: 3.2310e-04 - val_loss: 0.0264 - learning_rate: 2.2528e-05\n",
      "Epoch 397/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 3.2486e-04 - val_loss: 0.0258 - learning_rate: 2.2528e-05\n",
      "Epoch 398/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 3.1918e-04 - val_loss: 0.0261 - learning_rate: 2.2528e-05\n",
      "Epoch 399/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.1970e-04 - val_loss: 0.0261 - learning_rate: 2.2528e-05\n",
      "Epoch 400/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.1788e-04\n",
      "Epoch 400: ReduceLROnPlateau reducing learning rate to 2.0275563474569936e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 3.1909e-04 - val_loss: 0.0261 - learning_rate: 2.2528e-05\n",
      "Epoch 401/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 3.2052e-04 - val_loss: 0.0261 - learning_rate: 2.0276e-05\n",
      "Epoch 402/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 3.1588e-04 - val_loss: 0.0261 - learning_rate: 2.0276e-05\n",
      "Epoch 403/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 3.1780e-04 - val_loss: 0.0259 - learning_rate: 2.0276e-05\n",
      "Epoch 404/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.1560e-04 - val_loss: 0.0258 - learning_rate: 2.0276e-05\n",
      "Epoch 405/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.1890e-04 - val_loss: 0.0260 - learning_rate: 2.0276e-05\n",
      "Epoch 406/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 3.1735e-04 - val_loss: 0.0258 - learning_rate: 2.0276e-05\n",
      "Epoch 407/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 98ms/step - loss: 3.1643e-04 - val_loss: 0.0260 - learning_rate: 2.0276e-05\n",
      "Epoch 408/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 3.1832e-04 - val_loss: 0.0257 - learning_rate: 2.0276e-05\n",
      "Epoch 409/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.1292e-04 - val_loss: 0.0261 - learning_rate: 2.0276e-05\n",
      "Epoch 410/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.1391e-04\n",
      "Epoch 410: ReduceLROnPlateau reducing learning rate to 1.8248007290821987e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 3.1515e-04 - val_loss: 0.0261 - learning_rate: 2.0276e-05\n",
      "Epoch 411/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 3.1519e-04 - val_loss: 0.0260 - learning_rate: 1.8248e-05\n",
      "Epoch 412/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 3.1001e-04 - val_loss: 0.0262 - learning_rate: 1.8248e-05\n",
      "Epoch 413/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 3.1095e-04 - val_loss: 0.0261 - learning_rate: 1.8248e-05\n",
      "Epoch 414/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - loss: 3.1236e-04 - val_loss: 0.0260 - learning_rate: 1.8248e-05\n",
      "Epoch 415/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 3.1169e-04 - val_loss: 0.0260 - learning_rate: 1.8248e-05\n",
      "Epoch 416/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.0964e-04 - val_loss: 0.0262 - learning_rate: 1.8248e-05\n",
      "Epoch 417/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 3.1155e-04 - val_loss: 0.0261 - learning_rate: 1.8248e-05\n",
      "Epoch 418/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.1342e-04 - val_loss: 0.0260 - learning_rate: 1.8248e-05\n",
      "Epoch 419/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.1160e-04 - val_loss: 0.0262 - learning_rate: 1.8248e-05\n",
      "Epoch 420/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.1125e-04\n",
      "Epoch 420: ReduceLROnPlateau reducing learning rate to 1.6423206398030745e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.1252e-04 - val_loss: 0.0262 - learning_rate: 1.8248e-05\n",
      "Epoch 421/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.1107e-04 - val_loss: 0.0262 - learning_rate: 1.6423e-05\n",
      "Epoch 422/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.0653e-04 - val_loss: 0.0265 - learning_rate: 1.6423e-05\n",
      "Epoch 423/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 3.0628e-04 - val_loss: 0.0263 - learning_rate: 1.6423e-05\n",
      "Epoch 424/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 3.0944e-04 - val_loss: 0.0259 - learning_rate: 1.6423e-05\n",
      "Epoch 425/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.0354e-04 - val_loss: 0.0261 - learning_rate: 1.6423e-05\n",
      "Epoch 426/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 3.0914e-04 - val_loss: 0.0259 - learning_rate: 1.6423e-05\n",
      "Epoch 427/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 3.0382e-04 - val_loss: 0.0256 - learning_rate: 1.6423e-05\n",
      "Epoch 428/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 3.0854e-04 - val_loss: 0.0262 - learning_rate: 1.6423e-05\n",
      "Epoch 429/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - loss: 3.0641e-04 - val_loss: 0.0258 - learning_rate: 1.6423e-05\n",
      "Epoch 430/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.0310e-04\n",
      "Epoch 430: ReduceLROnPlateau reducing learning rate to 1.4780885430809576e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 3.0433e-04 - val_loss: 0.0265 - learning_rate: 1.6423e-05\n",
      "Epoch 431/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 3.0567e-04 - val_loss: 0.0259 - learning_rate: 1.4781e-05\n",
      "Epoch 432/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 3.0131e-04 - val_loss: 0.0260 - learning_rate: 1.4781e-05\n",
      "Epoch 433/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 3.0397e-04 - val_loss: 0.0263 - learning_rate: 1.4781e-05\n",
      "Epoch 434/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 3.0014e-04 - val_loss: 0.0260 - learning_rate: 1.4781e-05\n",
      "Epoch 435/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 3.0340e-04 - val_loss: 0.0254 - learning_rate: 1.4781e-05\n",
      "Epoch 436/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.0475e-04 - val_loss: 0.0257 - learning_rate: 1.4781e-05\n",
      "Epoch 437/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 3.0438e-04 - val_loss: 0.0258 - learning_rate: 1.4781e-05\n",
      "Epoch 438/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 3.0373e-04 - val_loss: 0.0260 - learning_rate: 1.4781e-05\n",
      "Epoch 439/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 3.0513e-04 - val_loss: 0.0259 - learning_rate: 1.4781e-05\n",
      "Epoch 440/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.0116e-04\n",
      "Epoch 440: ReduceLROnPlateau reducing learning rate to 1.3302796560310526e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 97ms/step - loss: 3.0242e-04 - val_loss: 0.0264 - learning_rate: 1.4781e-05\n",
      "Epoch 441/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.9974e-04 - val_loss: 0.0259 - learning_rate: 1.3303e-05\n",
      "Epoch 442/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.9659e-04 - val_loss: 0.0262 - learning_rate: 1.3303e-05\n",
      "Epoch 443/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 3.0040e-04 - val_loss: 0.0258 - learning_rate: 1.3303e-05\n",
      "Epoch 444/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.0261e-04 - val_loss: 0.0259 - learning_rate: 1.3303e-05\n",
      "Epoch 445/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.0255e-04 - val_loss: 0.0255 - learning_rate: 1.3303e-05\n",
      "Epoch 446/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.9888e-04 - val_loss: 0.0266 - learning_rate: 1.3303e-05\n",
      "Epoch 447/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.9854e-04 - val_loss: 0.0258 - learning_rate: 1.3303e-05\n",
      "Epoch 448/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.9908e-04 - val_loss: 0.0258 - learning_rate: 1.3303e-05\n",
      "Epoch 449/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 3.0073e-04 - val_loss: 0.0260 - learning_rate: 1.3303e-05\n",
      "Epoch 450/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.9500e-04\n",
      "Epoch 450: ReduceLROnPlateau reducing learning rate to 1.1972517313552089e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.9620e-04 - val_loss: 0.0261 - learning_rate: 1.3303e-05\n",
      "Epoch 451/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.9584e-04 - val_loss: 0.0260 - learning_rate: 1.1973e-05\n",
      "Epoch 452/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.9696e-04 - val_loss: 0.0258 - learning_rate: 1.1973e-05\n",
      "Epoch 453/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.9435e-04 - val_loss: 0.0267 - learning_rate: 1.1973e-05\n",
      "Epoch 454/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.9641e-04 - val_loss: 0.0260 - learning_rate: 1.1973e-05\n",
      "Epoch 455/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.9456e-04 - val_loss: 0.0261 - learning_rate: 1.1973e-05\n",
      "Epoch 456/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 2.9688e-04 - val_loss: 0.0260 - learning_rate: 1.1973e-05\n",
      "Epoch 457/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.9519e-04 - val_loss: 0.0256 - learning_rate: 1.1973e-05\n",
      "Epoch 458/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.9229e-04 - val_loss: 0.0264 - learning_rate: 1.1973e-05\n",
      "Epoch 459/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.9714e-04 - val_loss: 0.0267 - learning_rate: 1.1973e-05\n",
      "Epoch 460/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 2.9754e-04\n",
      "Epoch 460: ReduceLROnPlateau reducing learning rate to 1.077526558219688e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.9872e-04 - val_loss: 0.0264 - learning_rate: 1.1973e-05\n",
      "Epoch 461/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.9529e-04 - val_loss: 0.0259 - learning_rate: 1.0775e-05\n",
      "Epoch 462/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.9205e-04 - val_loss: 0.0261 - learning_rate: 1.0775e-05\n",
      "Epoch 463/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.9376e-04 - val_loss: 0.0263 - learning_rate: 1.0775e-05\n",
      "Epoch 464/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.9150e-04 - val_loss: 0.0262 - learning_rate: 1.0775e-05\n",
      "Epoch 465/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.9073e-04 - val_loss: 0.0258 - learning_rate: 1.0775e-05\n",
      "Epoch 466/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.9563e-04 - val_loss: 0.0261 - learning_rate: 1.0775e-05\n",
      "Epoch 467/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - loss: 2.8922e-04 - val_loss: 0.0262 - learning_rate: 1.0775e-05\n",
      "Epoch 468/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 2.9126e-04 - val_loss: 0.0262 - learning_rate: 1.0775e-05\n",
      "Epoch 469/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.8832e-04 - val_loss: 0.0263 - learning_rate: 1.0775e-05\n",
      "Epoch 470/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 2.9007e-04\n",
      "Epoch 470: ReduceLROnPlateau reducing learning rate to 9.697739187686238e-06.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.9120e-04 - val_loss: 0.0261 - learning_rate: 1.0775e-05\n",
      "Epoch 471/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.9032e-04 - val_loss: 0.0262 - learning_rate: 9.6977e-06\n",
      "Epoch 472/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.9042e-04 - val_loss: 0.0257 - learning_rate: 9.6977e-06\n",
      "Epoch 473/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.9215e-04 - val_loss: 0.0261 - learning_rate: 9.6977e-06\n",
      "Epoch 474/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.9172e-04 - val_loss: 0.0263 - learning_rate: 9.6977e-06\n",
      "Epoch 475/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 2.8932e-04 - val_loss: 0.0262 - learning_rate: 9.6977e-06\n",
      "Epoch 476/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.8648e-04 - val_loss: 0.0260 - learning_rate: 9.6977e-06\n",
      "Epoch 477/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.9041e-04 - val_loss: 0.0262 - learning_rate: 9.6977e-06\n",
      "Epoch 478/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.8802e-04 - val_loss: 0.0261 - learning_rate: 9.6977e-06\n",
      "Epoch 479/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.9137e-04 - val_loss: 0.0258 - learning_rate: 9.6977e-06\n",
      "Epoch 480/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.8916e-04\n",
      "Epoch 480: ReduceLROnPlateau reducing learning rate to 8.727965268917615e-06.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.9036e-04 - val_loss: 0.0266 - learning_rate: 9.6977e-06\n",
      "Epoch 481/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.8647e-04 - val_loss: 0.0261 - learning_rate: 8.7280e-06\n",
      "Epoch 482/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.8782e-04 - val_loss: 0.0258 - learning_rate: 8.7280e-06\n",
      "Epoch 483/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - loss: 2.8713e-04 - val_loss: 0.0259 - learning_rate: 8.7280e-06\n",
      "Epoch 484/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.8780e-04 - val_loss: 0.0265 - learning_rate: 8.7280e-06\n",
      "Epoch 485/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 2.8639e-04 - val_loss: 0.0256 - learning_rate: 8.7280e-06\n",
      "Epoch 486/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.8859e-04 - val_loss: 0.0262 - learning_rate: 8.7280e-06\n",
      "Epoch 487/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.8692e-04 - val_loss: 0.0260 - learning_rate: 8.7280e-06\n",
      "Epoch 488/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.8474e-04 - val_loss: 0.0264 - learning_rate: 8.7280e-06\n",
      "Epoch 489/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.8720e-04 - val_loss: 0.0263 - learning_rate: 8.7280e-06\n",
      "Epoch 490/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.8395e-04\n",
      "Epoch 490: ReduceLROnPlateau reducing learning rate to 7.855168496462283e-06.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.8511e-04 - val_loss: 0.0260 - learning_rate: 8.7280e-06\n",
      "Epoch 491/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.8392e-04 - val_loss: 0.0266 - learning_rate: 7.8552e-06\n",
      "Epoch 492/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.8424e-04 - val_loss: 0.0265 - learning_rate: 7.8552e-06\n",
      "Epoch 493/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.9048e-04 - val_loss: 0.0265 - learning_rate: 7.8552e-06\n",
      "Epoch 494/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.8480e-04 - val_loss: 0.0264 - learning_rate: 7.8552e-06\n",
      "Epoch 495/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.8496e-04 - val_loss: 0.0261 - learning_rate: 7.8552e-06\n",
      "Epoch 496/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 95ms/step - loss: 2.8604e-04 - val_loss: 0.0257 - learning_rate: 7.8552e-06\n",
      "Epoch 497/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.8618e-04 - val_loss: 0.0258 - learning_rate: 7.8552e-06\n",
      "Epoch 498/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 2.8917e-04 - val_loss: 0.0257 - learning_rate: 7.8552e-06\n",
      "Epoch 499/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.8542e-04 - val_loss: 0.0266 - learning_rate: 7.8552e-06\n",
      "Epoch 500/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.8320e-04\n",
      "Epoch 500: ReduceLROnPlateau reducing learning rate to 7.069651564961533e-06.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - loss: 2.8439e-04 - val_loss: 0.0265 - learning_rate: 7.8552e-06\n",
      "Epoch 501/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.8152e-04 - val_loss: 0.0261 - learning_rate: 7.0697e-06\n",
      "Epoch 502/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.8199e-04 - val_loss: 0.0261 - learning_rate: 7.0697e-06\n",
      "Epoch 503/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.8386e-04 - val_loss: 0.0262 - learning_rate: 7.0697e-06\n",
      "Epoch 504/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.8520e-04 - val_loss: 0.0259 - learning_rate: 7.0697e-06\n",
      "Epoch 505/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.8562e-04 - val_loss: 0.0259 - learning_rate: 7.0697e-06\n",
      "Epoch 506/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 2.8154e-04 - val_loss: 0.0260 - learning_rate: 7.0697e-06\n",
      "Epoch 507/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 2.8440e-04 - val_loss: 0.0267 - learning_rate: 7.0697e-06\n",
      "Epoch 508/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.8460e-04 - val_loss: 0.0255 - learning_rate: 7.0697e-06\n",
      "Epoch 509/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.8122e-04 - val_loss: 0.0258 - learning_rate: 7.0697e-06\n",
      "Epoch 510/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.8226e-04\n",
      "Epoch 510: ReduceLROnPlateau reducing learning rate to 7e-06.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.8336e-04 - val_loss: 0.0254 - learning_rate: 7.0697e-06\n",
      "Epoch 511/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.8076e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 512/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7914e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 513/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.7851e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 514/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.8232e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 515/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 2.8278e-04 - val_loss: 0.0258 - learning_rate: 7.0000e-06\n",
      "Epoch 516/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.8229e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 517/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.8174e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 518/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.8565e-04 - val_loss: 0.0257 - learning_rate: 7.0000e-06\n",
      "Epoch 519/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.8335e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 520/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.8051e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 521/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.8127e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 522/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.8077e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 523/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.8326e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 524/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.8209e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 525/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.7924e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 526/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.8360e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 527/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.7908e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 528/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7956e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 529/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.8182e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 530/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7948e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 531/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.7975e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 532/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.7737e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 533/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7734e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 534/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7842e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 535/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7940e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 536/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.7806e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 537/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.7768e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 538/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.8244e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 539/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.8088e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 540/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7655e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 541/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7843e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 542/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7892e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 543/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.7845e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 544/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.7631e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 545/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.7748e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 546/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.8042e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 547/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.7712e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 548/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 2.7840e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 549/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.7733e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 550/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7812e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 551/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.7538e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 552/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.7710e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 553/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7761e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 554/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 2.7779e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 555/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.7783e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 556/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.7778e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 557/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7732e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 558/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7566e-04 - val_loss: 0.0257 - learning_rate: 7.0000e-06\n",
      "Epoch 559/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.7493e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 560/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7497e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 561/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.8162e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 562/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 2.7811e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 563/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 2.7349e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 564/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.7631e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 565/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7778e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 566/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7520e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 567/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.7264e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 568/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.7551e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 569/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.7222e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 570/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.7654e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 571/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.7453e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 572/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.7636e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 573/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.7162e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 574/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.7571e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 575/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.7784e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 576/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7635e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 577/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7273e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 578/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7528e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 579/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7418e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 580/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.7379e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 581/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - loss: 2.7155e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 582/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7306e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 583/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.7439e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 584/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 2.7173e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 585/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7535e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 586/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - loss: 2.7416e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 587/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7263e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 588/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7156e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 589/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.7477e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 590/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.7112e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 591/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.7395e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 592/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 97ms/step - loss: 2.7355e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 593/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.7325e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 594/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.7476e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 595/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7295e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 596/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7348e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 597/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.7028e-04 - val_loss: 0.0256 - learning_rate: 7.0000e-06\n",
      "Epoch 598/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.6865e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 599/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 109ms/step - loss: 2.7292e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 600/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7066e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 601/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.7411e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 602/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7187e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 603/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6908e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 604/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.7157e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 605/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.7186e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 606/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.7165e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 607/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.7373e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 608/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.7024e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 609/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 108ms/step - loss: 2.7471e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 610/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.7095e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 611/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7243e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 612/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6985e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 613/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.6934e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 614/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.7210e-04 - val_loss: 0.0254 - learning_rate: 7.0000e-06\n",
      "Epoch 615/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.6859e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 616/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.7139e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 617/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6982e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 618/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.6901e-04 - val_loss: 0.0258 - learning_rate: 7.0000e-06\n",
      "Epoch 619/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 2.6853e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 620/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.6769e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 621/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.6983e-04 - val_loss: 0.0258 - learning_rate: 7.0000e-06\n",
      "Epoch 622/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7232e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 623/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.7262e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 624/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6789e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 625/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.6760e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 626/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 2.6970e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 627/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.6825e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 628/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - loss: 2.6960e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 629/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.6840e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 630/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.6972e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 631/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.7105e-04 - val_loss: 0.0258 - learning_rate: 7.0000e-06\n",
      "Epoch 632/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 2.6707e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 633/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.6467e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 634/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - loss: 2.6688e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 635/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.6760e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 636/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.6818e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 637/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.7123e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 638/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.7059e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 639/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.6669e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 640/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 2.6628e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 641/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 95ms/step - loss: 2.6679e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 642/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - loss: 2.6492e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 643/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.6650e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 644/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.6721e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 645/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.6803e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 646/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6779e-04 - val_loss: 0.0256 - learning_rate: 7.0000e-06\n",
      "Epoch 647/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.6698e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 648/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.6470e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 649/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.6436e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 650/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6754e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 651/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.6693e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 652/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.6399e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 653/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.6522e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 654/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.6552e-04 - val_loss: 0.0257 - learning_rate: 7.0000e-06\n",
      "Epoch 655/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.6633e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 656/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6636e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 657/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6324e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 658/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6374e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 659/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.6571e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 660/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.6580e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 661/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 2.6364e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 662/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.6604e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 663/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.6827e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 664/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6586e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 665/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 2.6420e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 666/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 2.6433e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 667/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 2.6218e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 668/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 2.6657e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 669/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.6308e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 670/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6240e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 671/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.6252e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 672/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 2.6752e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 673/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.6417e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 674/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.6336e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 675/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6382e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 676/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - loss: 2.6392e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 677/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.6565e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 678/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 2.6335e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 679/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.6448e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 680/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - loss: 2.6584e-04 - val_loss: 0.0257 - learning_rate: 7.0000e-06\n",
      "Epoch 681/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.6171e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 682/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.6217e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 683/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6377e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 684/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 2.6647e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 685/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.6277e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 23:40:54.585312: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 98ms/step - loss: 2.6385e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 686/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.6018e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 687/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6258e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 688/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.6188e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 689/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5983e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 690/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.6039e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 691/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6100e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 692/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6070e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 693/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.6427e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 694/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6344e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 695/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.6568e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 696/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.6206e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 697/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - loss: 2.5983e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 698/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6224e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 699/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6261e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 700/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6347e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 701/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.6075e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 702/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.6183e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 703/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.6202e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 704/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6039e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 705/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5923e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 706/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6076e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 707/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6006e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 708/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.6016e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 709/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.6059e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 710/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 2.6115e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 711/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5826e-04 - val_loss: 0.0258 - learning_rate: 7.0000e-06\n",
      "Epoch 712/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.6077e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 713/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - loss: 2.5939e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 714/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.5888e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 715/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5959e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 716/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6260e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 717/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.5951e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 718/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.5712e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 719/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.5959e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 720/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.5802e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 721/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5621e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 722/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.6010e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 723/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.6251e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 724/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.5830e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 725/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.6045e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 726/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.6078e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 727/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 94ms/step - loss: 2.5895e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 728/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.5921e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 729/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5793e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 730/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.6012e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 731/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5691e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 732/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5805e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 733/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5579e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 734/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.5909e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 735/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5689e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 736/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5651e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 737/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5518e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 738/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5868e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 739/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5622e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 740/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.5759e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 741/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 103ms/step - loss: 2.5959e-04 - val_loss: 0.0258 - learning_rate: 7.0000e-06\n",
      "Epoch 742/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5611e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 743/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 2.5483e-04 - val_loss: 0.0256 - learning_rate: 7.0000e-06\n",
      "Epoch 744/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.5618e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 745/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5819e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 746/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5416e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 747/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5549e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 748/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5702e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 749/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5481e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 750/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5596e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 751/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5748e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 752/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5639e-04 - val_loss: 0.0258 - learning_rate: 7.0000e-06\n",
      "Epoch 753/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5440e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 754/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5837e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 755/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5560e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 756/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.5775e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 757/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.5615e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 758/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.5232e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 759/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.5655e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 760/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.5358e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 761/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - loss: 2.5464e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 762/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5678e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 763/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.5464e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 764/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.5223e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 765/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.5295e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 766/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5549e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 767/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5495e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 768/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.5566e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 769/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5332e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 770/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5347e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 771/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5429e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 772/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5467e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 773/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5435e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 774/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5562e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 775/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5503e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 776/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5402e-04 - val_loss: 0.0258 - learning_rate: 7.0000e-06\n",
      "Epoch 777/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.5191e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 778/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.5423e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 779/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.5307e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 780/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5043e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 781/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.5118e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 782/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5120e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 783/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.5340e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 784/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5393e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 785/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.5064e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 786/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.5041e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 787/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4902e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 788/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5266e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 789/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.5232e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 790/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.5108e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 791/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.5213e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 792/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.5190e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 793/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.5323e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 794/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.5366e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 795/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5329e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 796/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5076e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 797/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.5196e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 798/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4907e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 799/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.4899e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 800/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.5056e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 801/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5156e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 802/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5474e-04 - val_loss: 0.0257 - learning_rate: 7.0000e-06\n",
      "Epoch 803/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.5238e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 804/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.4969e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 805/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - loss: 2.4994e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 806/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.5037e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 807/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.4940e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 808/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5005e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 809/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 2.5189e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 810/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.4907e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 811/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5136e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 812/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.4902e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 813/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4951e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 814/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.4890e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 815/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5125e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 816/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.4992e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 817/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.5152e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 818/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4865e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 819/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4885e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 820/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4950e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 821/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.4737e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 822/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 2.4785e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 823/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.4840e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 824/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.5024e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 825/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4838e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 826/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.4802e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 827/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 2.4887e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 828/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4945e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 829/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.4726e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 830/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 2.4976e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 831/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.5071e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 832/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4736e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 833/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.4830e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 834/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4836e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 835/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.5009e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 836/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.4684e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 837/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4703e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 838/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4687e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 839/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.5109e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 840/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4473e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 841/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4685e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 842/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.4678e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 843/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.4728e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 844/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.4817e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 845/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4488e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 846/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.5021e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 847/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4594e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 848/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4615e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 849/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4655e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 850/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.4847e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 851/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.4699e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 852/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.4773e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 853/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4672e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 854/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4569e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 855/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.4520e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 856/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4693e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 857/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4684e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 858/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4573e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 859/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4405e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 860/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.4476e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 861/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.4354e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 862/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4389e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 863/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.4569e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 864/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4439e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 865/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.4318e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 866/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4440e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 867/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.4408e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 868/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4531e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 869/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4434e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 870/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - loss: 2.4507e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 871/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.4682e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 872/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.4486e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 873/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4574e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 874/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.4381e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 875/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4556e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 876/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.4523e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 877/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.4750e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 878/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.4151e-04 - val_loss: 0.0257 - learning_rate: 7.0000e-06\n",
      "Epoch 879/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4359e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 880/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.4522e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 881/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4054e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 882/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4523e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 883/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4293e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 884/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.4199e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 885/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4288e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 886/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.4664e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 887/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4243e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 888/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.4192e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 889/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.3972e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 890/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - loss: 2.4243e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 891/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4060e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 892/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4206e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 893/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.4174e-04 - val_loss: 0.0274 - learning_rate: 7.0000e-06\n",
      "Epoch 894/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.4164e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 895/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4159e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 896/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.4151e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 897/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4003e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 898/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.4206e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 899/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.4193e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 900/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4117e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 901/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.4233e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 902/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4382e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 903/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4194e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 904/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.4199e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 905/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - loss: 2.3787e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 906/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3846e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 907/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.4221e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 908/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.4226e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 909/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3891e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 910/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3961e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 911/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.3764e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 912/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - loss: 2.4368e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 913/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3734e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 914/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.4404e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 915/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3950e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 916/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3887e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 917/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4008e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 918/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4025e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 919/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.4294e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 920/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.4230e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 921/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.4121e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 922/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.4162e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 923/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 2.3800e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 924/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 97ms/step - loss: 2.3860e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 925/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3994e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 926/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - loss: 2.3972e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 927/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3697e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 928/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3944e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 929/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.3886e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 930/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 2.3958e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 931/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4159e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 932/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3778e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 933/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.3758e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 934/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.4043e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 935/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.3841e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 936/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 2.3696e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 937/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.3934e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 938/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3929e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 939/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.3909e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 940/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3935e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 941/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.3832e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 942/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3845e-04 - val_loss: 0.0271 - learning_rate: 7.0000e-06\n",
      "Epoch 943/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.3551e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 944/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - loss: 2.3635e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 945/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3637e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 946/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3533e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 947/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.3698e-04 - val_loss: 0.0273 - learning_rate: 7.0000e-06\n",
      "Epoch 948/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.4070e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 949/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3774e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 950/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3606e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 951/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.3914e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 952/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3667e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 953/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - loss: 2.3774e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 954/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3735e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 955/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.3588e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 956/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.3435e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 957/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3414e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 958/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3733e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 959/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.4091e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 960/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 2.3775e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 961/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3645e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 962/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3638e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 963/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3557e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 964/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.3645e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 965/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3550e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 966/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3298e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 967/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3522e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 968/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.3521e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 969/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.3628e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 970/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.3818e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 971/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3641e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 972/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3697e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 973/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.3452e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 974/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.3258e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 975/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3482e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 976/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.3593e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 977/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3587e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 978/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.3162e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 979/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 2.3356e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 980/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 2.3396e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 981/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3304e-04 - val_loss: 0.0271 - learning_rate: 7.0000e-06\n",
      "Epoch 982/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.3560e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 983/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.3410e-04 - val_loss: 0.0274 - learning_rate: 7.0000e-06\n",
      "Epoch 984/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.3609e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 985/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.3640e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 986/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3327e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 987/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.3625e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 988/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3204e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 989/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.3269e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 990/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3315e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 991/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3456e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 992/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.3341e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 993/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 2.3227e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 994/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.3176e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 995/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3389e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 996/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3257e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 997/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 2.3157e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 998/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.3133e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 999/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.3203e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1000/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.3275e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1001/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3220e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1002/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.3385e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1003/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.2963e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1004/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3501e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1005/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3143e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1006/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3486e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1007/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.3149e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 1008/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3338e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1009/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.3102e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1010/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.3313e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 1011/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.2989e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1012/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.2771e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1013/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3295e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1014/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.3378e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1015/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2906e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1016/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3296e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1017/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3097e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 1018/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2988e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1019/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.3225e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1020/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 2.3126e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1021/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 96ms/step - loss: 2.3031e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1022/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3585e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1023/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2756e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1024/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3014e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1025/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 2.3031e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1026/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 2.3144e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1027/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 96ms/step - loss: 2.3242e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 1028/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2875e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1029/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2843e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1030/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3180e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1031/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2906e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1032/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.2913e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1033/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2883e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1034/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.3152e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1035/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2669e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1036/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.3445e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1037/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.3050e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1038/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2706e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1039/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2760e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1040/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2853e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1041/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.2868e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1042/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.3149e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1043/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2995e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1044/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2977e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1045/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.2730e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1046/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - loss: 2.2711e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1047/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 2.3019e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1048/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2824e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1049/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2723e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1050/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2642e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1051/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.2897e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1052/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 2.2677e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1053/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 97ms/step - loss: 2.2887e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1054/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2998e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1055/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2718e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1056/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2897e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1057/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2911e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1058/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.2748e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1059/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.2805e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1060/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2809e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1061/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.2688e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1062/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.2603e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1063/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.2994e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1064/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2787e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1065/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2968e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1066/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.2812e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1067/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.2654e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1068/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.2567e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1069/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - loss: 2.3016e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1070/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.2627e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1071/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2853e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1072/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.2805e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1073/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2475e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 1074/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.2552e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1075/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.2711e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1076/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.2762e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1077/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.2572e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1078/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2680e-04 - val_loss: 0.0271 - learning_rate: 7.0000e-06\n",
      "Epoch 1079/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2572e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1080/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2443e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1081/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2521e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1082/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.2779e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1083/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.2429e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1084/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2073e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1085/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.2304e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1086/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2602e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1087/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.2631e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1088/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2596e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1089/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2720e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1090/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 2.2594e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1091/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2613e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1092/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.2675e-04 - val_loss: 0.0259 - learning_rate: 7.0000e-06\n",
      "Epoch 1093/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 2.2348e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1094/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.2464e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1095/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - loss: 2.2426e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1096/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2476e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1097/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.2537e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 1098/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2540e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1099/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2430e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1100/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.2328e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1101/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.2444e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1102/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.2319e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1103/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 2.2420e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1104/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 95ms/step - loss: 2.2245e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1105/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2385e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1106/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2436e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 1107/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2517e-04 - val_loss: 0.0271 - learning_rate: 7.0000e-06\n",
      "Epoch 1108/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2438e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1109/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2284e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1110/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.2272e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 1111/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2370e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1112/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2290e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1113/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2542e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1114/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.2189e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1115/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2343e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1116/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.2307e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1117/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.2216e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1118/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.2309e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1119/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2249e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1120/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2083e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1121/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.2010e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1122/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.2246e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1123/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2185e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1124/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2317e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1125/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.2306e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1126/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2295e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1127/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2390e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1128/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2306e-04 - val_loss: 0.0271 - learning_rate: 7.0000e-06\n",
      "Epoch 1129/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2344e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1130/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2311e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1131/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2116e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1132/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2159e-04 - val_loss: 0.0272 - learning_rate: 7.0000e-06\n",
      "Epoch 1133/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2223e-04 - val_loss: 0.0272 - learning_rate: 7.0000e-06\n",
      "Epoch 1134/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 98ms/step - loss: 2.2468e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1135/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.2210e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1136/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2145e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1137/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2030e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1138/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.1884e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1139/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.2251e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1140/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2124e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1141/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.2124e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1142/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.2274e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1143/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.2137e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1144/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2484e-04 - val_loss: 0.0271 - learning_rate: 7.0000e-06\n",
      "Epoch 1145/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.2083e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1146/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 2.2163e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1147/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 96ms/step - loss: 2.2099e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1148/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.1782e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1149/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2222e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1150/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2560e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1151/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 2.2167e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1152/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.2225e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1153/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.1768e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1154/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - loss: 2.2168e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1155/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.1942e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1156/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 2.2112e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1157/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2453e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 1158/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2011e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1159/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2128e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1160/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.1910e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1161/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 2.1920e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1162/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.1931e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1163/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.1730e-04 - val_loss: 0.0272 - learning_rate: 7.0000e-06\n",
      "Epoch 1164/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.1848e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1165/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - loss: 2.1767e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1166/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 2.1795e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1167/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.1673e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1168/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.2336e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1169/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.1899e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1170/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2019e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1171/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.1743e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1172/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.2012e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1173/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.1986e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1174/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.1630e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1175/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1618e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1176/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.1849e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1177/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.1803e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1178/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.1560e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1179/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.1576e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1180/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.1717e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1181/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.1838e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1182/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.1489e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1183/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.1825e-04 - val_loss: 0.0271 - learning_rate: 7.0000e-06\n",
      "Epoch 1184/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.1688e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1185/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - loss: 2.1850e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1186/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.1469e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1187/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.1674e-04 - val_loss: 0.0258 - learning_rate: 7.0000e-06\n",
      "Epoch 1188/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1652e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1189/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1731e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1190/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.1759e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1191/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - loss: 2.1523e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1192/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.1910e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1193/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.2043e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1194/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - loss: 2.1768e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1195/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 2.1759e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1196/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.1507e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1197/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1480e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1198/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1504e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1199/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.1506e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1200/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.1738e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 1201/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.1524e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1202/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - loss: 2.1628e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1203/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.1395e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1204/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.1506e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1205/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1396e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1206/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.1397e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1207/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - loss: 2.1263e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1208/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.1454e-04 - val_loss: 0.0271 - learning_rate: 7.0000e-06\n",
      "Epoch 1209/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.1790e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1210/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.1880e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1211/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1263e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1212/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1567e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1213/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1393e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1214/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1846e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1215/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1546e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1216/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1446e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1217/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.1445e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1218/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - loss: 2.1314e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1219/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1525e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1220/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1366e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1221/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1453e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1222/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 2.1412e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1223/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1356e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1224/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1558e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1225/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1475e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1226/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1425e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1227/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1314e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1228/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.1460e-04 - val_loss: 0.0271 - learning_rate: 7.0000e-06\n",
      "Epoch 1229/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - loss: 2.1229e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 1230/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1416e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1231/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1233e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1232/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1333e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1233/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1231e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1234/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.1243e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1235/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - loss: 2.1159e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1236/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.1565e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1237/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1446e-04 - val_loss: 0.0274 - learning_rate: 7.0000e-06\n",
      "Epoch 1238/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 2.1260e-04 - val_loss: 0.0272 - learning_rate: 7.0000e-06\n",
      "Epoch 1239/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.1403e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1240/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - loss: 2.1275e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1241/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.1247e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1242/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1215e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1243/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1239e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1244/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 2.1398e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1245/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1051e-04 - val_loss: 0.0272 - learning_rate: 7.0000e-06\n",
      "Epoch 1246/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1022e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1247/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 2.1393e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1248/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1128e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1249/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1215e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1250/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.1000e-04 - val_loss: 0.0273 - learning_rate: 7.0000e-06\n",
      "Epoch 1251/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - loss: 2.1059e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 1252/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1147e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1253/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 2.1284e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1254/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.1220e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1255/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1088e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1256/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1087e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1257/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.1091e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1258/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - loss: 2.1189e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1259/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1105e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1260/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 2.1173e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1261/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 2.1140e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1262/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1266e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1263/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1179e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1264/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.0819e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1265/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - loss: 2.1079e-04 - val_loss: 0.0273 - learning_rate: 7.0000e-06\n",
      "Epoch 1266/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1290e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1267/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.1223e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1268/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1131e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1269/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 2.1076e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1270/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 2.1086e-04 - val_loss: 0.0271 - learning_rate: 7.0000e-06\n",
      "Epoch 1271/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.1099e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1272/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.0814e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1273/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 94ms/step - loss: 2.1236e-04 - val_loss: 0.0272 - learning_rate: 7.0000e-06\n",
      "Epoch 1274/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.0978e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1275/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.1215e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1276/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1376e-04 - val_loss: 0.0271 - learning_rate: 7.0000e-06\n",
      "Epoch 1277/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.1003e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1278/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.0812e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1279/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.0957e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1280/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.1014e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1281/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - loss: 2.0976e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1282/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1137e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1283/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.0924e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1284/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 2.0936e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1285/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - loss: 2.1021e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1286/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.1198e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1287/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.0675e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 1288/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.0597e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1289/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.0946e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1290/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.0886e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 1291/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.1014e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1292/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - loss: 2.0995e-04 - val_loss: 0.0260 - learning_rate: 7.0000e-06\n",
      "Epoch 1293/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.0963e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1294/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1015e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1295/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1177e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1296/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.0999e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1297/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.1453e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1298/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 94ms/step - loss: 2.0930e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1299/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.1085e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1300/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.1024e-04 - val_loss: 0.0271 - learning_rate: 7.0000e-06\n",
      "Epoch 1301/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.0857e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1302/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 2.0957e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1303/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - loss: 2.0964e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1304/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.0466e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1305/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.0583e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1306/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.0782e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1307/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.0804e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1308/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 2.1028e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1309/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.0523e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1310/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.0940e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1311/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.0726e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1312/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - loss: 2.0714e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1313/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - loss: 2.0471e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1314/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 2.0836e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1315/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.0509e-04 - val_loss: 0.0272 - learning_rate: 7.0000e-06\n",
      "Epoch 1316/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.0823e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1317/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.0622e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1318/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.0641e-04 - val_loss: 0.0272 - learning_rate: 7.0000e-06\n",
      "Epoch 1319/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.0722e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1320/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.0582e-04 - val_loss: 0.0272 - learning_rate: 7.0000e-06\n",
      "Epoch 1321/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 2.0766e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1322/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.0882e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1323/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 2.0579e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1324/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 2.0621e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1325/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.0395e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1326/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.0709e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1327/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - loss: 2.0709e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1328/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.0554e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1329/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.0876e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1330/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.0598e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1331/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.0368e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1332/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 2.0589e-04 - val_loss: 0.0271 - learning_rate: 7.0000e-06\n",
      "Epoch 1333/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.0698e-04 - val_loss: 0.0272 - learning_rate: 7.0000e-06\n",
      "Epoch 1334/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.0352e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1335/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.0652e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1336/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 2.0430e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1337/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.0392e-04 - val_loss: 0.0272 - learning_rate: 7.0000e-06\n",
      "Epoch 1338/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0728e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1339/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0740e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1340/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.0416e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1341/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - loss: 2.0673e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1342/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0534e-04 - val_loss: 0.0271 - learning_rate: 7.0000e-06\n",
      "Epoch 1343/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.0491e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1344/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0697e-04 - val_loss: 0.0274 - learning_rate: 7.0000e-06\n",
      "Epoch 1345/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0611e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1346/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.0699e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1347/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 2.0586e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1348/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 2.0370e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1349/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 2.0479e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1350/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 98ms/step - loss: 2.0483e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1351/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.0736e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1352/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0344e-04 - val_loss: 0.0261 - learning_rate: 7.0000e-06\n",
      "Epoch 1353/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.0370e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1354/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.0387e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1355/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0433e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1356/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0286e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1357/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0195e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1358/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.0661e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1359/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 2.0705e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1360/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 2.0512e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1361/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.0405e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1362/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0278e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1363/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.0314e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1364/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0249e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1365/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0377e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1366/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0251e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1367/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.0065e-04 - val_loss: 0.0265 - learning_rate: 7.0000e-06\n",
      "Epoch 1368/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0502e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1369/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 00:42:45.141213: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0297e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1370/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0511e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1371/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.0505e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1372/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0508e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1373/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.0015e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1374/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.0419e-04 - val_loss: 0.0273 - learning_rate: 7.0000e-06\n",
      "Epoch 1375/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0327e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1376/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.0113e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1377/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0276e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1378/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.0265e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1379/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.0323e-04 - val_loss: 0.0273 - learning_rate: 7.0000e-06\n",
      "Epoch 1380/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.0239e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1381/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 2.0194e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1382/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 2.0165e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1383/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.0229e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1384/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.0245e-04 - val_loss: 0.0272 - learning_rate: 7.0000e-06\n",
      "Epoch 1385/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 2.0360e-04 - val_loss: 0.0262 - learning_rate: 7.0000e-06\n",
      "Epoch 1386/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.0182e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1387/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0206e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1388/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - loss: 2.0060e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1389/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0181e-04 - val_loss: 0.0273 - learning_rate: 7.0000e-06\n",
      "Epoch 1390/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.0199e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1391/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 2.0232e-04 - val_loss: 0.0266 - learning_rate: 7.0000e-06\n",
      "Epoch 1392/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.0035e-04 - val_loss: 0.0268 - learning_rate: 7.0000e-06\n",
      "Epoch 1393/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 2.0248e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1394/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 2.0589e-04 - val_loss: 0.0267 - learning_rate: 7.0000e-06\n",
      "Epoch 1395/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - loss: 2.0164e-04 - val_loss: 0.0264 - learning_rate: 7.0000e-06\n",
      "Epoch 1396/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0112e-04 - val_loss: 0.0270 - learning_rate: 7.0000e-06\n",
      "Epoch 1397/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0165e-04 - val_loss: 0.0269 - learning_rate: 7.0000e-06\n",
      "Epoch 1398/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.0184e-04 - val_loss: 0.0263 - learning_rate: 7.0000e-06\n",
      "Epoch 1399/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 2.0025e-04 - val_loss: 0.0273 - learning_rate: 7.0000e-06\n",
      "Epoch 1400/1400\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.0437e-04 - val_loss: 0.0273 - learning_rate: 7.0000e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with the custom callback\n",
    "history = model_builder.train_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    epochs=1400,\n",
    "    callbacks_list=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the losses from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "train_loss_x_midpoints = history.history.get('x_midpoints_reshape_loss', train_loss)\n",
    "val_loss_x_midpoints = history.history.get('val_x_midpoints_reshape_loss', val_loss)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2,1)\n",
    "plt.plot(train_loss_x_midpoints, label='Train Loss x_midpoints_reshape')\n",
    "plt.plot(val_loss_x_midpoints, label='Validation Loss x_midpoints_reshape')\n",
    "plt.xlabel('Epochs')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder.model.save(\"/home/da886/Analysis/30KFixed_13_Sparsespots.keras\")\n",
    "# loaded_model = tf.keras.models.load_model(\n",
    "# \"/home/da886/Analysis/30KNoFalsePositivesFixed-index6_13__overfitNo.keras\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, batch shape: (800, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728572653.234346 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.235492 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.235580 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.235948 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.236197 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.236413 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.236633 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.236827 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.237062 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.237163 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.237306 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.237568 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.237962 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.238270 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.238282 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.238428 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.238783 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.238938 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.239147 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.239304 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.239618 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.239790 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.240026 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.240249 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.240422 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.240674 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.241009 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.241012 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.241160 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.241664 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.241812 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.241815 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.242186 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.242424 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.242424 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.242720 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.243143 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.243208 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.243369 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.243866 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.243974 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.244066 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.244620 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.244697 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.244719 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.245408 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.245440 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.245609 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.245992 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.246275 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.246381 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.246507 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.246960 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.247239 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.247267 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.247974 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.248050 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.248695 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.249224 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.249929 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.265120 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.265541 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.265840 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.265838 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.266288 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.266366 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.266731 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.266820 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.267096 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.267239 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.267486 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.267625 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.267740 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.267867 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.268051 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.268557 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.268580 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.268647 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.269162 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.269333 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.269333 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.269678 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.269927 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.269975 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.270237 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.270463 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.270517 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.270707 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.271100 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.271133 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.271258 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.271694 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.271836 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.271854 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.272218 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.272499 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.272657 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.272834 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.273201 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.273261 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.273473 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.273769 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.273956 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.274165 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.274526 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.274563 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.274692 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.275115 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.275279 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.275447 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.275614 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.276039 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.276155 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.276305 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.276630 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.276769 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.276943 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.277361 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.277388 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.277515 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.277985 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.278137 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.279097 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.279414 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.279848 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.280020 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.280037 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.280607 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.280824 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.281009 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.281206 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.281384 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.281551 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.281797 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.282022 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.282483 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.282907 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.283323 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.297083 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.297507 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.297828 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.298142 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.298443 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.298761 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.299064 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.299339 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.299625 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.299951 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.300246 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.300290 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.300571 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.300795 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.301218 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.301220 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.301355 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.301750 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.301920 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.301944 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.302215 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.302605 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.302720 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.302725 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.303149 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.303248 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.303378 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.303443 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.303906 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.303979 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.304007 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.304396 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.304466 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.304689 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.304849 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.304952 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.305332 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.305461 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.305662 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.305747 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.306151 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.306153 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.306474 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.306701 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.307188 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.307286 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.307648 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.307830 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.308379 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.308473 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.309022 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.309215 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.309520 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.309760 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.310008 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.310257 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.310767 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.310914 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.311188 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.311568 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.311968 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.312342 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.312711 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.313137 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.313516 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.313858 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.314235 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.314556 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.314899 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.315262 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.315625 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.316015 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.316240 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.316464 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.316666 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.317102 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.317336 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.317363 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.317709 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.317827 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.317927 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.318237 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.318421 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.318448 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.318739 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.318869 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.318952 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.319430 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.319433 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.319453 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.320034 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.320048 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.320165 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.320450 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.320577 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.320947 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.320948 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.321071 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.321363 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.321485 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.321784 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.322062 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.322294 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.322583 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.322692 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.322914 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.323103 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.323386 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.323481 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.323843 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.323946 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.324263 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.324367 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.324677 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.324781 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.325103 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.325202 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.325561 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.325656 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.326045 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.326144 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.326424 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.326746 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.326934 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.327333 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.327871 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.327898 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.328192 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.328471 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.328973 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.329263 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.329551 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.329839 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.330125 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.330413 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.330704 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.331003 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.331301 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.331596 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.331903 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.332213 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.332535 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.332858 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.333023 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.333219 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.333407 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.333608 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.333771 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.333995 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.334181 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.334282 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.334365 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.334679 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.334978 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.334989 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.335088 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.335414 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.335517 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.336036 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.336037 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.336049 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.336502 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.336587 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.337041 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.337058 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.337628 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.337634 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.337645 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.338164 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.338175 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.338449 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.338559 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.338971 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.339236 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.339236 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.339352 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.339635 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.339854 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.340015 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.340479 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.341290 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.341301 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.341886 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.342549 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.342654 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.343144 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.343373 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.343838 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.344073 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.344559 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.345250 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.355375 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.355731 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.356068 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.356234 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.356422 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.356613 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.356801 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.356982 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.357184 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.357505 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.357650 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.357751 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.357886 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.358270 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.358365 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.358547 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.358784 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.359072 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.359153 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.359289 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.359605 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.359824 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.359842 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.360141 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.360460 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.360465 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.360763 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.361070 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.361080 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.361701 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.361716 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.361789 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.362265 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.362268 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.362831 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.362915 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.362929 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.363473 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.363497 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.363805 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.364100 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.364111 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.364645 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.364655 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.365236 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.365250 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.365355 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.365824 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.365836 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.366275 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.366381 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.366790 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.366891 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.366993 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.367276 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.367563 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.367995 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.368008 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.368484 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.368800 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.368810 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.369586 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.370403 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.375739 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.376109 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.376435 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.376734 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.377059 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.377100 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.377649 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.377671 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.378202 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.378215 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.378754 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.378765 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.379320 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.379331 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.379878 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.379889 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.380437 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.380443 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.381010 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.381022 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.381342 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.381755 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.381860 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.382102 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.382453 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.382776 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.383227 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.383786 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.384146 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.384711 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.385154 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.386173 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.386279 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.387195 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.387654 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.388565 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.388936 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.389353 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.389674 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.389993 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.390428 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.390532 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.390843 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.391164 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.391496 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.391851 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.392212 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.392561 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.392904 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.393270 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.393674 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.394089 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.394492 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.394927 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.395355 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.396072 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.396828 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.398059 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.398853 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.406035 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.406459 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.406831 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.407218 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.407574 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.407973 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.408347 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.408718 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.409101 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.409502 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.409912 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.410342 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.410759 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.411233 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.411751 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.412358 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.412432 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.412678 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.413121 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.413196 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.413483 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.413843 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.413972 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.413975 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.414328 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.414437 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.414981 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.415064 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.415078 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.415640 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.415654 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.416219 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.416229 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.416543 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.416852 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.416863 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.417438 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.417449 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.418022 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.418026 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.418641 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.418653 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.418766 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.419265 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.419277 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.419776 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.419859 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.420252 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.420379 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.420465 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.421059 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.421067 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.421724 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.421734 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.422167 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.422576 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.422684 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.423118 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.423549 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.423657 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.424414 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.424800 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.425276 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.425769 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.426518 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.427470 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.429287 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.429933 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.430405 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.430833 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.431362 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.431853 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.432386 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.432867 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.433131 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.433381 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.433572 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.433877 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.434051 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.434522 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.434597 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.435072 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.435148 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.435234 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.435543 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.435732 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.436068 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.436179 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.436565 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.436674 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.437131 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.437143 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.437242 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.437682 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.437779 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.438349 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.438360 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.438963 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.438975 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.439500 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.439516 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.439923 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.440502 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.440513 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.440934 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.441729 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.442378 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.442392 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.444245 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.444246 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.444261 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.445965 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.446067 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.446442 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.447798 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.447808 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.448666 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.449292 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.450463 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.452159 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.452168 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.453081 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.453674 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.498678 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.499097 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.499487 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.500060 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.500078 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.500692 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.500711 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.501350 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.501363 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.501983 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.501995 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.502655 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.502670 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.503301 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.503316 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.503964 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.503976 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.504615 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.504622 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.505297 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.505300 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.505983 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.505993 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.506556 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.506657 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.507016 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.507240 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.507514 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.507832 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.508073 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.508566 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.508673 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.509482 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.509493 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.510111 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.510797 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.510988 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.512261 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.513142 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.514401 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.514830 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.516071 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.524641 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.525201 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.525695 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.525743 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.526322 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.526435 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.527162 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.527175 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.527895 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.527906 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.528680 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.528691 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.529422 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.529433 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.530151 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.530162 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.530948 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.530955 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.531677 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.531689 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.532469 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.532474 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.533036 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.533584 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.534925 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.535268 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.535727 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.536042 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.536217 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.536685 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.537177 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.537539 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.537704 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.538200 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.538767 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.538847 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.539389 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.540012 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.540172 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.540594 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.541231 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.541412 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.541835 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.542468 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.542641 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.543385 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.543693 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.544206 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.544862 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.545088 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.546256 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.546269 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.547314 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.548711 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.552342 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.553694 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.554315 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.556523 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.566290 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.566705 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.567093 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.567523 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.567946 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.568417 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.568898 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.570196 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.571510 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.572821 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.575104 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.576779 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.579052 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.580943 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.620772 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.621215 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.621932 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.622481 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.622949 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.623392 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.623848 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.624295 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.624746 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.625201 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.625598 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.626009 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.626421 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.626833 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.627305 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.627803 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.628352 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.628855 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.629389 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.630046 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.630656 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.632349 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.633998 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.643194 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.643463 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.643614 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.644238 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.644393 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.644407 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.644601 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.645368 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.645379 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.645379 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.645864 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.646126 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.646326 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.646407 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.646696 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.646985 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.647070 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.647264 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.647519 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.647714 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.647893 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.648512 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.648541 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.648643 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.649275 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.649393 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.649484 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.649993 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.650147 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.650229 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.650656 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.650860 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.651022 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.651305 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.651501 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.651947 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.652285 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.652377 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.652669 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.652991 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.653528 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.653980 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.654075 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.654412 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.654872 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.655274 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.655728 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.656254 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.656713 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.657325 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.657779 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.659752 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.660202 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.663367 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.663786 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.663865 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.664104 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.664276 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.664590 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.664902 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.665211 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.665526 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.665822 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.666120 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.666478 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.666849 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.667254 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.667579 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.667962 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.668281 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.668611 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.669034 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.669439 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.670198 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.670818 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.671516 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.672741 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.678238 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.678353 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.678754 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.678876 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.679291 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.679396 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.679891 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.679994 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.680483 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.680584 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.681121 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.681218 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.681551 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.681884 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.681898 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.682086 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.682366 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.682631 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.682892 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.683550 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.683581 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.683585 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.683896 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.684166 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.684622 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.685355 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.685391 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.685460 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.685980 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.686549 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.687204 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.687372 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.687455 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.688458 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.688686 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.688946 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.689719 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.691410 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.691557 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.691667 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.691863 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.692150 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.692434 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.692735 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.693001 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.693456 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.693519 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.693662 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.693813 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.694088 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.694455 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.694733 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.695149 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.695399 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.695574 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.695654 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.696028 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.696364 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.696717 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.697076 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.697789 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.698166 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.698567 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.699019 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.700144 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.700645 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.707006 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.707299 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.707566 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.707839 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.708373 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.708920 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.709475 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.710182 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.710881 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.711456 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.712655 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.714224 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.715182 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.715431 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.715689 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.715967 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.716229 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.716503 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.716766 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.717058 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.717358 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.717676 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.717950 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.718316 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.718699 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.719087 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.719489 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.719930 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.720346 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.720848 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.721395 4086230 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.741082 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.741680 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.741694 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.742305 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.742318 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.742900 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.743012 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.743421 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.743530 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.743865 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.744046 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.744297 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.744473 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.744826 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.744928 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.745478 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.745488 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.746113 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.746129 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.746773 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.746785 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.747358 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.747443 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.747906 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.748013 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.748516 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.748612 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.749094 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.749202 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.749687 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.749799 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.750338 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.750438 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.751146 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.751162 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.751923 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.751931 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.752607 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.752748 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.753405 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.753514 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.754126 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.755343 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.755864 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.756993 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.757518 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.765876 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.766227 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.766495 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.766557 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.767043 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.767264 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.767668 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.767770 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.768290 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.768300 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.769162 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.769338 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.769550 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.769820 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.770059 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.770413 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.770519 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.771102 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.771206 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.771912 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.772019 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.772607 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.772881 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.773465 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.773728 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.774306 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.774861 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.775438 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.776355 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.776929 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.788516 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.788837 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.789298 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.789427 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.789661 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.789965 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.790070 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.790396 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.790503 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.790873 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.790972 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.791432 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.791435 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.791968 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.791979 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.792522 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.792534 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.793063 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.793078 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.793493 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.793608 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.794107 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.794118 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.794719 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.794730 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.795289 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.795292 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.795751 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.795850 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.796412 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.796422 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.796970 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.796979 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.797417 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.797529 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.797955 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.798064 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.798377 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.798813 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.798925 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.799415 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.800189 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.800198 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.801458 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.807401 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.807714 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.807978 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.808247 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.808512 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.808564 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.809025 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.809050 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.809553 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.809570 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.810053 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.810069 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.810362 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.810639 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.810747 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.811138 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.811266 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.811443 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.811878 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.811981 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.812673 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.812685 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.813393 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.813402 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.813951 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.814481 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.814585 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.815580 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.815777 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.816866 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.817399 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.817676 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.817957 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.818244 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.818713 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.818720 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.819200 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.819216 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.819695 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.819710 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.820184 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.820195 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.820691 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.820698 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.820982 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.821166 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.821350 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.821603 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.821711 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.822125 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.822137 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.822555 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.822651 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.823142 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.823153 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.823663 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.823673 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.824179 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.824190 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.824767 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.824781 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.825118 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.825680 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.825692 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.826177 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.826262 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.826662 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.826898 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.827219 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.827323 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.827731 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.828198 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.828387 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.828888 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.829343 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.829840 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.835243 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.835543 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.835817 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.836085 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.836247 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.836651 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.836747 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.836941 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.837311 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.837418 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.837935 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.838039 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.838497 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.838746 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.839056 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.839443 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.839759 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.840032 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.840460 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.841032 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.841251 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.842256 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.842843 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728572653.844029 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.844033 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.844288 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.844555 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.844823 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.845122 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.845312 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.845411 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.845689 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.845806 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.846068 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.846173 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.846457 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.846562 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.846880 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.846984 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.847415 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.847421 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.847905 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.847915 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.848431 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.848441 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.848851 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.848947 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.849138 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.849368 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.849532 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.849869 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.849976 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.850523 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.850534 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.851144 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.851156 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.851796 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.851807 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.852300 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.852408 4086197 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.852999 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728572653.853547 4086210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 3, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 4, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 5, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "Processing batch 6, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 7, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 8, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 9, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 10, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 11, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 12, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 13, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 14, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step \n",
      "Processing batch 15, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 16, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 17, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 18, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 19, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 20, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 21, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 22, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 23, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 24, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 25, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 26, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 27, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 28, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 29, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "Processing batch 30, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the function for visualizing midpoints\n",
    "def visualize_midpoints(image, midpoints, title=\"Predicted Midpoint Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualizes midpoints on an image without using a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "    - title: The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    midpoints_np = midpoints\n",
    "\n",
    "    # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot midpoints directly, only if they are not (0, 0)\n",
    "    for i, (x, y) in enumerate(midpoints_np):\n",
    "        if x >= 3 and y >= 3:  # Only plot if the point is not (0, 0)\n",
    "            plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create the validation dataset\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n",
    "# val_dataset = val_dataset.batch(800)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)\n",
    "# # Initialize lists to collect the data\n",
    "all_images = []\n",
    "all_true_midpoints = []\n",
    "all_pred_midpoints = []\n",
    "\n",
    "# # Loop through each batch in the validation dataset, predict, and collect results\n",
    "# for i, (data_batch, midpoints_batch) in enumerate(val_dataset):\n",
    "\n",
    "for i, (data_batch, midpoints_batch) in enumerate(train_dataset):\n",
    "    print(f\"Processing batch {i + 1}, batch shape: {data_batch.shape}\")\n",
    "    \n",
    "    # Get the model predictions\n",
    "    predictions = model_builder.model.predict(data_batch)\n",
    "\n",
    "    # Extend the lists to store data from each batch\n",
    "    all_images.extend(data_batch.numpy())  # Store all images\n",
    "    all_true_midpoints.extend(midpoints_batch.numpy())  # Store all true midpoints\n",
    "    all_pred_midpoints.extend(predictions)  # Store all predicted midpoints\n",
    "\n",
    "# Convert lists to arrays for easier indexing\n",
    "all_images = np.array(all_images)\n",
    "all_true_midpoints = np.array(all_true_midpoints)\n",
    "all_pred_midpoints = np.array(all_pred_midpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24000, 64, 64), (24000, 1, 13, 2), (24000, 1, 13, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape,all_pred_midpoints.shape,all_true_midpoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select an index to visualize from the entire dataset\n",
    "index_to_visualize = np.random.randint(0, len(all_images))\n",
    "\n",
    "# index_to_visualize = 11548\n",
    "# Visualize the selected image with predicted and true midpoints\n",
    "visualize_midpoints(all_images[index_to_visualize], all_pred_midpoints[index_to_visualize, 0, :, :] * 64, title=\"Predicted Midpoints\")\n",
    "visualize_midpoints(all_images[index_to_visualize], all_true_midpoints[index_to_visualize, 0, :, :] * 64, title=\"Ground Truth Midpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.085455336, 0.8973845)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_pred_midpoints),np.max(all_pred_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.140625, 0.84375)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_true_midpoints),np.max(all_true_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.65831906, 0.14478773],\n",
       "         [0.7904177 , 0.15355638],\n",
       "         [0.17361225, 0.20449938],\n",
       "         [0.66889393, 0.2731334 ],\n",
       "         [0.21128556, 0.29179233],\n",
       "         [0.5561055 , 0.2980113 ],\n",
       "         [0.18257172, 0.34556022],\n",
       "         [0.24933907, 0.37970328],\n",
       "         [0.81192124, 0.44601887],\n",
       "         [0.3674544 , 0.5157404 ],\n",
       "         [0.25184494, 0.56984687],\n",
       "         [0.33452287, 0.86085165],\n",
       "         [0.34384012, 0.8332963 ]]], dtype=float32),\n",
       " array([[[0.65625 , 0.140625],\n",
       "         [0.78125 , 0.15625 ],\n",
       "         [0.1875  , 0.1875  ],\n",
       "         [0.65625 , 0.28125 ],\n",
       "         [0.234375, 0.296875],\n",
       "         [0.546875, 0.296875],\n",
       "         [0.1875  , 0.359375],\n",
       "         [0.234375, 0.375   ],\n",
       "         [0.828125, 0.453125],\n",
       "         [0.359375, 0.515625],\n",
       "         [0.265625, 0.546875],\n",
       "         [0.328125, 0.84375 ],\n",
       "         [0.359375, 0.84375 ]]], dtype=float32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred_midpoints[2],all_true_midpoints[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., 31., 25.],\n",
       "       [ 1., 44., 15.],\n",
       "       [ 1., 13., 15.],\n",
       "       [ 1., 32., 22.],\n",
       "       [ 1., 19., 53.],\n",
       "       [ 1., 44., 17.],\n",
       "       [ 1., 37., 27.],\n",
       "       [ 1., 17., 32.],\n",
       "       [ 1., 28., 26.],\n",
       "       [ 1., 24., 36.],\n",
       "       [ 1., 31., 50.],\n",
       "       [ 1., 14., 46.],\n",
       "       [ 1., 48., 29.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[2],)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables to track the min and max MSE\n",
    "min_mse = float('inf')\n",
    "max_mse = float('-inf')\n",
    "min_mse_index = -1\n",
    "max_mse_index = -1\n",
    "\n",
    "# Loop through each prediction to calculate the MSE\n",
    "for i in range(len(all_pred_midpoints)):\n",
    "    mse = np.mean((all_pred_midpoints[i] - all_true_midpoints[i]) **2)\n",
    "    \n",
    "    if mse < min_mse:\n",
    "        min_mse = mse\n",
    "        min_mse_index = i\n",
    "    \n",
    "    if mse > max_mse:\n",
    "        max_mse = mse\n",
    "        max_mse_index = i\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot an image with its centers\n",
    "def plot_image_with_centers(image, true_center, predicted_center, title):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  # Display the image\n",
    "\n",
    "    # Plot the actual center (Groundtruth)\n",
    "    plt.scatter(true_center[:, 0], true_center[:, 1], color='green', label='Groundtruth', s=10)\n",
    "\n",
    "    # Plot the predicted center\n",
    "    plt.scatter(predicted_center[:, 0], predicted_center[:, 1], color='red', label='Predictions', s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the image with the least MSE\n",
    "plot_image_with_centers(all_images[min_mse_index],\n",
    "                        all_true_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Least MSE. MSE: {min_mse:.4f}')\n",
    "\n",
    "# Plotting the image with the largest MSE\n",
    "plot_image_with_centers(all_images[max_mse_index],\n",
    "                        all_true_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Largest MSE. MSE: {max_mse:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5266"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mse_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
