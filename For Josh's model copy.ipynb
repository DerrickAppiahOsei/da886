{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Set CUDA device order and visible devices\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7,8,9\"\n",
    "\n",
    "# # Set the device\n",
    "# device = '/cpu:0'\n",
    "# if tf.config.experimental.list_physical_devices('GPU'):\n",
    "#     try:\n",
    "#         # Restrict TensorFlow to only use the second GPU\n",
    "#         gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#         if gpus:\n",
    "#             tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "#             device = '/gpu:0'\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "\n",
    "# print(\"device\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 18:31:09.120368: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-11 18:31:09.135383: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-11 18:31:09.148814: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-11 18:31:09.152863: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-11 18:31:09.165444: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-11 18:31:09.791671: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 18:31:11.392889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79196 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:45:00.0, compute capability: 8.0\n",
      "2024-10-11 18:31:11.394456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79196 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:46:00.0, compute capability: 8.0\n",
      "2024-10-11 18:31:11.395876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79194 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:49:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # Only GPUs 0 and 1 will be visible to TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\",\"/gpu:2\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# DataLoader Class Definition\n",
    "# -----------------------------\n",
    "class DataLoader:\n",
    "    def __init__(self, h5_filename):\n",
    "        self.h5_filename = h5_filename\n",
    "        self.images, self.centers = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with h5py.File(self.h5_filename, 'r') as f:\n",
    "            images = np.array(f['images'])\n",
    "            centers = np.array(f['centers_training'])\n",
    "        return images, centers\n",
    "\n",
    "    def plot_image_with_centers(self, image_index=None):\n",
    "        if image_index is None:\n",
    "            image_index = np.random.randint(0, len(self.images))\n",
    "\n",
    "        image = self.images[image_index]\n",
    "        centers = self.centers[image_index]\n",
    "\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        valid_centers = centers[centers[:, 0] == 1]\n",
    "        for center in valid_centers:\n",
    "            plt.scatter(center[1], center[2], c='red', marker='o',s=5)  # center[1] is x and center[2] is y\n",
    "        plt.title('Image with Valid Centers Marked')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_centers(centers):\n",
    "        return centers[np.lexsort((centers[:, 0], centers[:, 1]))]\n",
    "\n",
    "    def normalize_data(self):\n",
    "        normalized_images = self.images / np.max(self.images)\n",
    "        sorted_centers = np.array([self.sort_centers(image_centers[:, 1:]) for image_centers in self.centers])\n",
    "        normalized_centers = sorted_centers / np.max(centers)\n",
    "\n",
    "        normalized_midpoints = tf.expand_dims(normalized_centers, axis=1)\n",
    "        return normalized_images, normalized_midpoints.numpy()\n",
    "\n",
    "    def split_data(self, train_size=0.8, random_state=42):\n",
    "        normalized_images, normalized_midpoints_np = self.normalize_data()\n",
    "        return train_test_split(normalized_images, normalized_midpoints_np, train_size=train_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Utility Function Definition\n",
    "# -----------------------------\n",
    "def plot_transposed_images_with_midpoints(dataset, image_indices=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Extracts multiple images and their midpoints from the given dataset, transposes the images, \n",
    "    corrects the midpoints, and plots the transposed images with the corrected midpoints.\n",
    "\n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The dataset from which to extract the images and midpoints.\n",
    "    - image_indices (list): The indices of the images in the batch to visualize. Default is [0, 1, 2, 3].\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract a sample image batch and its corresponding midpoints from the dataset\n",
    "    sample_image_batch, sample_midpoints_batch = next(iter(dataset))\n",
    "\n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(image_indices):\n",
    "            # Select the specified image and corresponding midpoints from the batch\n",
    "            sample_image = np.array(sample_image_batch[image_indices[i]])\n",
    "            sample_midpoints = np.array(sample_midpoints_batch[image_indices[i]])\n",
    "\n",
    "            # Transpose the image\n",
    "            transposed_image = sample_image.T\n",
    "\n",
    "            # Correct the midpoints by swapping the x and y coordinates\n",
    "            transposed_midpoints_corrected = sample_midpoints[:, :, [1, 0]]\n",
    "\n",
    "            # Plot the transposed image with corrected midpoints\n",
    "            ax.imshow(transposed_image, cmap='gray')\n",
    "            ax.scatter(\n",
    "                transposed_midpoints_corrected[:, :, 0] * 63, \n",
    "                transposed_midpoints_corrected[:, :, 1] * 63, \n",
    "                c='red', marker='o', s=5\n",
    "            )\n",
    "            ax.set_title(f'Image {image_indices[i]} for this batch')\n",
    "        else:\n",
    "            ax.axis('off')  # If fewer than 4 images are requested, hide the unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Loss and Callback Definitions\n",
    "# -----------------------------\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(exponent):\n",
    "    def loss(y_true, y_pred):\n",
    "        diff = tf.abs(y_true - y_pred)\n",
    "        powered_diff = tf.pow(diff, exponent)\n",
    "        return tf.reduce_mean(powered_diff)\n",
    "    return loss\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DynamicExponentCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_exponent, increment, update_frequency):\n",
    "        super().__init__()\n",
    "        self.exponent = initial_exponent\n",
    "        self.increment = increment\n",
    "        self.update_frequency = update_frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.update_frequency == 0:\n",
    "            self.exponent += self.increment\n",
    "            print(f\"\\nEpoch {epoch + 1}: Increasing exponent to {self.exponent}\")\n",
    "            self.model.loss = self.custom_loss(self.exponent)\n",
    "\n",
    "    def custom_loss(self, exponent):\n",
    "        def loss(y_true, y_pred):\n",
    "            diff = tf.abs(y_true - y_pred)\n",
    "            powered_diff = tf.pow(diff, exponent)\n",
    "            return tf.reduce_mean(powered_diff)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'initial_exponent': self.exponent,\n",
    "            'increment': self.increment,\n",
    "            'update_frequency': self.update_frequency,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my NEW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# class ModelBuilder:\n",
    "#     def __init__(self, input_shape=(64, 64, 1), num_classes=3, num_coordinates=2, learning_rate=3e-5, weights_path=None, l2_reg=0.001):\n",
    "#         self.input_shape = input_shape\n",
    "#         self.num_classes = num_classes\n",
    "#         self.num_coordinates = num_coordinates\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.l2_reg = l2_reg\n",
    "#         self.model = self.build_model()\n",
    "\n",
    "#         # Load weights if a path is provided\n",
    "#         if weights_path is not None:\n",
    "#             self.model.load_weights(weights_path)\n",
    "\n",
    "#         self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "#         # self.optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "#     def build_model(self):\n",
    "#         l2 = regularizers.l2(self.l2_reg)\n",
    "        \n",
    "#         x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "#         # First branch\n",
    "#         x_1 = layers.Conv2D(64, kernel_size=6, strides=1, padding='same', activation='relu')(x_input)\n",
    "#         x_1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=3, padding='same', activation='relu', kernel_regularizer=l2)(x_1)\n",
    "#         # x_1 = layers.Dropout(0.1)(x_1)\n",
    "#         # x_1 = layers.BatchNormalization()(x_1)\n",
    "\n",
    "#         # Second branch\n",
    "#         x_2 = layers.Conv2D(32, kernel_size=8, strides=3, padding='same', activation='relu')(x_input)\n",
    "#         x_2 = layers.Conv2D(64, kernel_size=4, strides=1, padding='same', activation='relu')(x_2)\n",
    "#         x_2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_2)\n",
    "#         # x_2 = layers.Dropout(0.1)(x_2)\n",
    "#         # x_2 = layers.BatchNormalization()(x_2)\n",
    "\n",
    "#         # Concatenate branches\n",
    "#         x_3 = layers.concatenate([x_1, x_2])\n",
    "#         x_3 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_3)\n",
    "#         # x_3 = layers.Dropout(0.1)(x_3)\n",
    "#         # x_3 = layers.BatchNormalization()(x_3)\n",
    "\n",
    "#         # Third branch\n",
    "#         x_4 = layers.Conv2D(64, kernel_size=19, strides=5, padding='same', activation='relu', kernel_regularizer=l2)(x_input)\n",
    "        \n",
    "#         # Flatten and concatenate\n",
    "#         x_3 = layers.Flatten()(x_3)\n",
    "#         x_4 = layers.Flatten()(x_4)\n",
    "#         x = layers.Concatenate()([x_3, x_4])\n",
    "\n",
    "#         # Dense layers with L2 regularization\n",
    "#         x = layers.Dense(256, activation='relu', kernel_regularizer=l2)(x)\n",
    "#         # x = layers.Dropout(0.1)(x)\n",
    "\n",
    "#         # Output layer for midpoints\n",
    "#         x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "#         x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "#         return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "#     def compile_model(self, loss_function):\n",
    "#         self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "#     def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "#         history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "#         return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, input_shape=(64, 64, 1), num_classes=13, num_coordinates=2, learning_rate=1e-2, weights_path=None,l1_reg=0.001,l2_reg =0.01):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_coordinates = num_coordinates\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # Load weights if a path is provided\n",
    "        if weights_path is not None:\n",
    "            self.model.load_weights(weights_path)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        # self.optimizer =tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        l1 = regularizers.l1(self.l1_reg)\n",
    "        l2 = regularizers.l2(self.l2_reg)\n",
    "\n",
    "    \n",
    "        x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=5, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        # x = layers.Conv2D(128, kernel_size=5, padding='same', activation='relu')(x)\n",
    "        # # x = layers.MaxPool2D()(x)\n",
    "        # # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='linear', name='x_midpoints')(x)\n",
    "        x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "        return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "    def compile_model(self, loss_function):\n",
    "        self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "    def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "        history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Main Script Execution\n",
    "# -----------------------------\n",
    "\n",
    "# Load data\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_Mixed_13.h5'             \n",
    "h5_filename = '/home/da886/Final Electron counting project/Images and Labels/12KFixed_Mixed_13_SparsespotsRandomIndex.h5'\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_13_SparsespotsRandomIndex.h5'\n",
    "# h5_filename ='/home/da886/Final Electron counting project/Images and Labels/30KFixed-index6_13.h5'\n",
    "data_loader = DataLoader(h5_filename)\n",
    "images, centers = data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f527857d950>, 2806)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=np.random.randint(0,len(centers))\n",
    "data_loader.plot_image_with_centers(l)\n",
    "plt.imshow(images[l]),l\n",
    "# plt.grid(True),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_centers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mmax(\u001b[43msorted_centers\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_centers' is not defined"
     ]
    }
   ],
   "source": [
    "np.max(sorted_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f527840d950>, 2761)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[l]),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., 38., 19.],\n",
       "       [ 1., 45., 33.],\n",
       "       [ 1., 32., 28.],\n",
       "       [ 1., 29., 43.],\n",
       "       [ 1., 40., 63.],\n",
       "       [ 1., 15., 10.],\n",
       "       [ 1., 39., 52.],\n",
       "       [ 1., 48., 11.],\n",
       "       [ 1., 18., 18.],\n",
       "       [ 1., 62., 18.],\n",
       "       [ 1.,  3., 20.],\n",
       "       [ 1., 16., 41.],\n",
       "       [ 1., 30., 25.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.random.randint(0,len(centers))\n",
    "centers[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data and split it into training and validation sets\n",
    "train_images, val_images, train_midpoints, val_midpoints = data_loader.split_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_images), np.max(train_images), np.min(train_midpoints), np.max(train_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: (9600, 64, 64), Train Midpoints: (9600, 1, 13, 2)\n",
      "Validation Images: (2400, 64, 64), Validation Midpoints: (2400, 1, 13, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 400\n",
    "train_dataset = train_dataset.shuffle(buffer_size=8000, reshuffle_each_iteration=True).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=8000).batch(batch_size)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f'Train Images: {train_images.shape}, Train Midpoints: {train_midpoints.shape}')\n",
    "print(f'Validation Images: {val_images.shape}, Validation Midpoints: {val_midpoints.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_transposed_images_with_midpoints(train_dataset, image_indices=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=10, verbose=1, mode='min', min_lr=3e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">26,650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m3,277,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │        \u001b[38;5;34m26,650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m2\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,348,762</span> (39.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,348,762\u001b[0m (39.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,348,250</span> (39.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,348,250\u001b[0m (39.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# dynamic_exponent_callback = DynamicExponentCallback(2, 1, 400)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # Instantiate the model builder\n",
    "    # model_builder = ModelBuilder(weights_path= \"/home/da886/Analysis/30KFixed_13_SparsespotsrandomSPOTS.keras\")\n",
    "    model_builder = ModelBuilder()\n",
    "\n",
    "    # Build the model\n",
    "    model_builder.build_model()\n",
    "\n",
    "    # Display the model architecture\n",
    "    model_builder.model.summary()\n",
    "\n",
    "    # Compile the model using the custom loss function\n",
    "    # model_builder.compile_model(loss_function=dynamic_exponent_callback.custom_loss(2))\n",
    "    model_builder.compile_model(loss_function=tf.keras.losses.MeanSquaredError()) \n",
    "    \n",
    "    # model_builder.compile_model(loss_function=custom_loss(3))e\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 18:33:13.018081: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-11 18:33:13.021443: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-11 18:33:13.050643: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1728671593.097917  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.099891  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.109830  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.163070  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.163161  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.163180  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.163704  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.163886  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.163931  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.170356  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.170388  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.170595  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.191995  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.192305  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.192458  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.194618  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.194730  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.195119  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.195626  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.195636  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.195956  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.196390  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.196565  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.196817  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.198640  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.198712  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.199058  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.216387  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.217452  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.217448  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.217456  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.218292  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.218426  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.218519  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.219233  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.219267  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.219399  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.220106  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.220214  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.220366  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.220798  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.221142  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.221268  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.221604  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.222660  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.223551  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.223564  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.224050  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.226007  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.226042  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.226258  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.228416  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.228426  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.228764  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.230938  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.231012  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.231358  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.233573  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.233654  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.233969  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.236820  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.236914  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.237506  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.238587  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.238620  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.239034  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.239644  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.246527  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.246654  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.246696  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.248857  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.248872  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.249214  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.339845  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.339995  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.340380  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.340562  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.340681  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.341115  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.341307  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.341407  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.341730  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.342126  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.342158  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.342328  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.343037  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.343070  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.343141  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.343978  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.344076  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.344160  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.344997  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.345120  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.345201  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.345994  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.346180  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.346197  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.346855  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.347139  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.347219  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.347736  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.348175  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.348254  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.349095  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.349667  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.349747  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.350455  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.351041  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.351470  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.358139  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.358548  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.358793  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.359156  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.359339  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.359341  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.359760  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.359932  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.359953  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.360374  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.360540  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.360557  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.360999  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.361169  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.361185  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.361628  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.361797  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.361812  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.362285  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.362457  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.362474  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.363438  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.363544  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.364268  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.364398  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.364724  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.364934  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.365155  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.365352  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.365554  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.365746  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.365968  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.366175  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.366380  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.366671  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.366800  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.366978  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.367374  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.367636  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.367912  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.368128  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.368306  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.374884  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.374993  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.375012  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.375562  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.375795  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.375813  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.376121  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.376523  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.376541  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.378222  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.378231  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.378301  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.380287  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.380466  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.380484  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.383069  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.383276  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.383295  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.384202  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.384286  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.384393  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.385132  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.385378  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.385553  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.386197  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.386641  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.386740  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.387327  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.397937  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.398171  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.398407  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.398586  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.398787  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.399067  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.399258  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.399460  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.399654  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.399886  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.400107  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.400318  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.400593  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.400729  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.400898  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.401531  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.401686  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.401787  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.402950  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.403253  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.403353  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.404328  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.404691  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.404791  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.405670  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.406104  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.406202  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.407054  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.407527  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.407703  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.408396  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.408898  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.409073  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.409887  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.410416  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.410588  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.425002  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.425706  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.425709  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.425723  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.426457  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.426541  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.426550  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.427293  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.427366  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.427387  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.428163  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.428172  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.428266  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.429091  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.429160  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.429169  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.429994  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.430015  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.430121  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.430921  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.430946  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.431046  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.432034  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.432044  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.432058  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.433070  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.433085  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.433095  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.433997  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.434017  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.434705  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.435095  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.435175  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.435458  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.436030  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.436122  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.436226  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.437026  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.437062  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.437163  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.438076  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.438104  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.438211  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.439141  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.439158  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.439792  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.440728  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.440908  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.440927  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.441998  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.442018  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.442038  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.443249  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.443265  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.443285  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.444287  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.444417  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.444436  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.445364  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.445384  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.446268  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.446456  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.447324  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.448404  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.448929  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.449971  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.450473  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.451048  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.451507  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.452321  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.452595  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.453347  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.454375  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.454480  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.455338  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.456612  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.464630  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.465404  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.465470  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.466039  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.466481  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.466491  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.466739  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.467394  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.467554  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.467634  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.468141  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.468443  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.468544  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.469277  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.469468  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.469488  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.470398  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.470523  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.471217  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.471927  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.472101  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.472946  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.473121  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.473943  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.474387  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.474802  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.475390  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.475763  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.476780  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.476947  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.477962  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.477981  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.478981  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.479366  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.480145  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.480384  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.481394  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.481869  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.482906  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.483076  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.484309  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.484588  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.485727  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.485827  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.487312  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.488667  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.490297  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.493486  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.495982  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.500268  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.502947  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.505663  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.508967  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.514391  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.515098  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.515299  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.515928  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.516033  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.516954  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.517000  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.517990  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.517995  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.518920  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.519002  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.519764  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.519945  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.520554  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.520637  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.520888  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.521721  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.521901  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.521913  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.522584  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.522912  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.522986  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.523457  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.523892  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.524139  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.524435  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.524907  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.525585  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.525685  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.525917  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.526592  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.526860  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.527039  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.527627  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.527968  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.528299  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.528874  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.529216  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.529978  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.530669  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.530688  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.531233  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.532100  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.532118  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.532580  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.533218  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.533460  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.534093  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.534970  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.535472  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.536334  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.537850  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.538691  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.539526  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.542534  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.543006  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.543816  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.545746  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.546534  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.547241  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.549135  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.549880  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.551828  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.556399  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.560812  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.561396  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.561613  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.561984  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.562912  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.563012  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.563885  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.564158  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.565020  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.565511  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.566540  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.566610  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.566716  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.567985  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.567996  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.569114  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.569295  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.570379  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.570578  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.571769  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.571867  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.572887  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.573130  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.574128  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.577780  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.578749  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.582480  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.583403  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.587203  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.588089  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.591783  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.592631  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.596355  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.597166  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.601435  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.602210  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.606372  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.607100  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.624560  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.625668  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.626892  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.628114  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.629467  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.630767  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.632251  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.633514  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.634881  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.636433  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.638058  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.639716  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.641378  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.644271  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.646381  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.648721  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.650835  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.652729  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.660423  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.663048  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.665355  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.665650  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.665727  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.666466  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.666764  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.667711  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.668001  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.668567  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.668949  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.669249  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.670333  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.670627  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.671654  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.671943  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.673166  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.673450  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.673683  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.674440  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.674723  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.675826  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.676105  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.677416  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.677684  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.679076  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.679332  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.679601  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.680778  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.681021  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.682469  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.682708  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.685428  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.685655  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.687591  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.687809  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.689989  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.690186  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.692155  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.692346  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.694108  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.694113  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.694299  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.695942  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.697555  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.699363  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.701124  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.701839  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.702055  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.703365  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.704512  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.704742  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.705125  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.707190  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.707401  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.707420  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.709409  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.711399  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.712327  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.712564  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.713157  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.718212  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.718451  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.722464  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.731673  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.732625  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.733101  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.734437  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.734920  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.736042  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.736519  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.737841  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.738320  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.739607  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.740092  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.741034  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.741832  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.742329  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.743564  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.744060  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.745553  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.746056  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.747559  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.748073  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.749307  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.749817  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.750096  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.751315  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.751820  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.759164  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.760443  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.760946  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.768964  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.769731  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.770012  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.778464  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.779405  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.779415  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.788384  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.788564  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.797279  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.797634  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.806677  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.807176  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.816542  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.817188  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.894333  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.896155  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.898094  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.899985  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.902071  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.904110  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.906281  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.908342  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.910548  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.912805  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.915395  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.918072  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.921011  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.925349  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.929068  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.933081  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.933222  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.935003  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.935075  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.936844  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.937190  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.937283  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.938812  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.939103  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.940753  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.940828  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.941228  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.942948  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.943303  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.945030  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.945510  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.947236  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.947565  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.949292  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.949788  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.951516  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.952079  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.953822  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.954730  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.954945  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.956460  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.957425  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.959141  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.959863  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.960241  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.961963  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.964446  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.964620  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.966279  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.968089  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.969847  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.970017  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.971971  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.973906  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.975904  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.977885  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.979185  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.981197  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.987154  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.990320  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.993186  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.993511  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.995306  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.996307  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671593.998092  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.000307  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.000482  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.002799  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.003573  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.005086  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.007226  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.010355  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.013592  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.017224  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.020259  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.020875  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.022374  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.023426  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.025564  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.026593  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.028749  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.029361  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.031546  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.033427  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.035645  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.036475  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.038763  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.038970  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.040069  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.042402  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.043247  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.045628  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.046335  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.048810  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.050035  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.052519  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.053830  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.056276  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.057361  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.072466  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.074890  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.075827  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.090749  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.093271  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.093656  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.109092  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.111206  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.111635  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.126751  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.129489  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.129743  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.144865  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.147907  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.148745  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.163422  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.166860  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.182664  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.186216  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.377643  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.380992  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.384120  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.387572  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.391432  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.395052  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.398783  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.402815  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.406689  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.410913  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.414031  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.416066  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.417406  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.419452  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.420532  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.421293  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.422847  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.424000  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.425984  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.426854  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.427936  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.429460  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.431617  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.433174  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.433464  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.435561  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.437203  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.439791  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.440567  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.441056  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.443595  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.445224  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.447708  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.448245  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.448975  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.452773  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.453287  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.455658  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.458158  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.458558  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.463932  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.464034  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.465196  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.469678  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.470237  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.475426  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.476139  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.477827  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.483708  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.484882  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.485878  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.491580  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.493483  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.499097  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.502935  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.506390  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.508741  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.512237  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.518263  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.533528  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.539475  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.539806  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.541147  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.542650  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.544246  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.545891  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.547999  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.549564  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.551400  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.552973  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.554823  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.556639  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.565884  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.566627  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.568266  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.569750  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.571329  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.572938  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.572962  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.574618  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.575067  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.575243  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.576129  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.576621  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.577742  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.578436  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.579380  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.579995  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.581500  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.581830  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.583076  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.583657  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.584523  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.584923  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.586499  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.588352  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.590200  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.592793  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.593907  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.599607  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.601956  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.603356  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.608898  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.611111  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.612897  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.618321  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.620498  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.622962  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.627758  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.629838  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.637230  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.639245  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.646797  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.649234  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.656947  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.750375  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.752101  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.753767  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.755505  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.757375  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.759209  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.761056  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.762991  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.764896  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.766893  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.769285  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.771699  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.774369  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.777402  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.777683  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.779398  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.780771  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.781064  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.782796  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.784217  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.784703  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.786057  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.786576  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.787775  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.788064  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.788448  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.789443  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.790422  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.791188  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.792324  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.792636  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.793080  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.794334  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.794948  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.796865  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.796961  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.797593  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.798932  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.799330  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.800828  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.801997  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.802302  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.802837  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.804988  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.805224  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.807607  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.808395  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.810220  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.811866  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.813163  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.813369  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.815708  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.816530  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.820081  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.820284  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.824008  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.824952  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.828684  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.831140  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.831858  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.832492  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.833140  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.833439  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.833990  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.834628  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.835301  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.835812  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.836071  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.836837  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.837702  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.838456  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.841060  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.843632  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.844471  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.846348  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.849278  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.852502  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.853618  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.854334  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.854964  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.855596  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.855908  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.856748  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.857385  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.858039  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.858794  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.858905  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.859652  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.860499  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.861258  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.862437  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.863151  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.864021  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.864032  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.864677  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.865517  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.866157  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.866577  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.866830  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.867579  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.868339  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.869327  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.869426  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.870098  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.872311  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.872690  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.875240  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.875513  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.877921  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.878405  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.880804  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.881421  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.884014  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.886927  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.889959  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.892284  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.892934  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.893559  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.894233  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.894943  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.895595  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.896260  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.896915  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.897607  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.898297  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.899084  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.899875  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.900813  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.901801  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.902841  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.904103  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.905153  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.906455  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.907815  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.910227  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.914220  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.915126  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.915761  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.916377  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.917066  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.917767  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.918424  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.919089  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.919744  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.920431  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.921130  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.921918  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.922711  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.923749  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.923859  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.924498  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.924932  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.925100  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.925201  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.926050  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.926127  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.926840  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.927352  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.927534  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.928220  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.928559  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.928896  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.929593  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.929884  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.930305  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.931103  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.931894  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.932310  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.932844  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.933860  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.934834  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.934921  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.935304  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.935720  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.936317  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.936457  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.936539  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.936787  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.937520  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.938515  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.938844  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.940965  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.941274  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.943714  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.945244  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.947117  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.947590  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.951383  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.954048  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.955797  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.956772  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.957332  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.957399  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.957761  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.958196  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.958639  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.960339  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.962744  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.964767  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.965219  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.965241  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.965500  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.965935  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.965953  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.966486  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.966564  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.966976  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.967147  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.967455  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.967653  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.968214  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.968387  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.968666  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.969268  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.969285  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.969722  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.970236  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.970717  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.971286  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.971752  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.971924  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.972168  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.973687  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.974286  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.974501  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.974954  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.975829  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.976555  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.977456  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.977533  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.978110  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.978555  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.981232  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.983878  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.984101  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.985617  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.985707  813258 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.986085  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.986533  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.987214  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.987226  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.987701  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.988179  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.988828  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.989277  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.989784  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.990237  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.990754  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.991275  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.991845  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.992422  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.994364  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.994583  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.995219  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.995235  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.995685  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.996127  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.996703  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.996809  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.997188  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.997671  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.997772  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.998204  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.998494  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.998728  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.999179  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.999513  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671594.999735  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671595.000255  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671595.000817  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671595.001392  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671595.003124  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671595.003721  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671595.005077  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671595.005254  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671595.005979  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671595.006532  813290 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671595.006797  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671595.007809  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671595.013322  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671595.014749  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.146561  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.146686  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.147244  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.151605  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.151758  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.151787  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.152418  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.152583  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.152664  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.158182  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.158323  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.158351  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.159028  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.159162  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.159239  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.159677  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.159931  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.159960  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.160219  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.160720  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.160780  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.160917  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.161514  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.161736  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.161764  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.162089  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.162285  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.167267  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.167438  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.167560  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.167920  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.168197  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.168355  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.168595  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.168888  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.169010  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.169234  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.169631  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.169818  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.169932  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.170247  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.170581  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.170764  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.170886  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.171241  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.171563  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.171717  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.171916  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.173175  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.173381  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.173585  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.174966  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.175196  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.175361  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.189878  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.190045  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.190303  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.191926  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.192152  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.192362  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.193861  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.194203  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.194472  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.200833  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.201244  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.201453  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.228417  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.228920  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.229355  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.229867  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.230357  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.231567  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.232409  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.232908  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.232988  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.233425  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.233634  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.234159  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.234238  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.235038  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.235076  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.235205  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.235874  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.235884  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.235907  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.236352  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.236563  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.236919  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.237086  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.237776  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.238305  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.238847  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.238948  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.239391  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.239538  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.240123  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.240813  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.241102  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.241197  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.241422  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.242033  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.242133  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.242340  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.242859  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.242942  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.243191  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.243571  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.243648  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.243756  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.244203  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.244344  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.244424  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.245080  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.245098  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.245209  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.245547  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.246563  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.247172  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.247249  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.247355  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.249481  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.249491  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.249594  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.250384  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.250465  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.250475  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.251374  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.251452  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.251464  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.257038  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.257221  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.257234  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.262635  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.262999  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.263011  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.290798  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.291295  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.291353  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.291757  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.291860  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.292262  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.293586  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.293601  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.293619  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.294355  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.294371  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.294390  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.295136  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.295151  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.295170  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.295813  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.295897  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.295917  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.296441  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.296549  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.296620  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.297088  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.297264  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.297281  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.297726  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.297905  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.297920  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.298471  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.298659  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.298676  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.299066  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.299241  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.299258  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.299651  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.299836  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.299850  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.300152  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.300444  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.300534  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.300731  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.301161  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.301245  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.301353  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.301824  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.302040  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.302049  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.302323  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.302774  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.302815  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.302925  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.303491  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.303604  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.303684  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.304376  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.304412  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.304482  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.305210  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.305248  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.305320  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.306181  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.306194  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.306292  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.306904  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.307016  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.307084  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.307501  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.307678  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.307697  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.308182  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.308386  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.308557  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.308992  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.311070  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.311149  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.311162  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.314593  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.315161  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.315178  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.315905  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.316715  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.316733  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.320149  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.320981  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.321002  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.324044  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.324681  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.324700  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.327565  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.328337  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.328356  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.331025  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.332157  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.332175  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.349495  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.349902  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.350084  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.351778  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.351942  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.351963  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.352550  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.352722  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.352739  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.353684  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.353807  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.353824  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.355018  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.355023  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.355043  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.355949  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.355964  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.355981  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.358461  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.358473  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.358491  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.359595  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.359610  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.359628  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.362040  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.362048  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.362067  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.362994  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.363009  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.363027  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.364008  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.364016  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.364033  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.366625  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.366638  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.366654  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.368862  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.369030  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.369108  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.372418  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.372613  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.372628  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.382028  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.382371  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.382525  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.382690  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.383064  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.383248  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.385298  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.385514  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.385534  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.386027  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.386396  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.386414  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.386679  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.387261  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.387337  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.387444  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.388100  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.388175  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.388281  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.389146  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.389167  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.389270  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.390199  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.390220  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.390322  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.391252  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.391328  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.391339  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.391997  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.392292  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.392303  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.392702  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.393098  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.393192  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.393394  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.393782  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.394014  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.394128  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.394454  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.394765  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.394876  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.395140  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.395535  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.395745  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.395925  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.396444  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.396764  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.396879  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.397492  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.397896  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.398006  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.398541  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.398993  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.399105  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.401320  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.401771  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.401942  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.403859  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.404357  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.404535  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.406386  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.406927  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.407102  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.411412  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.411873  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.412100  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.420745  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.421032  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.421358  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.451228  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.451617  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.451636  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.451867  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.452422  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.452441  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.452657  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.453493  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.453514  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.453618  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.454681  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.454692  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.454688  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.455679  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.455694  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.455800  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.456524  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.456652  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.456670  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.457312  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.457499  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.457517  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.458006  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.458296  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.458313  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.458725  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.459103  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.459119  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.459435  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.459953  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.460135  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.460233  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.460695  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.461274  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.461283  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.461595  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.462323  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.462359  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.462487  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.463412  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.463530  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.463608  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.464392  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.464593  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.464611  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.465309  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.465618  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.465635  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.466369  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.466773  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.466790  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.468906  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.469438  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.469457  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.471291  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.471935  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.471952  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.478675  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.479372  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.479458  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.479485  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.480509  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.480589  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.480608  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.481558  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.481579  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.481600  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.482540  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.482635  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.482718  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.483563  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.483781  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.483814  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.484358  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.484768  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.484789  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.485127  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.485730  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.485848  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.485948  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.486634  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.486963  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.486972  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.487426  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.487865  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.487963  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.488198  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.488739  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.488868  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.489057  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.489536  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.489776  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.489976  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.490323  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.490603  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.490780  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.491267  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.491586  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.491764  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.492260  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.492626  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.492801  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.493161  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.493556  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.493734  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.494053  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.494478  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.494654  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.494896  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.495360  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.495537  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.495848  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.496361  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.496527  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.496739  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.497303  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.497470  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.498351  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.498946  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.499143  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.499354  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.499993  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.500281  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.500401  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.500918  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.501197  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.503565  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.504117  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.504384  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.506689  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.507266  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.507528  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.510339  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.510939  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.511161  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.514026  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.514694  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.514857  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.517719  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.518462  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.518574  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.521414  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.522308  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.522384  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.569219  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.570022  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.570022  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.570724  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.570892  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.570909  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.571457  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.571784  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.571810  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.572144  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.572715  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.572726  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.572933  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.573562  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.573795  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.573888  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.574452  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.574903  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.575004  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.575412  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.576007  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.576100  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.576397  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.577210  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.577347  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.577510  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.578416  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.578591  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.578695  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.579812  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.579995  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.580075  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.580702  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.580954  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.581251  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.582121  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.583704  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.583954  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.585154  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.592885  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.593172  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.594397  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.594502  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.594770  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.596224  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.596267  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.596438  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.598090  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.598095  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.598271  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.599805  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.599987  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.600068  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.601413  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.601713  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.601790  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.602989  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.603421  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.603499  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.604648  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.605043  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.605222  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.606343  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.606706  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.606939  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.608074  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.608410  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.608680  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.609611  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.610282  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.610359  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.611193  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.611862  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.612037  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.613041  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.613446  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.613894  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.615031  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.615303  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.615911  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.617052  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.617307  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.617937  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.619210  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.619387  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.620062  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.621672  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.621771  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.622350  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.624086  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.624627  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.625263  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.627027  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.635359  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.635851  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.637680  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.644564  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.645103  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.646849  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.653706  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.654307  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.656006  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.664061  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.664558  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.666458  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.674025  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.674464  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.676556  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.683684  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.684065  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.686341  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.803048  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.803146  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.804829  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.804928  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.806601  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.806698  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.807515  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.808400  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.808499  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.809158  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.810203  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.810388  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.810791  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.811965  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.812142  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.812460  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.813864  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.814079  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.814250  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.815699  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.816055  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.816131  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.817591  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.818077  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.818149  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.819631  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.820022  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.820194  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.821843  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.821945  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.822291  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.824100  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.824197  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.824416  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.826377  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.826561  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.826802  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.828542  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.829185  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.829413  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.830985  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.831802  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.832041  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.833668  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.834415  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.834706  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.836334  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.837800  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.838150  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.839001  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.841446  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.841908  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.842468  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.845935  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.846276  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.846551  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.850953  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.855074  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.856066  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.860485  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.870280  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.871596  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.872354  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.873684  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.874400  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.875702  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.876099  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.876460  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.877747  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.878197  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.878472  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.879840  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.880478  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.880641  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.881943  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.882695  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.882955  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.884216  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.884970  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.885114  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.886233  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.886966  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.887337  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.888443  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.889127  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.889555  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.890667  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.891165  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.891650  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.892769  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.893394  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.893867  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.895000  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.895633  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.896561  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.897839  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.897923  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.898650  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.899923  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.900175  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.901287  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.902569  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.902917  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.903885  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.905068  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.905240  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.906656  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.907742  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.907997  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.909276  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.910401  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.910598  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.912325  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.913180  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.913633  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.915106  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.915801  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.916408  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.918852  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.920792  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.921652  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.921961  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.923674  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.924822  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.926681  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.927322  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.927842  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.930217  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.933252  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.937431  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.938637  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.944137  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.948177  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.949402  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.955052  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.959331  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.960451  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.966319  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.970447  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.971498  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.977577  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.981563  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.982547  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.988739  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.992679  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.993594  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671598.999833  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.181795  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.182965  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.183467  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.184644  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.185314  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.186506  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.187248  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.188460  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.189223  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.190552  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.190680  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.191753  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.192386  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.193113  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.194253  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.194526  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.195921  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.196229  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.197529  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.198235  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.198954  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.201098  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.201224  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.202391  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.204182  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.204750  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.206077  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.207405  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.208910  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.210384  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.210902  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.211774  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.213265  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.214606  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.218707  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.221424  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.223139  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.224882  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.232883  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.237759  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.239588  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.240823  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.242630  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.243850  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.245637  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.246934  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.247619  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.248742  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.250162  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.250664  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.251946  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.253486  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.253691  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.255235  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.256512  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.256788  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.258230  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.259708  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.259991  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.261286  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.262903  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.263275  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.264659  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.266488  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.266575  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.267798  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.269773  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.269853  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.270903  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.273255  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.274044  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.275070  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.276408  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.277230  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.278263  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.279487  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.281417  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.282416  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.283624  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.285224  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.286206  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.286851  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.289556  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.290522  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.291074  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.294266  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.294934  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.295285  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.299301  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.300430  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.301485  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.304072  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.310264  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.321867  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.322925  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.331795  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.340325  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.341356  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.350211  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.358405  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.359411  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.368300  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.377898  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.379202  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.388266  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.396785  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.398305  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.407637  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.416822  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.418597  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.428177  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.651441  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.654548  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.655611  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.657673  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.658743  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.660870  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.661868  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.664278  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.665072  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.667713  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.667959  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.668469  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.671097  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.671358  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.671846  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.674243  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.674887  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.675527  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.677458  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.678501  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.679186  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.680870  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.682655  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.682948  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.684255  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.687235  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.687252  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.687899  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.691699  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.691859  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.691877  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.695688  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.696067  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.696847  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.699799  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.701131  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.702357  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.704072  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.706708  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.707788  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.708317  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.712155  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.713328  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.713513  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.717634  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.719110  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.720338  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.724864  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.724870  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.727939  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.730432  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.732547  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.737136  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.737506  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.741744  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.745282  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.754531  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.756123  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.760523  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.773369  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.783184  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.787031  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.787451  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.790871  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.791376  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.794707  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.795250  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.798567  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.799117  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.800407  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.802470  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.803004  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.804339  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.806352  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.806938  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.808276  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.810349  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.810803  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.812208  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.814489  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.814813  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.816154  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.818895  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.819063  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.820147  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.822918  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.823473  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.824072  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.827271  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.827513  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.828112  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.831618  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.831864  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.832299  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.835958  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.836203  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.836711  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.839638  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.839884  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.840779  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.843247  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.844240  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.845143  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.847383  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.847838  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.849504  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.851971  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.852342  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.853201  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.856939  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.857589  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.857858  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.861217  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.862474  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.863687  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.865400  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.868326  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.869203  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.870415  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.873854  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.874628  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.875987  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.879289  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.881590  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.881868  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.886279  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.887483  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.888510  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.892974  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.893272  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.894296  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.899091  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.900007  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.900337  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.905164  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.907054  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.912907  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.919004  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.920323  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.925336  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.939445  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.941913  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.947050  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.961262  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.963506  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.968756  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.983013  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.985070  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671599.990303  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.004612  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.006428  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.011835  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.026129  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.033967  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.039626  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.053819  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.408884  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.412049  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.415609  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.418601  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.419292  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.421795  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.423089  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.425385  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.427978  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.429088  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.432910  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.433649  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.434947  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.437811  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.438174  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.439069  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.441797  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.443481  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.444847  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.445539  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.448928  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.449397  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.451172  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.454807  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.455898  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.458243  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.461165  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.461632  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.467176  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.467254  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.468197  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.473107  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.477085  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.477255  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.479478  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.486454  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.487075  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.495205  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.502408  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.506416  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.511662  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.531071  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.550504  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.552389  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.554216  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.556159  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.558058  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.559410  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.559881  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.561290  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.561770  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.563092  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.563790  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.565008  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.565674  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.566891  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.567759  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.568679  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.569598  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.570519  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.571868  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.572513  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.573787  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.574356  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.576146  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.576401  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.578327  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.578620  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.580274  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.580441  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.580785  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.582332  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.582421  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.583452  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.584171  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.584785  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.586111  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.586908  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.587020  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.588016  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.589476  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.589825  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.591678  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.592119  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.593697  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.595725  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.595735  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.597790  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.598302  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.600033  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.601848  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.603708  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.606048  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.606990  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.607991  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.608217  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.610652  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.613268  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.616641  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.616737  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.617453  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.626043  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.628162  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.628452  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.636971  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.637886  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.638990  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.647280  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.647594  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.649298  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.657976  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.658323  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.669041  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.679470  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.768592  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.770459  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.772289  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.774189  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.776168  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.777761  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.778117  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.779643  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.780246  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.781496  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.782322  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.783405  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.784446  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.785403  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.786700  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.787351  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.789006  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.789483  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.791557  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.791673  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.793807  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.794437  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.796072  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.797828  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.798406  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.800051  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.800747  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.800933  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.801942  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.803641  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.803855  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.804071  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.805773  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.807051  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.807772  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.808022  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.809724  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.810045  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.811862  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.812893  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.813167  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.813949  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.816082  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.817117  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.817699  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.818353  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.820707  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.821996  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.823104  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.825950  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.826802  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.827434  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.829321  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.832290  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.835363  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.836424  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.839280  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.844200  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.845191  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.847420  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.849204  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.849616  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.852010  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.853780  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.854067  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.856013  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.856694  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.858218  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.858840  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.859833  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.860641  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.862849  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.862954  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.865507  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.865873  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.868660  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.869363  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.871593  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.872705  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.874527  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.875429  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.876116  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.878040  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.878358  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.879082  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.880562  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.881441  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.882225  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.882976  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.884177  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.885050  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.885380  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.887832  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.887928  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.889118  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.891123  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.891219  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.892852  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.894079  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.894398  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.897075  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.897145  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.898171  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.899773  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.900666  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.901957  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.902502  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.904044  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.906080  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.906816  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.907150  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.908796  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.910524  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.911519  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.911804  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.913718  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.915872  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.916230  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.916902  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.920637  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.921157  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.921179  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.924420  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.925437  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.925533  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.928560  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.930523  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.931296  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.934057  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.934741  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.935668  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.938761  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.943468  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.944984  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.945793  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.947602  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.952679  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.955227  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.956657  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.956927  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.966192  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.967397  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.967501  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.977077  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.977777  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.981367  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.988786  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.991034  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.995295  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671600.999762  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.004972  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.013847  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.027906  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.183989  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.185897  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.187907  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.189963  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.192152  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.194249  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.194821  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.196186  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.197703  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.198229  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.200306  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.200770  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.202519  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.204087  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.205202  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.208072  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.208725  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.211142  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.213260  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.214449  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.218174  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.218717  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.219078  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.220120  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.222156  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.223583  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.224243  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.226460  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.228448  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.229078  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.229250  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.232149  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.235234  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.238556  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.238779  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.243307  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.248063  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.249509  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.253704  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.259734  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.262431  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.263616  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.272798  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.284891  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.285508  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.286673  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.287789  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.288947  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.290132  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.291325  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.292525  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.293626  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.294727  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.295800  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.295897  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.297246  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.297324  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.298335  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.298462  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.298635  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.299624  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.299987  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.300790  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.301639  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.301998  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.303241  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.303424  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.304355  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.304809  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.305470  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.306284  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.306552  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.307877  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.308183  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.309137  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.310470  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.312089  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.313721  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.314031  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.315101  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.316575  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.318458  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.318794  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.321489  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.322664  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.323540  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.323780  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.324214  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.324937  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.326093  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.327283  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.328483  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.328922  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.329086  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.329599  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.330701  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.331772  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.333108  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.333569  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.334524  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.334600  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.335872  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.337505  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.339061  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.339235  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.339924  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.340623  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.342084  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.343977  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.344421  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.349766  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.349944  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.354695  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.359433  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.364976  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.370396  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.375732  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.400416  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.401594  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.402731  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.403929  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.405155  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.406418  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.407692  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.408985  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.410002  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.410341  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.411187  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.411729  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.412330  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.413114  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.413540  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.414893  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.414997  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.416191  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.416589  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.417470  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.418305  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.418780  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.420258  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.420362  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.421644  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.422512  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.423024  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.424673  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.424985  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.426278  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.427979  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.429924  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.429941  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.432083  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.434507  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.436564  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.437762  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.438916  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.439265  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.440137  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.441078  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.441369  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.442453  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.442651  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.443803  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.443977  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.445133  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.445333  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.446506  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.446697  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.448140  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.448216  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.449544  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.449709  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.450164  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.451050  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.451421  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.451603  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.452491  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.452945  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.453126  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.454282  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.454471  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.454863  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.455648  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.456608  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.456779  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.457157  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.458630  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.458726  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.458964  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.460131  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.460842  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.461545  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.461646  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.462361  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.463558  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.464096  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.465645  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.465950  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.466368  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.467576  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.468136  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.469672  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.470029  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.471191  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.472300  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.473086  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.474577  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.474945  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.477270  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.477371  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.477610  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.479012  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.479186  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.480333  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.480923  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.481574  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.481689  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.483061  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.483861  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.484569  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.485930  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.486166  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.486451  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.487449  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.488893  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.490012  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.490851  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.491761  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.492965  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.494915  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.495309  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.497057  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.497360  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.498592  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.500342  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.500963  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.502227  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.502957  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.504443  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.506353  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.506613  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.508613  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.508723  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.511027  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.512256  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.513647  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.515748  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.517253  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.517907  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.522612  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.522882  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.525083  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.528323  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.532192  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.534032  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.539738  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.545556  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.552898  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.560238  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.618045  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.619317  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.620597  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.622049  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.623589  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.625225  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.626956  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.627242  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.628508  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.628807  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.629824  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.631147  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.631338  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.632891  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.633652  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.634557  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.636305  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.636751  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.638186  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.640513  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.642062  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.643053  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.646160  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.648115  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.651509  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.656300  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.656529  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.657763  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.657792  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.659094  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.660560  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.662125  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.663777  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.665540  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.666249  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.667421  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.667726  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.669760  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.672288  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.675415  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.677573  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.680781  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.682461  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.683236  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.683990  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.684772  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.685536  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.686323  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.686947  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.687317  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.688115  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.688939  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.689773  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.690609  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.691470  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.692338  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.693216  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.693368  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.694314  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.694338  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.695081  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.695447  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.695556  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.695853  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.696623  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.696733  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.697462  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.697738  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.698203  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.698960  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.699076  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.699874  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.700586  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.701397  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.702332  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.702347  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.703348  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.703692  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.704209  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.705186  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.705303  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.706191  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.706897  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.707125  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.707708  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.708284  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.710695  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.711480  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.713698  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.713943  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.716501  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.719521  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.720934  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.721817  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.722518  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.722595  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.722763  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.723310  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.723694  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.724056  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.724725  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.724908  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.725818  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.725900  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.726565  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.726993  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.727316  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.728205  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.728223  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.729019  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.729402  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.729743  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.730552  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.731370  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.732362  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.733208  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.734199  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.735079  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.735898  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.736076  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.737225  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.737620  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.739741  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.740433  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.742166  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.742902  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.745073  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.745351  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.748156  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.748393  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.751430  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.752536  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.752769  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.753569  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.754349  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.755132  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.755936  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.756764  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.757095  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.757610  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.758477  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.759347  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.760219  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.761102  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.762174  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.762357  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.763230  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.764335  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.765497  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.766842  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.768201  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.770702  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.773742  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.777494  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.778121  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.778789  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.779445  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.780111  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.780790  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.781432  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.781645  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.782118  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.782237  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.782458  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.782729  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.783321  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.783500  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.783585  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.784168  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.784457  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.784539  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.785090  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.785387  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.785402  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.786274  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.786395  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.786467  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.787564  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.787587  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.787598  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.788627  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.788756  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.788835  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.789895  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.790030  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.790049  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.790939  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.791116  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.791139  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.791835  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.792255  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.792274  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.792894  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.793400  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.793967  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.794165  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.794622  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.795091  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.795653  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.795765  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.796272  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.796807  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.797031  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.797661  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.797886  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.798657  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.799184  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.799196  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.800244  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.800342  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.801599  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.801770  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.802870  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.804105  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.804841  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.805518  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.807161  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.809300  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.811083  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.813354  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.814013  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.814254  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.815062  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.815396  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.816140  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.816156  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.816779  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.817077  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.817189  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.817395  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.818045  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.818210  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.818752  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.819207  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.819467  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.820149  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.820320  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.820337  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.821072  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.821266  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.821820  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.822232  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.822567  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.823102  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.823470  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.823548  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.824202  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.824782  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.825041  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.825953  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.826042  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.827014  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.827144  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.827216  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.828376  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.828450  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.829188  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.829515  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.830741  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.830766  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.830873  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.832068  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.832433  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.833337  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.834580  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.835234  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.835987  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.837641  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.838868  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.839824  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.839928  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.840621  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.841543  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.841727  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.842332  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.843100  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.843790  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.844501  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.844681  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.845329  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.846049  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.846861  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.847749  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.847819  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.848638  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.849395  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.850237  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.850699  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.851138  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.852183  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.853233  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.853646  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.854579  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.855704  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.856833  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.857362  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.858030  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.859602  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.861117  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.861270  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.862844  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.864416  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.865493  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.866379  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.868332  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.870778  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.873047  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.883288  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.884226  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.885164  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.886152  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.887207  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.888293  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.889396  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.890582  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.897313  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.897322  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.897926  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.898602  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.899050  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.899327  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.900112  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.900842  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.901204  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.901498  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.902245  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.903654  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.905979  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.906775  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.907639  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.909595  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.911317  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.911964  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.913781  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.914030  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.914731  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.915664  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.916704  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.916874  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.917959  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.919051  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.920161  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.921361  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.923413  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.923922  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.924406  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.924858  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.925312  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.925801  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.926336  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.926828  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.927330  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.927965  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.928038  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.928506  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.929095  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.929859  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.929932  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.930508  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.931660  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.932095  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.932373  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.932479  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.933013  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.933296  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.933693  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.934115  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.934408  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.934575  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.935221  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.935239  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.935959  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.936137  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.936647  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.937243  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.937497  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.937899  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.937996  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.938694  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.938949  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.939448  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.940159  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.940906  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.941734  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.942307  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.942489  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.942662  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.943729  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.944673  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.945625  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.947492  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.947763  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.948860  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.949985  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.950216  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.950472  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.950938  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.951403  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.951996  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.952096  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.952634  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.953176  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.953789  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.953889  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.954429  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.954964  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.955513  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.956064  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.956632  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.957353  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.957892  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.958537  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.959707  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.960886  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.963542  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.964183  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.964848  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.965509  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.966172  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.966451  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.966855  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.967174  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.967541  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.967817  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.968142  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.968479  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.968782  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.969025  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.969182  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.969746  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.969939  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.970381  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.970593  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.971175  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.971420  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.971476  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.971806  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.972281  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.972372  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.972541  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.973005  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.973308  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.973435  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.973597  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.974337  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.974369  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.974443  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.975285  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.975328  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.975431  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.976025  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.976159  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.976339  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.976678  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.976926  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.977411  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.977527  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.977722  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.978700  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.978716  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.978807  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.979583  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.979802  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.979956  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.980458  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.981397  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.981422  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.981707  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.982783  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.982802  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.983086  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.983720  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.983742  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.984450  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.985178  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.985333  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.986094  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.986993  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.987088  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.987755  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.988633  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.990317  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.993364  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.994209  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.995051  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.995846  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.996619  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.997394  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.998097  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.998803  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671601.999618  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.000340  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.001168  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.002011  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.002594  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.002852  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.003241  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.003254  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.003680  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.003951  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.004030  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.004794  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.004802  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.004905  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.005387  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.005590  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.005755  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.005972  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.006214  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.006585  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.006970  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.007074  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.007281  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.007840  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.008207  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.008215  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.008554  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.009377  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.009544  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.009646  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.010300  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.010801  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.011059  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.011671  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.011998  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.012097  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.012743  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.013485  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.013521  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.013703  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.014582  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.015147  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.015274  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.015461  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.016606  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.016907  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.017006  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.017419  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.018659  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.018946  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.019020  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.020285  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.020645  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.022264  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.024253  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.026670  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.026750  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.027233  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.027618  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.028166  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.028177  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.029269  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.029293  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.029474  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.030194  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.030261  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.031023  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.031091  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.031775  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.031930  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.032664  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.032819  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.033384  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.033841  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.034217  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.034644  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.034954  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.035784  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.036623  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.037453  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.038269  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.038744  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.039146  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.040039  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.041098  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.041901  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.042173  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.043533  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.044677  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.045825  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.047029  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.048649  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.050267  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.051880  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.053626  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.053725  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.054329  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.055007  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.055641  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.055802  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.056589  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.057328  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.057628  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.057984  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.058741  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.060137  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.062490  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.062652  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.064322  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.066302  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.068683  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.070751  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.079626  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.080131  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.080615  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.081071  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.081559  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.082006  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.082496  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.082986  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.083485  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.083969  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.084501  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.085092  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.085732  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.086372  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.086954  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.087789  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.087796  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.088591  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.088683  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.089450  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.089552  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.090376  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.090469  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.091131  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.091350  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.091793  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.092176  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.092563  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.093533  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.094969  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.096357  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.097730  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.098036  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.099997  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.102387  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.104448  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.105448  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.105926  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.106395  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.106862  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.107349  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.107876  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.108442  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.108976  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.109519  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.110060  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.110605  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.111167  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.111742  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.112341  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.112874  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.113365  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.113527  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.113876  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.114366  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.114841  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.114950  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.115442  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.116005  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.116106  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.116513  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.117002  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.117508  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.118002  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.118532  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.119125  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.119763  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.120402  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.121571  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.121745  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.122550  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.122632  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.123201  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.123453  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.123874  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.124276  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.124540  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.125397  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.125409  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.126069  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.126266  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.126724  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.127378  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.127630  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.128064  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.128630  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.129084  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.129401  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.130000  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.130597  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.131237  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.132010  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.132093  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.133326  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.134592  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.135697  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.136802  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.137566  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.139137  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.139884  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.140364  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.140833  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.140942  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.141412  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.141891  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.142630  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.142647  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.143196  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.143730  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.144401  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.144491  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.144962  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.145507  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.146069  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.146642  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.147240  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.147774  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.148425  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.149608  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.150828  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.156532  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.156939  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.157278  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.157484  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.158156  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.158174  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.158752  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.158910  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.159301  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.159563  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.159868  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.160232  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.160485  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.160883  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.161187  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.161541  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.161862  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.162209  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.163106  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.163113  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.163676  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.164361  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.164960  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.165528  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.165631  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.166276  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.166922  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.167145  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.168229  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.168732  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.169507  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.170376  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.170631  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.171747  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.172471  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.172569  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.174153  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.175746  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.177453  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.177835  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.178796  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.179251  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.179343  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.180659  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.181278  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.181921  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.182623  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.183631  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.184647  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.185439  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.188253  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.191460  813272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.191736  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.192304  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.192824  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.193389  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.193933  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.194492  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.195095  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.195785  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.196449  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.197483  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.199760  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.201429  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.203008  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.204633  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.206610  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.211948  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.212897  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.213340  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.214604  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.215219  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.215863  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.216565  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.217579  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.218596  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.219388  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 4/24\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 11.5272"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728671602.222210  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671602.225416  813267 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 6.5500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 18:33:23.387849: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-11 18:33:23.388009: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-10-11 18:33:23.388109: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "W0000 00:00:1728671603.987760  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.988273  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.988863  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.989392  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.989899  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.990416  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.990937  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.991505  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.992032  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.992271  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.992686  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.992927  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.993471  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.994066  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.994620  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.995269  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.995399  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.995511  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.996122  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.996358  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.996364  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.997088  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.997098  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.997245  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.997856  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.997895  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.998098  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.998811  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.999349  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.999469  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671603.999998  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.000170  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.000272  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.000610  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.001092  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.001142  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.001329  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.001902  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.002108  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.002280  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.002518  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.003137  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.003243  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.003346  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.004266  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.004336  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.004507  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.005307  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.005315  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.005310  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.005891  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.006397  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.006521  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.006645  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.007370  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.007569  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.007876  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.008468  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.008569  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.008587  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.008917  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.009499  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.009673  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.009675  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.010648  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.010689  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.010809  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.011541  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.011718  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.012559  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.012726  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.012770  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.013005  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.013805  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.013924  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.013939  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.014760  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.014769  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.014957  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.015518  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.015648  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.016573  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.016810  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.017122  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.017224  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.017519  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.017736  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.017980  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.018528  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.018610  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.019510  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.019708  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.019761  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.020246  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.020772  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.021298  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.021524  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.021665  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.022618  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.022637  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.023066  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.023480  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.023672  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.024178  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.024679  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.025054  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.025198  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.025693  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.026804  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.027004  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.028133  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.028623  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.029637  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.030705  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.032251  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.040470  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.041000  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.041414  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.041889  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.042342  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.042756  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.043201  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.044436  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.046126  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.047989  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.048107  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.048481  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.048893  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.049340  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.049791  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.049946  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.050355  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.050448  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.050569  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.051147  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.051155  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.051608  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.052192  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.052285  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.052470  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.052732  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.053186  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.054310  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.054445  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.054547  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.056399  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.056475  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.056581  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.058506  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.058683  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.060476  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.060588  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.062521  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.062533  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.064485  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.064582  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.066422  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.090411  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.090821  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.091266  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.091713  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.092160  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.092654  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.093166  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.093669  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.094168  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.094669  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.095180  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.095739  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.096315  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.096966  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.097566  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.098204  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.098955  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.099026  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.099384  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.099835  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.100031  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.100303  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.100900  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.101012  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.101240  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.101428  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.101670  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.102193  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.102232  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.102343  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.102900  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.102981  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.103652  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.103663  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.103897  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.104303  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.104397  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.105090  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.105152  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.105253  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.105732  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.105827  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.106499  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.106652  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.107060  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.107329  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.107593  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.107948  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.108170  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.108718  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.108821  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.109394  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.109565  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.110176  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.110402  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.110831  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.111385  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.111500  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.112489  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.112929  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.113092  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.113516  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.113605  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.114202  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.114316  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.114736  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.115441  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.115515  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.115976  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.116435  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.116672  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.116974  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.117477  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.118154  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.118763  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.119430  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.121496  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.121869  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.122394  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.122867  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.123559  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.123641  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.123975  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.124077  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.124605  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.124707  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.125334  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.125342  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.125547  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.126011  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.126112  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.126597  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.126701  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.127133  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.127384  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.127613  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.128110  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.128216  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.128868  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.128951  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.129219  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.129633  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.130241  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.131033  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.131147  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.133078  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.133282  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.133368  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.135166  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.135380  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.135553  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.137269  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.137982  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.138858  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.140995  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.142587  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.144782  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.145003  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.147217  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.147441  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.149666  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.205674  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.206195  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.206723  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.207268  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.207821  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.208361  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.208922  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.209517  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.210127  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.210773  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.211460  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.212123  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.212849  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.213656  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.214500  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.215548  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.215604  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.216143  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.216618  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.216737  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.217296  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.217605  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.217860  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.218590  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.218612  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.218847  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.219295  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.219385  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.219961  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.220062  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.220324  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.220561  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.220735  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.221127  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.221395  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.221681  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.222223  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.222396  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.222414  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.223042  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.223136  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.223980  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.223997  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.224505  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.224717  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.224893  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.225424  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.225754  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.226106  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.226762  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.226885  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.227947  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.227955  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.228847  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.229024  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.229758  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.230482  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.230726  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.231693  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.232444  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.233093  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.233158  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.233796  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.234665  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.234766  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.235137  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.235518  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.236208  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.236932  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.237218  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.237702  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.238485  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.239263  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.240211  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.241108  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.242125  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.243040  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.243330  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.244204  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.244227  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.244884  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.245143  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.245645  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.245971  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.246388  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.246525  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.246709  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.247323  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.247422  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.247656  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.248073  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.248248  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.248718  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.249128  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.249197  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.249463  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.249877  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.250830  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.250848  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.250865  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.251509  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.251779  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.252246  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.252789  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.252911  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.253313  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.254371  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.254449  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.255426  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.256274  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.257812  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.258814  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.259828  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.260478  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.262399  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.263282  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.264954  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.265880  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.267637  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.268434  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.270283  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.274738  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.277449  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.277473  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.278476  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.279446  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.280523  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.281459  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.281971  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.282652  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.283615  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.284887  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.284970  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.286017  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.286348  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.286983  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.288059  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.289193  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.289389  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.295300  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.300639  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.307457  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.314075  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.321190  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.328358  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.342151  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.421561  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.422308  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.423040  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.423735  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.424495  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.425289  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.426165  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.426307  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.426992  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.427175  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.428041  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.428130  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.428830  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.429074  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.429605  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.430014  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.430412  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.430973  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.431209  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.432141  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.432157  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.433078  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.433325  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.434109  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.434611  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.435051  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.436192  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.436203  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.437133  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.437625  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.438323  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.439164  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.439614  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.440956  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.441812  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.442397  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.443922  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.446283  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.446592  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.449777  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.451076  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.454609  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.459419  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.460418  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.461381  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.462449  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.463380  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.464136  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.464556  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.465141  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.465531  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.466120  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.466697  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.467216  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.467754  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.468156  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.468714  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.469357  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.469793  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.470332  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.470904  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.471513  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.472568  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.473519  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.474594  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.475705  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.477009  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.481828  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.482321  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.487184  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.489152  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.494057  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.495765  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.500730  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.502931  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.507975  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.510191  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.515302  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.524091  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.529377  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.610574  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.611675  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.612796  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.613838  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.614978  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.616218  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.617422  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.618629  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.620052  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.621709  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.623182  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.624690  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.626199  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.628159  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.630337  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.632608  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.635062  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.638155  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.640850  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.645794  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.653744  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.666460  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.668113  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.669804  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.671644  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.673277  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.675273  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.676889  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.678968  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.680535  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.682125  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.683958  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.685864  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.696804  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.707113  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.720436  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.733370  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.747039  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.760956  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.789763  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.794173  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.795267  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.796378  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.797420  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.798559  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.799801  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.801001  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.802336  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.802469  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.803600  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.803799  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.804734  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.805479  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.805793  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.807180  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.807192  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.808445  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.808710  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.809665  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.810226  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.810901  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.812339  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.812453  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.814127  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.814521  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.815635  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.816823  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.817186  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.818701  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.819317  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.820690  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.822041  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.822883  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.825203  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.826973  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.827707  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.830443  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.834921  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.835415  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.843399  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.847712  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.849369  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.851075  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.852910  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.854537  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.856155  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.856518  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.857816  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.858133  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.859540  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.860210  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.861397  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.861782  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.863045  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.863371  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.865187  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.865295  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.866825  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.867219  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.868917  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.870492  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.872087  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.873937  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.875849  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.878209  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.886854  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.888559  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.897351  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.901964  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.910923  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.914969  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.924100  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.928896  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.938219  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.943289  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.952585  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.971644  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671604.980897  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.327499  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.329260  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.331021  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.332785  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.334693  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.336647  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.338596  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.340647  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.342779  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.345131  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.347607  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.350113  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.352770  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.356423  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.360001  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.363709  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.368277  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.373678  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.378576  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.397999  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.400836  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.403689  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.407323  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.410240  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.413105  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.415861  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.419171  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.422931  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.425732  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.429018  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.432491  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.454424  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.475648  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.502437  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.513757  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.515513  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.517276  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.519034  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.520956  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.522905  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.524866  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.526940  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.527227  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.528067  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.529165  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.529273  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.530949  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.531684  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.532735  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.534198  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.534685  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.536784  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.536884  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.538771  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.539544  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.540860  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.543033  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.543280  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.545448  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.546925  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.547971  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.550642  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.550746  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.553198  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.553368  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.555379  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.557098  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.560272  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.560743  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.564485  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.569128  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.574102  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.579669  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.580135  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.582508  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.585314  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.588901  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.591855  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.593409  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.594714  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.596270  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.597472  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.599126  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.600801  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.602764  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.604589  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.605752  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.607398  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.608637  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.610704  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.611444  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.614174  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.614838  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.618696  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.621554  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.624919  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.628434  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.636258  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.640324  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.651085  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.657573  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.672814  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.684480  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.700021  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.710265  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.726076  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.735388  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.751608  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.762760  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.779912  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.825327  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671605.843764  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.822200  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.825237  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.828318  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.831421  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.834759  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.838193  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.841646  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.845304  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.849053  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.853288  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.857772  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.862352  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.867437  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.874432  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.881645  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.889075  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.898125  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.908623  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.918272  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.951120  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.952695  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.954253  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.955799  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.957325  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.959268  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.961024  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.962507  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.964531  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.966044  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.967834  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.969701  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.980439  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671606.994280  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.007692  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.018596  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.031446  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.044532  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.073406  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.186299  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.186572  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.189398  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.189761  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.192512  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.192914  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.195659  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.196091  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.199043  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.199482  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.202522  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.202985  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.206039  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.206500  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.209771  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.210244  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.213627  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.214054  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.217975  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.218361  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.222599  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.223134  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.227290  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.228069  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.232439  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.233310  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.239562  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.240528  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.246879  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.247960  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.254551  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.255599  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.263852  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.264891  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.273756  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.274816  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.307010  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.307782  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.308596  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.309361  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.310169  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.310939  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.311718  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.312492  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.313245  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.314022  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.315191  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.315983  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.316947  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.317751  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.318429  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.319249  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.320454  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.321295  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.321953  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.322817  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.323726  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.324619  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.325574  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.326498  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.336177  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.337257  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.349899  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.351010  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.362948  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.364319  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.373769  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.375249  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.386645  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.388361  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.400179  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.401645  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.428480  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.430914  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.590386  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.592091  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.593683  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.595258  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.597013  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.598766  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.600685  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.602429  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.604288  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.606570  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.608868  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.610818  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.613330  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.616990  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.627901  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.631255  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.634667  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.639058  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.643843  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.654513  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.655198  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.655810  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.656548  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.657284  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.658056  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.658822  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.662331  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.666667  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.670306  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.673795  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.677345  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.680713  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.687592  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.807978  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.808619  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.809265  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.809865  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.810459  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.811148  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.811839  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.812466  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.813087  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.813748  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.814413  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.815097  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.815854  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.816607  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.817515  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.818519  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.819541  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.820767  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.822040  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.823457  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.825911  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.829167  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.832958  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.848804  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.849240  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.849677  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.850094  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.850509  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.850928  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.851352  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.851839  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.852568  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.854379  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.856228  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.858998  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.860942  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.864769  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.868170  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.871343  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.886238  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.886686  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.887136  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.887589  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.888055  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.888702  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.889168  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.889679  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.890113  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.890554  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.891062  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.891580  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.892070  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.892631  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.893207  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.893801  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.895579  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.896302  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.897118  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.898136  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.903667  813264 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.947127  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.948806  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.950382  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.951928  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.953704  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.954041  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.955476  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.955734  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.957523  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.957640  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.959391  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.959475  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.961412  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.961511  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.963200  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.963818  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.965116  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.966141  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.966859  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.968120  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.968752  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.970631  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.971064  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.973382  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.974306  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.975363  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.977874  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.981547  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.985340  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.988720  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.992154  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.992614  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.996016  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.996597  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671607.999479  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.003946  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.007033  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.007724  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.008330  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.009073  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.009806  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.010570  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.011336  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.014354  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.014771  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.015043  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.015652  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.016388  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.017118  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.017888  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.018657  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.019010  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.022144  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.022573  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.026010  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.026443  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.029517  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.030069  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.032821  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.033576  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.037123  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.039708  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.040464  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.047414  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.159692  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.160333  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.160970  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.161566  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.162153  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.162837  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.163530  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.164161  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.164786  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.165454  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.166114  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.166801  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.167563  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.168333  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.168604  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.169480  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.169494  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.170143  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.170515  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.170750  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.171342  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.171563  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.172039  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.172963  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.172975  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.173608  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.174354  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.174456  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.175033  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.175701  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.176381  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.176919  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.177162  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.177925  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.178835  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.179859  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.180197  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.180902  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.182132  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.183398  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.184302  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.185873  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.189135  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.193234  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.200026  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.200519  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.200935  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.201377  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.202241  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.204042  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.205882  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.208648  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.208909  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.209384  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.209801  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 266ms/step - loss: 6.4152 - val_loss: 7.6049 - learning_rate: 0.0100\n",
      "Epoch 2/1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728671608.210240  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.210644  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.211123  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.212615  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.212935  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.214789  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.216444  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.217562  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.219100  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.219551  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.221517  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.225347  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.227996  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.234009  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.234463  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.234918  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.235354  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.235820  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.236468  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.236933  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.237451  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.237874  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.238320  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.238828  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.239344  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.239869  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.240429  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.241004  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.241595  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.242948  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.243548  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.243641  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.244219  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.244316  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.244675  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.245289  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.245385  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.246037  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.246446  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.246545  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.247063  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.247491  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.247934  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.248447  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.248969  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.249505  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.250067  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.250644  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.251241  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.252003  813293 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.253032  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.253770  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.254590  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.255612  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728671608.261159  813288 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-10-11 18:33:28.321447: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.2598"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 18:33:30.005281: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.2581 - val_loss: 0.3621 - learning_rate: 0.0100\n",
      "Epoch 3/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 0.1340 - val_loss: 0.2373 - learning_rate: 0.0100\n",
      "Epoch 4/1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 18:33:34.279822: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.1138 - val_loss: 0.1994 - learning_rate: 0.0100\n",
      "Epoch 5/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 0.0976 - val_loss: 0.2528 - learning_rate: 0.0100\n",
      "Epoch 6/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 18:33:41.167263: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0915 - val_loss: 0.1390 - learning_rate: 0.0100\n",
      "Epoch 7/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 0.0908 - val_loss: 0.1193 - learning_rate: 0.0100\n",
      "Epoch 8/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0911 - val_loss: 0.0917 - learning_rate: 0.0100\n",
      "Epoch 9/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0886 - val_loss: 0.0899 - learning_rate: 0.0100\n",
      "Epoch 10/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0873 - val_loss: 0.0893 - learning_rate: 0.0100\n",
      "Epoch 11/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0843 - val_loss: 0.0868 - learning_rate: 0.0100\n",
      "Epoch 12/1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 18:33:56.021677: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0809 - val_loss: 0.0807 - learning_rate: 0.0100\n",
      "Epoch 13/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.0766 - val_loss: 0.0875 - learning_rate: 0.0100\n",
      "Epoch 14/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 0.0749 - val_loss: 0.0957 - learning_rate: 0.0100\n",
      "Epoch 15/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0706 - val_loss: 0.0912 - learning_rate: 0.0100\n",
      "Epoch 16/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0710 - val_loss: 0.0853 - learning_rate: 0.0100\n",
      "Epoch 17/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0668 - val_loss: 0.0712 - learning_rate: 0.0100\n",
      "Epoch 18/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 0.0629 - val_loss: 0.1002 - learning_rate: 0.0100\n",
      "Epoch 19/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0653 - val_loss: 0.2275 - learning_rate: 0.0100\n",
      "Epoch 20/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0567 - val_loss: 0.1298 - learning_rate: 0.0100\n",
      "Epoch 21/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0612 - val_loss: 0.0516 - learning_rate: 0.0100\n",
      "Epoch 22/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0587"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 18:34:26.004300: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0584 - val_loss: 0.0818 - learning_rate: 0.0100\n",
      "Epoch 23/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0534 - val_loss: 0.0531 - learning_rate: 0.0100\n",
      "Epoch 24/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0507 - val_loss: 0.0644 - learning_rate: 0.0100\n",
      "Epoch 25/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0551 - val_loss: 0.0539 - learning_rate: 0.0100\n",
      "Epoch 26/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 0.0513 - val_loss: 0.0772 - learning_rate: 0.0100\n",
      "Epoch 27/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0554 - val_loss: 0.0477 - learning_rate: 0.0100\n",
      "Epoch 28/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 0.0494 - val_loss: 0.0593 - learning_rate: 0.0100\n",
      "Epoch 29/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0496 - val_loss: 0.0549 - learning_rate: 0.0100\n",
      "Epoch 30/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0511 - val_loss: 0.0458 - learning_rate: 0.0100\n",
      "Epoch 31/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0507 - val_loss: 0.0575 - learning_rate: 0.0100\n",
      "Epoch 32/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 0.0502 - val_loss: 0.0558 - learning_rate: 0.0100\n",
      "Epoch 33/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0464 - val_loss: 0.0923 - learning_rate: 0.0100\n",
      "Epoch 34/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0456 - val_loss: 0.0657 - learning_rate: 0.0100\n",
      "Epoch 35/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0492 - val_loss: 0.0416 - learning_rate: 0.0100\n",
      "Epoch 36/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0531 - val_loss: 0.0583 - learning_rate: 0.0100\n",
      "Epoch 37/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0584 - val_loss: 0.0521 - learning_rate: 0.0100\n",
      "Epoch 38/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0529 - val_loss: 0.0509 - learning_rate: 0.0100\n",
      "Epoch 39/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0481 - val_loss: 0.0494 - learning_rate: 0.0100\n",
      "Epoch 40/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0438 - val_loss: 0.0483 - learning_rate: 0.0100\n",
      "Epoch 41/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0469 - val_loss: 0.0474 - learning_rate: 0.0100\n",
      "Epoch 42/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 0.0472 - val_loss: 0.0543 - learning_rate: 0.0100\n",
      "Epoch 43/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0475 - val_loss: 0.0467 - learning_rate: 0.0100\n",
      "Epoch 44/1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 18:35:24.362500: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0469 - val_loss: 0.0565 - learning_rate: 0.0100\n",
      "Epoch 45/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0489\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0487 - val_loss: 0.0450 - learning_rate: 0.0100\n",
      "Epoch 46/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0451 - val_loss: 0.0480 - learning_rate: 0.0090\n",
      "Epoch 47/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0492 - val_loss: 0.0485 - learning_rate: 0.0090\n",
      "Epoch 48/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0457 - val_loss: 0.0488 - learning_rate: 0.0090\n",
      "Epoch 49/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0424 - val_loss: 0.0396 - learning_rate: 0.0090\n",
      "Epoch 50/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0433 - val_loss: 0.0426 - learning_rate: 0.0090\n",
      "Epoch 51/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0420 - val_loss: 0.0447 - learning_rate: 0.0090\n",
      "Epoch 52/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0434 - val_loss: 0.0486 - learning_rate: 0.0090\n",
      "Epoch 53/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0414 - val_loss: 0.0412 - learning_rate: 0.0090\n",
      "Epoch 54/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0399 - val_loss: 0.0485 - learning_rate: 0.0090\n",
      "Epoch 55/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0426 - val_loss: 0.0458 - learning_rate: 0.0090\n",
      "Epoch 56/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.0446 - val_loss: 0.0435 - learning_rate: 0.0090\n",
      "Epoch 57/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 0.0443 - val_loss: 0.0507 - learning_rate: 0.0090\n",
      "Epoch 58/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0429 - val_loss: 0.0432 - learning_rate: 0.0090\n",
      "Epoch 59/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0413\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 0.0415 - val_loss: 0.0549 - learning_rate: 0.0090\n",
      "Epoch 60/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0437 - val_loss: 0.0416 - learning_rate: 0.0081\n",
      "Epoch 61/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0409 - val_loss: 0.0428 - learning_rate: 0.0081\n",
      "Epoch 62/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0425 - val_loss: 0.0451 - learning_rate: 0.0081\n",
      "Epoch 63/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0417 - val_loss: 0.0407 - learning_rate: 0.0081\n",
      "Epoch 64/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0394 - val_loss: 0.0446 - learning_rate: 0.0081\n",
      "Epoch 65/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0389 - val_loss: 0.0445 - learning_rate: 0.0081\n",
      "Epoch 66/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0404 - val_loss: 0.0416 - learning_rate: 0.0081\n",
      "Epoch 67/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0403 - val_loss: 0.0406 - learning_rate: 0.0081\n",
      "Epoch 68/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0391 - val_loss: 0.0440 - learning_rate: 0.0081\n",
      "Epoch 69/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0413 - val_loss: 0.0388 - learning_rate: 0.0081\n",
      "Epoch 70/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0400 - val_loss: 0.0425 - learning_rate: 0.0081\n",
      "Epoch 71/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0393 - val_loss: 0.0401 - learning_rate: 0.0081\n",
      "Epoch 72/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0386 - val_loss: 0.0421 - learning_rate: 0.0081\n",
      "Epoch 73/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0385 - val_loss: 0.0451 - learning_rate: 0.0081\n",
      "Epoch 74/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0412 - val_loss: 0.0560 - learning_rate: 0.0081\n",
      "Epoch 75/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 0.0403 - val_loss: 0.0453 - learning_rate: 0.0081\n",
      "Epoch 76/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0391 - val_loss: 0.0449 - learning_rate: 0.0081\n",
      "Epoch 77/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0401 - val_loss: 0.0423 - learning_rate: 0.0081\n",
      "Epoch 78/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0385 - val_loss: 0.0623 - learning_rate: 0.0081\n",
      "Epoch 79/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0422\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0423 - val_loss: 0.0487 - learning_rate: 0.0081\n",
      "Epoch 80/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0393 - val_loss: 0.0475 - learning_rate: 0.0073\n",
      "Epoch 81/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0374 - val_loss: 0.0434 - learning_rate: 0.0073\n",
      "Epoch 82/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0359 - val_loss: 0.0436 - learning_rate: 0.0073\n",
      "Epoch 83/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0344 - val_loss: 0.0410 - learning_rate: 0.0073\n",
      "Epoch 84/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0369 - val_loss: 0.0462 - learning_rate: 0.0073\n",
      "Epoch 85/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0364 - val_loss: 0.0397 - learning_rate: 0.0073\n",
      "Epoch 86/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 18:37:23.878609: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0351 - val_loss: 0.0395 - learning_rate: 0.0073\n",
      "Epoch 87/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0357 - val_loss: 0.0401 - learning_rate: 0.0073\n",
      "Epoch 88/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0351 - val_loss: 0.0473 - learning_rate: 0.0073\n",
      "Epoch 89/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0358\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0358 - val_loss: 0.0459 - learning_rate: 0.0073\n",
      "Epoch 90/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0351 - val_loss: 0.0471 - learning_rate: 0.0066\n",
      "Epoch 91/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0327 - val_loss: 0.0485 - learning_rate: 0.0066\n",
      "Epoch 92/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0329 - val_loss: 0.0427 - learning_rate: 0.0066\n",
      "Epoch 93/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 0.0338 - val_loss: 0.0499 - learning_rate: 0.0066\n",
      "Epoch 94/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 0.0339 - val_loss: 0.0408 - learning_rate: 0.0066\n",
      "Epoch 95/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0337 - val_loss: 0.0472 - learning_rate: 0.0066\n",
      "Epoch 96/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0335 - val_loss: 0.0394 - learning_rate: 0.0066\n",
      "Epoch 97/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0336 - val_loss: 0.0644 - learning_rate: 0.0066\n",
      "Epoch 98/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0338 - val_loss: 0.0431 - learning_rate: 0.0066\n",
      "Epoch 99/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0349\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0348 - val_loss: 0.0403 - learning_rate: 0.0066\n",
      "Epoch 100/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0330 - val_loss: 0.0441 - learning_rate: 0.0059\n",
      "Epoch 101/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0342 - val_loss: 0.0395 - learning_rate: 0.0059\n",
      "Epoch 102/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0326 - val_loss: 0.0413 - learning_rate: 0.0059\n",
      "Epoch 103/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - loss: 0.0316 - val_loss: 0.0434 - learning_rate: 0.0059\n",
      "Epoch 104/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 0.0314 - val_loss: 0.0439 - learning_rate: 0.0059\n",
      "Epoch 105/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0316 - val_loss: 0.0432 - learning_rate: 0.0059\n",
      "Epoch 106/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.0308 - val_loss: 0.0462 - learning_rate: 0.0059\n",
      "Epoch 107/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0315 - val_loss: 0.0424 - learning_rate: 0.0059\n",
      "Epoch 108/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0316 - val_loss: 0.0436 - learning_rate: 0.0059\n",
      "Epoch 109/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0353\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0350 - val_loss: 0.0430 - learning_rate: 0.0059\n",
      "Epoch 110/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0294 - val_loss: 0.0437 - learning_rate: 0.0053\n",
      "Epoch 111/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0289 - val_loss: 0.0413 - learning_rate: 0.0053\n",
      "Epoch 112/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0289 - val_loss: 0.0444 - learning_rate: 0.0053\n",
      "Epoch 113/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0290 - val_loss: 0.0441 - learning_rate: 0.0053\n",
      "Epoch 114/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0283 - val_loss: 0.0459 - learning_rate: 0.0053\n",
      "Epoch 115/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0311 - val_loss: 0.0424 - learning_rate: 0.0053\n",
      "Epoch 116/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0342 - val_loss: 0.0433 - learning_rate: 0.0053\n",
      "Epoch 117/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0390 - val_loss: 0.0454 - learning_rate: 0.0053\n",
      "Epoch 118/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0343 - val_loss: 0.0468 - learning_rate: 0.0053\n",
      "Epoch 119/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0312\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 0.004782968759536744.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0310 - val_loss: 0.0481 - learning_rate: 0.0053\n",
      "Epoch 120/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0291 - val_loss: 0.0437 - learning_rate: 0.0048\n",
      "Epoch 121/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0281 - val_loss: 0.0409 - learning_rate: 0.0048\n",
      "Epoch 122/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0273 - val_loss: 0.0427 - learning_rate: 0.0048\n",
      "Epoch 123/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0273 - val_loss: 0.0470 - learning_rate: 0.0048\n",
      "Epoch 124/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0267 - val_loss: 0.0480 - learning_rate: 0.0048\n",
      "Epoch 125/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 0.0264 - val_loss: 0.0445 - learning_rate: 0.0048\n",
      "Epoch 126/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0257 - val_loss: 0.0525 - learning_rate: 0.0048\n",
      "Epoch 127/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0258 - val_loss: 0.0466 - learning_rate: 0.0048\n",
      "Epoch 128/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0261 - val_loss: 0.0452 - learning_rate: 0.0048\n",
      "Epoch 129/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0262\n",
      "Epoch 129: ReduceLROnPlateau reducing learning rate to 0.0043046717997640375.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0260 - val_loss: 0.0463 - learning_rate: 0.0048\n",
      "Epoch 130/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0254 - val_loss: 0.0451 - learning_rate: 0.0043\n",
      "Epoch 131/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0242 - val_loss: 0.0433 - learning_rate: 0.0043\n",
      "Epoch 132/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0242 - val_loss: 0.0472 - learning_rate: 0.0043\n",
      "Epoch 133/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 0.0250 - val_loss: 0.0466 - learning_rate: 0.0043\n",
      "Epoch 134/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0235 - val_loss: 0.0460 - learning_rate: 0.0043\n",
      "Epoch 135/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0233 - val_loss: 0.0476 - learning_rate: 0.0043\n",
      "Epoch 136/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0235 - val_loss: 0.0459 - learning_rate: 0.0043\n",
      "Epoch 137/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0227 - val_loss: 0.0454 - learning_rate: 0.0043\n",
      "Epoch 138/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0219 - val_loss: 0.0466 - learning_rate: 0.0043\n",
      "Epoch 139/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0219\n",
      "Epoch 139: ReduceLROnPlateau reducing learning rate to 0.0038742044940590858.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 0.0217 - val_loss: 0.0471 - learning_rate: 0.0043\n",
      "Epoch 140/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0215 - val_loss: 0.0458 - learning_rate: 0.0039\n",
      "Epoch 141/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0206 - val_loss: 0.0464 - learning_rate: 0.0039\n",
      "Epoch 142/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0211 - val_loss: 0.0486 - learning_rate: 0.0039\n",
      "Epoch 143/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0198 - val_loss: 0.0519 - learning_rate: 0.0039\n",
      "Epoch 144/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0204 - val_loss: 0.0457 - learning_rate: 0.0039\n",
      "Epoch 145/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0200 - val_loss: 0.0484 - learning_rate: 0.0039\n",
      "Epoch 146/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0197 - val_loss: 0.0501 - learning_rate: 0.0039\n",
      "Epoch 147/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 0.0192 - val_loss: 0.0495 - learning_rate: 0.0039\n",
      "Epoch 148/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0185 - val_loss: 0.0489 - learning_rate: 0.0039\n",
      "Epoch 149/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0189\n",
      "Epoch 149: ReduceLROnPlateau reducing learning rate to 0.003486784128472209.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0187 - val_loss: 0.0493 - learning_rate: 0.0039\n",
      "Epoch 150/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0184 - val_loss: 0.0505 - learning_rate: 0.0035\n",
      "Epoch 151/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0179 - val_loss: 0.0488 - learning_rate: 0.0035\n",
      "Epoch 152/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0175 - val_loss: 0.0506 - learning_rate: 0.0035\n",
      "Epoch 153/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0170 - val_loss: 0.0483 - learning_rate: 0.0035\n",
      "Epoch 154/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0166 - val_loss: 0.0493 - learning_rate: 0.0035\n",
      "Epoch 155/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0166 - val_loss: 0.0500 - learning_rate: 0.0035\n",
      "Epoch 156/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0167 - val_loss: 0.0540 - learning_rate: 0.0035\n",
      "Epoch 157/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0167 - val_loss: 0.0557 - learning_rate: 0.0035\n",
      "Epoch 158/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0166 - val_loss: 0.0518 - learning_rate: 0.0035\n",
      "Epoch 159/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0162\n",
      "Epoch 159: ReduceLROnPlateau reducing learning rate to 0.003138105757534504.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0161 - val_loss: 0.0600 - learning_rate: 0.0035\n",
      "Epoch 160/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0153 - val_loss: 0.0494 - learning_rate: 0.0031\n",
      "Epoch 161/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.0149 - val_loss: 0.0519 - learning_rate: 0.0031\n",
      "Epoch 162/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0152 - val_loss: 0.0512 - learning_rate: 0.0031\n",
      "Epoch 163/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.0148 - val_loss: 0.0523 - learning_rate: 0.0031\n",
      "Epoch 164/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0143 - val_loss: 0.0536 - learning_rate: 0.0031\n",
      "Epoch 165/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0140 - val_loss: 0.0524 - learning_rate: 0.0031\n",
      "Epoch 166/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0138 - val_loss: 0.0500 - learning_rate: 0.0031\n",
      "Epoch 167/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0134 - val_loss: 0.0521 - learning_rate: 0.0031\n",
      "Epoch 168/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0136 - val_loss: 0.0522 - learning_rate: 0.0031\n",
      "Epoch 169/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0127\n",
      "Epoch 169: ReduceLROnPlateau reducing learning rate to 0.0028242952656000854.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0125 - val_loss: 0.0539 - learning_rate: 0.0031\n",
      "Epoch 170/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 0.0127 - val_loss: 0.0564 - learning_rate: 0.0028\n",
      "Epoch 171/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0129 - val_loss: 0.0550 - learning_rate: 0.0028\n",
      "Epoch 172/1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 18:41:12.171886: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0126 - val_loss: 0.0545 - learning_rate: 0.0028\n",
      "Epoch 173/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0120 - val_loss: 0.0515 - learning_rate: 0.0028\n",
      "Epoch 174/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0121 - val_loss: 0.0513 - learning_rate: 0.0028\n",
      "Epoch 175/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0117 - val_loss: 0.0552 - learning_rate: 0.0028\n",
      "Epoch 176/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0114 - val_loss: 0.0534 - learning_rate: 0.0028\n",
      "Epoch 177/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0116 - val_loss: 0.0544 - learning_rate: 0.0028\n",
      "Epoch 178/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0114 - val_loss: 0.0534 - learning_rate: 0.0028\n",
      "Epoch 179/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0114\n",
      "Epoch 179: ReduceLROnPlateau reducing learning rate to 0.0025418657809495927.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0113 - val_loss: 0.0562 - learning_rate: 0.0028\n",
      "Epoch 180/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0106 - val_loss: 0.0525 - learning_rate: 0.0025\n",
      "Epoch 181/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0103 - val_loss: 0.0549 - learning_rate: 0.0025\n",
      "Epoch 182/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0101 - val_loss: 0.0532 - learning_rate: 0.0025\n",
      "Epoch 183/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0099 - val_loss: 0.0546 - learning_rate: 0.0025\n",
      "Epoch 184/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0101 - val_loss: 0.0554 - learning_rate: 0.0025\n",
      "Epoch 185/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.0100 - val_loss: 0.0551 - learning_rate: 0.0025\n",
      "Epoch 186/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 0.0096 - val_loss: 0.0548 - learning_rate: 0.0025\n",
      "Epoch 187/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0096 - val_loss: 0.0556 - learning_rate: 0.0025\n",
      "Epoch 188/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0094 - val_loss: 0.0560 - learning_rate: 0.0025\n",
      "Epoch 189/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0094\n",
      "Epoch 189: ReduceLROnPlateau reducing learning rate to 0.0022876791190356016.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0093 - val_loss: 0.0547 - learning_rate: 0.0025\n",
      "Epoch 190/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0087 - val_loss: 0.0528 - learning_rate: 0.0023\n",
      "Epoch 191/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0086 - val_loss: 0.0548 - learning_rate: 0.0023\n",
      "Epoch 192/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0087 - val_loss: 0.0630 - learning_rate: 0.0023\n",
      "Epoch 193/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.0083 - val_loss: 0.0573 - learning_rate: 0.0023\n",
      "Epoch 194/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0087 - val_loss: 0.0577 - learning_rate: 0.0023\n",
      "Epoch 195/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0085 - val_loss: 0.0542 - learning_rate: 0.0023\n",
      "Epoch 196/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0081 - val_loss: 0.0539 - learning_rate: 0.0023\n",
      "Epoch 197/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0077 - val_loss: 0.0568 - learning_rate: 0.0023\n",
      "Epoch 198/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0078 - val_loss: 0.0557 - learning_rate: 0.0023\n",
      "Epoch 199/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0077\n",
      "Epoch 199: ReduceLROnPlateau reducing learning rate to 0.0020589112071320416.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0076 - val_loss: 0.0579 - learning_rate: 0.0023\n",
      "Epoch 200/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0075 - val_loss: 0.0546 - learning_rate: 0.0021\n",
      "Epoch 201/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0071 - val_loss: 0.0594 - learning_rate: 0.0021\n",
      "Epoch 202/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0071 - val_loss: 0.0539 - learning_rate: 0.0021\n",
      "Epoch 203/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0071 - val_loss: 0.0545 - learning_rate: 0.0021\n",
      "Epoch 204/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0069 - val_loss: 0.0576 - learning_rate: 0.0021\n",
      "Epoch 205/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0073 - val_loss: 0.0588 - learning_rate: 0.0021\n",
      "Epoch 206/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0072 - val_loss: 0.0561 - learning_rate: 0.0021\n",
      "Epoch 207/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0067 - val_loss: 0.0623 - learning_rate: 0.0021\n",
      "Epoch 208/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0065 - val_loss: 0.0561 - learning_rate: 0.0021\n",
      "Epoch 209/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0068\n",
      "Epoch 209: ReduceLROnPlateau reducing learning rate to 0.0018530200235545636.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0067 - val_loss: 0.0543 - learning_rate: 0.0021\n",
      "Epoch 210/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0062 - val_loss: 0.0584 - learning_rate: 0.0019\n",
      "Epoch 211/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0063 - val_loss: 0.0528 - learning_rate: 0.0019\n",
      "Epoch 212/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0062 - val_loss: 0.0587 - learning_rate: 0.0019\n",
      "Epoch 213/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0058 - val_loss: 0.0532 - learning_rate: 0.0019\n",
      "Epoch 214/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0059 - val_loss: 0.0569 - learning_rate: 0.0019\n",
      "Epoch 215/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0060 - val_loss: 0.0555 - learning_rate: 0.0019\n",
      "Epoch 216/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0059 - val_loss: 0.0568 - learning_rate: 0.0019\n",
      "Epoch 217/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - loss: 0.0058 - val_loss: 0.0553 - learning_rate: 0.0019\n",
      "Epoch 218/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0059 - val_loss: 0.0585 - learning_rate: 0.0019\n",
      "Epoch 219/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0058\n",
      "Epoch 219: ReduceLROnPlateau reducing learning rate to 0.0016677180421538651.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0058 - val_loss: 0.0561 - learning_rate: 0.0019\n",
      "Epoch 220/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0054 - val_loss: 0.0542 - learning_rate: 0.0017\n",
      "Epoch 221/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 0.0054 - val_loss: 0.0563 - learning_rate: 0.0017\n",
      "Epoch 222/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0051 - val_loss: 0.0564 - learning_rate: 0.0017\n",
      "Epoch 223/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - loss: 0.0051 - val_loss: 0.0566 - learning_rate: 0.0017\n",
      "Epoch 224/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 0.0050 - val_loss: 0.0542 - learning_rate: 0.0017\n",
      "Epoch 225/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0050 - val_loss: 0.0551 - learning_rate: 0.0017\n",
      "Epoch 226/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0049 - val_loss: 0.0583 - learning_rate: 0.0017\n",
      "Epoch 227/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0050 - val_loss: 0.0550 - learning_rate: 0.0017\n",
      "Epoch 228/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 0.0048 - val_loss: 0.0577 - learning_rate: 0.0017\n",
      "Epoch 229/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0052\n",
      "Epoch 229: ReduceLROnPlateau reducing learning rate to 0.0015009462484158575.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0051 - val_loss: 0.0555 - learning_rate: 0.0017\n",
      "Epoch 230/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 0.0046 - val_loss: 0.0583 - learning_rate: 0.0015\n",
      "Epoch 231/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0047 - val_loss: 0.0570 - learning_rate: 0.0015\n",
      "Epoch 232/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0046 - val_loss: 0.0562 - learning_rate: 0.0015\n",
      "Epoch 233/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0045 - val_loss: 0.0598 - learning_rate: 0.0015\n",
      "Epoch 234/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0046 - val_loss: 0.0572 - learning_rate: 0.0015\n",
      "Epoch 235/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0044 - val_loss: 0.0647 - learning_rate: 0.0015\n",
      "Epoch 236/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0042 - val_loss: 0.0562 - learning_rate: 0.0015\n",
      "Epoch 237/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0043 - val_loss: 0.0552 - learning_rate: 0.0015\n",
      "Epoch 238/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0044 - val_loss: 0.0571 - learning_rate: 0.0015\n",
      "Epoch 239/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0045\n",
      "Epoch 239: ReduceLROnPlateau reducing learning rate to 0.0013508516130968928.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0044 - val_loss: 0.0636 - learning_rate: 0.0015\n",
      "Epoch 240/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0042 - val_loss: 0.0668 - learning_rate: 0.0014\n",
      "Epoch 241/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0041 - val_loss: 0.0550 - learning_rate: 0.0014\n",
      "Epoch 242/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 0.0039 - val_loss: 0.0691 - learning_rate: 0.0014\n",
      "Epoch 243/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0038 - val_loss: 0.0567 - learning_rate: 0.0014\n",
      "Epoch 244/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0038 - val_loss: 0.0564 - learning_rate: 0.0014\n",
      "Epoch 245/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0038 - val_loss: 0.0571 - learning_rate: 0.0014\n",
      "Epoch 246/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0039 - val_loss: 0.0560 - learning_rate: 0.0014\n",
      "Epoch 247/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0038 - val_loss: 0.0580 - learning_rate: 0.0014\n",
      "Epoch 248/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0039 - val_loss: 0.0577 - learning_rate: 0.0014\n",
      "Epoch 249/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0037\n",
      "Epoch 249: ReduceLROnPlateau reducing learning rate to 0.0012157664517872036.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0036 - val_loss: 0.0579 - learning_rate: 0.0014\n",
      "Epoch 250/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 0.0038 - val_loss: 0.0580 - learning_rate: 0.0012\n",
      "Epoch 251/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0037 - val_loss: 0.0569 - learning_rate: 0.0012\n",
      "Epoch 252/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0035 - val_loss: 0.0569 - learning_rate: 0.0012\n",
      "Epoch 253/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0036 - val_loss: 0.0569 - learning_rate: 0.0012\n",
      "Epoch 254/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0034 - val_loss: 0.0564 - learning_rate: 0.0012\n",
      "Epoch 255/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0035 - val_loss: 0.0579 - learning_rate: 0.0012\n",
      "Epoch 256/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0032 - val_loss: 0.0579 - learning_rate: 0.0012\n",
      "Epoch 257/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0034 - val_loss: 0.0601 - learning_rate: 0.0012\n",
      "Epoch 258/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0035 - val_loss: 0.0566 - learning_rate: 0.0012\n",
      "Epoch 259/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0035\n",
      "Epoch 259: ReduceLROnPlateau reducing learning rate to 0.0010941897751763463.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0034 - val_loss: 0.0575 - learning_rate: 0.0012\n",
      "Epoch 260/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0035 - val_loss: 0.0585 - learning_rate: 0.0011\n",
      "Epoch 261/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0032 - val_loss: 0.0577 - learning_rate: 0.0011\n",
      "Epoch 262/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0031 - val_loss: 0.0571 - learning_rate: 0.0011\n",
      "Epoch 263/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0030 - val_loss: 0.0564 - learning_rate: 0.0011\n",
      "Epoch 264/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0029 - val_loss: 0.0569 - learning_rate: 0.0011\n",
      "Epoch 265/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0031 - val_loss: 0.0572 - learning_rate: 0.0011\n",
      "Epoch 266/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0031 - val_loss: 0.0590 - learning_rate: 0.0011\n",
      "Epoch 267/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 0.0029 - val_loss: 0.0570 - learning_rate: 0.0011\n",
      "Epoch 268/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0031 - val_loss: 0.0600 - learning_rate: 0.0011\n",
      "Epoch 269/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0030\n",
      "Epoch 269: ReduceLROnPlateau reducing learning rate to 0.0009847708395682275.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0030 - val_loss: 0.0601 - learning_rate: 0.0011\n",
      "Epoch 270/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0030 - val_loss: 0.0583 - learning_rate: 9.8477e-04\n",
      "Epoch 271/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0029 - val_loss: 0.0549 - learning_rate: 9.8477e-04\n",
      "Epoch 272/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0030 - val_loss: 0.0596 - learning_rate: 9.8477e-04\n",
      "Epoch 273/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0030 - val_loss: 0.0565 - learning_rate: 9.8477e-04\n",
      "Epoch 274/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0028 - val_loss: 0.0579 - learning_rate: 9.8477e-04\n",
      "Epoch 275/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0028 - val_loss: 0.0559 - learning_rate: 9.8477e-04\n",
      "Epoch 276/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0028 - val_loss: 0.0569 - learning_rate: 9.8477e-04\n",
      "Epoch 277/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 0.0030 - val_loss: 0.0573 - learning_rate: 9.8477e-04\n",
      "Epoch 278/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 0.0027 - val_loss: 0.0593 - learning_rate: 9.8477e-04\n",
      "Epoch 279/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0029\n",
      "Epoch 279: ReduceLROnPlateau reducing learning rate to 0.0008862937451340258.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0029 - val_loss: 0.0564 - learning_rate: 9.8477e-04\n",
      "Epoch 280/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0028 - val_loss: 0.0562 - learning_rate: 8.8629e-04\n",
      "Epoch 281/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0026 - val_loss: 0.0564 - learning_rate: 8.8629e-04\n",
      "Epoch 282/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0027 - val_loss: 0.0572 - learning_rate: 8.8629e-04\n",
      "Epoch 283/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0025 - val_loss: 0.0598 - learning_rate: 8.8629e-04\n",
      "Epoch 284/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 0.0028 - val_loss: 0.0576 - learning_rate: 8.8629e-04\n",
      "Epoch 285/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0026 - val_loss: 0.0589 - learning_rate: 8.8629e-04\n",
      "Epoch 286/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0027 - val_loss: 0.0633 - learning_rate: 8.8629e-04\n",
      "Epoch 287/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0025 - val_loss: 0.0600 - learning_rate: 8.8629e-04\n",
      "Epoch 288/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0028 - val_loss: 0.0585 - learning_rate: 8.8629e-04\n",
      "Epoch 289/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0026\n",
      "Epoch 289: ReduceLROnPlateau reducing learning rate to 0.0007976643915753812.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0026 - val_loss: 0.0583 - learning_rate: 8.8629e-04\n",
      "Epoch 290/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0026 - val_loss: 0.0570 - learning_rate: 7.9766e-04\n",
      "Epoch 291/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0027 - val_loss: 0.0585 - learning_rate: 7.9766e-04\n",
      "Epoch 292/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0026 - val_loss: 0.0622 - learning_rate: 7.9766e-04\n",
      "Epoch 293/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0024 - val_loss: 0.0567 - learning_rate: 7.9766e-04\n",
      "Epoch 294/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0023 - val_loss: 0.0576 - learning_rate: 7.9766e-04\n",
      "Epoch 295/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0024 - val_loss: 0.0551 - learning_rate: 7.9766e-04\n",
      "Epoch 296/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0024 - val_loss: 0.0572 - learning_rate: 7.9766e-04\n",
      "Epoch 297/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0024 - val_loss: 0.0576 - learning_rate: 7.9766e-04\n",
      "Epoch 298/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0024 - val_loss: 0.0574 - learning_rate: 7.9766e-04\n",
      "Epoch 299/1800\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0024\n",
      "Epoch 299: ReduceLROnPlateau reducing learning rate to 0.0007178979576565325.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0024 - val_loss: 0.0576 - learning_rate: 7.9766e-04\n",
      "Epoch 300/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0023 - val_loss: 0.0564 - learning_rate: 7.1790e-04\n",
      "Epoch 301/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0022 - val_loss: 0.0590 - learning_rate: 7.1790e-04\n",
      "Epoch 302/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0022 - val_loss: 0.0572 - learning_rate: 7.1790e-04\n",
      "Epoch 303/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0022 - val_loss: 0.0578 - learning_rate: 7.1790e-04\n",
      "Epoch 304/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0022 - val_loss: 0.0582 - learning_rate: 7.1790e-04\n",
      "Epoch 305/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0022 - val_loss: 0.0593 - learning_rate: 7.1790e-04\n",
      "Epoch 306/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0022 - val_loss: 0.0571 - learning_rate: 7.1790e-04\n",
      "Epoch 307/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 0.0022 - val_loss: 0.0579 - learning_rate: 7.1790e-04\n",
      "Epoch 308/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0021 - val_loss: 0.0589 - learning_rate: 7.1790e-04\n",
      "Epoch 309/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0022\n",
      "Epoch 309: ReduceLROnPlateau reducing learning rate to 0.0006461081618908793.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0022 - val_loss: 0.0569 - learning_rate: 7.1790e-04\n",
      "Epoch 310/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0022 - val_loss: 0.0580 - learning_rate: 6.4611e-04\n",
      "Epoch 311/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0020 - val_loss: 0.0568 - learning_rate: 6.4611e-04\n",
      "Epoch 312/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0021 - val_loss: 0.0561 - learning_rate: 6.4611e-04\n",
      "Epoch 313/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0019 - val_loss: 0.0590 - learning_rate: 6.4611e-04\n",
      "Epoch 314/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0020 - val_loss: 0.0564 - learning_rate: 6.4611e-04\n",
      "Epoch 315/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 0.0021 - val_loss: 0.0586 - learning_rate: 6.4611e-04\n",
      "Epoch 316/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0021 - val_loss: 0.0600 - learning_rate: 6.4611e-04\n",
      "Epoch 317/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.0022 - val_loss: 0.0563 - learning_rate: 6.4611e-04\n",
      "Epoch 318/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0021 - val_loss: 0.0575 - learning_rate: 6.4611e-04\n",
      "Epoch 319/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0020\n",
      "Epoch 319: ReduceLROnPlateau reducing learning rate to 0.0005814973614178598.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.0020 - val_loss: 0.0620 - learning_rate: 6.4611e-04\n",
      "Epoch 320/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0021 - val_loss: 0.0553 - learning_rate: 5.8150e-04\n",
      "Epoch 321/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0019 - val_loss: 0.0582 - learning_rate: 5.8150e-04\n",
      "Epoch 322/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0019 - val_loss: 0.0549 - learning_rate: 5.8150e-04\n",
      "Epoch 323/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0019 - val_loss: 0.0573 - learning_rate: 5.8150e-04\n",
      "Epoch 324/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0019 - val_loss: 0.0565 - learning_rate: 5.8150e-04\n",
      "Epoch 325/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0018 - val_loss: 0.0562 - learning_rate: 5.8150e-04\n",
      "Epoch 326/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0019 - val_loss: 0.0566 - learning_rate: 5.8150e-04\n",
      "Epoch 327/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0018 - val_loss: 0.0584 - learning_rate: 5.8150e-04\n",
      "Epoch 328/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0019 - val_loss: 0.0587 - learning_rate: 5.8150e-04\n",
      "Epoch 329/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0022\n",
      "Epoch 329: ReduceLROnPlateau reducing learning rate to 0.0005233476462308317.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0022 - val_loss: 0.0569 - learning_rate: 5.8150e-04\n",
      "Epoch 330/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0019 - val_loss: 0.0605 - learning_rate: 5.2335e-04\n",
      "Epoch 331/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0017 - val_loss: 0.0609 - learning_rate: 5.2335e-04\n",
      "Epoch 332/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0018 - val_loss: 0.0579 - learning_rate: 5.2335e-04\n",
      "Epoch 333/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0018 - val_loss: 0.0572 - learning_rate: 5.2335e-04\n",
      "Epoch 334/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0018 - val_loss: 0.0626 - learning_rate: 5.2335e-04\n",
      "Epoch 335/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0018 - val_loss: 0.0567 - learning_rate: 5.2335e-04\n",
      "Epoch 336/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0018 - val_loss: 0.0565 - learning_rate: 5.2335e-04\n",
      "Epoch 337/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - loss: 0.0017 - val_loss: 0.0582 - learning_rate: 5.2335e-04\n",
      "Epoch 338/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 0.0018 - val_loss: 0.0576 - learning_rate: 5.2335e-04\n",
      "Epoch 339/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0017\n",
      "Epoch 339: ReduceLROnPlateau reducing learning rate to 0.0004710128763690591.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0017 - val_loss: 0.0584 - learning_rate: 5.2335e-04\n",
      "Epoch 340/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0017 - val_loss: 0.0570 - learning_rate: 4.7101e-04\n",
      "Epoch 341/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0017 - val_loss: 0.0562 - learning_rate: 4.7101e-04\n",
      "Epoch 342/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0018 - val_loss: 0.0579 - learning_rate: 4.7101e-04\n",
      "Epoch 343/1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 18:48:58.839659: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0018 - val_loss: 0.0563 - learning_rate: 4.7101e-04\n",
      "Epoch 344/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0017 - val_loss: 0.0588 - learning_rate: 4.7101e-04\n",
      "Epoch 345/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0017 - val_loss: 0.0567 - learning_rate: 4.7101e-04\n",
      "Epoch 346/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0017 - val_loss: 0.0574 - learning_rate: 4.7101e-04\n",
      "Epoch 347/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0017 - val_loss: 0.0586 - learning_rate: 4.7101e-04\n",
      "Epoch 348/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0016 - val_loss: 0.0593 - learning_rate: 4.7101e-04\n",
      "Epoch 349/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0017\n",
      "Epoch 349: ReduceLROnPlateau reducing learning rate to 0.0004239115834934637.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0017 - val_loss: 0.0576 - learning_rate: 4.7101e-04\n",
      "Epoch 350/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0017 - val_loss: 0.0590 - learning_rate: 4.2391e-04\n",
      "Epoch 351/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0016 - val_loss: 0.0581 - learning_rate: 4.2391e-04\n",
      "Epoch 352/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0015 - val_loss: 0.0580 - learning_rate: 4.2391e-04\n",
      "Epoch 353/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0016 - val_loss: 0.0595 - learning_rate: 4.2391e-04\n",
      "Epoch 354/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0017 - val_loss: 0.0587 - learning_rate: 4.2391e-04\n",
      "Epoch 355/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0016 - val_loss: 0.0571 - learning_rate: 4.2391e-04\n",
      "Epoch 356/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0017 - val_loss: 0.0573 - learning_rate: 4.2391e-04\n",
      "Epoch 357/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0016 - val_loss: 0.0581 - learning_rate: 4.2391e-04\n",
      "Epoch 358/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0017 - val_loss: 0.0722 - learning_rate: 4.2391e-04\n",
      "Epoch 359/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0017\n",
      "Epoch 359: ReduceLROnPlateau reducing learning rate to 0.0003815204225247726.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 0.0017 - val_loss: 0.0653 - learning_rate: 4.2391e-04\n",
      "Epoch 360/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0016 - val_loss: 0.0622 - learning_rate: 3.8152e-04\n",
      "Epoch 361/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0015 - val_loss: 0.0805 - learning_rate: 3.8152e-04\n",
      "Epoch 362/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0015 - val_loss: 0.0772 - learning_rate: 3.8152e-04\n",
      "Epoch 363/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0016 - val_loss: 0.0636 - learning_rate: 3.8152e-04\n",
      "Epoch 364/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0016 - val_loss: 0.0572 - learning_rate: 3.8152e-04\n",
      "Epoch 365/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0015 - val_loss: 0.0568 - learning_rate: 3.8152e-04\n",
      "Epoch 366/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0016 - val_loss: 0.0564 - learning_rate: 3.8152e-04\n",
      "Epoch 367/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0016 - val_loss: 0.0588 - learning_rate: 3.8152e-04\n",
      "Epoch 368/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0015 - val_loss: 0.0580 - learning_rate: 3.8152e-04\n",
      "Epoch 369/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0016\n",
      "Epoch 369: ReduceLROnPlateau reducing learning rate to 0.0003433683828916401.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0016 - val_loss: 0.0582 - learning_rate: 3.8152e-04\n",
      "Epoch 370/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0015 - val_loss: 0.0578 - learning_rate: 3.4337e-04\n",
      "Epoch 371/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0014 - val_loss: 0.0645 - learning_rate: 3.4337e-04\n",
      "Epoch 372/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0014 - val_loss: 0.0573 - learning_rate: 3.4337e-04\n",
      "Epoch 373/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0014 - val_loss: 0.0569 - learning_rate: 3.4337e-04\n",
      "Epoch 374/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0014 - val_loss: 0.0601 - learning_rate: 3.4337e-04\n",
      "Epoch 375/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0015 - val_loss: 0.0571 - learning_rate: 3.4337e-04\n",
      "Epoch 376/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0014 - val_loss: 0.0589 - learning_rate: 3.4337e-04\n",
      "Epoch 377/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0014 - val_loss: 0.0705 - learning_rate: 3.4337e-04\n",
      "Epoch 378/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0014 - val_loss: 0.0568 - learning_rate: 3.4337e-04\n",
      "Epoch 379/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0015\n",
      "Epoch 379: ReduceLROnPlateau reducing learning rate to 0.0003090315498411656.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - loss: 0.0015 - val_loss: 0.0592 - learning_rate: 3.4337e-04\n",
      "Epoch 380/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0013 - val_loss: 0.0564 - learning_rate: 3.0903e-04\n",
      "Epoch 381/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0014 - val_loss: 0.0580 - learning_rate: 3.0903e-04\n",
      "Epoch 382/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0014 - val_loss: 0.0571 - learning_rate: 3.0903e-04\n",
      "Epoch 383/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0014 - val_loss: 0.0587 - learning_rate: 3.0903e-04\n",
      "Epoch 384/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0014 - val_loss: 0.0647 - learning_rate: 3.0903e-04\n",
      "Epoch 385/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0015 - val_loss: 0.0586 - learning_rate: 3.0903e-04\n",
      "Epoch 386/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0014 - val_loss: 0.0592 - learning_rate: 3.0903e-04\n",
      "Epoch 387/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0014 - val_loss: 0.0559 - learning_rate: 3.0903e-04\n",
      "Epoch 388/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0013 - val_loss: 0.0573 - learning_rate: 3.0903e-04\n",
      "Epoch 389/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0014\n",
      "Epoch 389: ReduceLROnPlateau reducing learning rate to 0.00027812838961835954.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0014 - val_loss: 0.0586 - learning_rate: 3.0903e-04\n",
      "Epoch 390/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0014 - val_loss: 0.0622 - learning_rate: 2.7813e-04\n",
      "Epoch 391/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0013 - val_loss: 0.0578 - learning_rate: 2.7813e-04\n",
      "Epoch 392/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 0.0012 - val_loss: 0.0576 - learning_rate: 2.7813e-04\n",
      "Epoch 393/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0013 - val_loss: 0.0580 - learning_rate: 2.7813e-04\n",
      "Epoch 394/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0014 - val_loss: 0.0573 - learning_rate: 2.7813e-04\n",
      "Epoch 395/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0013 - val_loss: 0.0581 - learning_rate: 2.7813e-04\n",
      "Epoch 396/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0014 - val_loss: 0.0568 - learning_rate: 2.7813e-04\n",
      "Epoch 397/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0013 - val_loss: 0.0585 - learning_rate: 2.7813e-04\n",
      "Epoch 398/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0014 - val_loss: 0.0593 - learning_rate: 2.7813e-04\n",
      "Epoch 399/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0013\n",
      "Epoch 399: ReduceLROnPlateau reducing learning rate to 0.00025031555851455777.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0013 - val_loss: 0.0585 - learning_rate: 2.7813e-04\n",
      "Epoch 400/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 0.0013 - val_loss: 0.0587 - learning_rate: 2.5032e-04\n",
      "Epoch 401/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0013 - val_loss: 0.0649 - learning_rate: 2.5032e-04\n",
      "Epoch 402/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0013 - val_loss: 0.0613 - learning_rate: 2.5032e-04\n",
      "Epoch 403/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0012 - val_loss: 0.0596 - learning_rate: 2.5032e-04\n",
      "Epoch 404/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0012 - val_loss: 0.0552 - learning_rate: 2.5032e-04\n",
      "Epoch 405/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0013 - val_loss: 0.0584 - learning_rate: 2.5032e-04\n",
      "Epoch 406/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 0.0014 - val_loss: 0.0558 - learning_rate: 2.5032e-04\n",
      "Epoch 407/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0013 - val_loss: 0.0580 - learning_rate: 2.5032e-04\n",
      "Epoch 408/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0012 - val_loss: 0.0617 - learning_rate: 2.5032e-04\n",
      "Epoch 409/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0013\n",
      "Epoch 409: ReduceLROnPlateau reducing learning rate to 0.00022528400004375725.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0013 - val_loss: 0.0579 - learning_rate: 2.5032e-04\n",
      "Epoch 410/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0012 - val_loss: 0.0565 - learning_rate: 2.2528e-04\n",
      "Epoch 411/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0012 - val_loss: 0.0589 - learning_rate: 2.2528e-04\n",
      "Epoch 412/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0012 - val_loss: 0.0572 - learning_rate: 2.2528e-04\n",
      "Epoch 413/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0012 - val_loss: 0.0605 - learning_rate: 2.2528e-04\n",
      "Epoch 414/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0011 - val_loss: 0.0581 - learning_rate: 2.2528e-04\n",
      "Epoch 415/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0012 - val_loss: 0.0571 - learning_rate: 2.2528e-04\n",
      "Epoch 416/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0012 - val_loss: 0.0630 - learning_rate: 2.2528e-04\n",
      "Epoch 417/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0012 - val_loss: 0.0584 - learning_rate: 2.2528e-04\n",
      "Epoch 418/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0013 - val_loss: 0.0670 - learning_rate: 2.2528e-04\n",
      "Epoch 419/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0012\n",
      "Epoch 419: ReduceLROnPlateau reducing learning rate to 0.000202755605278071.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0012 - val_loss: 0.0588 - learning_rate: 2.2528e-04\n",
      "Epoch 420/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0012 - val_loss: 0.0578 - learning_rate: 2.0276e-04\n",
      "Epoch 421/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0012 - val_loss: 0.0573 - learning_rate: 2.0276e-04\n",
      "Epoch 422/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 0.0012 - val_loss: 0.0577 - learning_rate: 2.0276e-04\n",
      "Epoch 423/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0011 - val_loss: 0.0579 - learning_rate: 2.0276e-04\n",
      "Epoch 424/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0011 - val_loss: 0.0580 - learning_rate: 2.0276e-04\n",
      "Epoch 425/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0012 - val_loss: 0.0577 - learning_rate: 2.0276e-04\n",
      "Epoch 426/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0011 - val_loss: 0.0640 - learning_rate: 2.0276e-04\n",
      "Epoch 427/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0011 - val_loss: 0.0564 - learning_rate: 2.0276e-04\n",
      "Epoch 428/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0012 - val_loss: 0.0616 - learning_rate: 2.0276e-04\n",
      "Epoch 429/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0012\n",
      "Epoch 429: ReduceLROnPlateau reducing learning rate to 0.00018248004344059154.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0012 - val_loss: 0.0585 - learning_rate: 2.0276e-04\n",
      "Epoch 430/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0011 - val_loss: 0.0585 - learning_rate: 1.8248e-04\n",
      "Epoch 431/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0011 - val_loss: 0.0794 - learning_rate: 1.8248e-04\n",
      "Epoch 432/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 0.0011 - val_loss: 0.0574 - learning_rate: 1.8248e-04\n",
      "Epoch 433/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0011 - val_loss: 0.0585 - learning_rate: 1.8248e-04\n",
      "Epoch 434/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0011 - val_loss: 0.0711 - learning_rate: 1.8248e-04\n",
      "Epoch 435/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0012 - val_loss: 0.0580 - learning_rate: 1.8248e-04\n",
      "Epoch 436/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.0010 - val_loss: 0.0786 - learning_rate: 1.8248e-04\n",
      "Epoch 437/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0011 - val_loss: 0.0583 - learning_rate: 1.8248e-04\n",
      "Epoch 438/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0011 - val_loss: 0.0952 - learning_rate: 1.8248e-04\n",
      "Epoch 439/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0011\n",
      "Epoch 439: ReduceLROnPlateau reducing learning rate to 0.00016423203778686004.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0011 - val_loss: 0.1207 - learning_rate: 1.8248e-04\n",
      "Epoch 440/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0011 - val_loss: 0.0693 - learning_rate: 1.6423e-04\n",
      "Epoch 441/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0011 - val_loss: 0.0625 - learning_rate: 1.6423e-04\n",
      "Epoch 442/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0010 - val_loss: 0.0566 - learning_rate: 1.6423e-04\n",
      "Epoch 443/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0011 - val_loss: 0.0572 - learning_rate: 1.6423e-04\n",
      "Epoch 444/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0011 - val_loss: 0.0567 - learning_rate: 1.6423e-04\n",
      "Epoch 445/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0011 - val_loss: 0.0651 - learning_rate: 1.6423e-04\n",
      "Epoch 446/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0011 - val_loss: 0.0567 - learning_rate: 1.6423e-04\n",
      "Epoch 447/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0011 - val_loss: 0.0591 - learning_rate: 1.6423e-04\n",
      "Epoch 448/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0011 - val_loss: 0.0574 - learning_rate: 1.6423e-04\n",
      "Epoch 449/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0011\n",
      "Epoch 449: ReduceLROnPlateau reducing learning rate to 0.00014780883793719113.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0011 - val_loss: 0.0612 - learning_rate: 1.6423e-04\n",
      "Epoch 450/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0011 - val_loss: 0.0646 - learning_rate: 1.4781e-04\n",
      "Epoch 451/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 0.0011 - val_loss: 0.0565 - learning_rate: 1.4781e-04\n",
      "Epoch 452/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0010 - val_loss: 0.0577 - learning_rate: 1.4781e-04\n",
      "Epoch 453/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0011 - val_loss: 0.0575 - learning_rate: 1.4781e-04\n",
      "Epoch 454/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0010 - val_loss: 0.0750 - learning_rate: 1.4781e-04\n",
      "Epoch 455/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 9.9869e-04 - val_loss: 0.0572 - learning_rate: 1.4781e-04\n",
      "Epoch 456/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 9.8578e-04 - val_loss: 0.0576 - learning_rate: 1.4781e-04\n",
      "Epoch 457/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0011 - val_loss: 0.0573 - learning_rate: 1.4781e-04\n",
      "Epoch 458/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0011 - val_loss: 0.0589 - learning_rate: 1.4781e-04\n",
      "Epoch 459/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0011\n",
      "Epoch 459: ReduceLROnPlateau reducing learning rate to 0.00013302795414347202.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0011 - val_loss: 0.0577 - learning_rate: 1.4781e-04\n",
      "Epoch 460/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0011 - val_loss: 0.0585 - learning_rate: 1.3303e-04\n",
      "Epoch 461/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0010 - val_loss: 0.0578 - learning_rate: 1.3303e-04\n",
      "Epoch 462/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0010 - val_loss: 0.0658 - learning_rate: 1.3303e-04\n",
      "Epoch 463/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0010 - val_loss: 0.0566 - learning_rate: 1.3303e-04\n",
      "Epoch 464/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0010 - val_loss: 0.0563 - learning_rate: 1.3303e-04\n",
      "Epoch 465/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 9.8728e-04 - val_loss: 0.0566 - learning_rate: 1.3303e-04\n",
      "Epoch 466/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0010 - val_loss: 0.0563 - learning_rate: 1.3303e-04\n",
      "Epoch 467/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0011 - val_loss: 0.0581 - learning_rate: 1.3303e-04\n",
      "Epoch 468/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0010 - val_loss: 0.0596 - learning_rate: 1.3303e-04\n",
      "Epoch 469/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0010\n",
      "Epoch 469: ReduceLROnPlateau reducing learning rate to 0.00011972515349043534.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0010 - val_loss: 0.0565 - learning_rate: 1.3303e-04\n",
      "Epoch 470/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 9.9939e-04 - val_loss: 0.0700 - learning_rate: 1.1973e-04\n",
      "Epoch 471/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0010 - val_loss: 0.0575 - learning_rate: 1.1973e-04\n",
      "Epoch 472/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0010 - val_loss: 0.0577 - learning_rate: 1.1973e-04\n",
      "Epoch 473/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0010 - val_loss: 0.0599 - learning_rate: 1.1973e-04\n",
      "Epoch 474/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0010 - val_loss: 0.0617 - learning_rate: 1.1973e-04\n",
      "Epoch 475/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 9.7645e-04 - val_loss: 0.0577 - learning_rate: 1.1973e-04\n",
      "Epoch 476/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 9.7342e-04 - val_loss: 0.0577 - learning_rate: 1.1973e-04\n",
      "Epoch 477/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 9.8462e-04 - val_loss: 0.0571 - learning_rate: 1.1973e-04\n",
      "Epoch 478/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 9.7162e-04 - val_loss: 0.0614 - learning_rate: 1.1973e-04\n",
      "Epoch 479/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0010\n",
      "Epoch 479: ReduceLROnPlateau reducing learning rate to 0.00010775263945106417.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 9.9660e-04 - val_loss: 0.0576 - learning_rate: 1.1973e-04\n",
      "Epoch 480/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 9.5807e-04 - val_loss: 0.0628 - learning_rate: 1.0775e-04\n",
      "Epoch 481/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 9.5419e-04 - val_loss: 0.0556 - learning_rate: 1.0775e-04\n",
      "Epoch 482/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 9.5909e-04 - val_loss: 0.0683 - learning_rate: 1.0775e-04\n",
      "Epoch 483/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 9.7325e-04 - val_loss: 0.0576 - learning_rate: 1.0775e-04\n",
      "Epoch 484/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 9.8683e-04 - val_loss: 0.0777 - learning_rate: 1.0775e-04\n",
      "Epoch 485/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 9.6275e-04 - val_loss: 0.0809 - learning_rate: 1.0775e-04\n",
      "Epoch 486/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 9.3600e-04 - val_loss: 0.0592 - learning_rate: 1.0775e-04\n",
      "Epoch 487/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 9.3232e-04 - val_loss: 0.0804 - learning_rate: 1.0775e-04\n",
      "Epoch 488/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 9.5642e-04 - val_loss: 0.0584 - learning_rate: 1.0775e-04\n",
      "Epoch 489/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 9.8424e-04\n",
      "Epoch 489: ReduceLROnPlateau reducing learning rate to 9.697737550595775e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 9.7312e-04 - val_loss: 0.0579 - learning_rate: 1.0775e-04\n",
      "Epoch 490/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 9.4908e-04 - val_loss: 0.0706 - learning_rate: 9.6977e-05\n",
      "Epoch 491/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 9.5957e-04 - val_loss: 0.0653 - learning_rate: 9.6977e-05\n",
      "Epoch 492/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 9.4095e-04 - val_loss: 0.0589 - learning_rate: 9.6977e-05\n",
      "Epoch 493/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 8.8352e-04 - val_loss: 0.0566 - learning_rate: 9.6977e-05\n",
      "Epoch 494/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 9.2356e-04 - val_loss: 0.0570 - learning_rate: 9.6977e-05\n",
      "Epoch 495/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 9.1378e-04 - val_loss: 0.0860 - learning_rate: 9.6977e-05\n",
      "Epoch 496/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 9.0195e-04 - val_loss: 0.0574 - learning_rate: 9.6977e-05\n",
      "Epoch 497/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 9.1746e-04 - val_loss: 0.0576 - learning_rate: 9.6977e-05\n",
      "Epoch 498/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 9.2193e-04 - val_loss: 0.0694 - learning_rate: 9.6977e-05\n",
      "Epoch 499/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 9.3646e-04\n",
      "Epoch 499: ReduceLROnPlateau reducing learning rate to 8.727963795536197e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 9.2643e-04 - val_loss: 0.0680 - learning_rate: 9.6977e-05\n",
      "Epoch 500/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 9.1734e-04 - val_loss: 0.0565 - learning_rate: 8.7280e-05\n",
      "Epoch 501/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 9.1725e-04 - val_loss: 0.0751 - learning_rate: 8.7280e-05\n",
      "Epoch 502/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 8.6490e-04 - val_loss: 0.0574 - learning_rate: 8.7280e-05\n",
      "Epoch 503/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 9.0271e-04 - val_loss: 0.0589 - learning_rate: 8.7280e-05\n",
      "Epoch 504/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 8.7759e-04 - val_loss: 0.0570 - learning_rate: 8.7280e-05\n",
      "Epoch 505/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 8.9008e-04 - val_loss: 0.0691 - learning_rate: 8.7280e-05\n",
      "Epoch 506/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.9958e-04 - val_loss: 0.0584 - learning_rate: 8.7280e-05\n",
      "Epoch 507/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 9.1000e-04 - val_loss: 0.0641 - learning_rate: 8.7280e-05\n",
      "Epoch 508/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 9.2337e-04 - val_loss: 0.0583 - learning_rate: 8.7280e-05\n",
      "Epoch 509/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 9.1478e-04\n",
      "Epoch 509: ReduceLROnPlateau reducing learning rate to 7.85516735049896e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 9.0496e-04 - val_loss: 0.0578 - learning_rate: 8.7280e-05\n",
      "Epoch 510/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 9.1017e-04 - val_loss: 0.0616 - learning_rate: 7.8552e-05\n",
      "Epoch 511/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 8.9927e-04 - val_loss: 0.0572 - learning_rate: 7.8552e-05\n",
      "Epoch 512/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.9239e-04 - val_loss: 0.0576 - learning_rate: 7.8552e-05\n",
      "Epoch 513/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 8.9678e-04 - val_loss: 0.0575 - learning_rate: 7.8552e-05\n",
      "Epoch 514/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.7443e-04 - val_loss: 0.0582 - learning_rate: 7.8552e-05\n",
      "Epoch 515/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 8.8998e-04 - val_loss: 0.0574 - learning_rate: 7.8552e-05\n",
      "Epoch 516/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 8.7216e-04 - val_loss: 0.0570 - learning_rate: 7.8552e-05\n",
      "Epoch 517/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 9.0549e-04 - val_loss: 0.0664 - learning_rate: 7.8552e-05\n",
      "Epoch 518/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 9.0320e-04 - val_loss: 0.0574 - learning_rate: 7.8552e-05\n",
      "Epoch 519/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 8.5748e-04\n",
      "Epoch 519: ReduceLROnPlateau reducing learning rate to 7.0696507464163e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 8.4981e-04 - val_loss: 0.0573 - learning_rate: 7.8552e-05\n",
      "Epoch 520/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.4034e-04 - val_loss: 0.0577 - learning_rate: 7.0697e-05\n",
      "Epoch 521/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 8.7342e-04 - val_loss: 0.0639 - learning_rate: 7.0697e-05\n",
      "Epoch 522/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 8.9552e-04 - val_loss: 0.0567 - learning_rate: 7.0697e-05\n",
      "Epoch 523/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 9.4799e-04 - val_loss: 0.0595 - learning_rate: 7.0697e-05\n",
      "Epoch 524/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 8.5857e-04 - val_loss: 0.0627 - learning_rate: 7.0697e-05\n",
      "Epoch 525/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 8.8061e-04 - val_loss: 0.0565 - learning_rate: 7.0697e-05\n",
      "Epoch 526/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 9.0144e-04 - val_loss: 0.0583 - learning_rate: 7.0697e-05\n",
      "Epoch 527/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 8.6927e-04 - val_loss: 0.0657 - learning_rate: 7.0697e-05\n",
      "Epoch 528/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 8.9534e-04 - val_loss: 0.0595 - learning_rate: 7.0697e-05\n",
      "Epoch 529/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8.6354e-04\n",
      "Epoch 529: ReduceLROnPlateau reducing learning rate to 6.36268567177467e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 8.5594e-04 - val_loss: 0.0774 - learning_rate: 7.0697e-05\n",
      "Epoch 530/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 8.6697e-04 - val_loss: 0.0580 - learning_rate: 6.3627e-05\n",
      "Epoch 531/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 8.8626e-04 - val_loss: 0.0795 - learning_rate: 6.3627e-05\n",
      "Epoch 532/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.5202e-04 - val_loss: 0.0729 - learning_rate: 6.3627e-05\n",
      "Epoch 533/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 8.6293e-04 - val_loss: 0.0574 - learning_rate: 6.3627e-05\n",
      "Epoch 534/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.7594e-04 - val_loss: 0.0567 - learning_rate: 6.3627e-05\n",
      "Epoch 535/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 8.8498e-04 - val_loss: 0.0574 - learning_rate: 6.3627e-05\n",
      "Epoch 536/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.4611e-04 - val_loss: 0.0591 - learning_rate: 6.3627e-05\n",
      "Epoch 537/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 8.2888e-04 - val_loss: 0.0592 - learning_rate: 6.3627e-05\n",
      "Epoch 538/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.0985e-04 - val_loss: 0.0576 - learning_rate: 6.3627e-05\n",
      "Epoch 539/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 8.8640e-04\n",
      "Epoch 539: ReduceLROnPlateau reducing learning rate to 5.726417366531678e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 8.7689e-04 - val_loss: 0.0577 - learning_rate: 6.3627e-05\n",
      "Epoch 540/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 8.6727e-04 - val_loss: 0.0580 - learning_rate: 5.7264e-05\n",
      "Epoch 541/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 8.3917e-04 - val_loss: 0.0573 - learning_rate: 5.7264e-05\n",
      "Epoch 542/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.6481e-04 - val_loss: 0.0588 - learning_rate: 5.7264e-05\n",
      "Epoch 543/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 8.9126e-04 - val_loss: 0.0587 - learning_rate: 5.7264e-05\n",
      "Epoch 544/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 8.5803e-04 - val_loss: 0.0582 - learning_rate: 5.7264e-05\n",
      "Epoch 545/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 8.6405e-04 - val_loss: 0.0593 - learning_rate: 5.7264e-05\n",
      "Epoch 546/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 8.5364e-04 - val_loss: 0.0751 - learning_rate: 5.7264e-05\n",
      "Epoch 547/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 8.3972e-04 - val_loss: 0.0576 - learning_rate: 5.7264e-05\n",
      "Epoch 548/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.2691e-04 - val_loss: 0.0896 - learning_rate: 5.7264e-05\n",
      "Epoch 549/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 8.7921e-04\n",
      "Epoch 549: ReduceLROnPlateau reducing learning rate to 5.1537755643948914e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 8.6877e-04 - val_loss: 0.0577 - learning_rate: 5.7264e-05\n",
      "Epoch 550/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 8.4478e-04 - val_loss: 0.0572 - learning_rate: 5.1538e-05\n",
      "Epoch 551/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 8.3041e-04 - val_loss: 0.0574 - learning_rate: 5.1538e-05\n",
      "Epoch 552/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.2376e-04 - val_loss: 0.0571 - learning_rate: 5.1538e-05\n",
      "Epoch 553/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 8.3727e-04 - val_loss: 0.0657 - learning_rate: 5.1538e-05\n",
      "Epoch 554/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.1708e-04 - val_loss: 0.0586 - learning_rate: 5.1538e-05\n",
      "Epoch 555/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 8.5415e-04 - val_loss: 0.0583 - learning_rate: 5.1538e-05\n",
      "Epoch 556/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 8.3424e-04 - val_loss: 0.0709 - learning_rate: 5.1538e-05\n",
      "Epoch 557/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 8.0076e-04 - val_loss: 0.0569 - learning_rate: 5.1538e-05\n",
      "Epoch 558/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 8.2950e-04 - val_loss: 0.0588 - learning_rate: 5.1538e-05\n",
      "Epoch 559/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8.2789e-04\n",
      "Epoch 559: ReduceLROnPlateau reducing learning rate to 4.638397876988165e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 8.1731e-04 - val_loss: 0.0570 - learning_rate: 5.1538e-05\n",
      "Epoch 560/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 8.2851e-04 - val_loss: 0.0579 - learning_rate: 4.6384e-05\n",
      "Epoch 561/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.0208e-04 - val_loss: 0.0708 - learning_rate: 4.6384e-05\n",
      "Epoch 562/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 8.1594e-04 - val_loss: 0.0578 - learning_rate: 4.6384e-05\n",
      "Epoch 563/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.6965e-04 - val_loss: 0.0588 - learning_rate: 4.6384e-05\n",
      "Epoch 564/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 8.4384e-04 - val_loss: 0.0636 - learning_rate: 4.6384e-05\n",
      "Epoch 565/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.1820e-04 - val_loss: 0.0626 - learning_rate: 4.6384e-05\n",
      "Epoch 566/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 8.1539e-04 - val_loss: 0.0583 - learning_rate: 4.6384e-05\n",
      "Epoch 567/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 8.4034e-04 - val_loss: 0.0782 - learning_rate: 4.6384e-05\n",
      "Epoch 568/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 8.2692e-04 - val_loss: 0.0577 - learning_rate: 4.6384e-05\n",
      "Epoch 569/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8.1765e-04\n",
      "Epoch 569: ReduceLROnPlateau reducing learning rate to 4.174558089289349e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 8.0863e-04 - val_loss: 0.0569 - learning_rate: 4.6384e-05\n",
      "Epoch 570/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 8.1389e-04 - val_loss: 0.0588 - learning_rate: 4.1746e-05\n",
      "Epoch 571/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 8.0028e-04 - val_loss: 0.0578 - learning_rate: 4.1746e-05\n",
      "Epoch 572/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.7659e-04 - val_loss: 0.0568 - learning_rate: 4.1746e-05\n",
      "Epoch 573/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.8361e-04 - val_loss: 0.0574 - learning_rate: 4.1746e-05\n",
      "Epoch 574/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.6700e-04 - val_loss: 0.0560 - learning_rate: 4.1746e-05\n",
      "Epoch 575/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 7.8283e-04 - val_loss: 0.0575 - learning_rate: 4.1746e-05\n",
      "Epoch 576/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.0984e-04 - val_loss: 0.0582 - learning_rate: 4.1746e-05\n",
      "Epoch 577/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 7.8010e-04 - val_loss: 0.0667 - learning_rate: 4.1746e-05\n",
      "Epoch 578/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.7058e-04 - val_loss: 0.0567 - learning_rate: 4.1746e-05\n",
      "Epoch 579/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 8.3266e-04\n",
      "Epoch 579: ReduceLROnPlateau reducing learning rate to 3.7571023131022234e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 8.2180e-04 - val_loss: 0.0610 - learning_rate: 4.1746e-05\n",
      "Epoch 580/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.0762e-04 - val_loss: 0.0679 - learning_rate: 3.7571e-05\n",
      "Epoch 581/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.9070e-04 - val_loss: 0.0690 - learning_rate: 3.7571e-05\n",
      "Epoch 582/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.8843e-04 - val_loss: 0.0575 - learning_rate: 3.7571e-05\n",
      "Epoch 583/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 7.6719e-04 - val_loss: 0.0566 - learning_rate: 3.7571e-05\n",
      "Epoch 584/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.8492e-04 - val_loss: 0.0720 - learning_rate: 3.7571e-05\n",
      "Epoch 585/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 8.1462e-04 - val_loss: 0.0622 - learning_rate: 3.7571e-05\n",
      "Epoch 586/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.8664e-04 - val_loss: 0.0557 - learning_rate: 3.7571e-05\n",
      "Epoch 587/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.6372e-04 - val_loss: 0.0664 - learning_rate: 3.7571e-05\n",
      "Epoch 588/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.8847e-04 - val_loss: 0.0585 - learning_rate: 3.7571e-05\n",
      "Epoch 589/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8.0264e-04\n",
      "Epoch 589: ReduceLROnPlateau reducing learning rate to 3.381392016308382e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 7.9346e-04 - val_loss: 0.0574 - learning_rate: 3.7571e-05\n",
      "Epoch 590/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.8384e-04 - val_loss: 0.0681 - learning_rate: 3.3814e-05\n",
      "Epoch 591/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 7.8124e-04 - val_loss: 0.0571 - learning_rate: 3.3814e-05\n",
      "Epoch 592/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 7.8935e-04 - val_loss: 0.0674 - learning_rate: 3.3814e-05\n",
      "Epoch 593/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - loss: 7.8136e-04 - val_loss: 0.0597 - learning_rate: 3.3814e-05\n",
      "Epoch 594/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.8777e-04 - val_loss: 0.0671 - learning_rate: 3.3814e-05\n",
      "Epoch 595/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.3422e-04 - val_loss: 0.0581 - learning_rate: 3.3814e-05\n",
      "Epoch 596/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.6831e-04 - val_loss: 0.0589 - learning_rate: 3.3814e-05\n",
      "Epoch 597/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 7.7082e-04 - val_loss: 0.0568 - learning_rate: 3.3814e-05\n",
      "Epoch 598/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.8659e-04 - val_loss: 0.0667 - learning_rate: 3.3814e-05\n",
      "Epoch 599/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 7.8247e-04\n",
      "Epoch 599: ReduceLROnPlateau reducing learning rate to 3.043252945644781e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.7254e-04 - val_loss: 0.0579 - learning_rate: 3.3814e-05\n",
      "Epoch 600/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.6605e-04 - val_loss: 0.0642 - learning_rate: 3.0433e-05\n",
      "Epoch 601/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 7.4734e-04 - val_loss: 0.0580 - learning_rate: 3.0433e-05\n",
      "Epoch 602/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.9277e-04 - val_loss: 0.0642 - learning_rate: 3.0433e-05\n",
      "Epoch 603/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 7.7949e-04 - val_loss: 0.0578 - learning_rate: 3.0433e-05\n",
      "Epoch 604/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 7.6785e-04 - val_loss: 0.0613 - learning_rate: 3.0433e-05\n",
      "Epoch 605/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 7.8449e-04 - val_loss: 0.0574 - learning_rate: 3.0433e-05\n",
      "Epoch 606/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 7.6817e-04 - val_loss: 0.0564 - learning_rate: 3.0433e-05\n",
      "Epoch 607/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.7927e-04 - val_loss: 0.0576 - learning_rate: 3.0433e-05\n",
      "Epoch 608/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 8.2532e-04 - val_loss: 0.0576 - learning_rate: 3.0433e-05\n",
      "Epoch 609/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8.0025e-04\n",
      "Epoch 609: ReduceLROnPlateau reducing learning rate to 3e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.9114e-04 - val_loss: 0.0576 - learning_rate: 3.0433e-05\n",
      "Epoch 610/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 8.1467e-04 - val_loss: 0.0563 - learning_rate: 3.0000e-05\n",
      "Epoch 611/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.2275e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 612/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 7.7534e-04 - val_loss: 0.0559 - learning_rate: 3.0000e-05\n",
      "Epoch 613/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.7402e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 614/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 7.6514e-04 - val_loss: 0.0635 - learning_rate: 3.0000e-05\n",
      "Epoch 615/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.6366e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 616/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - loss: 7.7888e-04 - val_loss: 0.0707 - learning_rate: 3.0000e-05\n",
      "Epoch 617/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.8192e-04 - val_loss: 0.0566 - learning_rate: 3.0000e-05\n",
      "Epoch 618/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 7.6783e-04 - val_loss: 0.0795 - learning_rate: 3.0000e-05\n",
      "Epoch 619/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.5572e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 620/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 7.7249e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 621/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.6111e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 622/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.6645e-04 - val_loss: 0.0643 - learning_rate: 3.0000e-05\n",
      "Epoch 623/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 8.1215e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 624/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 7.5084e-04 - val_loss: 0.0587 - learning_rate: 3.0000e-05\n",
      "Epoch 625/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 7.7410e-04 - val_loss: 0.0646 - learning_rate: 3.0000e-05\n",
      "Epoch 626/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.7414e-04 - val_loss: 0.0633 - learning_rate: 3.0000e-05\n",
      "Epoch 627/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 7.3457e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 628/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.6569e-04 - val_loss: 0.0636 - learning_rate: 3.0000e-05\n",
      "Epoch 629/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.8065e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 630/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.6667e-04 - val_loss: 0.0650 - learning_rate: 3.0000e-05\n",
      "Epoch 631/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 8.0306e-04 - val_loss: 0.0562 - learning_rate: 3.0000e-05\n",
      "Epoch 632/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.9584e-04 - val_loss: 0.0591 - learning_rate: 3.0000e-05\n",
      "Epoch 633/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 7.7198e-04 - val_loss: 0.0727 - learning_rate: 3.0000e-05\n",
      "Epoch 634/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.8140e-04 - val_loss: 0.0563 - learning_rate: 3.0000e-05\n",
      "Epoch 635/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 7.6215e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 636/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.4384e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 637/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 7.6630e-04 - val_loss: 0.0619 - learning_rate: 3.0000e-05\n",
      "Epoch 638/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.5796e-04 - val_loss: 0.0627 - learning_rate: 3.0000e-05\n",
      "Epoch 639/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.6068e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 640/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 7.4655e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 641/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.6845e-04 - val_loss: 0.0595 - learning_rate: 3.0000e-05\n",
      "Epoch 642/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.4335e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 643/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 7.6802e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 644/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.6725e-04 - val_loss: 0.0632 - learning_rate: 3.0000e-05\n",
      "Epoch 645/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 7.4598e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 646/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.3840e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 647/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.7403e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 648/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.7241e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 649/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 7.2850e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 650/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.4390e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 651/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 7.8368e-04 - val_loss: 0.0562 - learning_rate: 3.0000e-05\n",
      "Epoch 652/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.6144e-04 - val_loss: 0.0558 - learning_rate: 3.0000e-05\n",
      "Epoch 653/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.4846e-04 - val_loss: 0.0738 - learning_rate: 3.0000e-05\n",
      "Epoch 654/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.5431e-04 - val_loss: 0.0604 - learning_rate: 3.0000e-05\n",
      "Epoch 655/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 7.5605e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 656/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.5362e-04 - val_loss: 0.0565 - learning_rate: 3.0000e-05\n",
      "Epoch 657/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 7.6510e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 658/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.8256e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 659/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.6553e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 660/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 8.1870e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 661/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 8.1568e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 662/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 7.4405e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 663/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.6165e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 664/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.6002e-04 - val_loss: 0.0616 - learning_rate: 3.0000e-05\n",
      "Epoch 665/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.6329e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 666/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.5952e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 667/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.9879e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 668/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 7.5853e-04 - val_loss: 0.0739 - learning_rate: 3.0000e-05\n",
      "Epoch 669/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.4231e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 670/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 7.4833e-04 - val_loss: 0.0818 - learning_rate: 3.0000e-05\n",
      "Epoch 671/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.8291e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 672/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 8.0948e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 673/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.3961e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 674/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 7.5500e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 675/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.8471e-04 - val_loss: 0.0697 - learning_rate: 3.0000e-05\n",
      "Epoch 676/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 7.4606e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 677/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 7.5665e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 678/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 7.2931e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 679/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 7.6659e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 680/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.5573e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 681/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 7.5558e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 682/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.6465e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 683/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.4309e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 684/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 7.7132e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 19:04:24.440103: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - loss: 7.6400e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 685/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.4311e-04 - val_loss: 0.0590 - learning_rate: 3.0000e-05\n",
      "Epoch 686/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 7.4970e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 687/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.5553e-04 - val_loss: 0.0617 - learning_rate: 3.0000e-05\n",
      "Epoch 688/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 7.5807e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 689/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.5087e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 690/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 7.5813e-04 - val_loss: 0.0630 - learning_rate: 3.0000e-05\n",
      "Epoch 691/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.4813e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 692/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 7.3737e-04 - val_loss: 0.0565 - learning_rate: 3.0000e-05\n",
      "Epoch 693/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.4405e-04 - val_loss: 0.0766 - learning_rate: 3.0000e-05\n",
      "Epoch 694/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 7.4197e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 695/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.6786e-04 - val_loss: 0.0777 - learning_rate: 3.0000e-05\n",
      "Epoch 696/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.6125e-04 - val_loss: 0.0566 - learning_rate: 3.0000e-05\n",
      "Epoch 697/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.4941e-04 - val_loss: 0.0557 - learning_rate: 3.0000e-05\n",
      "Epoch 698/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 7.3251e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 699/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.5314e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 700/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.4429e-04 - val_loss: 0.0694 - learning_rate: 3.0000e-05\n",
      "Epoch 701/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.2860e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 702/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.4367e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 703/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.8129e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 704/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.3414e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 705/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.4413e-04 - val_loss: 0.0731 - learning_rate: 3.0000e-05\n",
      "Epoch 706/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 7.6320e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 707/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.5415e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 708/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 7.4056e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 709/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 7.3592e-04 - val_loss: 0.0880 - learning_rate: 3.0000e-05\n",
      "Epoch 710/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.3523e-04 - val_loss: 0.0566 - learning_rate: 3.0000e-05\n",
      "Epoch 711/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.5748e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 712/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.4103e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 713/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.7231e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 714/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 7.5157e-04 - val_loss: 0.0762 - learning_rate: 3.0000e-05\n",
      "Epoch 715/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.4806e-04 - val_loss: 0.0565 - learning_rate: 3.0000e-05\n",
      "Epoch 716/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 7.4549e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 717/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.3679e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 718/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 7.5461e-04 - val_loss: 0.0617 - learning_rate: 3.0000e-05\n",
      "Epoch 719/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.3413e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 720/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 7.4381e-04 - val_loss: 0.0587 - learning_rate: 3.0000e-05\n",
      "Epoch 721/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - loss: 7.2155e-04 - val_loss: 0.0590 - learning_rate: 3.0000e-05\n",
      "Epoch 722/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.6438e-04 - val_loss: 0.0641 - learning_rate: 3.0000e-05\n",
      "Epoch 723/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 7.3760e-04 - val_loss: 0.0557 - learning_rate: 3.0000e-05\n",
      "Epoch 724/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.3153e-04 - val_loss: 0.0715 - learning_rate: 3.0000e-05\n",
      "Epoch 725/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 7.4070e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 726/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.4400e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 727/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 7.7639e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 728/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.7099e-04 - val_loss: 0.0633 - learning_rate: 3.0000e-05\n",
      "Epoch 729/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.3975e-04 - val_loss: 0.0626 - learning_rate: 3.0000e-05\n",
      "Epoch 730/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.4904e-04 - val_loss: 0.0644 - learning_rate: 3.0000e-05\n",
      "Epoch 731/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 7.2418e-04 - val_loss: 0.0597 - learning_rate: 3.0000e-05\n",
      "Epoch 732/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.4718e-04 - val_loss: 0.0628 - learning_rate: 3.0000e-05\n",
      "Epoch 733/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 7.1970e-04 - val_loss: 0.0611 - learning_rate: 3.0000e-05\n",
      "Epoch 734/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.4913e-04 - val_loss: 0.0635 - learning_rate: 3.0000e-05\n",
      "Epoch 735/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.9246e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 736/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.5103e-04 - val_loss: 0.0558 - learning_rate: 3.0000e-05\n",
      "Epoch 737/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 7.3439e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 738/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.5016e-04 - val_loss: 0.0750 - learning_rate: 3.0000e-05\n",
      "Epoch 739/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - loss: 7.2024e-04 - val_loss: 0.0706 - learning_rate: 3.0000e-05\n",
      "Epoch 740/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.2396e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 741/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 7.3424e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 742/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 7.3668e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 743/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.6289e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 744/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 7.2816e-04 - val_loss: 0.0800 - learning_rate: 3.0000e-05\n",
      "Epoch 745/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.2954e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 746/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.3602e-04 - val_loss: 0.0966 - learning_rate: 3.0000e-05\n",
      "Epoch 747/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.6927e-04 - val_loss: 0.0564 - learning_rate: 3.0000e-05\n",
      "Epoch 748/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 7.4906e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 749/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.3232e-04 - val_loss: 0.0873 - learning_rate: 3.0000e-05\n",
      "Epoch 750/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 7.2799e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 751/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.3147e-04 - val_loss: 0.0797 - learning_rate: 3.0000e-05\n",
      "Epoch 752/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 7.2830e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 753/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.1507e-04 - val_loss: 0.0706 - learning_rate: 3.0000e-05\n",
      "Epoch 754/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 7.2238e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 755/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 7.3391e-04 - val_loss: 0.0593 - learning_rate: 3.0000e-05\n",
      "Epoch 756/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.2082e-04 - val_loss: 0.0933 - learning_rate: 3.0000e-05\n",
      "Epoch 757/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 7.3174e-04 - val_loss: 0.0638 - learning_rate: 3.0000e-05\n",
      "Epoch 758/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.3611e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 759/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - loss: 7.3244e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 760/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.7009e-04 - val_loss: 0.0708 - learning_rate: 3.0000e-05\n",
      "Epoch 761/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 7.2188e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 762/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.3723e-04 - val_loss: 0.0751 - learning_rate: 3.0000e-05\n",
      "Epoch 763/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 7.3645e-04 - val_loss: 0.0564 - learning_rate: 3.0000e-05\n",
      "Epoch 764/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.2274e-04 - val_loss: 0.0704 - learning_rate: 3.0000e-05\n",
      "Epoch 765/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 7.2270e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 766/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.3670e-04 - val_loss: 0.0560 - learning_rate: 3.0000e-05\n",
      "Epoch 767/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.5699e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 768/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.2643e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 769/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.2918e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 770/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.2352e-04 - val_loss: 0.0564 - learning_rate: 3.0000e-05\n",
      "Epoch 771/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 7.4831e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 772/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.0045e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 773/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 7.1875e-04 - val_loss: 0.0790 - learning_rate: 3.0000e-05\n",
      "Epoch 774/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.6069e-04 - val_loss: 0.0605 - learning_rate: 3.0000e-05\n",
      "Epoch 775/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.0986e-04 - val_loss: 0.0791 - learning_rate: 3.0000e-05\n",
      "Epoch 776/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.4728e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 777/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.9899e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 778/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.2142e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 779/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 7.3377e-04 - val_loss: 0.0564 - learning_rate: 3.0000e-05\n",
      "Epoch 780/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.3035e-04 - val_loss: 0.0797 - learning_rate: 3.0000e-05\n",
      "Epoch 781/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.3357e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 782/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.1505e-04 - val_loss: 0.0909 - learning_rate: 3.0000e-05\n",
      "Epoch 783/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 7.2727e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 784/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.6510e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 785/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.0999e-04 - val_loss: 0.0587 - learning_rate: 3.0000e-05\n",
      "Epoch 786/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.5671e-04 - val_loss: 0.1016 - learning_rate: 3.0000e-05\n",
      "Epoch 787/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 7.2194e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 788/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.2882e-04 - val_loss: 0.1365 - learning_rate: 3.0000e-05\n",
      "Epoch 789/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.1175e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 790/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 7.0978e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 791/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.1476e-04 - val_loss: 0.0767 - learning_rate: 3.0000e-05\n",
      "Epoch 792/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 7.6445e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 793/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.1079e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 794/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 7.3120e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 795/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.5585e-04 - val_loss: 0.0566 - learning_rate: 3.0000e-05\n",
      "Epoch 796/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 7.2656e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 797/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.1294e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 798/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 7.0977e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 799/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.3798e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 800/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 7.2850e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 801/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.1846e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 802/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.2961e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 803/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.0331e-04 - val_loss: 0.0621 - learning_rate: 3.0000e-05\n",
      "Epoch 804/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.0461e-04 - val_loss: 0.0736 - learning_rate: 3.0000e-05\n",
      "Epoch 805/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.2792e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 806/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.8575e-04 - val_loss: 0.0590 - learning_rate: 3.0000e-05\n",
      "Epoch 807/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.1651e-04 - val_loss: 0.0660 - learning_rate: 3.0000e-05\n",
      "Epoch 808/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 7.1754e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 809/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.1342e-04 - val_loss: 0.0553 - learning_rate: 3.0000e-05\n",
      "Epoch 810/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 7.1629e-04 - val_loss: 0.0727 - learning_rate: 3.0000e-05\n",
      "Epoch 811/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.8984e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 812/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.3796e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 813/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.1772e-04 - val_loss: 0.0651 - learning_rate: 3.0000e-05\n",
      "Epoch 814/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 7.1935e-04 - val_loss: 0.0593 - learning_rate: 3.0000e-05\n",
      "Epoch 815/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 7.1847e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 816/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.4696e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 817/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.1129e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 818/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.1145e-04 - val_loss: 0.0821 - learning_rate: 3.0000e-05\n",
      "Epoch 819/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 7.3222e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 820/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.1731e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 821/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 7.1816e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 822/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.2769e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 823/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 7.3868e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 824/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 7.0881e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 825/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 7.5006e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 826/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.2966e-04 - val_loss: 0.0593 - learning_rate: 3.0000e-05\n",
      "Epoch 827/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.3377e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 828/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.2288e-04 - val_loss: 0.1365 - learning_rate: 3.0000e-05\n",
      "Epoch 829/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.0490e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 830/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.3489e-04 - val_loss: 0.0587 - learning_rate: 3.0000e-05\n",
      "Epoch 831/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.4708e-04 - val_loss: 0.0898 - learning_rate: 3.0000e-05\n",
      "Epoch 832/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.1325e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 833/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.1756e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 834/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.1333e-04 - val_loss: 0.0985 - learning_rate: 3.0000e-05\n",
      "Epoch 835/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 7.4151e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 836/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.2197e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 837/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 7.1723e-04 - val_loss: 0.2162 - learning_rate: 3.0000e-05\n",
      "Epoch 838/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.2905e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 839/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 7.1088e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 840/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.9908e-04 - val_loss: 0.3169 - learning_rate: 3.0000e-05\n",
      "Epoch 841/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 7.2816e-04 - val_loss: 0.0864 - learning_rate: 3.0000e-05\n",
      "Epoch 842/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.8642e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 843/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 7.1309e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 844/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.1362e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 845/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 7.0393e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 846/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.1803e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 847/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 7.4076e-04 - val_loss: 0.0730 - learning_rate: 3.0000e-05\n",
      "Epoch 848/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.7906e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 849/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 7.4391e-04 - val_loss: 0.0561 - learning_rate: 3.0000e-05\n",
      "Epoch 850/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.9576e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 851/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.9689e-04 - val_loss: 0.0566 - learning_rate: 3.0000e-05\n",
      "Epoch 852/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.0977e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 853/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.2323e-04 - val_loss: 0.0711 - learning_rate: 3.0000e-05\n",
      "Epoch 854/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.3083e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 855/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 7.0608e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 856/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.0377e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 857/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 6.9220e-04 - val_loss: 0.0564 - learning_rate: 3.0000e-05\n",
      "Epoch 858/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.8856e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 859/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 7.0924e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 860/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.0014e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 861/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 7.2706e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 862/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.9677e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 863/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.8628e-04 - val_loss: 0.0985 - learning_rate: 3.0000e-05\n",
      "Epoch 864/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.1093e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 865/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.2642e-04 - val_loss: 0.1475 - learning_rate: 3.0000e-05\n",
      "Epoch 866/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.1144e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 867/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.3055e-04 - val_loss: 0.0643 - learning_rate: 3.0000e-05\n",
      "Epoch 868/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.1178e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 869/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 7.1449e-04 - val_loss: 0.0619 - learning_rate: 3.0000e-05\n",
      "Epoch 870/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 7.1889e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 871/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.3871e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 872/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.1733e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 873/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7971e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 874/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.9530e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 875/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.0544e-04 - val_loss: 0.0595 - learning_rate: 3.0000e-05\n",
      "Epoch 876/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 7.4281e-04 - val_loss: 0.0805 - learning_rate: 3.0000e-05\n",
      "Epoch 877/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.0866e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 878/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.0206e-04 - val_loss: 0.1031 - learning_rate: 3.0000e-05\n",
      "Epoch 879/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.2854e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 880/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.9968e-04 - val_loss: 0.0695 - learning_rate: 3.0000e-05\n",
      "Epoch 881/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.8883e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 882/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.3051e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 883/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.2635e-04 - val_loss: 0.0913 - learning_rate: 3.0000e-05\n",
      "Epoch 884/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 7.3591e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 885/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.0276e-04 - val_loss: 0.0564 - learning_rate: 3.0000e-05\n",
      "Epoch 886/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 7.0513e-04 - val_loss: 0.1123 - learning_rate: 3.0000e-05\n",
      "Epoch 887/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.0170e-04 - val_loss: 0.1157 - learning_rate: 3.0000e-05\n",
      "Epoch 888/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 7.3381e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 889/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.9260e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 890/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 7.0131e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 891/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.9435e-04 - val_loss: 0.1032 - learning_rate: 3.0000e-05\n",
      "Epoch 892/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.0775e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 893/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 7.0515e-04 - val_loss: 0.1276 - learning_rate: 3.0000e-05\n",
      "Epoch 894/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.9083e-04 - val_loss: 0.0556 - learning_rate: 3.0000e-05\n",
      "Epoch 895/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.9676e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 896/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 7.1295e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 897/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.7872e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 898/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.2588e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 899/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.2086e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 900/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.0809e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 901/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 7.1211e-04 - val_loss: 0.0892 - learning_rate: 3.0000e-05\n",
      "Epoch 902/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 6.8975e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 903/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - loss: 7.0176e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 904/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 6.8505e-04 - val_loss: 0.1315 - learning_rate: 3.0000e-05\n",
      "Epoch 905/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.0644e-04 - val_loss: 0.0595 - learning_rate: 3.0000e-05\n",
      "Epoch 906/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.9319e-04 - val_loss: 0.0730 - learning_rate: 3.0000e-05\n",
      "Epoch 907/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.9070e-04 - val_loss: 0.0566 - learning_rate: 3.0000e-05\n",
      "Epoch 908/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.9623e-04 - val_loss: 0.1108 - learning_rate: 3.0000e-05\n",
      "Epoch 909/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.0243e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 910/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.1523e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 911/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.1206e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 912/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 7.4113e-04 - val_loss: 0.0712 - learning_rate: 3.0000e-05\n",
      "Epoch 913/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7515e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 914/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.0302e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 915/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.9492e-04 - val_loss: 0.0705 - learning_rate: 3.0000e-05\n",
      "Epoch 916/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.7674e-04 - val_loss: 0.0891 - learning_rate: 3.0000e-05\n",
      "Epoch 917/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 7.0453e-04 - val_loss: 0.0868 - learning_rate: 3.0000e-05\n",
      "Epoch 918/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.0321e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 919/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.6884e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 920/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 7.3947e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 921/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.8124e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 922/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.8288e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 923/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.2613e-04 - val_loss: 0.0807 - learning_rate: 3.0000e-05\n",
      "Epoch 924/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.1713e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 925/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.1020e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 926/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 7.1781e-04 - val_loss: 0.0966 - learning_rate: 3.0000e-05\n",
      "Epoch 927/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.0713e-04 - val_loss: 0.0592 - learning_rate: 3.0000e-05\n",
      "Epoch 928/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 6.9769e-04 - val_loss: 0.0563 - learning_rate: 3.0000e-05\n",
      "Epoch 929/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 6.7299e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 930/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.0457e-04 - val_loss: 0.0983 - learning_rate: 3.0000e-05\n",
      "Epoch 931/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.8627e-04 - val_loss: 0.0922 - learning_rate: 3.0000e-05\n",
      "Epoch 932/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.0128e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 933/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.0977e-04 - val_loss: 0.0863 - learning_rate: 3.0000e-05\n",
      "Epoch 934/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.0221e-04 - val_loss: 0.0852 - learning_rate: 3.0000e-05\n",
      "Epoch 935/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.6659e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 936/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.9172e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 937/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.0412e-04 - val_loss: 0.0746 - learning_rate: 3.0000e-05\n",
      "Epoch 938/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.9376e-04 - val_loss: 0.0741 - learning_rate: 3.0000e-05\n",
      "Epoch 939/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.9041e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 940/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 7.0389e-04 - val_loss: 0.0770 - learning_rate: 3.0000e-05\n",
      "Epoch 941/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.6194e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 942/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 6.9005e-04 - val_loss: 0.0907 - learning_rate: 3.0000e-05\n",
      "Epoch 943/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7462e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 944/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 7.0427e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 945/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.8995e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 946/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.9361e-04 - val_loss: 0.0560 - learning_rate: 3.0000e-05\n",
      "Epoch 947/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.7878e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 948/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 6.8092e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 949/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.8691e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 950/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 6.8107e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 951/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.9759e-04 - val_loss: 0.0722 - learning_rate: 3.0000e-05\n",
      "Epoch 952/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.9484e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 953/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.0802e-04 - val_loss: 0.0773 - learning_rate: 3.0000e-05\n",
      "Epoch 954/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.9582e-04 - val_loss: 0.0593 - learning_rate: 3.0000e-05\n",
      "Epoch 955/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 6.8653e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 956/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 7.0068e-04 - val_loss: 0.0602 - learning_rate: 3.0000e-05\n",
      "Epoch 957/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 6.8826e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 958/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.9425e-04 - val_loss: 0.0932 - learning_rate: 3.0000e-05\n",
      "Epoch 959/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.8982e-04 - val_loss: 0.1155 - learning_rate: 3.0000e-05\n",
      "Epoch 960/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.9348e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 961/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.8499e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 962/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.9206e-04 - val_loss: 0.0587 - learning_rate: 3.0000e-05\n",
      "Epoch 963/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.1980e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 964/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - loss: 6.9220e-04 - val_loss: 0.1862 - learning_rate: 3.0000e-05\n",
      "Epoch 965/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 6.7428e-04 - val_loss: 0.1879 - learning_rate: 3.0000e-05\n",
      "Epoch 966/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.9480e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 967/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.7627e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 968/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.8071e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 969/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 7.0358e-04 - val_loss: 0.0753 - learning_rate: 3.0000e-05\n",
      "Epoch 970/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.7002e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 971/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.9812e-04 - val_loss: 0.0737 - learning_rate: 3.0000e-05\n",
      "Epoch 972/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.8430e-04 - val_loss: 0.0854 - learning_rate: 3.0000e-05\n",
      "Epoch 973/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.9642e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 974/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.8552e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 975/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 7.1046e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 976/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.0469e-04 - val_loss: 0.1023 - learning_rate: 3.0000e-05\n",
      "Epoch 977/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.5584e-04 - val_loss: 0.1133 - learning_rate: 3.0000e-05\n",
      "Epoch 978/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.0679e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 979/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.8359e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 980/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.6774e-04 - val_loss: 0.0557 - learning_rate: 3.0000e-05\n",
      "Epoch 981/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 6.7917e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 982/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.0540e-04 - val_loss: 0.0590 - learning_rate: 3.0000e-05\n",
      "Epoch 983/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.6734e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 984/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 6.6354e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 985/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 6.8273e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 986/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 6.9928e-04 - val_loss: 0.4586 - learning_rate: 3.0000e-05\n",
      "Epoch 987/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7187e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 988/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.0238e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 989/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5985e-04 - val_loss: 0.0717 - learning_rate: 3.0000e-05\n",
      "Epoch 990/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 6.9299e-04 - val_loss: 0.0748 - learning_rate: 3.0000e-05\n",
      "Epoch 991/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 6.8828e-04 - val_loss: 0.0708 - learning_rate: 3.0000e-05\n",
      "Epoch 992/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 6.7144e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 993/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.6696e-04 - val_loss: 0.0566 - learning_rate: 3.0000e-05\n",
      "Epoch 994/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.6312e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 995/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.0831e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 996/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.7198e-04 - val_loss: 0.0565 - learning_rate: 3.0000e-05\n",
      "Epoch 997/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.8510e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 998/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.8518e-04 - val_loss: 0.1694 - learning_rate: 3.0000e-05\n",
      "Epoch 999/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.9657e-04 - val_loss: 0.0587 - learning_rate: 3.0000e-05\n",
      "Epoch 1000/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.9495e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1001/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7874e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1002/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.9272e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1003/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7986e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 1004/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.7840e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 1005/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.6977e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1006/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.7599e-04 - val_loss: 0.0562 - learning_rate: 3.0000e-05\n",
      "Epoch 1007/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.8363e-04 - val_loss: 0.0596 - learning_rate: 3.0000e-05\n",
      "Epoch 1008/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.0152e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 1009/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.8532e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1010/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.9954e-04 - val_loss: 0.0983 - learning_rate: 3.0000e-05\n",
      "Epoch 1011/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.6680e-04 - val_loss: 0.1021 - learning_rate: 3.0000e-05\n",
      "Epoch 1012/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 6.7486e-04 - val_loss: 0.0562 - learning_rate: 3.0000e-05\n",
      "Epoch 1013/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.8509e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1014/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 6.6228e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1015/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 6.8812e-04 - val_loss: 0.0805 - learning_rate: 3.0000e-05\n",
      "Epoch 1016/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7550e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1017/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 6.9893e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1018/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7067e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1019/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.9371e-04 - val_loss: 0.0824 - learning_rate: 3.0000e-05\n",
      "Epoch 1020/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.8333e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1021/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.2441e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1022/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.7573e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1023/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.7302e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1024/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 6.8703e-04 - val_loss: 0.0929 - learning_rate: 3.0000e-05\n",
      "Epoch 1025/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 7.0506e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 1026/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5541e-04 - val_loss: 0.0977 - learning_rate: 3.0000e-05\n",
      "Epoch 1027/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5276e-04 - val_loss: 0.0716 - learning_rate: 3.0000e-05\n",
      "Epoch 1028/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 6.5766e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1029/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.0015e-04 - val_loss: 0.0656 - learning_rate: 3.0000e-05\n",
      "Epoch 1030/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 6.7809e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 1031/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.8381e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 1032/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.7269e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1033/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.0581e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1034/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 7.0338e-04 - val_loss: 0.0858 - learning_rate: 3.0000e-05\n",
      "Epoch 1035/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 6.8120e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 1036/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 6.5248e-04 - val_loss: 0.0564 - learning_rate: 3.0000e-05\n",
      "Epoch 1037/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.8354e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1038/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.6389e-04 - val_loss: 0.0959 - learning_rate: 3.0000e-05\n",
      "Epoch 1039/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.9419e-04 - val_loss: 0.0997 - learning_rate: 3.0000e-05\n",
      "Epoch 1040/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.7058e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 1041/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 6.6220e-04 - val_loss: 0.1045 - learning_rate: 3.0000e-05\n",
      "Epoch 1042/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 6.8363e-04 - val_loss: 0.0976 - learning_rate: 3.0000e-05\n",
      "Epoch 1043/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 6.8909e-04 - val_loss: 0.0604 - learning_rate: 3.0000e-05\n",
      "Epoch 1044/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.4393e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 1045/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.6777e-04 - val_loss: 0.0591 - learning_rate: 3.0000e-05\n",
      "Epoch 1046/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.0997e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1047/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.5607e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1048/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5929e-04 - val_loss: 0.0859 - learning_rate: 3.0000e-05\n",
      "Epoch 1049/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.8500e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1050/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5265e-04 - val_loss: 0.0984 - learning_rate: 3.0000e-05\n",
      "Epoch 1051/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.8807e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 1052/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.8343e-04 - val_loss: 0.1142 - learning_rate: 3.0000e-05\n",
      "Epoch 1053/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.7191e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1054/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.8311e-04 - val_loss: 0.1549 - learning_rate: 3.0000e-05\n",
      "Epoch 1055/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.0366e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1056/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.8331e-04 - val_loss: 0.2004 - learning_rate: 3.0000e-05\n",
      "Epoch 1057/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 6.4300e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1058/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.8764e-04 - val_loss: 0.1998 - learning_rate: 3.0000e-05\n",
      "Epoch 1059/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.7959e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1060/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.0880e-04 - val_loss: 0.0775 - learning_rate: 3.0000e-05\n",
      "Epoch 1061/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.7319e-04 - val_loss: 0.1108 - learning_rate: 3.0000e-05\n",
      "Epoch 1062/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.5230e-04 - val_loss: 0.0782 - learning_rate: 3.0000e-05\n",
      "Epoch 1063/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.8445e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 1064/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7344e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1065/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 6.8996e-04 - val_loss: 0.0918 - learning_rate: 3.0000e-05\n",
      "Epoch 1066/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.7035e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1067/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.5582e-04 - val_loss: 0.0591 - learning_rate: 3.0000e-05\n",
      "Epoch 1068/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5244e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1069/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 6.6937e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 1070/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.7066e-04 - val_loss: 0.0591 - learning_rate: 3.0000e-05\n",
      "Epoch 1071/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 6.6739e-04 - val_loss: 0.0806 - learning_rate: 3.0000e-05\n",
      "Epoch 1072/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.6814e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1073/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.5812e-04 - val_loss: 0.0844 - learning_rate: 3.0000e-05\n",
      "Epoch 1074/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7303e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1075/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.8391e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1076/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7160e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1077/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.6881e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1078/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.9346e-04 - val_loss: 0.0594 - learning_rate: 3.0000e-05\n",
      "Epoch 1079/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.7530e-04 - val_loss: 0.0775 - learning_rate: 3.0000e-05\n",
      "Epoch 1080/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.5661e-04 - val_loss: 0.0789 - learning_rate: 3.0000e-05\n",
      "Epoch 1081/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.6965e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1082/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.5117e-04 - val_loss: 0.0983 - learning_rate: 3.0000e-05\n",
      "Epoch 1083/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.6387e-04 - val_loss: 0.0980 - learning_rate: 3.0000e-05\n",
      "Epoch 1084/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.5517e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1085/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.4738e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1086/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.9353e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 1087/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.0074e-04 - val_loss: 0.0991 - learning_rate: 3.0000e-05\n",
      "Epoch 1088/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 7.5463e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 1089/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.9374e-04 - val_loss: 0.1871 - learning_rate: 3.0000e-05\n",
      "Epoch 1090/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7673e-04 - val_loss: 0.0564 - learning_rate: 3.0000e-05\n",
      "Epoch 1091/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.8132e-04 - val_loss: 0.2894 - learning_rate: 3.0000e-05\n",
      "Epoch 1092/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7697e-04 - val_loss: 0.1536 - learning_rate: 3.0000e-05\n",
      "Epoch 1093/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 6.6226e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1094/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.6625e-04 - val_loss: 0.4192 - learning_rate: 3.0000e-05\n",
      "Epoch 1095/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.5903e-04 - val_loss: 0.0560 - learning_rate: 3.0000e-05\n",
      "Epoch 1096/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.8582e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1097/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.7335e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1098/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.6620e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1099/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.6833e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1100/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.8427e-04 - val_loss: 0.0587 - learning_rate: 3.0000e-05\n",
      "Epoch 1101/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.6633e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1102/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.7968e-04 - val_loss: 0.1584 - learning_rate: 3.0000e-05\n",
      "Epoch 1103/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.6281e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 1104/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.4649e-04 - val_loss: 0.0594 - learning_rate: 3.0000e-05\n",
      "Epoch 1105/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.5443e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1106/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.6361e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 1107/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.9739e-04 - val_loss: 0.0912 - learning_rate: 3.0000e-05\n",
      "Epoch 1108/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.9623e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1109/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.5548e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1110/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3768e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1111/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.5453e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1112/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5297e-04 - val_loss: 0.1554 - learning_rate: 3.0000e-05\n",
      "Epoch 1113/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.4783e-04 - val_loss: 0.1885 - learning_rate: 3.0000e-05\n",
      "Epoch 1114/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.8053e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 1115/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.9019e-04 - val_loss: 0.2587 - learning_rate: 3.0000e-05\n",
      "Epoch 1116/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.5537e-04 - val_loss: 0.2194 - learning_rate: 3.0000e-05\n",
      "Epoch 1117/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 7.2563e-04 - val_loss: 0.3366 - learning_rate: 3.0000e-05\n",
      "Epoch 1118/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.5633e-04 - val_loss: 0.0558 - learning_rate: 3.0000e-05\n",
      "Epoch 1119/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.9183e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1120/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.3879e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1121/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.5030e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 1122/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5470e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1123/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.7114e-04 - val_loss: 0.0699 - learning_rate: 3.0000e-05\n",
      "Epoch 1124/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.6316e-04 - val_loss: 0.0889 - learning_rate: 3.0000e-05\n",
      "Epoch 1125/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.9942e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1126/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3617e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1127/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.8365e-04 - val_loss: 0.0734 - learning_rate: 3.0000e-05\n",
      "Epoch 1128/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.9084e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1129/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.3238e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1130/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.8185e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1131/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.5403e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 1132/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.6321e-04 - val_loss: 0.0661 - learning_rate: 3.0000e-05\n",
      "Epoch 1133/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.4675e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1134/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5705e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 1135/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.4884e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1136/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.2316e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 1137/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 6.4534e-04 - val_loss: 0.0888 - learning_rate: 3.0000e-05\n",
      "Epoch 1138/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.4115e-04 - val_loss: 0.0908 - learning_rate: 3.0000e-05\n",
      "Epoch 1139/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.3941e-04 - val_loss: 0.0564 - learning_rate: 3.0000e-05\n",
      "Epoch 1140/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7262e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1141/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.5752e-04 - val_loss: 0.0730 - learning_rate: 3.0000e-05\n",
      "Epoch 1142/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.7951e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1143/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.4658e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1144/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5191e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1145/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 6.1840e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 1146/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.6637e-04 - val_loss: 0.0714 - learning_rate: 3.0000e-05\n",
      "Epoch 1147/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.7243e-04 - val_loss: 0.0596 - learning_rate: 3.0000e-05\n",
      "Epoch 1148/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7378e-04 - val_loss: 0.0914 - learning_rate: 3.0000e-05\n",
      "Epoch 1149/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.5844e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1150/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 6.4077e-04 - val_loss: 0.0796 - learning_rate: 3.0000e-05\n",
      "Epoch 1151/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 6.4947e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1152/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 6.4087e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 1153/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.6929e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1154/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.6490e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 1155/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.8218e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 1156/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.5467e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 1157/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.2833e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 1158/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.8365e-04 - val_loss: 0.0706 - learning_rate: 3.0000e-05\n",
      "Epoch 1159/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.6149e-04 - val_loss: 0.0563 - learning_rate: 3.0000e-05\n",
      "Epoch 1160/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.4955e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 1161/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5003e-04 - val_loss: 0.0745 - learning_rate: 3.0000e-05\n",
      "Epoch 1162/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.5604e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1163/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.4533e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1164/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.6483e-04 - val_loss: 0.0816 - learning_rate: 3.0000e-05\n",
      "Epoch 1165/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.5469e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 1166/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.6244e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1167/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5296e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1168/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.4106e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1169/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5271e-04 - val_loss: 0.1149 - learning_rate: 3.0000e-05\n",
      "Epoch 1170/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.9833e-04 - val_loss: 0.0777 - learning_rate: 3.0000e-05\n",
      "Epoch 1171/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.4977e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1172/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.3934e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 1173/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.6928e-04 - val_loss: 0.0716 - learning_rate: 3.0000e-05\n",
      "Epoch 1174/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 6.5003e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 1175/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.5040e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1176/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 6.9446e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1177/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.6802e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1178/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.5865e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 1179/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.4941e-04 - val_loss: 0.0713 - learning_rate: 3.0000e-05\n",
      "Epoch 1180/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.4285e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1181/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3171e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1182/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 6.5508e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 1183/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7054e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1184/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.5123e-04 - val_loss: 0.0766 - learning_rate: 3.0000e-05\n",
      "Epoch 1185/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.4744e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1186/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 6.2366e-04 - val_loss: 0.0876 - learning_rate: 3.0000e-05\n",
      "Epoch 1187/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.5161e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1188/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 6.1795e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1189/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.9394e-04 - val_loss: 0.0840 - learning_rate: 3.0000e-05\n",
      "Epoch 1190/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.6213e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1191/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3670e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1192/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.3884e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1193/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.5825e-04 - val_loss: 0.1143 - learning_rate: 3.0000e-05\n",
      "Epoch 1194/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.4576e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1195/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.2268e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 1196/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.1656e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 1197/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.4746e-04 - val_loss: 0.0563 - learning_rate: 3.0000e-05\n",
      "Epoch 1198/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.4677e-04 - val_loss: 0.0562 - learning_rate: 3.0000e-05\n",
      "Epoch 1199/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7076e-04 - val_loss: 0.0986 - learning_rate: 3.0000e-05\n",
      "Epoch 1200/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 6.4681e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1201/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5992e-04 - val_loss: 0.0840 - learning_rate: 3.0000e-05\n",
      "Epoch 1202/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.4755e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1203/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5595e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1204/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.2599e-04 - val_loss: 0.0752 - learning_rate: 3.0000e-05\n",
      "Epoch 1205/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.4373e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1206/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.3165e-04 - val_loss: 0.0755 - learning_rate: 3.0000e-05\n",
      "Epoch 1207/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3233e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 1208/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.5471e-04 - val_loss: 0.0716 - learning_rate: 3.0000e-05\n",
      "Epoch 1209/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 6.6550e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 1210/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 6.5554e-04 - val_loss: 0.0797 - learning_rate: 3.0000e-05\n",
      "Epoch 1211/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.3941e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1212/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.6755e-04 - val_loss: 0.0811 - learning_rate: 3.0000e-05\n",
      "Epoch 1213/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.1746e-04 - val_loss: 0.0558 - learning_rate: 3.0000e-05\n",
      "Epoch 1214/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.3799e-04 - val_loss: 0.0767 - learning_rate: 3.0000e-05\n",
      "Epoch 1215/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.6982e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1216/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.6613e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 1217/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.4276e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1218/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.3150e-04 - val_loss: 0.0874 - learning_rate: 3.0000e-05\n",
      "Epoch 1219/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.7180e-04 - val_loss: 0.0924 - learning_rate: 3.0000e-05\n",
      "Epoch 1220/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.3581e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1221/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.4990e-04 - val_loss: 0.0591 - learning_rate: 3.0000e-05\n",
      "Epoch 1222/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.3302e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1223/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3507e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1224/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.5439e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1225/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.4257e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1226/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.4412e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1227/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5302e-04 - val_loss: 0.1939 - learning_rate: 3.0000e-05\n",
      "Epoch 1228/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.5141e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1229/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3384e-04 - val_loss: 0.2593 - learning_rate: 3.0000e-05\n",
      "Epoch 1230/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.3442e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1231/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.4365e-04 - val_loss: 0.3821 - learning_rate: 3.0000e-05\n",
      "Epoch 1232/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.4161e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1233/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.3585e-04 - val_loss: 0.0819 - learning_rate: 3.0000e-05\n",
      "Epoch 1234/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.3447e-04 - val_loss: 0.0762 - learning_rate: 3.0000e-05\n",
      "Epoch 1235/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.7521e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1236/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.3561e-04 - val_loss: 0.0727 - learning_rate: 3.0000e-05\n",
      "Epoch 1237/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3863e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1238/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 6.5321e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 1239/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - loss: 6.4672e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 1240/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5920e-04 - val_loss: 0.0806 - learning_rate: 3.0000e-05\n",
      "Epoch 1241/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 6.4814e-04 - val_loss: 0.0595 - learning_rate: 3.0000e-05\n",
      "Epoch 1242/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 7.3893e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1243/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.3065e-04 - val_loss: 0.0594 - learning_rate: 3.0000e-05\n",
      "Epoch 1244/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.4633e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1245/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 6.1817e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1246/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5871e-04 - val_loss: 0.0762 - learning_rate: 3.0000e-05\n",
      "Epoch 1247/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.6634e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1248/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3949e-04 - val_loss: 0.0896 - learning_rate: 3.0000e-05\n",
      "Epoch 1249/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.1735e-04 - val_loss: 0.0849 - learning_rate: 3.0000e-05\n",
      "Epoch 1250/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5176e-04 - val_loss: 0.0930 - learning_rate: 3.0000e-05\n",
      "Epoch 1251/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.2584e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 1252/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 6.6317e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 1253/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 6.2583e-04 - val_loss: 0.1820 - learning_rate: 3.0000e-05\n",
      "Epoch 1254/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.4780e-04 - val_loss: 0.1494 - learning_rate: 3.0000e-05\n",
      "Epoch 1255/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.3218e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1256/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.0394e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1257/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.9958e-04 - val_loss: 0.2859 - learning_rate: 3.0000e-05\n",
      "Epoch 1258/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.4230e-04 - val_loss: 0.0928 - learning_rate: 3.0000e-05\n",
      "Epoch 1259/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.3070e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1260/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.4580e-04 - val_loss: 0.0596 - learning_rate: 3.0000e-05\n",
      "Epoch 1261/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.4017e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1262/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3525e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1263/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 140ms/step - loss: 6.1787e-04 - val_loss: 0.0703 - learning_rate: 3.0000e-05\n",
      "Epoch 1264/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 6.0492e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1265/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.3174e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1266/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.5392e-04 - val_loss: 0.1007 - learning_rate: 3.0000e-05\n",
      "Epoch 1267/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.3508e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1268/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.3687e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1269/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.2665e-04 - val_loss: 0.1075 - learning_rate: 3.0000e-05\n",
      "Epoch 1270/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3228e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 1271/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.2313e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1272/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.3031e-04 - val_loss: 0.1743 - learning_rate: 3.0000e-05\n",
      "Epoch 1273/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.7893e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1274/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.2644e-04 - val_loss: 0.2803 - learning_rate: 3.0000e-05\n",
      "Epoch 1275/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 6.4157e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1276/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 6.5925e-04 - val_loss: 0.0760 - learning_rate: 3.0000e-05\n",
      "Epoch 1277/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 6.4133e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1278/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 6.3034e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 1279/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3892e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 1280/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.3514e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1281/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.2179e-04 - val_loss: 0.0974 - learning_rate: 3.0000e-05\n",
      "Epoch 1282/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.3105e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1283/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.4762e-04 - val_loss: 0.0565 - learning_rate: 3.0000e-05\n",
      "Epoch 1284/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 6.6180e-04 - val_loss: 0.0944 - learning_rate: 3.0000e-05\n",
      "Epoch 1285/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.1959e-04 - val_loss: 0.0780 - learning_rate: 3.0000e-05\n",
      "Epoch 1286/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.4973e-04 - val_loss: 0.0997 - learning_rate: 3.0000e-05\n",
      "Epoch 1287/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.3119e-04 - val_loss: 0.1343 - learning_rate: 3.0000e-05\n",
      "Epoch 1288/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 6.2309e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1289/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.4010e-04 - val_loss: 0.1072 - learning_rate: 3.0000e-05\n",
      "Epoch 1290/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.1611e-04 - val_loss: 0.1081 - learning_rate: 3.0000e-05\n",
      "Epoch 1291/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.2516e-04 - val_loss: 0.0895 - learning_rate: 3.0000e-05\n",
      "Epoch 1292/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.5372e-04 - val_loss: 0.0908 - learning_rate: 3.0000e-05\n",
      "Epoch 1293/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.4437e-04 - val_loss: 0.0587 - learning_rate: 3.0000e-05\n",
      "Epoch 1294/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.0658e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1295/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5005e-04 - val_loss: 0.0847 - learning_rate: 3.0000e-05\n",
      "Epoch 1296/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.0672e-04 - val_loss: 0.0590 - learning_rate: 3.0000e-05\n",
      "Epoch 1297/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1834e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 1298/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.4467e-04 - val_loss: 0.1249 - learning_rate: 3.0000e-05\n",
      "Epoch 1299/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3953e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1300/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 6.1256e-04 - val_loss: 0.1571 - learning_rate: 3.0000e-05\n",
      "Epoch 1301/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.6243e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1302/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.3779e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1303/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.1461e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1304/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.2543e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1305/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 6.3448e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 1306/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.1532e-04 - val_loss: 0.1741 - learning_rate: 3.0000e-05\n",
      "Epoch 1307/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.1167e-04 - val_loss: 0.1482 - learning_rate: 3.0000e-05\n",
      "Epoch 1308/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.0771e-04 - val_loss: 0.1363 - learning_rate: 3.0000e-05\n",
      "Epoch 1309/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.5184e-04 - val_loss: 0.1715 - learning_rate: 3.0000e-05\n",
      "Epoch 1310/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.3366e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1311/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.1810e-04 - val_loss: 0.3046 - learning_rate: 3.0000e-05\n",
      "Epoch 1312/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 6.1853e-04 - val_loss: 0.1307 - learning_rate: 3.0000e-05\n",
      "Epoch 1313/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 212ms/step - loss: 6.1362e-04 - val_loss: 0.0590 - learning_rate: 3.0000e-05\n",
      "Epoch 1314/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.2266e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1315/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.1637e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1316/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.0655e-04 - val_loss: 0.1759 - learning_rate: 3.0000e-05\n",
      "Epoch 1317/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.2030e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1318/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.0798e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1319/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.7567e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1320/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.1114e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1321/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.3405e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1322/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.2622e-04 - val_loss: 0.2005 - learning_rate: 3.0000e-05\n",
      "Epoch 1323/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.4765e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1324/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.8464e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1325/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.2893e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 1326/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3166e-04 - val_loss: 0.0564 - learning_rate: 3.0000e-05\n",
      "Epoch 1327/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.2601e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1328/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.2668e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1329/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.3559e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1330/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1050e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1331/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.3580e-04 - val_loss: 0.1270 - learning_rate: 3.0000e-05\n",
      "Epoch 1332/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.0974e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1333/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.9479e-04 - val_loss: 0.1697 - learning_rate: 3.0000e-05\n",
      "Epoch 1334/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1661e-04 - val_loss: 0.1856 - learning_rate: 3.0000e-05\n",
      "Epoch 1335/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.5925e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1336/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5749e-04 - val_loss: 0.1601 - learning_rate: 3.0000e-05\n",
      "Epoch 1337/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.1026e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1338/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3613e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1339/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.2794e-04 - val_loss: 0.0827 - learning_rate: 3.0000e-05\n",
      "Epoch 1340/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1986e-04 - val_loss: 0.0935 - learning_rate: 3.0000e-05\n",
      "Epoch 1341/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.4305e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 1342/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.2999e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 1343/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 6.5112e-04 - val_loss: 0.1329 - learning_rate: 3.0000e-05\n",
      "Epoch 1344/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.2564e-04 - val_loss: 0.1543 - learning_rate: 3.0000e-05\n",
      "Epoch 1345/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.0732e-04 - val_loss: 0.1159 - learning_rate: 3.0000e-05\n",
      "Epoch 1346/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1687e-04 - val_loss: 0.1357 - learning_rate: 3.0000e-05\n",
      "Epoch 1347/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 6.1773e-04 - val_loss: 0.2629 - learning_rate: 3.0000e-05\n",
      "Epoch 1348/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 6.3583e-04 - val_loss: 0.3191 - learning_rate: 3.0000e-05\n",
      "Epoch 1349/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.2557e-04 - val_loss: 0.3880 - learning_rate: 3.0000e-05\n",
      "Epoch 1350/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.3175e-04 - val_loss: 0.3152 - learning_rate: 3.0000e-05\n",
      "Epoch 1351/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.1912e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1352/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.2267e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1353/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.3881e-04 - val_loss: 0.1669 - learning_rate: 3.0000e-05\n",
      "Epoch 1354/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.3694e-04 - val_loss: 0.1708 - learning_rate: 3.0000e-05\n",
      "Epoch 1355/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1972e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1356/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.6545e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 1357/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.2169e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1358/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.3587e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1359/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9553e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1360/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 6.2332e-04 - val_loss: 0.0564 - learning_rate: 3.0000e-05\n",
      "Epoch 1361/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1457e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1362/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.1852e-04 - val_loss: 0.2813 - learning_rate: 3.0000e-05\n",
      "Epoch 1363/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.3802e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 1364/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 6.2526e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1365/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 6.2902e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1366/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 6.5146e-04 - val_loss: 0.0656 - learning_rate: 3.0000e-05\n",
      "Epoch 1367/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 6.3714e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 19:35:37.050145: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.3023e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1368/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.5838e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1369/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.1118e-04 - val_loss: 0.0620 - learning_rate: 3.0000e-05\n",
      "Epoch 1370/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.4147e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 1371/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.0521e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1372/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.0480e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 1373/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.4362e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1374/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.2216e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1375/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.2526e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1376/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.1180e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1377/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3129e-04 - val_loss: 0.0618 - learning_rate: 3.0000e-05\n",
      "Epoch 1378/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.0855e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 1379/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7808e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1380/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 5.9284e-04 - val_loss: 0.0603 - learning_rate: 3.0000e-05\n",
      "Epoch 1381/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3913e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1382/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 6.5131e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 1383/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.6278e-04 - val_loss: 0.0565 - learning_rate: 3.0000e-05\n",
      "Epoch 1384/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.0559e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1385/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.0578e-04 - val_loss: 0.0600 - learning_rate: 3.0000e-05\n",
      "Epoch 1386/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.0931e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1387/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3765e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1388/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.0890e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1389/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5540e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1390/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 6.2232e-04 - val_loss: 0.0562 - learning_rate: 3.0000e-05\n",
      "Epoch 1391/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8466e-04 - val_loss: 0.0604 - learning_rate: 3.0000e-05\n",
      "Epoch 1392/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.8989e-04 - val_loss: 0.0595 - learning_rate: 3.0000e-05\n",
      "Epoch 1393/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1656e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1394/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.1451e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 1395/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.2831e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1396/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.2374e-04 - val_loss: 0.0561 - learning_rate: 3.0000e-05\n",
      "Epoch 1397/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1317e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 1398/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.0688e-04 - val_loss: 0.0599 - learning_rate: 3.0000e-05\n",
      "Epoch 1399/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.2936e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1400/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 6.2618e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 1401/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1017e-04 - val_loss: 0.0606 - learning_rate: 3.0000e-05\n",
      "Epoch 1402/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.0801e-04 - val_loss: 0.0613 - learning_rate: 3.0000e-05\n",
      "Epoch 1403/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.2665e-04 - val_loss: 0.0595 - learning_rate: 3.0000e-05\n",
      "Epoch 1404/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.0344e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1405/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.1022e-04 - val_loss: 0.0603 - learning_rate: 3.0000e-05\n",
      "Epoch 1406/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 5.9786e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1407/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 6.0780e-04 - val_loss: 0.0591 - learning_rate: 3.0000e-05\n",
      "Epoch 1408/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.2140e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1409/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.0195e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1410/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.2138e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1411/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.7400e-04 - val_loss: 0.0701 - learning_rate: 3.0000e-05\n",
      "Epoch 1412/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.1225e-04 - val_loss: 0.0786 - learning_rate: 3.0000e-05\n",
      "Epoch 1413/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.0915e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 1414/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.9056e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 1415/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.2081e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1416/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.2484e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 1417/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.9962e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1418/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.0304e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1419/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.3668e-04 - val_loss: 0.0628 - learning_rate: 3.0000e-05\n",
      "Epoch 1420/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.0855e-04 - val_loss: 0.0651 - learning_rate: 3.0000e-05\n",
      "Epoch 1421/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.1947e-04 - val_loss: 0.0593 - learning_rate: 3.0000e-05\n",
      "Epoch 1422/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.2835e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 1423/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.0588e-04 - val_loss: 0.0596 - learning_rate: 3.0000e-05\n",
      "Epoch 1424/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3236e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1425/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.2212e-04 - val_loss: 0.0591 - learning_rate: 3.0000e-05\n",
      "Epoch 1426/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9208e-04 - val_loss: 0.0587 - learning_rate: 3.0000e-05\n",
      "Epoch 1427/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.2212e-04 - val_loss: 0.0563 - learning_rate: 3.0000e-05\n",
      "Epoch 1428/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.0765e-04 - val_loss: 0.0593 - learning_rate: 3.0000e-05\n",
      "Epoch 1429/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.0218e-04 - val_loss: 0.0559 - learning_rate: 3.0000e-05\n",
      "Epoch 1430/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.3348e-04 - val_loss: 0.0635 - learning_rate: 3.0000e-05\n",
      "Epoch 1431/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 5.8917e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1432/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3342e-04 - val_loss: 0.0647 - learning_rate: 3.0000e-05\n",
      "Epoch 1433/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.3588e-04 - val_loss: 0.0566 - learning_rate: 3.0000e-05\n",
      "Epoch 1434/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.8743e-04 - val_loss: 0.0695 - learning_rate: 3.0000e-05\n",
      "Epoch 1435/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.0533e-04 - val_loss: 0.0773 - learning_rate: 3.0000e-05\n",
      "Epoch 1436/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.1396e-04 - val_loss: 0.0780 - learning_rate: 3.0000e-05\n",
      "Epoch 1437/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.3447e-04 - val_loss: 0.0615 - learning_rate: 3.0000e-05\n",
      "Epoch 1438/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.1226e-04 - val_loss: 0.0606 - learning_rate: 3.0000e-05\n",
      "Epoch 1439/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.1465e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1440/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1785e-04 - val_loss: 0.0642 - learning_rate: 3.0000e-05\n",
      "Epoch 1441/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.9668e-04 - val_loss: 0.0595 - learning_rate: 3.0000e-05\n",
      "Epoch 1442/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.0546e-04 - val_loss: 0.0594 - learning_rate: 3.0000e-05\n",
      "Epoch 1443/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 5.8337e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1444/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.0261e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1445/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.1497e-04 - val_loss: 0.0599 - learning_rate: 3.0000e-05\n",
      "Epoch 1446/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.1012e-04 - val_loss: 0.0590 - learning_rate: 3.0000e-05\n",
      "Epoch 1447/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.2743e-04 - val_loss: 0.0618 - learning_rate: 3.0000e-05\n",
      "Epoch 1448/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.4451e-04 - val_loss: 0.0600 - learning_rate: 3.0000e-05\n",
      "Epoch 1449/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.9910e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1450/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.0137e-04 - val_loss: 0.0597 - learning_rate: 3.0000e-05\n",
      "Epoch 1451/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 5.8065e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1452/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.0244e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1453/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.0651e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1454/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 5.9638e-04 - val_loss: 0.0659 - learning_rate: 3.0000e-05\n",
      "Epoch 1455/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.0743e-04 - val_loss: 0.0613 - learning_rate: 3.0000e-05\n",
      "Epoch 1456/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1848e-04 - val_loss: 0.0619 - learning_rate: 3.0000e-05\n",
      "Epoch 1457/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.1321e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1458/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 6.2962e-04 - val_loss: 0.0609 - learning_rate: 3.0000e-05\n",
      "Epoch 1459/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 6.2734e-04 - val_loss: 0.0620 - learning_rate: 3.0000e-05\n",
      "Epoch 1460/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 5.9200e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1461/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - loss: 6.2401e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 1462/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 5.9316e-04 - val_loss: 0.0563 - learning_rate: 3.0000e-05\n",
      "Epoch 1463/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.9520e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 1464/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.1573e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1465/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.4368e-04 - val_loss: 0.0596 - learning_rate: 3.0000e-05\n",
      "Epoch 1466/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9045e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1467/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.1608e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1468/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9110e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1469/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.8711e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 1470/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.9167e-04 - val_loss: 0.0558 - learning_rate: 3.0000e-05\n",
      "Epoch 1471/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.0678e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1472/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.9874e-04 - val_loss: 0.0598 - learning_rate: 3.0000e-05\n",
      "Epoch 1473/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 5.9789e-04 - val_loss: 0.0609 - learning_rate: 3.0000e-05\n",
      "Epoch 1474/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.0008e-04 - val_loss: 0.0601 - learning_rate: 3.0000e-05\n",
      "Epoch 1475/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 5.9913e-04 - val_loss: 0.0618 - learning_rate: 3.0000e-05\n",
      "Epoch 1476/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8614e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1477/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.9683e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 1478/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1550e-04 - val_loss: 0.0604 - learning_rate: 3.0000e-05\n",
      "Epoch 1479/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.2517e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1480/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.2465e-04 - val_loss: 0.0592 - learning_rate: 3.0000e-05\n",
      "Epoch 1481/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.3140e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1482/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8715e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 1483/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.9057e-04 - val_loss: 0.0622 - learning_rate: 3.0000e-05\n",
      "Epoch 1484/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.8372e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 1485/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 6.0530e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1486/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.8247e-04 - val_loss: 0.0623 - learning_rate: 3.0000e-05\n",
      "Epoch 1487/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.0989e-04 - val_loss: 0.0591 - learning_rate: 3.0000e-05\n",
      "Epoch 1488/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1340e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1489/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 6.1737e-04 - val_loss: 0.0587 - learning_rate: 3.0000e-05\n",
      "Epoch 1490/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.8754e-04 - val_loss: 0.0617 - learning_rate: 3.0000e-05\n",
      "Epoch 1491/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.8954e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1492/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.0035e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1493/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.1216e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1494/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.1259e-04 - val_loss: 0.0619 - learning_rate: 3.0000e-05\n",
      "Epoch 1495/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.0906e-04 - val_loss: 0.0637 - learning_rate: 3.0000e-05\n",
      "Epoch 1496/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.9517e-04 - val_loss: 0.0565 - learning_rate: 3.0000e-05\n",
      "Epoch 1497/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 5.8580e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1498/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.0779e-04 - val_loss: 0.0560 - learning_rate: 3.0000e-05\n",
      "Epoch 1499/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.0956e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1500/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.2338e-04 - val_loss: 0.0736 - learning_rate: 3.0000e-05\n",
      "Epoch 1501/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.9891e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1502/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7904e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1503/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.0255e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1504/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9428e-04 - val_loss: 0.0564 - learning_rate: 3.0000e-05\n",
      "Epoch 1505/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.0606e-04 - val_loss: 0.0591 - learning_rate: 3.0000e-05\n",
      "Epoch 1506/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1240e-04 - val_loss: 0.0600 - learning_rate: 3.0000e-05\n",
      "Epoch 1507/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.1320e-04 - val_loss: 0.0566 - learning_rate: 3.0000e-05\n",
      "Epoch 1508/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.9962e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1509/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - loss: 6.0400e-04 - val_loss: 0.0590 - learning_rate: 3.0000e-05\n",
      "Epoch 1510/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 5.8462e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 1511/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8186e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1512/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 5.9820e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1513/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.7330e-04 - val_loss: 0.0591 - learning_rate: 3.0000e-05\n",
      "Epoch 1514/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 5.9478e-04 - val_loss: 0.0599 - learning_rate: 3.0000e-05\n",
      "Epoch 1515/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9697e-04 - val_loss: 0.0592 - learning_rate: 3.0000e-05\n",
      "Epoch 1516/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.1983e-04 - val_loss: 0.0605 - learning_rate: 3.0000e-05\n",
      "Epoch 1517/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9179e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1518/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.1419e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1519/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.0307e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1520/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 5.7042e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1521/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 5.7654e-04 - val_loss: 0.0596 - learning_rate: 3.0000e-05\n",
      "Epoch 1522/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8683e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1523/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.9882e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1524/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.3491e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1525/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 6.1831e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 1526/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9492e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1527/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.2807e-04 - val_loss: 0.0594 - learning_rate: 3.0000e-05\n",
      "Epoch 1528/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.9531e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1529/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.8313e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1530/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.9113e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1531/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.0974e-04 - val_loss: 0.0563 - learning_rate: 3.0000e-05\n",
      "Epoch 1532/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7878e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1533/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 5.7200e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1534/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8452e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1535/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.1285e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1536/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.9978e-04 - val_loss: 0.0617 - learning_rate: 3.0000e-05\n",
      "Epoch 1537/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.9319e-04 - val_loss: 0.0591 - learning_rate: 3.0000e-05\n",
      "Epoch 1538/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.7128e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1539/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.0517e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1540/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8260e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1541/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.7808e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1542/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.1045e-04 - val_loss: 0.0596 - learning_rate: 3.0000e-05\n",
      "Epoch 1543/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.1243e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1544/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.0971e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 1545/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.0925e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1546/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.8657e-04 - val_loss: 0.0590 - learning_rate: 3.0000e-05\n",
      "Epoch 1547/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 6.2675e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1548/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.2344e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1549/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.7832e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1550/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.0032e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 1551/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 5.9862e-04 - val_loss: 0.0604 - learning_rate: 3.0000e-05\n",
      "Epoch 1552/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1188e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 1553/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.0828e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 1554/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9542e-04 - val_loss: 0.0609 - learning_rate: 3.0000e-05\n",
      "Epoch 1555/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.8004e-04 - val_loss: 0.0596 - learning_rate: 3.0000e-05\n",
      "Epoch 1556/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.9374e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 1557/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.8645e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 1558/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7940e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1559/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.8480e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1560/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9687e-04 - val_loss: 0.0600 - learning_rate: 3.0000e-05\n",
      "Epoch 1561/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.7070e-04 - val_loss: 0.0566 - learning_rate: 3.0000e-05\n",
      "Epoch 1562/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9291e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 1563/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.2692e-04 - val_loss: 0.0606 - learning_rate: 3.0000e-05\n",
      "Epoch 1564/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7360e-04 - val_loss: 0.0563 - learning_rate: 3.0000e-05\n",
      "Epoch 1565/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.7900e-04 - val_loss: 0.0564 - learning_rate: 3.0000e-05\n",
      "Epoch 1566/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9893e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1567/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.8153e-04 - val_loss: 0.0591 - learning_rate: 3.0000e-05\n",
      "Epoch 1568/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7819e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1569/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.7891e-04 - val_loss: 0.0612 - learning_rate: 3.0000e-05\n",
      "Epoch 1570/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9027e-04 - val_loss: 0.0611 - learning_rate: 3.0000e-05\n",
      "Epoch 1571/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.0107e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1572/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1163e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 1573/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.0622e-04 - val_loss: 0.0597 - learning_rate: 3.0000e-05\n",
      "Epoch 1574/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 5.9562e-04 - val_loss: 0.0600 - learning_rate: 3.0000e-05\n",
      "Epoch 1575/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9874e-04 - val_loss: 0.0595 - learning_rate: 3.0000e-05\n",
      "Epoch 1576/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.9951e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1577/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 5.8908e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 1578/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.8671e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1579/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.6779e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1580/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.8627e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1581/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.8616e-04 - val_loss: 0.0563 - learning_rate: 3.0000e-05\n",
      "Epoch 1582/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.7422e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1583/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.5353e-04 - val_loss: 0.0563 - learning_rate: 3.0000e-05\n",
      "Epoch 1584/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.2625e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1585/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8278e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1586/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.7054e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1587/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.5348e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 1588/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.2033e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1589/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8186e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1590/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.8271e-04 - val_loss: 0.0601 - learning_rate: 3.0000e-05\n",
      "Epoch 1591/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1060e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1592/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.1845e-04 - val_loss: 0.0591 - learning_rate: 3.0000e-05\n",
      "Epoch 1593/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9282e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1594/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.8784e-04 - val_loss: 0.0559 - learning_rate: 3.0000e-05\n",
      "Epoch 1595/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1351e-04 - val_loss: 0.0601 - learning_rate: 3.0000e-05\n",
      "Epoch 1596/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 5.8665e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1597/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.9768e-04 - val_loss: 0.0597 - learning_rate: 3.0000e-05\n",
      "Epoch 1598/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.9288e-04 - val_loss: 0.0614 - learning_rate: 3.0000e-05\n",
      "Epoch 1599/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.9031e-04 - val_loss: 0.0600 - learning_rate: 3.0000e-05\n",
      "Epoch 1600/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.7592e-04 - val_loss: 0.0595 - learning_rate: 3.0000e-05\n",
      "Epoch 1601/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.1299e-04 - val_loss: 0.0587 - learning_rate: 3.0000e-05\n",
      "Epoch 1602/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.0234e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1603/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8844e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1604/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.8554e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 1605/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.6880e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1606/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 5.9498e-04 - val_loss: 0.0564 - learning_rate: 3.0000e-05\n",
      "Epoch 1607/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.8582e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1608/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.7390e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 1609/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.1501e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 1610/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.0031e-04 - val_loss: 0.0599 - learning_rate: 3.0000e-05\n",
      "Epoch 1611/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.2500e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 1612/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 5.9100e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 1613/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7497e-04 - val_loss: 0.0751 - learning_rate: 3.0000e-05\n",
      "Epoch 1614/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.7158e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 1615/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.4547e-04 - val_loss: 0.0627 - learning_rate: 3.0000e-05\n",
      "Epoch 1616/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.7793e-04 - val_loss: 0.0587 - learning_rate: 3.0000e-05\n",
      "Epoch 1617/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.5572e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1618/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.8810e-04 - val_loss: 0.0595 - learning_rate: 3.0000e-05\n",
      "Epoch 1619/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7930e-04 - val_loss: 0.0599 - learning_rate: 3.0000e-05\n",
      "Epoch 1620/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.6712e-04 - val_loss: 0.0607 - learning_rate: 3.0000e-05\n",
      "Epoch 1621/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.7169e-04 - val_loss: 0.0597 - learning_rate: 3.0000e-05\n",
      "Epoch 1622/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.9239e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 1623/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7355e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 1624/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.7762e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1625/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.0413e-04 - val_loss: 0.0627 - learning_rate: 3.0000e-05\n",
      "Epoch 1626/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.9930e-04 - val_loss: 0.0641 - learning_rate: 3.0000e-05\n",
      "Epoch 1627/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8355e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1628/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.9958e-04 - val_loss: 0.0587 - learning_rate: 3.0000e-05\n",
      "Epoch 1629/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7188e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1630/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.1073e-04 - val_loss: 0.0600 - learning_rate: 3.0000e-05\n",
      "Epoch 1631/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 6.0048e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1632/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.9882e-04 - val_loss: 0.0590 - learning_rate: 3.0000e-05\n",
      "Epoch 1633/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 5.8594e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 1634/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - loss: 5.5835e-04 - val_loss: 0.0609 - learning_rate: 3.0000e-05\n",
      "Epoch 1635/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 5.8493e-04 - val_loss: 0.0596 - learning_rate: 3.0000e-05\n",
      "Epoch 1636/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.7267e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1637/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.6060e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1638/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - loss: 5.9034e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1639/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 6.1304e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1640/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.7315e-04 - val_loss: 0.0555 - learning_rate: 3.0000e-05\n",
      "Epoch 1641/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 5.7231e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1642/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8717e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1643/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.6991e-04 - val_loss: 0.0629 - learning_rate: 3.0000e-05\n",
      "Epoch 1644/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.7835e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1645/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 5.8774e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1646/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.6165e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1647/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.9426e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 1648/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7316e-04 - val_loss: 0.0735 - learning_rate: 3.0000e-05\n",
      "Epoch 1649/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 6.0617e-04 - val_loss: 0.0741 - learning_rate: 3.0000e-05\n",
      "Epoch 1650/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.4651e-04 - val_loss: 0.0588 - learning_rate: 3.0000e-05\n",
      "Epoch 1651/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.7689e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1652/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.7031e-04 - val_loss: 0.0593 - learning_rate: 3.0000e-05\n",
      "Epoch 1653/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 5.9774e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1654/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.6496e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 1655/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 5.6582e-04 - val_loss: 0.0625 - learning_rate: 3.0000e-05\n",
      "Epoch 1656/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.7324e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 1657/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.1755e-04 - val_loss: 0.0565 - learning_rate: 3.0000e-05\n",
      "Epoch 1658/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8426e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1659/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.3820e-04 - val_loss: 0.0631 - learning_rate: 3.0000e-05\n",
      "Epoch 1660/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.4111e-04 - val_loss: 0.0566 - learning_rate: 3.0000e-05\n",
      "Epoch 1661/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.7803e-04 - val_loss: 0.0651 - learning_rate: 3.0000e-05\n",
      "Epoch 1662/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.0803e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1663/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 5.6686e-04 - val_loss: 0.0562 - learning_rate: 3.0000e-05\n",
      "Epoch 1664/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9747e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1665/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.6463e-04 - val_loss: 0.0587 - learning_rate: 3.0000e-05\n",
      "Epoch 1666/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.6598e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1667/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 5.8260e-04 - val_loss: 0.0623 - learning_rate: 3.0000e-05\n",
      "Epoch 1668/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.4964e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1669/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.9022e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1670/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8560e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1671/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.1900e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1672/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.4994e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1673/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 5.7366e-04 - val_loss: 0.0603 - learning_rate: 3.0000e-05\n",
      "Epoch 1674/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7732e-04 - val_loss: 0.0564 - learning_rate: 3.0000e-05\n",
      "Epoch 1675/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 5.6329e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1676/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.7748e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1677/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.8386e-04 - val_loss: 0.0603 - learning_rate: 3.0000e-05\n",
      "Epoch 1678/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.6928e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 1679/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.5632e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 1680/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7208e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1681/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.7664e-04 - val_loss: 0.0617 - learning_rate: 3.0000e-05\n",
      "Epoch 1682/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.5989e-04 - val_loss: 0.0595 - learning_rate: 3.0000e-05\n",
      "Epoch 1683/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.6007e-04 - val_loss: 0.0607 - learning_rate: 3.0000e-05\n",
      "Epoch 1684/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7963e-04 - val_loss: 0.0593 - learning_rate: 3.0000e-05\n",
      "Epoch 1685/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.7825e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1686/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8496e-04 - val_loss: 0.0643 - learning_rate: 3.0000e-05\n",
      "Epoch 1687/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 5.6996e-04 - val_loss: 0.0612 - learning_rate: 3.0000e-05\n",
      "Epoch 1688/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.5853e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1689/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - loss: 5.7477e-04 - val_loss: 0.0604 - learning_rate: 3.0000e-05\n",
      "Epoch 1690/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 5.7912e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1691/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 5.8859e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1692/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 5.9791e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1693/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.8454e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1694/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.7804e-04 - val_loss: 0.0636 - learning_rate: 3.0000e-05\n",
      "Epoch 1695/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.7085e-04 - val_loss: 0.0637 - learning_rate: 3.0000e-05\n",
      "Epoch 1696/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.8853e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 1697/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.9981e-04 - val_loss: 0.0566 - learning_rate: 3.0000e-05\n",
      "Epoch 1698/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.5884e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1699/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.8808e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 1700/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.0139e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1701/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.6245e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1702/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - loss: 5.7350e-04 - val_loss: 0.0865 - learning_rate: 3.0000e-05\n",
      "Epoch 1703/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.6622e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 1704/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.6875e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 1705/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.3702e-04 - val_loss: 0.0625 - learning_rate: 3.0000e-05\n",
      "Epoch 1706/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.7375e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1707/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.2288e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1708/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.3832e-04 - val_loss: 0.0608 - learning_rate: 3.0000e-05\n",
      "Epoch 1709/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.4718e-04 - val_loss: 0.0619 - learning_rate: 3.0000e-05\n",
      "Epoch 1710/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.8239e-04 - val_loss: 0.0595 - learning_rate: 3.0000e-05\n",
      "Epoch 1711/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.5524e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1712/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.7256e-04 - val_loss: 0.0607 - learning_rate: 3.0000e-05\n",
      "Epoch 1713/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8766e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1714/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.7513e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1715/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.7989e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1716/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.8666e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1717/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.8564e-04 - val_loss: 0.0648 - learning_rate: 3.0000e-05\n",
      "Epoch 1718/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 5.7336e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1719/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7324e-04 - val_loss: 0.0591 - learning_rate: 3.0000e-05\n",
      "Epoch 1720/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.8667e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1721/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.5549e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1722/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.6078e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1723/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.6098e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1724/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.7171e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1725/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.6464e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1726/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.7221e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1727/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.8451e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1728/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.5942e-04 - val_loss: 0.0566 - learning_rate: 3.0000e-05\n",
      "Epoch 1729/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.5414e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1730/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 5.5801e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1731/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.5410e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1732/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.7714e-04 - val_loss: 0.0589 - learning_rate: 3.0000e-05\n",
      "Epoch 1733/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8217e-04 - val_loss: 0.0614 - learning_rate: 3.0000e-05\n",
      "Epoch 1734/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.6993e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 1735/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7555e-04 - val_loss: 0.0567 - learning_rate: 3.0000e-05\n",
      "Epoch 1736/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.5702e-04 - val_loss: 0.0607 - learning_rate: 3.0000e-05\n",
      "Epoch 1737/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.6565e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1738/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.5934e-04 - val_loss: 0.0590 - learning_rate: 3.0000e-05\n",
      "Epoch 1739/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.6338e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 1740/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.7619e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1741/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7119e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 1742/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.8741e-04 - val_loss: 0.0604 - learning_rate: 3.0000e-05\n",
      "Epoch 1743/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 5.4601e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1744/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.6831e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1745/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.6592e-04 - val_loss: 0.0617 - learning_rate: 3.0000e-05\n",
      "Epoch 1746/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.6789e-04 - val_loss: 0.0596 - learning_rate: 3.0000e-05\n",
      "Epoch 1747/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8136e-04 - val_loss: 0.0624 - learning_rate: 3.0000e-05\n",
      "Epoch 1748/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 5.7053e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1749/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9540e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1750/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.4617e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1751/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 5.6957e-04 - val_loss: 0.0645 - learning_rate: 3.0000e-05\n",
      "Epoch 1752/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.5528e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1753/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.7686e-04 - val_loss: 0.0635 - learning_rate: 3.0000e-05\n",
      "Epoch 1754/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 5.7968e-04 - val_loss: 0.0586 - learning_rate: 3.0000e-05\n",
      "Epoch 1755/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8011e-04 - val_loss: 0.0645 - learning_rate: 3.0000e-05\n",
      "Epoch 1756/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.9953e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1757/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.7894e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 1758/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.6524e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1759/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.6661e-04 - val_loss: 0.0764 - learning_rate: 3.0000e-05\n",
      "Epoch 1760/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 5.4367e-04 - val_loss: 0.0785 - learning_rate: 3.0000e-05\n",
      "Epoch 1761/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.5339e-04 - val_loss: 0.0885 - learning_rate: 3.0000e-05\n",
      "Epoch 1762/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 5.5710e-04 - val_loss: 0.0575 - learning_rate: 3.0000e-05\n",
      "Epoch 1763/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.4547e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1764/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 5.5898e-04 - val_loss: 0.0577 - learning_rate: 3.0000e-05\n",
      "Epoch 1765/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7103e-04 - val_loss: 0.0578 - learning_rate: 3.0000e-05\n",
      "Epoch 1766/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.7748e-04 - val_loss: 0.0587 - learning_rate: 3.0000e-05\n",
      "Epoch 1767/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.9622e-04 - val_loss: 0.0565 - learning_rate: 3.0000e-05\n",
      "Epoch 1768/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.5646e-04 - val_loss: 0.0644 - learning_rate: 3.0000e-05\n",
      "Epoch 1769/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.7010e-04 - val_loss: 0.0596 - learning_rate: 3.0000e-05\n",
      "Epoch 1770/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.6826e-04 - val_loss: 0.0576 - learning_rate: 3.0000e-05\n",
      "Epoch 1771/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.5155e-04 - val_loss: 0.0573 - learning_rate: 3.0000e-05\n",
      "Epoch 1772/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.8505e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1773/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.6633e-04 - val_loss: 0.0614 - learning_rate: 3.0000e-05\n",
      "Epoch 1774/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.7270e-04 - val_loss: 0.0574 - learning_rate: 3.0000e-05\n",
      "Epoch 1775/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.8516e-04 - val_loss: 0.0579 - learning_rate: 3.0000e-05\n",
      "Epoch 1776/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.7462e-04 - val_loss: 0.0614 - learning_rate: 3.0000e-05\n",
      "Epoch 1777/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.4390e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1778/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.8284e-04 - val_loss: 0.0572 - learning_rate: 3.0000e-05\n",
      "Epoch 1779/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.9751e-04 - val_loss: 0.0580 - learning_rate: 3.0000e-05\n",
      "Epoch 1780/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.7473e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1781/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.9545e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 1782/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.8460e-04 - val_loss: 0.0601 - learning_rate: 3.0000e-05\n",
      "Epoch 1783/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.5386e-04 - val_loss: 0.0581 - learning_rate: 3.0000e-05\n",
      "Epoch 1784/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.3633e-04 - val_loss: 0.0568 - learning_rate: 3.0000e-05\n",
      "Epoch 1785/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.4400e-04 - val_loss: 0.0571 - learning_rate: 3.0000e-05\n",
      "Epoch 1786/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.5324e-04 - val_loss: 0.0620 - learning_rate: 3.0000e-05\n",
      "Epoch 1787/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.4491e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 1788/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.8138e-04 - val_loss: 0.0587 - learning_rate: 3.0000e-05\n",
      "Epoch 1789/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.7081e-04 - val_loss: 0.0598 - learning_rate: 3.0000e-05\n",
      "Epoch 1790/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 5.7709e-04 - val_loss: 0.0584 - learning_rate: 3.0000e-05\n",
      "Epoch 1791/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.5590e-04 - val_loss: 0.0585 - learning_rate: 3.0000e-05\n",
      "Epoch 1792/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.8704e-04 - val_loss: 0.0628 - learning_rate: 3.0000e-05\n",
      "Epoch 1793/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.6304e-04 - val_loss: 0.0583 - learning_rate: 3.0000e-05\n",
      "Epoch 1794/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 5.8482e-04 - val_loss: 0.0569 - learning_rate: 3.0000e-05\n",
      "Epoch 1795/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.6142e-04 - val_loss: 0.0658 - learning_rate: 3.0000e-05\n",
      "Epoch 1796/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.5804e-04 - val_loss: 0.0570 - learning_rate: 3.0000e-05\n",
      "Epoch 1797/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.6980e-04 - val_loss: 0.0707 - learning_rate: 3.0000e-05\n",
      "Epoch 1798/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.8300e-04 - val_loss: 0.0582 - learning_rate: 3.0000e-05\n",
      "Epoch 1799/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.5832e-04 - val_loss: 0.0624 - learning_rate: 3.0000e-05\n",
      "Epoch 1800/1800\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.6343e-04 - val_loss: 0.0592 - learning_rate: 3.0000e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with the custom callback\n",
    "history = model_builder.train_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    epochs=1800,\n",
    "    callbacks_list=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the losses from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "train_loss_x_midpoints = history.history.get('x_midpoints_reshape_loss', train_loss)\n",
    "val_loss_x_midpoints = history.history.get('val_x_midpoints_reshape_loss', val_loss)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2,1)\n",
    "plt.plot(train_loss_x_midpoints, label='Train Loss x_midpoints_reshape')\n",
    "plt.plot(val_loss_x_midpoints, label='Validation Loss x_midpoints_reshape')\n",
    "plt.xlabel('Epochs')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_builder.model.save(\"/home/da886/Analysis/12KFixed_13_SparsespotsrandomSPOTSoverfit.keras\")\n",
    "# loaded_model = tf.keras.models.load_model(\n",
    "# \"/home/da886/Analysis/30KFixed_13_SparsespotsrandomSPOTS.keras\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, batch shape: (800, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728677090.987900  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.988805  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.989864  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.990394  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.990490  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.990771  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.990922  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.990943  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.991396  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.991502  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.991517  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.991827  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.992096  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.992126  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.992276  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.992623  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.992857  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.992872  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.993139  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.993371  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.993462  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.993604  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.994019  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.994136  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.994251  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.994563  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.994845  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.994874  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.995028  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.995329  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.995636  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.995657  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.995785  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.996192  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.996429  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.996447  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.996670  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.997090  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.997159  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.997214  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.997771  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.997841  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.997908  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.998405  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.998490  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.998536  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.999000  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.999141  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.999257  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.999756  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.999779  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677090.999909  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.000332  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.000585  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.000694  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.001209  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.001345  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.002050  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.002511  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.003183  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.008544  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.008830  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.008935  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.009129  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.009323  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.009509  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.009697  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.009880  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.010061  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.010250  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.010433  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.010618  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.010802  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.010997  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.011175  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.011363  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.011551  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.011736  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.011919  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.012111  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.012292  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.012494  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.012684  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.012870  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.013082  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.013222  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.013411  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.013620  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.013801  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.013999  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.014199  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.014398  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.014599  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.014790  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.014982  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.015186  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.015370  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.015576  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.015770  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.015951  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.016153  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.016336  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.016483  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.016932  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.016950  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.017485  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.017608  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.017979  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.018149  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.018372  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.018534  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.018798  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.018908  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.019205  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.019511  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.019821  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.020115  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.020420  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.020722  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.021152  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.021488  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.021807  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.022332  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.022667  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.022976  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.023294  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.023608  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.023928  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.024255  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.024563  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.024883  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.025228  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.025569  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.025930  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.026442  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.027104  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.027422  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.027570  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.027761  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.028132  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.028227  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.028448  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.028504  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.028864  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.028939  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.029284  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.029361  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.029685  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.029763  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.030070  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.030150  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.030464  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.030542  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.030865  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.030943  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.031245  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.031531  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.031777  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.031921  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.032080  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.032468  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.032554  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.032739  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.033028  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.033298  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.033448  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.033740  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.033898  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.034156  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.034375  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.034929  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.035006  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.035588  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.035666  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.036089  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.036566  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.041058  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.041306  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.041564  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.041817  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.042077  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.042343  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.042570  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.042638  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.043144  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.043192  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.043294  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.043784  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.043788  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.043925  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.044218  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.044336  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.044446  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.044712  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.044831  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.045096  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.045318  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.045322  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.045570  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.045890  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.045902  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.046176  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.046462  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.046496  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.046763  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.047042  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.047087  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.047317  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.047612  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.047646  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.047865  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.048200  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.048221  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.048468  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.048765  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.048784  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.048940  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.049116  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.049498  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.049516  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.049623  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.050227  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.050235  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.050249  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.050767  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.050916  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.050923  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.051124  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.051343  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.051618  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.051714  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.052085  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.052097  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.052392  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.052499  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.053211  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.053224  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.053849  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.053862  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.054264  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.054837  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.058844  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.059164  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.059447  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.059731  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.060177  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.060189  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.060579  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.060779  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.060902  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.060938  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.061362  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.061382  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.061596  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.061836  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.062147  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.062244  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.062381  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.062790  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.062964  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.063005  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.063311  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.063624  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.063641  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.063888  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.064235  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.064251  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.064483  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.064847  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.064864  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.065105  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.065403  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.065415  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.065692  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.066028  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.066059  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.066155  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.066502  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.066784  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.066805  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.067039  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.067359  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.067385  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.067516  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.067923  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.068057  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.068076  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.068520  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.068661  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.069058  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.069073  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.069226  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.069491  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.069863  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.069935  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.070041  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.070431  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.070557  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.070957  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.071305  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.071500  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.071614  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.071907  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.072698  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.072876  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.073551  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.073627  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.074198  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.074353  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.074948  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.077784  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.078130  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.078429  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.078737  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.079046  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.079349  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.079659  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.079934  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.080251  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.080554  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.080837  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.081121  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.081948  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.082528  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.083744  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.084319  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.084999  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.085731  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.086466  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.086638  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.086934  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.087223  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.087510  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.087807  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.088096  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.088392  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.088689  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.089010  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.089337  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.089646  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.089955  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.090260  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.090405  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.090642  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.090861  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.091063  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.091267  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.091474  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.091660  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.091904  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.092071  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.092326  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.092491  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.092923  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.093004  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.093269  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.093698  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.093771  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.094093  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.094533  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.094615  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.094885  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.095241  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.095632  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.096405  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.097221  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.098745  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.098837  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.099055  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.099343  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.099632  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.099949  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.100250  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.100367  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.100662  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.101096  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.101190  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.101438  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.101756  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.101944  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.102187  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.102204  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.102491  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.102586  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.103071  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.103084  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.103539  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.103626  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.104009  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.104108  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.104581  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.104590  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.105137  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.105151  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.105703  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.105714  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.106160  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.106260  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.106480  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.107058  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.107073  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.107428  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.107841  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.108205  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.108453  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.109121  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.110136  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.111058  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.112530  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.113443  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.115061  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.115171  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.115427  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.115756  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.116066  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.116383  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.116720  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.117033  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.117352  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.117672  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.117980  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.118315  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.118655  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.119405  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.120311  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.121302  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.122211  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.123084  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.123405  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.123788  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.123887  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.124189  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.124499  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.124739  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.124915  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.125233  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.125578  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.125933  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.126290  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.126511  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.126678  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.127038  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.127442  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.127850  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.128264  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.128694  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.129129  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.129853  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.130612  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.131846  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.132636  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.138537  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.138870  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.139196  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.139522  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.139848  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.139865  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.140324  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.140411  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.140716  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.140934  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.141112  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.141391  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.141574  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.141811  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.142043  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.142344  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.142608  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.142885  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.143149  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.143418  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.143688  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.143945  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.144259  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.144478  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.144849  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.145040  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.145358  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.145564  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.145906  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.146117  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.146468  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.146693  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.147373  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.147392  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.147985  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.148260  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.148596  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.149187  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.149560  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.149860  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.149948  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.150225  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.150763  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.150777  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.151100  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.151654  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.151666  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.151996  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.152330  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.152674  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.153153  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.153542  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.153857  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.153966  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.154321  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.154684  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.155233  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.155335  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.155668  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.156077  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.156516  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.156977  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.157699  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.158463  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.158568  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.158906  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.159300  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.159899  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.160000  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.160283  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.160719  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.161104  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.161200  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.161573  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.161942  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.162343  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.162761  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.163173  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.164303  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.164460  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.164802  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.165263  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.165693  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.166162  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.166326  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.166816  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.167348  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.167894  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.167972  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.168455  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.168591  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.169157  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.169183  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.169869  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.169883  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.169984  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.170289  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.170623  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.170731  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.171156  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.171393  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.171586  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.171953  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.172396  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.172503  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.172807  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.173225  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.173636  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.174060  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.174674  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.174914  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.175582  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.176545  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.176908  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.178133  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.179196  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.179734  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.181234  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.181404  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.183631  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.183873  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.185379  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.188073  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.221970  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.222383  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.222774  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.223162  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.223558  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.223964  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.224371  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.224776  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.225203  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.225644  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.226086  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.226533  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.227009  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.227555  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.228113  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.228688  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.229306  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.229957  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.231479  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.231597  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.232022  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.232410  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.232803  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.233201  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.233735  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.233842  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.234154  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.234556  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.234990  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.235555  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.235658  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.236006  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.236455  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.236923  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.237476  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.238038  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.238609  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.239225  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.240007  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.241484  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.243611  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.245267  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.245454  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.246012  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.246504  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.246988  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.247586  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.248075  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.248614  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.249161  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.249716  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.250262  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.250822  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.251370  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.253812  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.254923  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.255478  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.255970  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.256586  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.256669  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.257268  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.257754  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.258285  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.258826  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.259267  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.259364  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.259912  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.260470  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.261010  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.261567  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.263449  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.263979  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.266037  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.266435  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.268568  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.270273  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.270941  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.270962  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.271574  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.271642  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.272058  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.272551  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.273062  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.273377  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.273572  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.274076  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.274617  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.275210  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.275964  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.275982  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.276575  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.277169  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.277963  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.278708  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.279518  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.280400  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.280931  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.281359  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.289411  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.291619  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.301436  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.301846  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.302234  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.302661  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.303086  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.303556  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.304036  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.305316  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.306623  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.307929  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.310211  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.311881  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.314149  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.316032  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.355700  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.356100  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.356484  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.356877  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.357265  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.357650  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.358048  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.358450  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.358849  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.359224  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.359610  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.360025  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.360436  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.360849  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.361320  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.361821  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.362487  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.362634  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.363050  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.363221  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.363634  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.363810  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.364426  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.364498  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.365143  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.365159  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.365694  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.366230  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.366930  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.367009  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.367531  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.368144  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.368726  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.368891  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.369525  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.370201  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.371083  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.371320  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.371900  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.372070  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.372407  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.373055  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.373144  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.373687  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.374156  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.374252  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.374791  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.375341  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.375449  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.376027  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.376638  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.377260  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.377468  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.378058  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.378175  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.378186  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.378516  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.378988  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.379003  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.379458  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.380002  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.380012  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.381268  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.381524  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.382093  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.382327  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.382332  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.382608  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.383467  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.383487  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.384184  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.384555  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.384872  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.385572  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.386691  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.386973  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.388187  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.390840  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.396398  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.396851  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.397265  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.397464  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.397841  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.397919  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.398353  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.398430  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.398703  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.399203  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.399227  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.399568  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.399772  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.399943  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.400241  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.400539  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.400915  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.401120  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.401318  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.401715  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.402036  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.402410  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.402780  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.402857  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.403185  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.403607  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.404003  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.404565  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.404586  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.405007  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.405080  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.405470  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.405839  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.405990  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.406157  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.406433  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.406979  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.407254  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.407654  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.408322  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.408921  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.409817  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.410995  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.411484  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.412840  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.413356  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.414027  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.414551  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.415320  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.415338  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.415779  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.416296  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.416823  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.417372  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.417942  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.418205  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.418526  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.419796  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.420199  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.421090  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.422007  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.422478  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/25\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728677091.424980  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.428451  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.429977  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.433144  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.436433  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.436781  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.437139  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.437529  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.437839  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.438178  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.438518  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.438875  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.439234  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.439869  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.440246  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.440665  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.441098  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.441653  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.442220  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.442811  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.443538  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.444203  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.444915  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.445786  813257 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.458894  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.459288  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.459669  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.460064  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.460450  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.460833  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.461233  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.461633  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.462024  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.462444  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.462856  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.463280  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.463734  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.464180  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.464656  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.465182  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.465751  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.466287  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.466851  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.467514  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.467764  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.468305  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.468399  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.468698  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.469092  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.469488  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.469869  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.470467  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.470481  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.470879  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.471274  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.471690  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.472235  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.472333  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.472676  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.473128  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.473578  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.474050  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.474570  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.475263  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.475812  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.476366  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.477052  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.477761  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.479467  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.481108  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.481205  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.481557  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.481890  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.482227  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.482677  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.483050  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.483518  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.484050  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.484538  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.485223  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.485913  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.486769  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.487609  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.488729  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.490066  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.490332  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.490452  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.490785  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.491126  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.491553  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.491919  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.492391  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.492795  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.493270  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.493954  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.494641  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.495488  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.496327  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.497446  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.498927  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.502579  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.502904  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.503209  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.503522  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.503842  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.504159  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.504472  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.504772  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.505076  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.505439  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.505813  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.506214  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.506557  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.506930  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.507258  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.507588  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.508015  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.508421  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.508901  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.509396  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.510017  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.511333  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.511334  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.511660  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.511959  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.512272  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.512700  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.513009  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.513320  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.513618  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.513911  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.514273  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.514647  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.515045  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.515383  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.515751  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.516077  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.516407  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.516823  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.517244  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.517716  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.517929  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.518340  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.518454  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.518791  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.519085  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.519198  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.519514  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.519864  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.520450  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.520455  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.520806  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.521192  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.522290  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.523396  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.524571  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.526892  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.527110  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.527299  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.527615  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.527923  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.528245  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.528585  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.528919  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.529264  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.529646  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.530668  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.530835  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.531938  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.532212  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.533117  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.535385  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.535608  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.538661  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.539141  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.539240  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.539520  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.539908  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.540220  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.540554  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.540796  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.540964  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.541569  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.541930  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.542569  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.542950  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.543370  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.543918  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.544014  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.544492  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.545063  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.545648  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.546371  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.547052  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.547285  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.547664  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.547831  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.548043  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.548427  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.548859  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.548957  813224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.549246  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.549582  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.550056  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.550430  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.551065  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.551449  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.551872  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.552296  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.552851  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.553421  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.554006  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.554733  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.555428  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.556141  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728677091.557055  813289 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "Processing batch 2, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 3, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 4, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 5, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 6, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Processing batch 7, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "Processing batch 8, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 9, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 10, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 11, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 12, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the function for visualizing midpoints\n",
    "def visualize_midpoints(image, midpoints, title=\"Predicted Midpoint Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualizes midpoints on an image without using a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "    - title: The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    midpoints_np = midpoints\n",
    "\n",
    "    # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot midpoints directly, only if they are not (0, 0)\n",
    "    for i, (x, y) in enumerate(midpoints_np):\n",
    "        if x >= 0 and y >= 0:  # Only plot if the point is not (0, 0)\n",
    "            plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create the validation dataset\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n",
    "# val_dataset = val_dataset.batch(800)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)\n",
    "# # Initialize lists to collect the data\n",
    "all_images = []\n",
    "all_true_midpoints = []\n",
    "all_pred_midpoints = []\n",
    "\n",
    "# # Loop through each batch in the validation dataset, predict, and collect results\n",
    "# for i, (data_batch, midpoints_batch) in enumerate(val_dataset):\n",
    "\n",
    "for i, (data_batch, midpoints_batch) in enumerate(train_dataset):\n",
    "    print(f\"Processing batch {i + 1}, batch shape: {data_batch.shape}\")\n",
    "    \n",
    "    # Get the model predictions\n",
    "    predictions =model_builder.model.predict(data_batch)\n",
    "\n",
    "    # Extend the lists to store data from each batch\n",
    "    all_images.extend(data_batch.numpy())  # Store all images\n",
    "    all_true_midpoints.extend(midpoints_batch.numpy())  # Store all true midpoints\n",
    "    all_pred_midpoints.extend(predictions)  # Store all predicted midpoints\n",
    "\n",
    "# Convert lists to arrays for easier indexing\n",
    "all_images = np.array(all_images)\n",
    "all_true_midpoints = np.array(all_true_midpoints)\n",
    "all_pred_midpoints = np.array(all_pred_midpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9600, 64, 64), (9600, 1, 13, 2), (9600, 1, 13, 2))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape,all_pred_midpoints.shape,all_true_midpoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select an index to visualize from the entire dataset\n",
    "index_to_visualize = np.random.randint(0, len(all_images))\n",
    "\n",
    "# index_to_visualize = 11548\n",
    "# Visualize the selected image with predicted and true midpoints\n",
    "visualize_midpoints(all_images[index_to_visualize], all_pred_midpoints[index_to_visualize, 0, :, :] * np.max(centers), title=\"Predicted Midpoints\")\n",
    "visualize_midpoints(all_images[index_to_visualize], all_true_midpoints[index_to_visualize, 0, :, :] * np.max(centers), title=\"Ground Truth Midpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-160.59007, 303.0473)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_pred_midpoints)*np.max(centers),np.max(all_pred_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 63.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_true_midpoints)*np.max(centers),np.max(all_true_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 63.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_images), np.max(train_images), np.min(train_midpoints)*np.max(centers), np.max(train_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[37.49769  ,  0.893701 ],\n",
       "         [ 5.268126 ,  2.3811095],\n",
       "         [ 6.2055097,  9.41111  ],\n",
       "         [38.5479   , 14.923272 ],\n",
       "         [ 1.6805356, 27.386879 ],\n",
       "         [45.822754 , 30.42933  ],\n",
       "         [27.461199 , 36.76014  ],\n",
       "         [39.048737 , 38.981136 ],\n",
       "         [13.185979 , 48.234604 ],\n",
       "         [38.724014 , 50.478184 ],\n",
       "         [ 5.041256 , 56.032772 ],\n",
       "         [27.951286 , 54.13892  ],\n",
       "         [28.76817  , 58.81217  ]]], dtype=float32),\n",
       " array([[[37.,  1.],\n",
       "         [ 6.,  3.],\n",
       "         [ 5., 11.],\n",
       "         [38., 13.],\n",
       "         [ 1., 30.],\n",
       "         [46., 33.],\n",
       "         [28., 34.],\n",
       "         [38., 38.],\n",
       "         [14., 48.],\n",
       "         [38., 50.],\n",
       "         [ 5., 57.],\n",
       "         [28., 57.],\n",
       "         [29., 59.]]], dtype=float32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred_midpoints[2]*np.max(centers),all_true_midpoints[2]*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1., 35., 12.],\n",
       "        [ 1., 63., 52.],\n",
       "        [ 1., 11., 43.],\n",
       "        ...,\n",
       "        [ 1., 10., 33.],\n",
       "        [ 1., 11., 48.],\n",
       "        [ 1., 59., 49.]],\n",
       "\n",
       "       [[ 1.,  5., 24.],\n",
       "        [ 1., 34., 55.],\n",
       "        [ 1., 42., 29.],\n",
       "        ...,\n",
       "        [ 1.,  2., 55.],\n",
       "        [ 1., 13., 17.],\n",
       "        [ 1., 45.,  8.]],\n",
       "\n",
       "       [[ 1., 38., 36.],\n",
       "        [ 1., 11., 33.],\n",
       "        [ 1., 40., 40.],\n",
       "        ...,\n",
       "        [ 1., 45.,  5.],\n",
       "        [ 1.,  8.,  7.],\n",
       "        [ 1., 55., 37.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1., 50., 18.],\n",
       "        [ 1., 20., 19.],\n",
       "        [ 1., 63.,  8.],\n",
       "        ...,\n",
       "        [ 1., 32., 44.],\n",
       "        [ 1., 63., 24.],\n",
       "        [ 1., 51., 52.]],\n",
       "\n",
       "       [[ 1.,  6., 33.],\n",
       "        [ 1., 23., 59.],\n",
       "        [ 1., 13., 48.],\n",
       "        ...,\n",
       "        [ 1., 26., 62.],\n",
       "        [ 1., 20., 42.],\n",
       "        [ 1., 53.,  2.]],\n",
       "\n",
       "       [[ 1., 24., 40.],\n",
       "        [ 1., 30., 43.],\n",
       "        [ 1., 38., 55.],\n",
       "        ...,\n",
       "        [ 1., 31., 56.],\n",
       "        [ 1., 21., 50.],\n",
       "        [ 1., 15.,  6.]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[2],)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables to track the min and max MSE\n",
    "min_mse = float('inf')\n",
    "max_mse = float('-inf')\n",
    "min_mse_index = -1\n",
    "max_mse_index = -1\n",
    "\n",
    "# Loop through each prediction to calculate the MSE\n",
    "for i in range(len(all_pred_midpoints)):\n",
    "    mse = np.mean((all_pred_midpoints[i] - all_true_midpoints[i]) **2)\n",
    "    \n",
    "    if mse < min_mse:\n",
    "        min_mse = mse\n",
    "        min_mse_index = i\n",
    "    \n",
    "    if mse > max_mse:\n",
    "        max_mse = mse\n",
    "        max_mse_index = i\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot an image with its centers\n",
    "def plot_image_with_centers(image, true_center, predicted_center, title):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  # Display the image\n",
    "\n",
    "    # Plot the actual center (Groundtruth)\n",
    "    plt.scatter(true_center[:, 0], true_center[:, 1], color='green', label='Groundtruth', s=10)\n",
    "\n",
    "    # Plot the predicted center\n",
    "    plt.scatter(predicted_center[:, 0], predicted_center[:, 1], color='red', label='Predictions', s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the image with the least MSE\n",
    "plot_image_with_centers(all_images[min_mse_index],\n",
    "                        all_true_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Least MSE. MSE: {min_mse:.4f}')\n",
    "\n",
    "# Plotting the image with the largest MSE\n",
    "plot_image_with_centers(all_images[max_mse_index],\n",
    "                        all_true_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Largest MSE. MSE: {max_mse:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5266"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mse_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
