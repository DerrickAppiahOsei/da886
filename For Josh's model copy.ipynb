{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Set CUDA device order and visible devices\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7,8,9\"\n",
    "\n",
    "# # Set the device\n",
    "# device = '/cpu:0'\n",
    "# if tf.config.experimental.list_physical_devices('GPU'):\n",
    "#     try:\n",
    "#         # Restrict TensorFlow to only use the second GPU\n",
    "#         gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#         if gpus:\n",
    "#             tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "#             device = '/gpu:0'\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "\n",
    "# print(\"device\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:32:06.983537: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-04 18:32:06.997360: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-04 18:32:07.009996: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-04 18:32:07.013825: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-04 18:32:07.025424: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-04 18:32:07.646055: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:32:09.239678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79194 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:45:00.0, compute capability: 8.0\n",
      "2024-10-04 18:32:09.242178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79194 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:46:00.0, compute capability: 8.0\n",
      "2024-10-04 18:32:09.243555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79194 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:49:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # Only GPUs 0 and 1 will be visible to TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\",\"/gpu:2\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# DataLoader Class Definition\n",
    "# -----------------------------\n",
    "class DataLoader:\n",
    "    def __init__(self, h5_filename):\n",
    "        self.h5_filename = h5_filename\n",
    "        self.images, self.centers = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with h5py.File(self.h5_filename, 'r') as f:\n",
    "            images = np.array(f['images'])\n",
    "            centers = np.array(f['centers_training'])\n",
    "        return images, centers\n",
    "\n",
    "    def plot_image_with_centers(self, image_index=None):\n",
    "        if image_index is None:\n",
    "            image_index = np.random.randint(0, len(self.images))\n",
    "\n",
    "        image = self.images[image_index]\n",
    "        centers = self.centers[image_index]\n",
    "\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        valid_centers = centers[centers[:, 0] == 1]\n",
    "        for center in valid_centers:\n",
    "            plt.scatter(center[1], center[2], c='red', marker='x')  # center[1] is x and center[2] is y\n",
    "        plt.title('Image with Valid Centers Marked')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_centers(centers):\n",
    "        return centers[np.lexsort((centers[:, 0], centers[:, 1]))]\n",
    "\n",
    "    def normalize_data(self):\n",
    "        normalized_images = self.images / np.max(self.images)\n",
    "        sorted_centers = np.array([self.sort_centers(image_centers[:, 1:]) for image_centers in self.centers])\n",
    "        normalized_centers = sorted_centers / 64\n",
    "\n",
    "        normalized_midpoints = tf.expand_dims(normalized_centers, axis=1)\n",
    "        return normalized_images, normalized_midpoints.numpy()\n",
    "\n",
    "    def split_data(self, train_size=0.8, random_state=42):\n",
    "        normalized_images, normalized_midpoints_np = self.normalize_data()\n",
    "        return train_test_split(normalized_images, normalized_midpoints_np, train_size=train_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Utility Function Definition\n",
    "# -----------------------------\n",
    "def plot_transposed_images_with_midpoints(dataset, image_indices=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Extracts multiple images and their midpoints from the given dataset, transposes the images, \n",
    "    corrects the midpoints, and plots the transposed images with the corrected midpoints.\n",
    "\n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The dataset from which to extract the images and midpoints.\n",
    "    - image_indices (list): The indices of the images in the batch to visualize. Default is [0, 1, 2, 3].\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract a sample image batch and its corresponding midpoints from the dataset\n",
    "    sample_image_batch, sample_midpoints_batch = next(iter(dataset))\n",
    "\n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(image_indices):\n",
    "            # Select the specified image and corresponding midpoints from the batch\n",
    "            sample_image = np.array(sample_image_batch[image_indices[i]])\n",
    "            sample_midpoints = np.array(sample_midpoints_batch[image_indices[i]])\n",
    "\n",
    "            # Transpose the image\n",
    "            transposed_image = sample_image.T\n",
    "\n",
    "            # Correct the midpoints by swapping the x and y coordinates\n",
    "            transposed_midpoints_corrected = sample_midpoints[:, :, [1, 0]]\n",
    "\n",
    "            # Plot the transposed image with corrected midpoints\n",
    "            ax.imshow(transposed_image, cmap='gray')\n",
    "            ax.scatter(\n",
    "                transposed_midpoints_corrected[:, :, 0] * 64, \n",
    "                transposed_midpoints_corrected[:, :, 1] * 64, \n",
    "                c='red', marker='o', s=5\n",
    "            )\n",
    "            ax.set_title(f'Image {image_indices[i]} for this batch')\n",
    "        else:\n",
    "            ax.axis('off')  # If fewer than 4 images are requested, hide the unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Loss and Callback Definitions\n",
    "# -----------------------------\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(exponent):\n",
    "    def loss(y_true, y_pred):\n",
    "        diff = tf.abs(y_true - y_pred)\n",
    "        powered_diff = tf.pow(diff, exponent)\n",
    "        return tf.reduce_mean(powered_diff)\n",
    "    return loss\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DynamicExponentCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_exponent, increment, update_frequency):\n",
    "        super().__init__()\n",
    "        self.exponent = initial_exponent\n",
    "        self.increment = increment\n",
    "        self.update_frequency = update_frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.update_frequency == 0:\n",
    "            self.exponent += self.increment\n",
    "            print(f\"\\nEpoch {epoch + 1}: Increasing exponent to {self.exponent}\")\n",
    "            self.model.loss = self.custom_loss(self.exponent)\n",
    "\n",
    "    def custom_loss(self, exponent):\n",
    "        def loss(y_true, y_pred):\n",
    "            diff = tf.abs(y_true - y_pred)\n",
    "            powered_diff = tf.pow(diff, exponent)\n",
    "            return tf.reduce_mean(powered_diff)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'initial_exponent': self.exponent,\n",
    "            'increment': self.increment,\n",
    "            'update_frequency': self.update_frequency,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my NEW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# class ModelBuilder:\n",
    "#     def __init__(self, input_shape=(64, 64, 1), num_classes=3, num_coordinates=2, learning_rate=3e-5, weights_path=None, l2_reg=0.001):\n",
    "#         self.input_shape = input_shape\n",
    "#         self.num_classes = num_classes\n",
    "#         self.num_coordinates = num_coordinates\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.l2_reg = l2_reg\n",
    "#         self.model = self.build_model()\n",
    "\n",
    "#         # Load weights if a path is provided\n",
    "#         if weights_path is not None:\n",
    "#             self.model.load_weights(weights_path)\n",
    "\n",
    "#         self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "#         # self.optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "#     def build_model(self):\n",
    "#         l2 = regularizers.l2(self.l2_reg)\n",
    "        \n",
    "#         x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "#         # First branch\n",
    "#         x_1 = layers.Conv2D(64, kernel_size=6, strides=1, padding='same', activation='relu')(x_input)\n",
    "#         x_1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=3, padding='same', activation='relu', kernel_regularizer=l2)(x_1)\n",
    "#         # x_1 = layers.Dropout(0.1)(x_1)\n",
    "#         # x_1 = layers.BatchNormalization()(x_1)\n",
    "\n",
    "#         # Second branch\n",
    "#         x_2 = layers.Conv2D(32, kernel_size=8, strides=3, padding='same', activation='relu')(x_input)\n",
    "#         x_2 = layers.Conv2D(64, kernel_size=4, strides=1, padding='same', activation='relu')(x_2)\n",
    "#         x_2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_2)\n",
    "#         # x_2 = layers.Dropout(0.1)(x_2)\n",
    "#         # x_2 = layers.BatchNormalization()(x_2)\n",
    "\n",
    "#         # Concatenate branches\n",
    "#         x_3 = layers.concatenate([x_1, x_2])\n",
    "#         x_3 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_3)\n",
    "#         # x_3 = layers.Dropout(0.1)(x_3)\n",
    "#         # x_3 = layers.BatchNormalization()(x_3)\n",
    "\n",
    "#         # Third branch\n",
    "#         x_4 = layers.Conv2D(64, kernel_size=19, strides=5, padding='same', activation='relu', kernel_regularizer=l2)(x_input)\n",
    "        \n",
    "#         # Flatten and concatenate\n",
    "#         x_3 = layers.Flatten()(x_3)\n",
    "#         x_4 = layers.Flatten()(x_4)\n",
    "#         x = layers.Concatenate()([x_3, x_4])\n",
    "\n",
    "#         # Dense layers with L2 regularization\n",
    "#         x = layers.Dense(256, activation='relu', kernel_regularizer=l2)(x)\n",
    "#         # x = layers.Dropout(0.1)(x)\n",
    "\n",
    "#         # Output layer for midpoints\n",
    "#         x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "#         x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "#         return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "#     def compile_model(self, loss_function):\n",
    "#         self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "#     def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "#         history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "#         return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, input_shape=(64, 64, 1), num_classes=13, num_coordinates=2, learning_rate=1e-3, weights_path=None,l1_reg=0.001,l2_reg =0.005):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_coordinates = num_coordinates\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # Load weights if a path is provided\n",
    "        if weights_path is not None:\n",
    "            self.model.load_weights(weights_path)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        # self.optimizer =tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        l1 = regularizers.l1(self.l1_reg)\n",
    "        l2 = regularizers.l2(self.l2_reg)\n",
    "\n",
    "    \n",
    "        x_input = layers.Input(shape=self.input_shape)\n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu',kernel_regularizer=l2)(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=5, padding='same', activation='relu',kernel_regularizer=l2)(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        # x = layers.Dense(16, activation='relu')(x)\n",
    "        \n",
    "        \n",
    "        x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "        x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "        return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "    def compile_model(self, loss_function):\n",
    "        self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "    def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "        history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Main Script Execution\n",
    "# -----------------------------\n",
    "\n",
    "# Load data\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_Mixed_13.h5'             \n",
    "h5_filename = '/home/da886/Final Electron counting project/Images and Labels/50KFixed-index6_13.h5'\n",
    "data_loader = DataLoader(h5_filename)\n",
    "images, centers = data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6914246750>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=np.random.randint(0,len(centers))\n",
    "data_loader.plot_image_with_centers(l)\n",
    "plt.imshow(images[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data and split it into training and validation sets\n",
    "train_images, val_images, train_midpoints, val_midpoints = data_loader.split_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: (40000, 64, 64), Train Midpoints: (40000, 1, 13, 2)\n",
      "Validation Images: (10000, 64, 64), Validation Midpoints: (10000, 1, 13, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 1000\n",
    "train_dataset = train_dataset.shuffle(buffer_size=8000, reshuffle_each_iteration=True).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=8000).batch(batch_size)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f'Train Images: {train_images.shape}, Train Midpoints: {train_midpoints.shape}')\n",
    "print(f'Validation Images: {val_images.shape}, Validation Midpoints: {val_midpoints.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_transposed_images_with_midpoints(train_dataset, image_indices=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=10, verbose=1, mode='min', min_lr=3e-6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">26,650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m3,277,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │        \u001b[38;5;34m26,650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m2\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,352,602</span> (39.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,352,602\u001b[0m (39.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,350,170</span> (39.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,350,170\u001b[0m (39.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> (9.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,432\u001b[0m (9.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# dynamic_exponent_callback = DynamicExponentCallback(2, 1, 50)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # Instantiate the model builder\n",
    "    # model_builder = ModelBuilder(weights_path= \"/home/da886/Weights from Josh's model/Josh's5fixedMSE45overfit-1.keras\")\n",
    "    model_builder = ModelBuilder()\n",
    "\n",
    "    # Build the model\n",
    "    model_builder.build_model()\n",
    "\n",
    "    # Display the model architecture\n",
    "    model_builder.model.summary()\n",
    "\n",
    "    # Compile the model using the custom loss function\n",
    "    # model_builder.compile_model(loss_function=dynamic_exponent_callback.custom_loss(2))\n",
    "    model_builder.compile_model(loss_function=tf.keras.losses.MeanSquaredError()) \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:33:43.383704: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/cond/else/_402/cond/StatefulPartitionedCall/functional_1/dropout_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-10-04 18:33:47.557547: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-04 18:33:47.567823: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-04 18:33:47.614224: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1728066827.643439  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.649072  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.652186  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.686329  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.686329  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.686476  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.687390  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.687400  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.687598  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.688336  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.688409  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.688566  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.690330  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.690855  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.691067  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.691296  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.691803  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.692081  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.693531  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.693605  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.694025  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.694728  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.694811  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.695152  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.695796  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.695878  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.696158  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.696997  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.697101  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.697334  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.700126  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.700135  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.700741  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.701104  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.701111  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.701821  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.702025  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.702105  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.702652  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.702871  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.702972  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.703539  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.704153  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.704246  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.704710  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.705510  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.705602  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.706036  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.715371  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.715378  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.715806  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.716873  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.716953  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.717303  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.718460  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.718535  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.718803  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.720091  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.720213  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.720439  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.721797  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.721902  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.722127  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.723452  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.723553  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.723779  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.737956  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.737956  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.739675  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.739759  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.740535  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.740916  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.740923  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.741328  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.742087  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.742095  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.742205  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.743196  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.766623  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.766623  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.768014  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.773480  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.773571  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.774131  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.776340  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.776340  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.776378  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.779108  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.779300  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.779399  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.782064  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.782226  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.782237  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.783424  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.783729  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.783734  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.786561  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.786658  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.787098  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.788926  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.790477  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.790584  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.792724  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.794099  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.794202  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.796197  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.797253  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.797330  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.798297  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.806165  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.806242  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066827.806266  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.146252  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.150193  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.150869  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.151618  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.152408  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.153107  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.153855  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.160774  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.165328  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.169870  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.173829  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.177435  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.181720  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.185895  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.270566  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.271221  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.271942  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.272699  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.273466  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.275352  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.276252  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.277140  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.278016  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.278904  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.280383  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.282266  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.284031  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.286196  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.288101  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.289337  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.290532  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.292602  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.294431  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.297779  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.300183  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.309694  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.310537  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.311345  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.312278  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.313209  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.313993  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.314811  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.315756  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.316653  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.317969  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.319125  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.320423  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.324621  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.328998  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.333220  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.342001  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.350691  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.356052  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.361497  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.404575  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.406101  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.406776  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.407533  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.408322  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.408998  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.409738  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.412763  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.417321  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.421866  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.425279  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.428876  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.433176  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.437362  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.457183  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.458693  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.459363  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.460122  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.460910  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.461600  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.462341  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.464871  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.469436  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.474002  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.477412  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.481052  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.485364  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.489578  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.522214  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.522867  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.523587  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.524344  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.525118  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.526127  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.527025  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.527905  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.528784  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.529669  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.530618  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.530747  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.531554  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.531899  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.532519  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.533110  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.533574  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.534729  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.534742  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.535740  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.535974  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.536764  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.537212  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.537893  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.538420  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.539076  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.540339  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.540504  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.541691  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.542109  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.542999  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.543955  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.544449  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.546099  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.547286  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.547853  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.549801  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.549817  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.551828  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.553862  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.557097  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.559228  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.560076  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.560887  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.561661  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.561850  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.562781  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.563569  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.564391  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.565337  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.566360  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.566481  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.567693  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.568854  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.570155  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.574330  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.574915  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.575557  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.576265  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.577020  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.577802  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.578017  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.578880  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.578968  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.579334  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.579885  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.580745  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.580852  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.581727  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.582305  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.582625  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.583137  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.583618  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.584086  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.584775  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.585488  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.585963  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.586795  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.587347  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.588042  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.588576  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.589525  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.589792  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.590990  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.591836  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.592008  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.593073  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.593802  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.594915  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.596038  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.598248  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.600769  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.600793  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.602939  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.606174  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.610237  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.611092  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.611371  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.611621  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.611913  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.612854  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.613781  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.614572  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.615394  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.616339  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.617243  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.618568  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.619525  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.619753  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.621080  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.625271  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.629697  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.633959  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.636777  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.642821  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.651561  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.653785  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.656966  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.662446  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.664001  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.674376  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.780535  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.781432  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.782382  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.783327  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.784334  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.785329  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.786339  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.787451  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.788618  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.789847  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.791171  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.792443  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.793872  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.795507  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.797253  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.799090  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.801079  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.803103  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.805750  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.808987  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.813446  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.818202  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.829916  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.831225  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.832625  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.832646  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.833541  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.834202  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.834499  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.835491  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.835759  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.836526  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.837168  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.837530  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.838620  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.838697  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.839947  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.840013  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.841125  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.841501  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.842378  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.843852  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.843919  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.845178  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.845882  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.846622  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.848165  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.848338  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.850093  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.851925  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.853936  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.855057  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.855981  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.859228  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.863712  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.863817  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.868585  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.872002  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.880184  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.881496  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.882789  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.884337  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.885890  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.887282  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.888578  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.889456  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.889831  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.891302  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.893578  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.895534  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.897779  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.904710  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.906699  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.913222  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.917029  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.921461  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.927497  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.938869  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.956119  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.966396  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066828.976857  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.012294  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.013718  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.015136  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.016610  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.018114  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.019691  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.021258  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.022884  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.024713  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.026660  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.028576  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.030546  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.032685  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.035227  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.037984  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.046738  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.049659  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.052833  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.056281  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.062614  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.268954  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.270386  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.271806  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.273294  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.274792  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.276380  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.277927  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.279555  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.281374  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.283320  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.285245  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.287232  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.289363  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.291892  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.294653  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.303424  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.306342  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.309507  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.312933  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.317094  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.317412  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.318843  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.320274  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.321776  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.323280  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.323633  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.324881  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.326444  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.328079  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.329922  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.331876  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.333815  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.337803  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.339951  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.342506  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.345296  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.354070  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.356994  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.360214  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.363693  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.370028  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.517126  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.519271  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.521364  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.523694  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.526213  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.528258  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.530252  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.532835  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.535111  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.537124  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.539450  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.541869  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.554374  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.567647  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.584653  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.600862  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.618289  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.636943  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.674502  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.780893  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.783070  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.785184  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.787509  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.790033  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.792092  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.794111  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.796698  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.798987  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.801035  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.803387  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.805834  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.818293  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.826216  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.828379  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.830491  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.831936  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.832835  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.835375  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.837429  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.839443  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.842043  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.844322  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.846358  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.848709  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.849296  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.851150  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.863764  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.865847  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.877281  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.883532  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.894501  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.901912  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.911006  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.928751  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.939752  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.947135  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066829.984791  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.351461  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.353778  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.356248  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.358563  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.361000  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.363623  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.366370  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.369072  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.372205  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.375933  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.379234  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.382627  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.386112  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.390814  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.396057  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.401548  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.417508  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.423567  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.430181  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.442587  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.466585  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.470290  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.474552  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.478444  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.482194  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.486903  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.490688  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.495631  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.499300  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.503019  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.507417  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.512036  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.535702  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.562497  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.597227  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.615638  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.617984  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.620482  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.622817  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.625283  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.627898  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.630014  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.630675  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.633378  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.636502  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.640239  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.643539  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.647037  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.650596  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.655330  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.660659  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.664888  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.665328  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.666275  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.667676  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.670173  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.672493  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.674954  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.677578  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.680339  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.682559  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.683054  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.686206  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.688682  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.690004  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.693457  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.696315  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.697029  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.700570  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.703016  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.703678  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.705310  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.710590  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.715726  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.716238  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.732495  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.738665  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.740284  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.744026  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.745449  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.748375  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.752291  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.756079  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.758115  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.760796  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.764519  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.769578  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.773329  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.777163  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.780692  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.781628  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.782734  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.786290  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.786509  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.790862  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.794765  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.798540  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.803239  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.806964  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.810529  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.811941  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.815707  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.819510  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.823967  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.828590  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.837702  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.852885  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.871510  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.879786  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.903620  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.913392  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.938736  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.945605  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.977326  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066830.980380  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066831.015628  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066831.055297  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066831.094534  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.126606  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.130628  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.134687  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.138775  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.143140  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.147674  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.152564  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.157074  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.162757  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.167825  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.174020  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.180327  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.187053  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.196273  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.205575  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.215038  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.243222  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.254867  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.273277  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.283698  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.290499  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.299300  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.306328  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.313574  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.321860  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.328977  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.338887  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.346178  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.354762  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.363776  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.403041  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.407091  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.410224  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.411194  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.415321  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.419696  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.424255  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.429135  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.433671  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.439380  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.444506  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.450777  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.453672  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.457128  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.457713  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.461869  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.461994  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.464012  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.466007  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.470430  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.473398  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.474988  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.479922  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.482824  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.484593  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.490518  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.492444  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.495643  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.501910  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.508353  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.515189  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.520755  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.524541  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.527366  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.532430  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.533919  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.543525  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.546077  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.564692  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.572030  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.575547  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.582736  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.583849  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.590265  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.592095  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.599565  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.602379  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.606825  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.612974  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.615292  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.620029  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.622408  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.629243  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.632529  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.636580  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.639954  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.644108  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.648719  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.652794  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.654514  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.657846  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.659981  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.669927  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.677247  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.685873  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.694816  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.705886  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.740620  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.741171  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.757452  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.792844  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.822399  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.858811  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.885294  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.888755  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.921766  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.952552  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066832.988077  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066833.028830  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066833.069558  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066833.173806  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066833.214565  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.577570  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.584832  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.592249  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.599764  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.607777  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.616718  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.626636  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.636023  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.647500  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.657423  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.669675  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.682038  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.695028  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.713119  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.730557  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.748989  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.801297  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.823824  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.854129  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.863093  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.865037  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.866692  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.870328  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.872386  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.875084  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.878646  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.879886  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.883087  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.886650  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.887550  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.891628  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.895293  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.895773  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.899540  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.904020  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.904463  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.914579  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.923980  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.927583  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.931401  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.934892  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.935691  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.942340  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.945760  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.949916  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.953078  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.958076  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.958501  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.967412  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.970616  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.977649  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.983924  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.986370  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.987172  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066835.998859  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.002650  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.008937  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.018250  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.020572  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.021385  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.033960  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.039262  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.047073  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.050781  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.065587  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.083329  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.086918  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.092218  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.101880  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.115065  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.142026  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.153888  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.166280  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.172979  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.176335  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.182009  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.185642  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.189394  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.194335  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.198052  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.202483  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.206046  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.207097  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.211069  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.214822  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.216012  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.219171  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.219669  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.223355  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.223739  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.228222  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.231861  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.236195  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.239677  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.244531  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.248155  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.251930  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.252358  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.256811  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.273986  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.284338  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.306384  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.307799  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.340053  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.340075  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.372113  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.372312  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.404563  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.408606  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.440155  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.486122  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066836.518804  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.453594  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.457368  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.460907  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.464668  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.468654  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.472632  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.476848  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.480845  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.485284  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.489955  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.495687  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.501436  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.507820  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.516369  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.525769  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.534419  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.556740  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.567767  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.585232  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.586424  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.587532  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.588779  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.589889  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.591035  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.592469  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.593960  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.595527  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.596755  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.598076  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.599400  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.606905  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.615660  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.624186  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.632455  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.640830  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.657443  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.674112  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.775230  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.779035  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.782628  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.786437  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.790452  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.794509  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.798910  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.803137  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.807836  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.812475  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.816954  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.818134  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.820755  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.824138  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.824334  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.828111  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.830793  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.832130  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.836139  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.839559  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.840385  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.844380  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.849166  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.849278  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.854056  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.858003  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.859856  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.865676  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.872248  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.880572  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.880931  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.890407  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.891648  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.899074  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.904173  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.921446  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.921864  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.923076  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.924205  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.925481  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.926613  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.927788  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.929256  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.930782  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.932503  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.932529  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.933768  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.935120  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.936478  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.944157  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.950172  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.951359  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.952467  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.953179  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.953733  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.954844  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.956001  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.957452  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.958955  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.960531  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.961822  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.961993  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.963157  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.964492  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.970470  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.971369  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.972055  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.972567  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.973721  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.974863  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.976053  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.977347  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.978607  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.979007  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.979809  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.981111  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.981214  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.982494  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.983994  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.985498  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.987239  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.989317  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.989721  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.991883  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.994020  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.996089  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066837.998040  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.006493  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.013095  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.014139  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.020141  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.022922  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.023482  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.034375  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.035049  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.035681  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.036306  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.037199  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.040423  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.040870  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.044086  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.048212  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.052526  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.057531  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.062135  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.067042  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.105310  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.105952  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.106600  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.107221  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.107904  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.108550  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.109235  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.110019  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.110621  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.111226  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.112073  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.112928  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.113779  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.114353  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.114940  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.115549  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.118701  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.119563  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.121016  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.122166  758681 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.309810  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.311006  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.312170  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.313349  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.314558  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.315884  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.317183  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.318025  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.318395  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.318691  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.319270  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.319837  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.319974  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.320770  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.321422  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.321570  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.322462  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.323044  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.324576  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.325336  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.326401  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.328030  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.328515  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.330733  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.331092  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.333362  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.333474  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.338438  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.338873  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.340062  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.341228  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.342370  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.343576  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.344891  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.346171  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.347365  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.348677  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.348931  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.349977  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.351491  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.352997  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.353678  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.354765  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.356868  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.359430  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.359713  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.361580  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.362499  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.365906  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.365924  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.378284  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.378973  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.379611  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.380238  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.381139  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.382103  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.384812  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.388069  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.388250  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.391065  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.392175  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.396464  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.401481  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.402715  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.403412  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.404046  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.404678  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.405578  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.406142  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.409272  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.411069  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.411487  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.412500  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.413856  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.414463  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.415048  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.415643  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.416282  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.417734  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.418364  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.420649  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.420835  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.421491  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.424305  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.425861  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.426212  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.428829  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.429499  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.430258  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.430567  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.430989  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.432722  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.433446  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.434301  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.435187  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.435529  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.447080  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.449672  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.450322  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.450973  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.451602  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.452289  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.452949  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.453634  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.454417  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.455030  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.455636  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.456484  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.457346  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.458195  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.458769  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.459367  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.459978  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.463135  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.464002  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.465434  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.466569  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.474194  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.474841  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.475492  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.476117  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.476807  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.477476  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.478163  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.480493  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.481112  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.481718  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.482569  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.483428  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.484273  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.484847  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.485441  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.486044  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.489184  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.490042  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.491469  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.492623  758651 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.499174  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.500970  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.501600  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.502359  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.503201  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.503804  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.504455  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.506637  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.507288  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.507951  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.508622  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.509289  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.509949  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.510569  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.511253  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.512300  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.512943  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.513741  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.514549  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.515367  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.516202  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.517119  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.517857  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.520790  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.523709  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.528056  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.530749  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.533547  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.542678  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.551085  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.699544  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.701803  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.704586  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.705698  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.706987  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.707745  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.710879  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.711880  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.714396  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.715111  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.715375  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.715485  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.715775  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.716151  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.716596  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.716730  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.716824  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.717193  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.717592  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.717849  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.718263  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.718456  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.718873  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.719182  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.719610  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.719915  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.721705  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.721980  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.722424  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.724665  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.725121  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.727393  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.727856  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.730214  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.730317  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.730651  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.735034  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.735398  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.745574  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.745979  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.746282  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.747407  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.749882  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.750965  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.752044  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.753258  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.755993  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.757215  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.759952  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.761154  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.762301  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.762480  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.765530  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.765532  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.768592  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.770144  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.771912  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.778513  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.786940  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.794164  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.798704  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.799724  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.800319  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.800899  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.801499  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.802130  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.802822  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.803163  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.803454  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.804325  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.804681  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.804939  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.805364  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.805855  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.806658  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.806684  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.807013  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.807474  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.807987  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.808556  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.808927  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.809233  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.809585  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.810144  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.810548  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.811271  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.811702  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.812307  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.812780  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.813038  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.813459  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.813922  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.814233  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.814865  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.815153  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.815978  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.816698  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.817566  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.818464  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.826421  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.826788  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.830107  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.865902  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.866961  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.867684  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.868547  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.869309  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.869902  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.870072  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.870563  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.870950  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.871232  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.871584  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.871886  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.872383  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.872583  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.873244  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.873352  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.873896  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.874067  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.874613  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.874781  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.875328  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.875497  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.875985  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.876197  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.876658  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.877374  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.877455  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.878082  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.878207  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.878993  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.879011  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.879653  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.879838  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.880353  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.880664  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.881454  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.881566  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.882112  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.882499  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.882924  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.883247  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.883759  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.884579  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.885476  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.885649  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.886418  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.887167  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.888523  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.889517  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.891550  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.892469  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.894241  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.895512  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.897061  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.898227  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.901067  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.905538  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.909617  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.913873  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066838.918020  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.060591  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.061736  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.062464  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.063308  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.064300  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.065051  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.065772  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.066286  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.067094  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.067191  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.067838  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.068343  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.068708  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.069304  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.069736  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.070421  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.070769  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.071923  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.072608  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.073078  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.073822  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.073984  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.074790  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.075879  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.078412  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.079294  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.082288  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.087653  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.098698  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.099821  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.101134  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.102209  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.103291  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.103642  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.104500  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.105075  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.106165  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.106985  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.107388  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.108072  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.108807  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.109170  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.110009  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.110401  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.111126  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.111864  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.112498  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.113091  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.113816  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.114537  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.115380  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.115741  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.116842  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.117159  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.118211  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.119520  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.120088  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.121194  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.121303  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.122566  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.122975  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.123869  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.123972  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.125011  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.126167  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.127394  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.128612  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.129638  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.129934  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.131135  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.131903  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.132491  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.133837  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.135373  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.136907  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.137603  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.138593  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.139171  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.140221  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.141965  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.144077  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.144904  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.146426  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.151352  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.152101  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.157170  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.164441  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.165825  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.167162  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.168621  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.170087  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.171707  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.171740  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.173522  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.175437  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.177285  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.177480  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.179162  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.181323  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.183188  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.185155  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.187115  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.188886  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.190816  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.192481  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.194265  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.197808  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.200061  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.202166  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.209802  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.217437  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.226027  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.234612  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.243244  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.251902  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.466305  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.467449  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.468696  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.469852  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.470984  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.472156  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.473377  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.473860  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.474615  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.475012  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.475842  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.476286  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.477060  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.477464  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.478412  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.478606  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.479963  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.479979  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.481212  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.481526  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.482451  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.483054  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.483683  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.484757  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.484930  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.486318  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.486473  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.487684  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.488223  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.489251  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.490342  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.490798  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.492484  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.492682  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.494120  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.495866  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.497972  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.498389  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.500324  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.506053  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.510190  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.511571  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.512993  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.514459  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.516034  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.517497  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.518015  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.519541  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.519601  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.520902  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.521411  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.522381  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.523218  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.523867  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.525093  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.525341  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.527181  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.527294  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.529243  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.529311  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.531072  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.531287  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.532979  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.533259  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.535069  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.535244  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.537062  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.537231  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.538746  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.539220  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.540532  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.541208  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.542992  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.544030  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.544951  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.546307  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.546649  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.548531  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.548597  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.552154  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.554441  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.556203  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.556562  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.563877  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.564295  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.571993  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.572493  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.580678  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.581110  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.589351  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.589719  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.598028  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.598481  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066839.606694  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.002022  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.003208  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.004453  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.005775  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.007109  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.008802  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.010679  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.012642  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.014790  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.017042  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.019637  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.021391  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.028372  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.039643  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.042938  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.046211  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.049658  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.052934  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.056377  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.059758  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.063278  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.066615  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.070561  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.074039  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.078724  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.083686  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.089303  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.094035  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.120130  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.146376  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.170773  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.191637  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.220642  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.245715  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.339954  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.341130  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.342366  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.343682  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.345009  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.346703  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.348594  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.350561  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.351886  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.352722  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.353082  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.354336  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.354981  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.355680  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.357012  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.357592  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.358725  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.359361  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.360635  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.362612  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.364776  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.366374  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.367051  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.369669  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.371446  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.377745  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.378482  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.381083  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.384393  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.387893  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.389860  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.391198  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.393186  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.394697  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.396483  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.398144  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.399961  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.401816  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.403287  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.405314  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.406817  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.409247  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.410243  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.412695  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.413854  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.417323  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.417435  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.421170  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.422611  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.424730  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.428406  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.429483  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.433277  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.434556  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.440252  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.445017  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.459999  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.471493  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.486711  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.498136  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.511312  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.522559  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.532399  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.543535  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.561827  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.572834  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.587140  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066840.598271  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.524292  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.527733  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.531282  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.534825  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.538594  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.542320  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.545996  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.550046  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.553972  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.558266  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.563063  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.567996  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.573018  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.578846  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.585300  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.591694  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.598034  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.606389  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.615541  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.627298  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.659282  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.663987  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.668627  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.673757  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.678868  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.684054  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.690473  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.696592  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.702704  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.710738  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.717387  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.723973  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.730972  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.737951  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.744420  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.751535  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.757597  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.764103  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.779649  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.787159  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.795730  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.824898  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.853821  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.867647  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.871093  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.874659  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.878221  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.880874  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.882042  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.885795  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.889180  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.889522  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.892684  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.893635  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.896289  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.897675  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.899868  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.901828  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.903691  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.906417  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.907461  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.907910  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.911263  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.911432  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.915410  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.916543  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.919469  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.922375  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.923638  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.928228  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.928840  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.933141  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.934962  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.935273  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.938223  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.941664  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.944055  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.950088  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.950469  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.956857  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.959250  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.963228  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.965833  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.971303  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.971624  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.980726  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066841.992771  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.003694  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.009760  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.014399  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.019527  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.024652  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.026752  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.029847  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.031533  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.036211  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.036625  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.041394  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.042835  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.046549  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.049071  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.051779  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.057264  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.058254  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.064059  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.064428  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.070589  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.070832  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.077952  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.078705  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.085077  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.085434  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.091712  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.092159  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.099001  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.099255  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.105206  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.106364  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.111867  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.112946  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.120166  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.126218  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.126380  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.132969  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.133764  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.142266  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.147644  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.155242  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.163859  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.171590  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.193459  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.200844  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.222903  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.227921  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.250178  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.255107  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.277443  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.282362  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.304718  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.313484  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066842.335629  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.340603  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.344591  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.349121  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.353819  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.358680  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.364985  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.371946  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.379486  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.387732  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.396570  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.406697  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.413329  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.442056  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.468045  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.484764  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.491654  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.498720  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.505609  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.512684  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.519779  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.527183  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.535083  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.541968  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.551938  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.559420  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.569550  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.580008  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.591510  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.636263  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.687176  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.688372  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.692302  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.696707  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.701291  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.706008  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.712133  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.719088  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.726685  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.734192  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.735014  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.738199  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.738985  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.742768  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.743940  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.747654  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.752761  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.754497  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.759293  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.761371  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.766380  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.773977  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.782316  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.788601  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.790557  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.791257  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.801602  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.808362  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.816083  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.833187  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.837663  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.840106  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.846724  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.847180  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.854110  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.861548  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.863410  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.869037  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.876913  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.880552  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.885318  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.887506  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.892621  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.894655  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.896532  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.901837  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.902636  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.909205  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.910060  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.916659  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.919970  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.924612  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.930235  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.933092  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.940484  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.941489  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.950624  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.958089  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.968068  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.978421  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.985499  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066847.989851  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066848.034807  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066848.036265  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066848.085976  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066848.088598  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066848.134525  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066848.139189  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066848.185700  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066848.197121  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066848.243583  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066848.247485  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066848.294836  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.531715  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.538831  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.545984  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.553326  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.561291  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.569424  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.577532  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.586566  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.595506  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.604768  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.614836  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.625328  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.635776  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.647863  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.661114  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.673913  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.686893  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.703643  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.721814  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.745179  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.811377  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.820914  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.830413  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.839925  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.849759  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.858931  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.868868  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.880136  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.891475  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.900908  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.909993  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.912528  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.917408  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.924701  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.925353  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.932091  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.936151  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.939255  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.940119  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.943341  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.948364  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.950534  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.951673  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.956618  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.957968  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.966086  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.966189  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.966295  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.974143  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.975209  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.978807  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.982532  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.984677  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.991755  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.991941  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066850.995013  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.000952  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.005660  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.009600  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.010444  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.016214  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.020761  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.023905  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.028400  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.031448  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.038430  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.041728  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.042085  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.054517  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.054678  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.068109  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.068113  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.081217  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.085038  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.087959  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.094467  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.103299  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.111458  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.126956  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.128148  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.129831  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.143934  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.153421  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.166754  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.193497  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.193674  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.203143  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.212739  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.220537  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.222403  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.230119  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.232304  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.239647  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.241563  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.245367  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.249359  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.251502  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.259130  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.262709  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.268548  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.273970  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.278464  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.283346  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.290029  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.294816  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.297056  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.304460  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.307496  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.314063  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.321191  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.325799  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.333722  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.338667  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.348224  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.352760  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.355064  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.360706  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.365514  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.373707  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.380094  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.391182  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.392790  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.405368  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.405911  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.406918  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.419953  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.423666  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.438180  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.452878  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.459783  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.469598  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.502148  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.509884  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.514137  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.525778  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.542023  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.548782  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.557792  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.575981  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.580641  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.607586  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.628205  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.659728  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.680431  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.711840  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.738892  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.770115  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.791264  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.822343  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.845042  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.876025  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.900998  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066851.932064  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.395783  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.403684  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.412728  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.422653  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.433023  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.446869  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.460010  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.461960  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.467856  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.476969  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.478076  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.486434  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.495384  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.496483  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.504364  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.510068  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.512179  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.514162  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.521237  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.525187  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.530608  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.537187  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.540587  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.541347  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.553991  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.558565  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.563015  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.568781  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.577373  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.584902  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.600446  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.601796  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.620396  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.626035  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.627281  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.643424  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.669735  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.690004  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.691271  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.703409  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.707138  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.710856  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.714697  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.718694  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.722784  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.727022  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.731622  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.735622  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.735881  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.740691  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.744785  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.750209  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.752355  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.755903  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.762134  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.764818  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.768536  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.772252  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.776083  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.780220  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.784290  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.787252  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.788532  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.793164  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.797142  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.798033  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.802290  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.806369  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.809990  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.811787  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.813704  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.817037  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.817637  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.817651  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.821444  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.823914  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.825417  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.829434  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.833599  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.838146  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.842041  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.844439  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.847160  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.849340  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.851226  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.856611  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.862262  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.868426  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.872540  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.879300  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.893160  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.903403  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.908535  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.921312  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.930114  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.937898  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.948251  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.968251  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.976149  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066881.994756  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066882.006523  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066882.032874  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.263845  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.267826  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.271722  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.275796  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.280117  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.284367  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.288522  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.293463  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.298341  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.303355  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.308772  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.314527  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.320271  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.327258  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.335663  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.341792  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.343014  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.345774  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.349665  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.350641  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.353748  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.358039  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.360233  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.362295  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.366439  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.369253  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.371226  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.372329  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.373227  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.376013  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.377102  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.381105  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.381209  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.385249  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.385493  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.386442  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.389720  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.392115  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.393967  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.397851  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.398743  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.403431  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.404859  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.408281  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.413151  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.413574  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.419193  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.420350  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.422749  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.424783  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.427857  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.428283  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.431601  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.433640  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.437381  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.439023  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.439800  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.444107  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.446938  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.449382  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.449715  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.454357  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.455408  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.462227  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.462337  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.463837  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.470481  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.475787  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.478657  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.486600  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.488525  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.494704  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.499222  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.502122  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.504846  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.510131  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.510708  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.515437  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.519221  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.520447  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.525199  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.525957  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.526544  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.531240  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.531486  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.533326  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.536501  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.538115  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.541011  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.541762  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.546116  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.546731  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.551410  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.552213  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.554057  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.557796  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.560752  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.561871  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.564425  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.569695  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.570224  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.572364  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.577042  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.577800  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.580279  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.585587  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.588072  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.589594  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.594027  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.595848  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.600404  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.601232  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.603101  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.607946  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.611510  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.613965  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.615610  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.619868  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.626064  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.627039  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.627890  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.633725  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.635185  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.641343  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.644302  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.651896  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.652018  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.654259  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.661009  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.663563  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.670205  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.674277  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.677632  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.680999  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.687674  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.689171  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.699896  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.701524  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.708087  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.713350  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.727246  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.727931  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.735383  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.753622  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.754596  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.767328  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.779977  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.781607  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.799203  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.806576  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.808761  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.833164  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.840815  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.864610  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.873215  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066883.896120  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.343465  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.348127  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.353131  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.358297  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.363969  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.370931  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.378510  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.386799  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.395811  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.408627  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.420958  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.446363  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.486469  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.491040  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.495939  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.501076  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.501352  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.506677  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.513527  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.520982  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.529155  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.538007  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.538347  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.550520  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.562619  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.582832  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.584829  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.585178  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.587516  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.587693  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.594418  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.594515  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.596931  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.599295  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.599500  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.601847  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.604194  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.604321  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.606534  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.609707  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.610178  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.613029  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.616004  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.616337  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.619301  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.622272  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.623511  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.626085  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.631359  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.639135  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.639981  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.642079  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.652234  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.653675  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.664284  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.668658  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.678006  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.682914  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.689517  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.709386  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.721907  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.724226  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.726503  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.728881  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.731266  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.733809  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.736154  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.738372  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.740700  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.743070  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.744550  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.747563  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.750744  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.754239  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.757310  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.761225  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.774892  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.777986  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.789561  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.803700  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.818297  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.821532  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.823851  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.826115  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.828485  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.830859  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.833421  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.835797  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.838035  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.840397  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.844098  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.845040  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.847012  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.850030  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.853461  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.856465  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.860303  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.873545  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.888024  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.902056  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.916596  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066898.942772  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.377892  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.380315  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.382693  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.385177  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.387710  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.390230  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.392872  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.395594  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.398309  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.401162  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.404107  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.407252  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.411151  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.414841  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.418864  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.423291  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.428434  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.435333  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.457910  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.461085  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.464386  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.467593  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.471062  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.474945  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.479342  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.482944  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.486522  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.490511  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.494928  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.499056  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.503677  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.508501  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.512201  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.517321  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.518817  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.521218  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.522443  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.523608  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.526083  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.527557  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.528629  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.531139  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.533216  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.533791  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.536488  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.538885  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.539230  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.542085  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.545050  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.545344  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.547966  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.551844  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.554312  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.555573  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.559782  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.564257  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.567665  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.569405  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.576168  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.581336  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.594992  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.598479  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.601642  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.604919  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.608141  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.608694  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.611617  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.612144  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.614538  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.615482  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.616911  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.619367  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.619845  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.621897  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.622643  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.623440  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.624410  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.627240  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.627245  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.629934  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.631311  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.632656  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.635490  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.635769  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.638500  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.638712  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.639922  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.641577  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.644553  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.645359  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.648977  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.649372  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.653006  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.653118  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.654867  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.657318  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.658221  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.662391  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.663332  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.668409  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.669094  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.674009  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.679611  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.686006  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.690735  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.693854  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.694850  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.697115  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.700235  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.703641  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.707477  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.707891  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.711815  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.715350  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.718870  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.721484  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.722843  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.727250  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.731331  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.735134  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.735939  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.740717  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.744364  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.749136  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.749425  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.754454  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.759486  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.763068  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.765054  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.770615  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.776955  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.779069  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.785734  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.795041  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.798785  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.812243  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.825702  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.839150  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.852746  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.868401  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066899.884172  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.585273  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.588428  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.591671  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.594903  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.598621  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.602613  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.606910  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.611413  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.616277  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.622892  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.629541  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.637736  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.651698  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.667084  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.684812  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.713393  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.745937  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.747525  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.748568  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.750051  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.750792  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.751594  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.753184  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.754145  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.754869  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.756379  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.757506  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.757849  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.759380  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.761373  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.761639  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.763366  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.765143  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.765320  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.767160  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.769005  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.769437  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.770621  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.773792  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.777627  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.778494  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.784904  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.785276  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.791407  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.793147  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.799504  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.800986  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.813273  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.814597  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.828576  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.846310  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.862254  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.865311  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.868432  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.871552  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.875253  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.875368  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.879053  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.883093  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.887384  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.892000  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.898319  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.904685  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.907083  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.909909  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.911211  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.912810  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.912816  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.914248  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.915741  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.917082  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.918354  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.919714  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.921725  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.923273  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.924978  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.926407  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.926853  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.928874  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.930501  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.937573  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.941555  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.945287  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.953135  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.959166  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.960913  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.974521  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066905.987752  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.019346  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.022170  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.023466  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.024824  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.026230  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.027717  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.029061  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.030325  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.031672  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.033670  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.035214  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.036905  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.038750  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.040753  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.042381  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.049468  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.057130  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.064964  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.072896  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.086472  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.153140  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.154622  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.156021  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.157442  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.158922  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.160393  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.161929  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.163506  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.165104  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.166749  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.168418  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.170086  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.172177  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.174260  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.176488  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.178892  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.181731  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.185218  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.199564  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.201444  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.203493  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.205984  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.208279  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.210850  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.213513  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.216265  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.218599  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.220980  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.223040  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.225869  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.229365  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.232194  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.236527  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.239779  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.243035  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.247763  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.252467  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.257700  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.262930  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.269808  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.276603  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.283407  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.290203  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.298169  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.306154  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.315321  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.316457  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.317902  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.319305  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.320715  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.322194  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.323663  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.324109  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.325210  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.326784  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.328425  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.330067  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.331745  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.333411  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.335477  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.337549  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.339761  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.342126  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.344963  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.348396  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.362692  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.364563  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.366603  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.369051  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.371331  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.373840  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.376465  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.379201  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.381514  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.383880  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.385933  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.388742  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.392217  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.395031  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.399312  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.402534  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.405764  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.410456  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.415115  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.420344  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.425578  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.426033  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.427474  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.428863  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.430269  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.431733  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.432462  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.433217  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.434737  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.436300  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.437892  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.439332  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.439546  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.441206  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.442858  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.444907  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.446215  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.446971  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.449169  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.451527  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.453101  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.454329  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.457747  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.460984  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.468852  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.471752  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.473604  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.475609  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.478201  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.478307  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.480566  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.483061  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.485646  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.486863  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.488382  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.490660  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.492983  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.495018  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.497784  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.501200  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.503967  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.508198  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.511368  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.514539  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.519158  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.523787  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.528985  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.534184  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.540982  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.547775  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.554568  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.561364  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.569152  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.576924  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.585903  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066906.594518  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066908.975637  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066908.977689  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066908.979882  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066908.982072  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066908.984414  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066908.986875  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066908.989497  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066908.992146  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066908.995010  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.011842  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.016077  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.021776  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.027941  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.035951  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.045583  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.058813  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.089184  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.090232  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.091239  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.092381  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.093607  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.094840  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.096127  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.097364  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.098424  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.099480  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.100787  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.102279  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.103684  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.104858  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.106292  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.107642  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.111699  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.115731  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.119778  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.123882  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.129579  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.154239  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.156247  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.158395  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.160524  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.162905  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.165399  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.168052  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.170731  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.173593  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.190406  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.194774  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.200649  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.207010  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.215168  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.224773  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.238127  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.259584  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.261512  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.263586  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.265648  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.267881  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.269411  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.270247  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.270488  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.271505  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.272842  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.272954  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.274086  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.275443  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.275553  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.276764  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.278007  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.278304  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.279082  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.280158  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.281481  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.282986  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.284397  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.285585  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.287022  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.288378  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.292503  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.294589  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.296555  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.298716  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.300624  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.301559  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.302634  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.303721  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.304261  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.304845  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.304963  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.306062  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.307337  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.308670  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.310087  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.310434  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.310438  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.311475  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.312882  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.314248  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.315734  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.317088  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.318097  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.318751  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.320434  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.322081  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.324397  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.326343  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.327292  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.336060  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.338143  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.339736  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.340195  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.341509  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.342894  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.344696  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.346308  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.348148  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.349756  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.351180  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.352847  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.354901  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.357017  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.358787  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.360511  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.362234  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.364525  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.366818  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.369550  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.370078  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.371134  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.372257  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.372278  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.373431  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.374688  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.374847  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.375926  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.377219  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.377836  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.378456  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.379528  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.380581  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.380838  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.381905  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.383398  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.384375  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.384814  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.385993  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.387424  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.387908  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.388780  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.391458  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.392872  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.394998  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.396885  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.401074  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.401090  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.405229  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.405328  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.409309  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.410744  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.413787  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.482251  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.483325  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.484414  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.485476  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.486552  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.487835  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.489172  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.490474  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.491858  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.493279  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.494660  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.496159  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.497536  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.499191  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.500895  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.502546  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.504878  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.506827  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.516380  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.518494  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.520115  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.521893  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.523293  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.525113  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.526734  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.528604  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.530223  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.531658  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.533333  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.535409  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.537557  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.539342  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.541081  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.542815  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.545126  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.547438  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.550185  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.552720  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.555249  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.558280  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.561316  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.564869  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.568413  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.571952  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.575503  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.581508  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.581567  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.582594  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.583682  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.584720  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.585740  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.585842  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.587121  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.588453  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.589966  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.589978  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.591353  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.592768  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.594143  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.594540  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.595662  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.597025  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.598673  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.600353  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.602001  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.604320  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.606264  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.615751  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.617656  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.619247  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.621009  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.622391  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.624188  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.625797  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.627635  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.629245  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.630672  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.632325  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.634395  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.636523  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.638291  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.640013  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.641744  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.644037  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.646337  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.649053  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.651571  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.654083  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.657084  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.660096  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.663601  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.667101  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.670587  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.674085  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.679939  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.683935  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.687923  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066909.692414  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.675036  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.676339  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.677665  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.679240  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.680725  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.682343  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.684145  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.685695  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.695372  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.699548  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.704948  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.711015  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.715988  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.726731  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.727457  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.728140  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.728930  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.729705  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.730496  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.731169  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.731989  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.732822  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.733495  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.734319  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.735088  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.736024  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.737086  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.738019  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.738905  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.741399  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.745078  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.747880  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.750801  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.753735  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.839598  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.840320  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.841002  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.841706  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.842418  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.843253  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.844145  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.845036  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.845905  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.846796  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.847700  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.848618  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.849599  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.850638  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.851832  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.852971  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.858430  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.859716  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.860712  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.861013  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.861828  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.862553  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.862904  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.864114  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.864133  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.865364  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.865703  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.866615  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.867432  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.867934  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.868966  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.869285  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.870645  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.872012  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.873018  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.874261  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.875479  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.876705  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.877997  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.878421  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.879296  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.880547  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.881799  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.882488  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.883083  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.885213  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.887341  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.887820  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.889725  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.893080  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.893720  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.896445  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.898589  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.899809  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.903162  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.909050  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.909760  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.910433  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.911212  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.911978  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.912756  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.913428  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.914240  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.915066  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.915733  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.916546  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.917310  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.918248  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.919301  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.920222  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.921107  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.923592  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.927262  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.930061  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.932931  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.935879  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.967564  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.968844  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.970136  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.971658  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.973102  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.974667  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.976411  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.977954  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.987517  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.991574  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066910.996888  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.002804  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.007566  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.017894  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.018611  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.019288  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.020064  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.020830  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.021770  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.021796  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.022666  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.022680  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.023477  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.023589  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.024188  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.024423  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.024916  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.025108  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.025884  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.025980  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.026967  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.026975  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.028096  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.028113  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.028971  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.029177  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.029871  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.030098  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.030786  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.030989  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.031712  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.032687  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.033480  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.033740  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.034930  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.036068  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.037152  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.039983  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.042857  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.043757  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.044871  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.045915  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.046025  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.047103  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.048360  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.049613  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.050930  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.052252  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.053633  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.055010  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.056013  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.057264  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.058489  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.059718  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.061020  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.062324  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.063581  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.064832  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.066116  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.068246  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.070372  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.072744  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.076082  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.079420  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.082757  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.086095  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.131193  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.131925  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.132609  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.133315  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.134022  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.134856  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.135753  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.136640  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.137507  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.138389  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.139289  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.140200  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.141178  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.142201  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.143389  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.144530  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.152151  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.153267  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.154327  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.155412  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.156662  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.158130  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.159506  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.160835  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.162216  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.163600  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.164608  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.165863  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.167081  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.168310  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.169615  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.170920  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.172168  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.173426  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.174703  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.176826  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.178957  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.181323  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.184650  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.187986  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.191322  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.194657  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.494295  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.495346  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.496347  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.497550  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.498682  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.499851  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.501066  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.502507  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.503972  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.506498  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.512543  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.515756  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.519801  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.524916  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.537976  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.538912  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.540178  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.541448  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.542565  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.543829  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.545108  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.546379  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.547629  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.549365  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.551058  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.552741  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.554438  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.555708  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.556964  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.558224  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.559473  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.560732  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.561993  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.563237  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.564483  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.573873  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.575139  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.577118  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.578582  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.580272  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.581549  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.582860  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.584315  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.585987  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.588249  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.595169  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.598053  758641 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.684277  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.685300  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.686276  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.687433  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.688538  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.689676  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.690854  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.692235  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.693601  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.695938  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.701712  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.704822  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.708739  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.713724  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.726391  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.727320  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.728581  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.729841  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.730952  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.732226  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.733503  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.734782  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.736037  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.737732  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.739417  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.741108  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.742802  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.744096  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.745362  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.746631  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.747892  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.749161  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.750432  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.751699  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.752951  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.762367  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.763640  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.765625  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.767104  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.768786  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.770070  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.771393  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.772858  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.774556  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.776834  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.783815  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.786619  758652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.802833  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.803853  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.804809  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.805945  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.807000  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.808093  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.809233  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.810579  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.811941  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.814276  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.820014  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.823086  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.826986  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.831952  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.844732  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.845674  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.846935  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.848179  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.849297  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.850566  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.851845  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.853127  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.854382  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.856060  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.857747  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.859434  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.861125  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.862412  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.863677  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.864946  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.866218  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.867484  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.868748  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.870010  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.871272  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.880660  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.881934  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.883911  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.885399  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.887078  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.888355  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.889678  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.891137  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.892825  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.895101  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - loss: 4.3196   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728066911.902086  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066911.904906  758617 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 2.2325"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:35:17.323606: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-04 18:35:17.323780: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-10-04 18:35:17.323932: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 174ms/step - loss: 2.2039 - val_loss: 0.1217 - learning_rate: 0.0010\n",
      "Epoch 2/800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:35:18.646953: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0905"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:35:24.827336: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0901 - val_loss: 0.0649 - learning_rate: 0.0010\n",
      "Epoch 3/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0614 - val_loss: 0.0753 - learning_rate: 0.0010\n",
      "Epoch 4/800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:35:32.372211: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0596 - val_loss: 0.0894 - learning_rate: 0.0010\n",
      "Epoch 5/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0589 - val_loss: 0.1536 - learning_rate: 0.0010\n",
      "Epoch 6/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0561"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:35:52.311849: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - loss: 0.0560 - val_loss: 0.0807 - learning_rate: 0.0010\n",
      "Epoch 7/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0507 - val_loss: 0.0627 - learning_rate: 0.0010\n",
      "Epoch 8/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0476 - val_loss: 0.0643 - learning_rate: 0.0010\n",
      "Epoch 9/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0444 - val_loss: 0.0543 - learning_rate: 0.0010\n",
      "Epoch 10/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0428 - val_loss: 0.0570 - learning_rate: 0.0010\n",
      "Epoch 11/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0461 - val_loss: 0.0480 - learning_rate: 0.0010\n",
      "Epoch 12/800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:36:27.687312: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0470 - val_loss: 0.0430 - learning_rate: 0.0010\n",
      "Epoch 13/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0406 - val_loss: 0.0470 - learning_rate: 0.0010\n",
      "Epoch 14/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0392 - val_loss: 0.0444 - learning_rate: 0.0010\n",
      "Epoch 15/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0393 - val_loss: 0.0428 - learning_rate: 0.0010\n",
      "Epoch 16/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0387 - val_loss: 0.0413 - learning_rate: 0.0010\n",
      "Epoch 17/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0551 - val_loss: 0.0381 - learning_rate: 0.0010\n",
      "Epoch 18/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0420 - val_loss: 0.0418 - learning_rate: 0.0010\n",
      "Epoch 19/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0583 - val_loss: 0.0379 - learning_rate: 0.0010\n",
      "Epoch 20/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0338 - val_loss: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 21/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0336 - val_loss: 0.0350 - learning_rate: 0.0010\n",
      "Epoch 22/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0528"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:37:41.899235: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0522 - val_loss: 0.0332 - learning_rate: 0.0010\n",
      "Epoch 23/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0536 - val_loss: 0.0321 - learning_rate: 0.0010\n",
      "Epoch 24/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0349 - val_loss: 0.0321 - learning_rate: 0.0010\n",
      "Epoch 25/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0319 - val_loss: 0.0297 - learning_rate: 0.0010\n",
      "Epoch 26/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0312 - val_loss: 0.0298 - learning_rate: 0.0010\n",
      "Epoch 27/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0327 - val_loss: 0.0302 - learning_rate: 0.0010\n",
      "Epoch 28/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0309 - val_loss: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 29/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0333 - val_loss: 0.0287 - learning_rate: 0.0010\n",
      "Epoch 30/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0306 - val_loss: 0.0273 - learning_rate: 0.0010\n",
      "Epoch 31/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0289 - val_loss: 0.0285 - learning_rate: 0.0010\n",
      "Epoch 32/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0304 - val_loss: 0.0279 - learning_rate: 0.0010\n",
      "Epoch 33/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0290 - val_loss: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 34/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0312 - val_loss: 0.0274 - learning_rate: 0.0010\n",
      "Epoch 35/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0303 - val_loss: 0.0275 - learning_rate: 0.0010\n",
      "Epoch 36/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0288 - val_loss: 0.0269 - learning_rate: 0.0010\n",
      "Epoch 37/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0292 - val_loss: 0.0268 - learning_rate: 0.0010\n",
      "Epoch 38/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0290 - val_loss: 0.0266 - learning_rate: 0.0010\n",
      "Epoch 39/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0280 - val_loss: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 40/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0281 - val_loss: 0.0266 - learning_rate: 0.0010\n",
      "Epoch 41/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0322 - val_loss: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 42/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0283 - val_loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 43/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0282 - val_loss: 0.0256 - learning_rate: 0.0010\n",
      "Epoch 44/800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:40:03.748124: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0276 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 45/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0278 - val_loss: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 46/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - loss: 0.0292 - val_loss: 0.0256 - learning_rate: 0.0010\n",
      "Epoch 47/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0289 - val_loss: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 48/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0282 - val_loss: 0.0261 - learning_rate: 0.0010\n",
      "Epoch 49/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0274 - val_loss: 0.0288 - learning_rate: 0.0010\n",
      "Epoch 50/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0298 - val_loss: 0.0258 - learning_rate: 0.0010\n",
      "Epoch 51/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0286 - val_loss: 0.0252 - learning_rate: 0.0010\n",
      "Epoch 52/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0283 - val_loss: 0.0266 - learning_rate: 0.0010\n",
      "Epoch 53/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0303 - val_loss: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 54/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - loss: 0.0331 - val_loss: 0.0251 - learning_rate: 0.0010\n",
      "Epoch 55/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0287\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0286 - val_loss: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 56/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0278 - val_loss: 0.0255 - learning_rate: 9.0000e-04\n",
      "Epoch 57/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0268 - val_loss: 0.0248 - learning_rate: 9.0000e-04\n",
      "Epoch 58/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0267 - val_loss: 0.0251 - learning_rate: 9.0000e-04\n",
      "Epoch 59/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0270 - val_loss: 0.0258 - learning_rate: 9.0000e-04\n",
      "Epoch 60/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0268 - val_loss: 0.0251 - learning_rate: 9.0000e-04\n",
      "Epoch 61/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0305 - val_loss: 0.0260 - learning_rate: 9.0000e-04\n",
      "Epoch 62/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0274 - val_loss: 0.0256 - learning_rate: 9.0000e-04\n",
      "Epoch 63/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0277 - val_loss: 0.0258 - learning_rate: 9.0000e-04\n",
      "Epoch 64/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0273 - val_loss: 0.0302 - learning_rate: 9.0000e-04\n",
      "Epoch 65/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0309\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0308 - val_loss: 0.0269 - learning_rate: 9.0000e-04\n",
      "Epoch 66/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0267 - val_loss: 0.0249 - learning_rate: 8.1000e-04\n",
      "Epoch 67/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0265 - val_loss: 0.0259 - learning_rate: 8.1000e-04\n",
      "Epoch 68/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0265 - val_loss: 0.0247 - learning_rate: 8.1000e-04\n",
      "Epoch 69/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0259 - val_loss: 0.0261 - learning_rate: 8.1000e-04\n",
      "Epoch 70/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0261 - val_loss: 0.0243 - learning_rate: 8.1000e-04\n",
      "Epoch 71/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0258 - val_loss: 0.0251 - learning_rate: 8.1000e-04\n",
      "Epoch 72/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0259 - val_loss: 0.0271 - learning_rate: 8.1000e-04\n",
      "Epoch 73/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0257 - val_loss: 0.0252 - learning_rate: 8.1000e-04\n",
      "Epoch 74/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0261 - val_loss: 0.0251 - learning_rate: 8.1000e-04\n",
      "Epoch 75/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0261 - val_loss: 0.0293 - learning_rate: 8.1000e-04\n",
      "Epoch 76/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0262 - val_loss: 0.0272 - learning_rate: 8.1000e-04\n",
      "Epoch 77/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0259 - val_loss: 0.0300 - learning_rate: 8.1000e-04\n",
      "Epoch 78/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0257 - val_loss: 0.0306 - learning_rate: 8.1000e-04\n",
      "Epoch 79/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0258 - val_loss: 0.0305 - learning_rate: 8.1000e-04\n",
      "Epoch 80/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0267\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0267 - val_loss: 0.0266 - learning_rate: 8.1000e-04\n",
      "Epoch 81/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0265 - val_loss: 0.0255 - learning_rate: 7.2900e-04\n",
      "Epoch 82/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0263 - val_loss: 0.0306 - learning_rate: 7.2900e-04\n",
      "Epoch 83/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0258 - val_loss: 0.0251 - learning_rate: 7.2900e-04\n",
      "Epoch 84/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0260 - val_loss: 0.0269 - learning_rate: 7.2900e-04\n",
      "Epoch 85/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0260 - val_loss: 0.0265 - learning_rate: 7.2900e-04\n",
      "Epoch 86/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0258"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:44:50.587799: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0258 - val_loss: 0.0251 - learning_rate: 7.2900e-04\n",
      "Epoch 87/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0261 - val_loss: 0.0267 - learning_rate: 7.2900e-04\n",
      "Epoch 88/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0255 - val_loss: 0.0256 - learning_rate: 7.2900e-04\n",
      "Epoch 89/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0264 - val_loss: 0.0257 - learning_rate: 7.2900e-04\n",
      "Epoch 90/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0259\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0258 - val_loss: 0.0246 - learning_rate: 7.2900e-04\n",
      "Epoch 91/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0251 - val_loss: 0.0248 - learning_rate: 6.5610e-04\n",
      "Epoch 92/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0253 - val_loss: 0.0243 - learning_rate: 6.5610e-04\n",
      "Epoch 93/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0250 - val_loss: 0.0248 - learning_rate: 6.5610e-04\n",
      "Epoch 94/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0249 - val_loss: 0.0272 - learning_rate: 6.5610e-04\n",
      "Epoch 95/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0247 - val_loss: 0.0242 - learning_rate: 6.5610e-04\n",
      "Epoch 96/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0242 - val_loss: 0.0267 - learning_rate: 6.5610e-04\n",
      "Epoch 97/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 164ms/step - loss: 0.0244 - val_loss: 0.0262 - learning_rate: 6.5610e-04\n",
      "Epoch 98/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0236 - val_loss: 0.0250 - learning_rate: 6.5610e-04\n",
      "Epoch 99/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0234 - val_loss: 0.0250 - learning_rate: 6.5610e-04\n",
      "Epoch 100/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0233 - val_loss: 0.0253 - learning_rate: 6.5610e-04\n",
      "Epoch 101/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0232 - val_loss: 0.0246 - learning_rate: 6.5610e-04\n",
      "Epoch 102/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0231 - val_loss: 0.0262 - learning_rate: 6.5610e-04\n",
      "Epoch 103/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0231 - val_loss: 0.0242 - learning_rate: 6.5610e-04\n",
      "Epoch 104/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0231 - val_loss: 0.0247 - learning_rate: 6.5610e-04\n",
      "Epoch 105/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0230\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - loss: 0.0230 - val_loss: 0.0244 - learning_rate: 6.5610e-04\n",
      "Epoch 106/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0228 - val_loss: 0.0245 - learning_rate: 5.9049e-04\n",
      "Epoch 107/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0227 - val_loss: 0.0251 - learning_rate: 5.9049e-04\n",
      "Epoch 108/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0226 - val_loss: 0.0271 - learning_rate: 5.9049e-04\n",
      "Epoch 109/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0226 - val_loss: 0.0244 - learning_rate: 5.9049e-04\n",
      "Epoch 110/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0227 - val_loss: 0.0237 - learning_rate: 5.9049e-04\n",
      "Epoch 111/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0226 - val_loss: 0.0245 - learning_rate: 5.9049e-04\n",
      "Epoch 112/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0226 - val_loss: 0.0244 - learning_rate: 5.9049e-04\n",
      "Epoch 113/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0226 - val_loss: 0.0255 - learning_rate: 5.9049e-04\n",
      "Epoch 114/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0226 - val_loss: 0.0245 - learning_rate: 5.9049e-04\n",
      "Epoch 115/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0225 - val_loss: 0.0233 - learning_rate: 5.9049e-04\n",
      "Epoch 116/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0226 - val_loss: 0.0240 - learning_rate: 5.9049e-04\n",
      "Epoch 117/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0225 - val_loss: 0.0248 - learning_rate: 5.9049e-04\n",
      "Epoch 118/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0225 - val_loss: 0.0235 - learning_rate: 5.9049e-04\n",
      "Epoch 119/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0226 - val_loss: 0.0239 - learning_rate: 5.9049e-04\n",
      "Epoch 120/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0225 - val_loss: 0.0248 - learning_rate: 5.9049e-04\n",
      "Epoch 121/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0225 - val_loss: 0.0238 - learning_rate: 5.9049e-04\n",
      "Epoch 122/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0225 - val_loss: 0.0260 - learning_rate: 5.9049e-04\n",
      "Epoch 123/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0225 - val_loss: 0.0244 - learning_rate: 5.9049e-04\n",
      "Epoch 124/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0224 - val_loss: 0.0242 - learning_rate: 5.9049e-04\n",
      "Epoch 125/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0224\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0224 - val_loss: 0.0234 - learning_rate: 5.9049e-04\n",
      "Epoch 126/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0223 - val_loss: 0.0238 - learning_rate: 5.3144e-04\n",
      "Epoch 127/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0222 - val_loss: 0.0239 - learning_rate: 5.3144e-04\n",
      "Epoch 128/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - loss: 0.0222 - val_loss: 0.0228 - learning_rate: 5.3144e-04\n",
      "Epoch 129/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0222 - val_loss: 0.0226 - learning_rate: 5.3144e-04\n",
      "Epoch 130/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0222 - val_loss: 0.0233 - learning_rate: 5.3144e-04\n",
      "Epoch 131/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0221 - val_loss: 0.0238 - learning_rate: 5.3144e-04\n",
      "Epoch 132/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0221 - val_loss: 0.0238 - learning_rate: 5.3144e-04\n",
      "Epoch 133/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0221 - val_loss: 0.0244 - learning_rate: 5.3144e-04\n",
      "Epoch 134/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0221 - val_loss: 0.0241 - learning_rate: 5.3144e-04\n",
      "Epoch 135/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0220 - val_loss: 0.0227 - learning_rate: 5.3144e-04\n",
      "Epoch 136/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0220 - val_loss: 0.0228 - learning_rate: 5.3144e-04\n",
      "Epoch 137/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0220 - val_loss: 0.0416 - learning_rate: 5.3144e-04\n",
      "Epoch 138/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0219 - val_loss: 0.0342 - learning_rate: 5.3144e-04\n",
      "Epoch 139/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0219\n",
      "Epoch 139: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0219 - val_loss: 0.0235 - learning_rate: 5.3144e-04\n",
      "Epoch 140/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0218 - val_loss: 0.0235 - learning_rate: 4.7830e-04\n",
      "Epoch 141/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0217 - val_loss: 0.0222 - learning_rate: 4.7830e-04\n",
      "Epoch 142/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - loss: 0.0217 - val_loss: 0.0228 - learning_rate: 4.7830e-04\n",
      "Epoch 143/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0217 - val_loss: 0.0222 - learning_rate: 4.7830e-04\n",
      "Epoch 144/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0216 - val_loss: 0.0219 - learning_rate: 4.7830e-04\n",
      "Epoch 145/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0216 - val_loss: 0.0225 - learning_rate: 4.7830e-04\n",
      "Epoch 146/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0215 - val_loss: 0.0227 - learning_rate: 4.7830e-04\n",
      "Epoch 147/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0215 - val_loss: 0.0226 - learning_rate: 4.7830e-04\n",
      "Epoch 148/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0215 - val_loss: 0.0221 - learning_rate: 4.7830e-04\n",
      "Epoch 149/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0215 - val_loss: 0.0223 - learning_rate: 4.7830e-04\n",
      "Epoch 150/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0214 - val_loss: 0.0222 - learning_rate: 4.7830e-04\n",
      "Epoch 151/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0215 - val_loss: 0.0219 - learning_rate: 4.7830e-04\n",
      "Epoch 152/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0214 - val_loss: 0.0224 - learning_rate: 4.7830e-04\n",
      "Epoch 153/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0214 - val_loss: 0.0218 - learning_rate: 4.7830e-04\n",
      "Epoch 154/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0214 - val_loss: 0.0226 - learning_rate: 4.7830e-04\n",
      "Epoch 155/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0214 - val_loss: 0.0220 - learning_rate: 4.7830e-04\n",
      "Epoch 156/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0213 - val_loss: 0.0220 - learning_rate: 4.7830e-04\n",
      "Epoch 157/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0213 - val_loss: 0.0220 - learning_rate: 4.7830e-04\n",
      "Epoch 158/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0213 - val_loss: 0.0238 - learning_rate: 4.7830e-04\n",
      "Epoch 159/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0212 - val_loss: 0.0224 - learning_rate: 4.7830e-04\n",
      "Epoch 160/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0212 - val_loss: 0.0224 - learning_rate: 4.7830e-04\n",
      "Epoch 161/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0211 - val_loss: 0.0235 - learning_rate: 4.7830e-04\n",
      "Epoch 162/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0211 - val_loss: 0.0219 - learning_rate: 4.7830e-04\n",
      "Epoch 163/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0212\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 168ms/step - loss: 0.0212 - val_loss: 0.0218 - learning_rate: 4.7830e-04\n",
      "Epoch 164/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0211 - val_loss: 0.0219 - learning_rate: 4.3047e-04\n",
      "Epoch 165/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0210 - val_loss: 0.0216 - learning_rate: 4.3047e-04\n",
      "Epoch 166/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0209 - val_loss: 0.0216 - learning_rate: 4.3047e-04\n",
      "Epoch 167/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0209 - val_loss: 0.0217 - learning_rate: 4.3047e-04\n",
      "Epoch 168/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - loss: 0.0209 - val_loss: 0.0218 - learning_rate: 4.3047e-04\n",
      "Epoch 169/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0208 - val_loss: 0.0221 - learning_rate: 4.3047e-04\n",
      "Epoch 170/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0208 - val_loss: 0.0219 - learning_rate: 4.3047e-04\n",
      "Epoch 171/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0208 - val_loss: 0.0217 - learning_rate: 4.3047e-04\n",
      "Epoch 172/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0208"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 18:54:26.277837: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0208 - val_loss: 0.0216 - learning_rate: 4.3047e-04\n",
      "Epoch 173/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0207 - val_loss: 0.0218 - learning_rate: 4.3047e-04\n",
      "Epoch 174/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0207 - val_loss: 0.0216 - learning_rate: 4.3047e-04\n",
      "Epoch 175/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0207\n",
      "Epoch 175: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0207 - val_loss: 0.0217 - learning_rate: 4.3047e-04\n",
      "Epoch 176/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0206 - val_loss: 0.0219 - learning_rate: 3.8742e-04\n",
      "Epoch 177/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0205 - val_loss: 0.0218 - learning_rate: 3.8742e-04\n",
      "Epoch 178/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0205 - val_loss: 0.0227 - learning_rate: 3.8742e-04\n",
      "Epoch 179/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0205 - val_loss: 0.0219 - learning_rate: 3.8742e-04\n",
      "Epoch 180/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0204 - val_loss: 0.0218 - learning_rate: 3.8742e-04\n",
      "Epoch 181/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0205 - val_loss: 0.0222 - learning_rate: 3.8742e-04\n",
      "Epoch 182/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0204 - val_loss: 0.0241 - learning_rate: 3.8742e-04\n",
      "Epoch 183/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 3.8742e-04\n",
      "Epoch 184/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 3.8742e-04\n",
      "Epoch 185/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0204\n",
      "Epoch 185: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0204 - val_loss: 0.0219 - learning_rate: 3.8742e-04\n",
      "Epoch 186/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0203 - val_loss: 0.0227 - learning_rate: 3.4868e-04\n",
      "Epoch 187/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 3.4868e-04\n",
      "Epoch 188/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 3.4868e-04\n",
      "Epoch 189/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 3.4868e-04\n",
      "Epoch 190/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0201 - val_loss: 0.0226 - learning_rate: 3.4868e-04\n",
      "Epoch 191/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 3.4868e-04\n",
      "Epoch 192/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0200 - val_loss: 0.0223 - learning_rate: 3.4868e-04\n",
      "Epoch 193/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0200 - val_loss: 0.0221 - learning_rate: 3.4868e-04\n",
      "Epoch 194/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0200 - val_loss: 0.0266 - learning_rate: 3.4868e-04\n",
      "Epoch 195/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0200\n",
      "Epoch 195: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0200 - val_loss: 0.0226 - learning_rate: 3.4868e-04\n",
      "Epoch 196/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0199 - val_loss: 0.0217 - learning_rate: 3.1381e-04\n",
      "Epoch 197/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0198 - val_loss: 0.0218 - learning_rate: 3.1381e-04\n",
      "Epoch 198/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0198 - val_loss: 0.0217 - learning_rate: 3.1381e-04\n",
      "Epoch 199/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0198 - val_loss: 0.0217 - learning_rate: 3.1381e-04\n",
      "Epoch 200/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0197 - val_loss: 0.0226 - learning_rate: 3.1381e-04\n",
      "Epoch 201/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0198 - val_loss: 0.0224 - learning_rate: 3.1381e-04\n",
      "Epoch 202/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0197 - val_loss: 0.0221 - learning_rate: 3.1381e-04\n",
      "Epoch 203/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0197 - val_loss: 0.0218 - learning_rate: 3.1381e-04\n",
      "Epoch 204/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0197 - val_loss: 0.0221 - learning_rate: 3.1381e-04\n",
      "Epoch 205/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0197\n",
      "Epoch 205: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0196 - val_loss: 0.0225 - learning_rate: 3.1381e-04\n",
      "Epoch 206/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0195 - val_loss: 0.0222 - learning_rate: 2.8243e-04\n",
      "Epoch 207/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0195 - val_loss: 0.0224 - learning_rate: 2.8243e-04\n",
      "Epoch 208/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0195 - val_loss: 0.0221 - learning_rate: 2.8243e-04\n",
      "Epoch 209/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0195 - val_loss: 0.0224 - learning_rate: 2.8243e-04\n",
      "Epoch 210/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0194 - val_loss: 0.0219 - learning_rate: 2.8243e-04\n",
      "Epoch 211/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0194 - val_loss: 0.0220 - learning_rate: 2.8243e-04\n",
      "Epoch 212/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0194 - val_loss: 0.0226 - learning_rate: 2.8243e-04\n",
      "Epoch 213/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0194 - val_loss: 0.0230 - learning_rate: 2.8243e-04\n",
      "Epoch 214/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0193 - val_loss: 0.0292 - learning_rate: 2.8243e-04\n",
      "Epoch 215/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0194\n",
      "Epoch 215: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0193 - val_loss: 0.0236 - learning_rate: 2.8243e-04\n",
      "Epoch 216/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0192 - val_loss: 0.0222 - learning_rate: 2.5419e-04\n",
      "Epoch 217/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0192 - val_loss: 0.0220 - learning_rate: 2.5419e-04\n",
      "Epoch 218/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0192 - val_loss: 0.0219 - learning_rate: 2.5419e-04\n",
      "Epoch 219/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - loss: 0.0192 - val_loss: 0.0222 - learning_rate: 2.5419e-04\n",
      "Epoch 220/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0191 - val_loss: 0.0218 - learning_rate: 2.5419e-04\n",
      "Epoch 221/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0191 - val_loss: 0.0220 - learning_rate: 2.5419e-04\n",
      "Epoch 222/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0191 - val_loss: 0.0220 - learning_rate: 2.5419e-04\n",
      "Epoch 223/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0191 - val_loss: 0.0223 - learning_rate: 2.5419e-04\n",
      "Epoch 224/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0191 - val_loss: 0.0219 - learning_rate: 2.5419e-04\n",
      "Epoch 225/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0191\n",
      "Epoch 225: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0191 - val_loss: 0.0216 - learning_rate: 2.5419e-04\n",
      "Epoch 226/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0190 - val_loss: 0.0226 - learning_rate: 2.2877e-04\n",
      "Epoch 227/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0189 - val_loss: 0.0221 - learning_rate: 2.2877e-04\n",
      "Epoch 228/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0189 - val_loss: 0.0224 - learning_rate: 2.2877e-04\n",
      "Epoch 229/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0189 - val_loss: 0.0222 - learning_rate: 2.2877e-04\n",
      "Epoch 230/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0188 - val_loss: 0.0222 - learning_rate: 2.2877e-04\n",
      "Epoch 231/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0188 - val_loss: 0.0222 - learning_rate: 2.2877e-04\n",
      "Epoch 232/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0189 - val_loss: 0.0227 - learning_rate: 2.2877e-04\n",
      "Epoch 233/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0188 - val_loss: 0.0227 - learning_rate: 2.2877e-04\n",
      "Epoch 234/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0187 - val_loss: 0.0225 - learning_rate: 2.2877e-04\n",
      "Epoch 235/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0188\n",
      "Epoch 235: ReduceLROnPlateau reducing learning rate to 0.00020589114428730683.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0188 - val_loss: 0.0223 - learning_rate: 2.2877e-04\n",
      "Epoch 236/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0187 - val_loss: 0.0223 - learning_rate: 2.0589e-04\n",
      "Epoch 237/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0186 - val_loss: 0.0223 - learning_rate: 2.0589e-04\n",
      "Epoch 238/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0187 - val_loss: 0.0223 - learning_rate: 2.0589e-04\n",
      "Epoch 239/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0186 - val_loss: 0.0222 - learning_rate: 2.0589e-04\n",
      "Epoch 240/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0186 - val_loss: 0.0225 - learning_rate: 2.0589e-04\n",
      "Epoch 241/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0186 - val_loss: 0.0222 - learning_rate: 2.0589e-04\n",
      "Epoch 242/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0186 - val_loss: 0.0224 - learning_rate: 2.0589e-04\n",
      "Epoch 243/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0186 - val_loss: 0.0219 - learning_rate: 2.0589e-04\n",
      "Epoch 244/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0185 - val_loss: 0.0220 - learning_rate: 2.0589e-04\n",
      "Epoch 245/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0186\n",
      "Epoch 245: ReduceLROnPlateau reducing learning rate to 0.00018530203378759326.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0185 - val_loss: 0.0222 - learning_rate: 2.0589e-04\n",
      "Epoch 246/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0185 - val_loss: 0.0224 - learning_rate: 1.8530e-04\n",
      "Epoch 247/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0184 - val_loss: 0.0221 - learning_rate: 1.8530e-04\n",
      "Epoch 248/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0184 - val_loss: 0.0223 - learning_rate: 1.8530e-04\n",
      "Epoch 249/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0184 - val_loss: 0.0223 - learning_rate: 1.8530e-04\n",
      "Epoch 250/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0184 - val_loss: 0.0223 - learning_rate: 1.8530e-04\n",
      "Epoch 251/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0184 - val_loss: 0.0221 - learning_rate: 1.8530e-04\n",
      "Epoch 252/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0183 - val_loss: 0.0221 - learning_rate: 1.8530e-04\n",
      "Epoch 253/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0183 - val_loss: 0.0224 - learning_rate: 1.8530e-04\n",
      "Epoch 254/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0184 - val_loss: 0.0222 - learning_rate: 1.8530e-04\n",
      "Epoch 255/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0183\n",
      "Epoch 255: ReduceLROnPlateau reducing learning rate to 0.00016677183302817866.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0183 - val_loss: 0.0221 - learning_rate: 1.8530e-04\n",
      "Epoch 256/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0183 - val_loss: 0.0222 - learning_rate: 1.6677e-04\n",
      "Epoch 257/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0182 - val_loss: 0.0220 - learning_rate: 1.6677e-04\n",
      "Epoch 258/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0182 - val_loss: 0.0224 - learning_rate: 1.6677e-04\n",
      "Epoch 259/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0182 - val_loss: 0.0222 - learning_rate: 1.6677e-04\n",
      "Epoch 260/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0182 - val_loss: 0.0220 - learning_rate: 1.6677e-04\n",
      "Epoch 261/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0182 - val_loss: 0.0224 - learning_rate: 1.6677e-04\n",
      "Epoch 262/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0182 - val_loss: 0.0224 - learning_rate: 1.6677e-04\n",
      "Epoch 263/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0181 - val_loss: 0.0228 - learning_rate: 1.6677e-04\n",
      "Epoch 264/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0182 - val_loss: 0.0223 - learning_rate: 1.6677e-04\n",
      "Epoch 265/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0181\n",
      "Epoch 265: ReduceLROnPlateau reducing learning rate to 0.00015009464841568844.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0181 - val_loss: 0.0222 - learning_rate: 1.6677e-04\n",
      "Epoch 266/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0181 - val_loss: 0.0227 - learning_rate: 1.5009e-04\n",
      "Epoch 267/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0181 - val_loss: 0.0224 - learning_rate: 1.5009e-04\n",
      "Epoch 268/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - loss: 0.0180 - val_loss: 0.0226 - learning_rate: 1.5009e-04\n",
      "Epoch 269/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0180 - val_loss: 0.0223 - learning_rate: 1.5009e-04\n",
      "Epoch 270/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0180 - val_loss: 0.0226 - learning_rate: 1.5009e-04\n",
      "Epoch 271/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0180 - val_loss: 0.0220 - learning_rate: 1.5009e-04\n",
      "Epoch 272/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - loss: 0.0180 - val_loss: 0.0226 - learning_rate: 1.5009e-04\n",
      "Epoch 273/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0180 - val_loss: 0.0221 - learning_rate: 1.5009e-04\n",
      "Epoch 274/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0179 - val_loss: 0.0223 - learning_rate: 1.5009e-04\n",
      "Epoch 275/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0180\n",
      "Epoch 275: ReduceLROnPlateau reducing learning rate to 0.0001350851875031367.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0180 - val_loss: 0.0237 - learning_rate: 1.5009e-04\n",
      "Epoch 276/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0179 - val_loss: 0.0222 - learning_rate: 1.3509e-04\n",
      "Epoch 277/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0179 - val_loss: 0.0222 - learning_rate: 1.3509e-04\n",
      "Epoch 278/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0178 - val_loss: 0.0223 - learning_rate: 1.3509e-04\n",
      "Epoch 279/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0178 - val_loss: 0.0228 - learning_rate: 1.3509e-04\n",
      "Epoch 280/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0178 - val_loss: 0.0226 - learning_rate: 1.3509e-04\n",
      "Epoch 281/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0178 - val_loss: 0.0225 - learning_rate: 1.3509e-04\n",
      "Epoch 282/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0178 - val_loss: 0.0223 - learning_rate: 1.3509e-04\n",
      "Epoch 283/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0178 - val_loss: 0.0227 - learning_rate: 1.3509e-04\n",
      "Epoch 284/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0177 - val_loss: 0.0225 - learning_rate: 1.3509e-04\n",
      "Epoch 285/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0178\n",
      "Epoch 285: ReduceLROnPlateau reducing learning rate to 0.00012157666351413355.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0178 - val_loss: 0.0226 - learning_rate: 1.3509e-04\n",
      "Epoch 286/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0177 - val_loss: 0.0226 - learning_rate: 1.2158e-04\n",
      "Epoch 287/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0177 - val_loss: 0.0227 - learning_rate: 1.2158e-04\n",
      "Epoch 288/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0177 - val_loss: 0.0227 - learning_rate: 1.2158e-04\n",
      "Epoch 289/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0177 - val_loss: 0.0224 - learning_rate: 1.2158e-04\n",
      "Epoch 290/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0177 - val_loss: 0.0225 - learning_rate: 1.2158e-04\n",
      "Epoch 291/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0177 - val_loss: 0.0228 - learning_rate: 1.2158e-04\n",
      "Epoch 292/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0176 - val_loss: 0.0226 - learning_rate: 1.2158e-04\n",
      "Epoch 293/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0176 - val_loss: 0.0227 - learning_rate: 1.2158e-04\n",
      "Epoch 294/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0177 - val_loss: 0.0227 - learning_rate: 1.2158e-04\n",
      "Epoch 295/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0176\n",
      "Epoch 295: ReduceLROnPlateau reducing learning rate to 0.00010941899454337544.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0176 - val_loss: 0.0230 - learning_rate: 1.2158e-04\n",
      "Epoch 296/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0176 - val_loss: 0.0227 - learning_rate: 1.0942e-04\n",
      "Epoch 297/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0176 - val_loss: 0.0227 - learning_rate: 1.0942e-04\n",
      "Epoch 298/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0176 - val_loss: 0.0227 - learning_rate: 1.0942e-04\n",
      "Epoch 299/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0175 - val_loss: 0.0226 - learning_rate: 1.0942e-04\n",
      "Epoch 300/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0175 - val_loss: 0.0227 - learning_rate: 1.0942e-04\n",
      "Epoch 301/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0175 - val_loss: 0.0226 - learning_rate: 1.0942e-04\n",
      "Epoch 302/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0175 - val_loss: 0.0229 - learning_rate: 1.0942e-04\n",
      "Epoch 303/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0175 - val_loss: 0.0230 - learning_rate: 1.0942e-04\n",
      "Epoch 304/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0175 - val_loss: 0.0234 - learning_rate: 1.0942e-04\n",
      "Epoch 305/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0175\n",
      "Epoch 305: ReduceLROnPlateau reducing learning rate to 9.847709443420172e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0175 - val_loss: 0.0231 - learning_rate: 1.0942e-04\n",
      "Epoch 306/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0174 - val_loss: 0.0229 - learning_rate: 9.8477e-05\n",
      "Epoch 307/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0174 - val_loss: 0.0231 - learning_rate: 9.8477e-05\n",
      "Epoch 308/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0174 - val_loss: 0.0234 - learning_rate: 9.8477e-05\n",
      "Epoch 309/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0174 - val_loss: 0.0232 - learning_rate: 9.8477e-05\n",
      "Epoch 310/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0174 - val_loss: 0.0231 - learning_rate: 9.8477e-05\n",
      "Epoch 311/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0174 - val_loss: 0.0231 - learning_rate: 9.8477e-05\n",
      "Epoch 312/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - loss: 0.0173 - val_loss: 0.0227 - learning_rate: 9.8477e-05\n",
      "Epoch 313/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0173 - val_loss: 0.0226 - learning_rate: 9.8477e-05\n",
      "Epoch 314/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0173 - val_loss: 0.0230 - learning_rate: 9.8477e-05\n",
      "Epoch 315/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0174\n",
      "Epoch 315: ReduceLROnPlateau reducing learning rate to 8.862938630045391e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0173 - val_loss: 0.0230 - learning_rate: 9.8477e-05\n",
      "Epoch 316/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0173 - val_loss: 0.0229 - learning_rate: 8.8629e-05\n",
      "Epoch 317/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0172 - val_loss: 0.0226 - learning_rate: 8.8629e-05\n",
      "Epoch 318/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0173 - val_loss: 0.0232 - learning_rate: 8.8629e-05\n",
      "Epoch 319/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0172 - val_loss: 0.0231 - learning_rate: 8.8629e-05\n",
      "Epoch 320/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0172 - val_loss: 0.0229 - learning_rate: 8.8629e-05\n",
      "Epoch 321/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0172 - val_loss: 0.0233 - learning_rate: 8.8629e-05\n",
      "Epoch 322/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0172 - val_loss: 0.0232 - learning_rate: 8.8629e-05\n",
      "Epoch 323/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0172 - val_loss: 0.0229 - learning_rate: 8.8629e-05\n",
      "Epoch 324/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0172 - val_loss: 0.0234 - learning_rate: 8.8629e-05\n",
      "Epoch 325/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0172\n",
      "Epoch 325: ReduceLROnPlateau reducing learning rate to 7.976644701557234e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0172 - val_loss: 0.0230 - learning_rate: 8.8629e-05\n",
      "Epoch 326/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0172 - val_loss: 0.0229 - learning_rate: 7.9766e-05\n",
      "Epoch 327/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0172 - val_loss: 0.0231 - learning_rate: 7.9766e-05\n",
      "Epoch 328/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0172 - val_loss: 0.0235 - learning_rate: 7.9766e-05\n",
      "Epoch 329/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0171 - val_loss: 0.0237 - learning_rate: 7.9766e-05\n",
      "Epoch 330/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0171 - val_loss: 0.0231 - learning_rate: 7.9766e-05\n",
      "Epoch 331/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0171 - val_loss: 0.0231 - learning_rate: 7.9766e-05\n",
      "Epoch 332/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0171 - val_loss: 0.0235 - learning_rate: 7.9766e-05\n",
      "Epoch 333/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0171 - val_loss: 0.0236 - learning_rate: 7.9766e-05\n",
      "Epoch 334/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0171 - val_loss: 0.0241 - learning_rate: 7.9766e-05\n",
      "Epoch 335/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0171\n",
      "Epoch 335: ReduceLROnPlateau reducing learning rate to 7.178980231401511e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0171 - val_loss: 0.0244 - learning_rate: 7.9766e-05\n",
      "Epoch 336/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0171 - val_loss: 0.0233 - learning_rate: 7.1790e-05\n",
      "Epoch 337/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0170 - val_loss: 0.0235 - learning_rate: 7.1790e-05\n",
      "Epoch 338/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0170 - val_loss: 0.0235 - learning_rate: 7.1790e-05\n",
      "Epoch 339/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0170 - val_loss: 0.0234 - learning_rate: 7.1790e-05\n",
      "Epoch 340/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0170 - val_loss: 0.0236 - learning_rate: 7.1790e-05\n",
      "Epoch 341/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0170 - val_loss: 0.0233 - learning_rate: 7.1790e-05\n",
      "Epoch 342/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0170 - val_loss: 0.0233 - learning_rate: 7.1790e-05\n",
      "Epoch 343/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0170"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 19:13:21.266383: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - loss: 0.0170 - val_loss: 0.0235 - learning_rate: 7.1790e-05\n",
      "Epoch 344/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0170 - val_loss: 0.0233 - learning_rate: 7.1790e-05\n",
      "Epoch 345/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0170\n",
      "Epoch 345: ReduceLROnPlateau reducing learning rate to 6.461082011810504e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0169 - val_loss: 0.0234 - learning_rate: 7.1790e-05\n",
      "Epoch 346/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0169 - val_loss: 0.0240 - learning_rate: 6.4611e-05\n",
      "Epoch 347/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0170 - val_loss: 0.0239 - learning_rate: 6.4611e-05\n",
      "Epoch 348/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0169 - val_loss: 0.0233 - learning_rate: 6.4611e-05\n",
      "Epoch 349/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0169 - val_loss: 0.0237 - learning_rate: 6.4611e-05\n",
      "Epoch 350/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0169 - val_loss: 0.0238 - learning_rate: 6.4611e-05\n",
      "Epoch 351/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0169 - val_loss: 0.0238 - learning_rate: 6.4611e-05\n",
      "Epoch 352/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0169 - val_loss: 0.0236 - learning_rate: 6.4611e-05\n",
      "Epoch 353/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0168 - val_loss: 0.0241 - learning_rate: 6.4611e-05\n",
      "Epoch 354/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0169 - val_loss: 0.0240 - learning_rate: 6.4611e-05\n",
      "Epoch 355/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0169\n",
      "Epoch 355: ReduceLROnPlateau reducing learning rate to 5.8149741380475466e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0169 - val_loss: 0.0242 - learning_rate: 6.4611e-05\n",
      "Epoch 356/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0168 - val_loss: 0.0246 - learning_rate: 5.8150e-05\n",
      "Epoch 357/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0168 - val_loss: 0.0237 - learning_rate: 5.8150e-05\n",
      "Epoch 358/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0168 - val_loss: 0.0239 - learning_rate: 5.8150e-05\n",
      "Epoch 359/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0168 - val_loss: 0.0239 - learning_rate: 5.8150e-05\n",
      "Epoch 360/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0168 - val_loss: 0.0242 - learning_rate: 5.8150e-05\n",
      "Epoch 361/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0168 - val_loss: 0.0242 - learning_rate: 5.8150e-05\n",
      "Epoch 362/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0168 - val_loss: 0.0242 - learning_rate: 5.8150e-05\n",
      "Epoch 363/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0168 - val_loss: 0.0242 - learning_rate: 5.8150e-05\n",
      "Epoch 364/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0168 - val_loss: 0.0244 - learning_rate: 5.8150e-05\n",
      "Epoch 365/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0168\n",
      "Epoch 365: ReduceLROnPlateau reducing learning rate to 5.233476658759173e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0167 - val_loss: 0.0240 - learning_rate: 5.8150e-05\n",
      "Epoch 366/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0167 - val_loss: 0.0240 - learning_rate: 5.2335e-05\n",
      "Epoch 367/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0168 - val_loss: 0.0242 - learning_rate: 5.2335e-05\n",
      "Epoch 368/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0167 - val_loss: 0.0242 - learning_rate: 5.2335e-05\n",
      "Epoch 369/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0167 - val_loss: 0.0239 - learning_rate: 5.2335e-05\n",
      "Epoch 370/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0168 - val_loss: 0.0238 - learning_rate: 5.2335e-05\n",
      "Epoch 371/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0167 - val_loss: 0.0242 - learning_rate: 5.2335e-05\n",
      "Epoch 372/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0166 - val_loss: 0.0243 - learning_rate: 5.2335e-05\n",
      "Epoch 373/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0167 - val_loss: 0.0243 - learning_rate: 5.2335e-05\n",
      "Epoch 374/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0167 - val_loss: 0.0245 - learning_rate: 5.2335e-05\n",
      "Epoch 375/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0167\n",
      "Epoch 375: ReduceLROnPlateau reducing learning rate to 4.7101289601414466e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0167 - val_loss: 0.0241 - learning_rate: 5.2335e-05\n",
      "Epoch 376/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0167 - val_loss: 0.0244 - learning_rate: 4.7101e-05\n",
      "Epoch 377/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0166 - val_loss: 0.0244 - learning_rate: 4.7101e-05\n",
      "Epoch 378/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0167 - val_loss: 0.0240 - learning_rate: 4.7101e-05\n",
      "Epoch 379/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0166 - val_loss: 0.0246 - learning_rate: 4.7101e-05\n",
      "Epoch 380/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0166 - val_loss: 0.0243 - learning_rate: 4.7101e-05\n",
      "Epoch 381/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0166 - val_loss: 0.0246 - learning_rate: 4.7101e-05\n",
      "Epoch 382/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0166 - val_loss: 0.0247 - learning_rate: 4.7101e-05\n",
      "Epoch 383/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0166 - val_loss: 0.0244 - learning_rate: 4.7101e-05\n",
      "Epoch 384/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0166 - val_loss: 0.0249 - learning_rate: 4.7101e-05\n",
      "Epoch 385/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0166\n",
      "Epoch 385: ReduceLROnPlateau reducing learning rate to 4.239116096869111e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0166 - val_loss: 0.0245 - learning_rate: 4.7101e-05\n",
      "Epoch 386/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0166 - val_loss: 0.0246 - learning_rate: 4.2391e-05\n",
      "Epoch 387/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0166 - val_loss: 0.0248 - learning_rate: 4.2391e-05\n",
      "Epoch 388/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0166 - val_loss: 0.0253 - learning_rate: 4.2391e-05\n",
      "Epoch 389/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0165 - val_loss: 0.0250 - learning_rate: 4.2391e-05\n",
      "Epoch 390/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0166 - val_loss: 0.0245 - learning_rate: 4.2391e-05\n",
      "Epoch 391/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0166 - val_loss: 0.0251 - learning_rate: 4.2391e-05\n",
      "Epoch 392/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0165 - val_loss: 0.0250 - learning_rate: 4.2391e-05\n",
      "Epoch 393/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0165 - val_loss: 0.0248 - learning_rate: 4.2391e-05\n",
      "Epoch 394/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0165 - val_loss: 0.0243 - learning_rate: 4.2391e-05\n",
      "Epoch 395/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0165\n",
      "Epoch 395: ReduceLROnPlateau reducing learning rate to 3.815204618149437e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0165 - val_loss: 0.0248 - learning_rate: 4.2391e-05\n",
      "Epoch 396/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0165 - val_loss: 0.0249 - learning_rate: 3.8152e-05\n",
      "Epoch 397/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0165 - val_loss: 0.0250 - learning_rate: 3.8152e-05\n",
      "Epoch 398/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0165 - val_loss: 0.0252 - learning_rate: 3.8152e-05\n",
      "Epoch 399/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0164 - val_loss: 0.0244 - learning_rate: 3.8152e-05\n",
      "Epoch 400/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0165 - val_loss: 0.0246 - learning_rate: 3.8152e-05\n",
      "Epoch 401/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0165 - val_loss: 0.0251 - learning_rate: 3.8152e-05\n",
      "Epoch 402/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0164 - val_loss: 0.0256 - learning_rate: 3.8152e-05\n",
      "Epoch 403/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0165 - val_loss: 0.0248 - learning_rate: 3.8152e-05\n",
      "Epoch 404/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0164 - val_loss: 0.0252 - learning_rate: 3.8152e-05\n",
      "Epoch 405/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0165\n",
      "Epoch 405: ReduceLROnPlateau reducing learning rate to 3.4336842873017304e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0164 - val_loss: 0.0252 - learning_rate: 3.8152e-05\n",
      "Epoch 406/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0165 - val_loss: 0.0257 - learning_rate: 3.4337e-05\n",
      "Epoch 407/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0165 - val_loss: 0.0254 - learning_rate: 3.4337e-05\n",
      "Epoch 408/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0164 - val_loss: 0.0250 - learning_rate: 3.4337e-05\n",
      "Epoch 409/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0164 - val_loss: 0.0254 - learning_rate: 3.4337e-05\n",
      "Epoch 410/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0164 - val_loss: 0.0254 - learning_rate: 3.4337e-05\n",
      "Epoch 411/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0164 - val_loss: 0.0252 - learning_rate: 3.4337e-05\n",
      "Epoch 412/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - loss: 0.0164 - val_loss: 0.0255 - learning_rate: 3.4337e-05\n",
      "Epoch 413/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0164 - val_loss: 0.0249 - learning_rate: 3.4337e-05\n",
      "Epoch 414/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0163 - val_loss: 0.0256 - learning_rate: 3.4337e-05\n",
      "Epoch 415/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0164\n",
      "Epoch 415: ReduceLROnPlateau reducing learning rate to 3.0903160222806036e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0164 - val_loss: 0.0251 - learning_rate: 3.4337e-05\n",
      "Epoch 416/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0164 - val_loss: 0.0252 - learning_rate: 3.0903e-05\n",
      "Epoch 417/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0164 - val_loss: 0.0255 - learning_rate: 3.0903e-05\n",
      "Epoch 418/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0164 - val_loss: 0.0250 - learning_rate: 3.0903e-05\n",
      "Epoch 419/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 158ms/step - loss: 0.0163 - val_loss: 0.0257 - learning_rate: 3.0903e-05\n",
      "Epoch 420/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0163 - val_loss: 0.0258 - learning_rate: 3.0903e-05\n",
      "Epoch 421/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0163 - val_loss: 0.0252 - learning_rate: 3.0903e-05\n",
      "Epoch 422/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0163 - val_loss: 0.0251 - learning_rate: 3.0903e-05\n",
      "Epoch 423/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0163 - val_loss: 0.0250 - learning_rate: 3.0903e-05\n",
      "Epoch 424/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0163 - val_loss: 0.0251 - learning_rate: 3.0903e-05\n",
      "Epoch 425/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0164\n",
      "Epoch 425: ReduceLROnPlateau reducing learning rate to 2.7812844200525434e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0163 - val_loss: 0.0252 - learning_rate: 3.0903e-05\n",
      "Epoch 426/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0163 - val_loss: 0.0256 - learning_rate: 2.7813e-05\n",
      "Epoch 427/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0163 - val_loss: 0.0254 - learning_rate: 2.7813e-05\n",
      "Epoch 428/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0163 - val_loss: 0.0257 - learning_rate: 2.7813e-05\n",
      "Epoch 429/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0163 - val_loss: 0.0257 - learning_rate: 2.7813e-05\n",
      "Epoch 430/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0163 - val_loss: 0.0260 - learning_rate: 2.7813e-05\n",
      "Epoch 431/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0162 - val_loss: 0.0257 - learning_rate: 2.7813e-05\n",
      "Epoch 432/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0163 - val_loss: 0.0259 - learning_rate: 2.7813e-05\n",
      "Epoch 433/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0162 - val_loss: 0.0256 - learning_rate: 2.7813e-05\n",
      "Epoch 434/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0162 - val_loss: 0.0256 - learning_rate: 2.7813e-05\n",
      "Epoch 435/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0163\n",
      "Epoch 435: ReduceLROnPlateau reducing learning rate to 2.5031560107890984e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0162 - val_loss: 0.0263 - learning_rate: 2.7813e-05\n",
      "Epoch 436/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0162 - val_loss: 0.0258 - learning_rate: 2.5032e-05\n",
      "Epoch 437/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0162 - val_loss: 0.0255 - learning_rate: 2.5032e-05\n",
      "Epoch 438/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0162 - val_loss: 0.0258 - learning_rate: 2.5032e-05\n",
      "Epoch 439/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0163 - val_loss: 0.0256 - learning_rate: 2.5032e-05\n",
      "Epoch 440/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0162 - val_loss: 0.0256 - learning_rate: 2.5032e-05\n",
      "Epoch 441/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0162 - val_loss: 0.0257 - learning_rate: 2.5032e-05\n",
      "Epoch 442/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0162 - val_loss: 0.0257 - learning_rate: 2.5032e-05\n",
      "Epoch 443/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0162 - val_loss: 0.0252 - learning_rate: 2.5032e-05\n",
      "Epoch 444/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0162 - val_loss: 0.0256 - learning_rate: 2.5032e-05\n",
      "Epoch 445/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0162\n",
      "Epoch 445: ReduceLROnPlateau reducing learning rate to 2.2528404588229024e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0162 - val_loss: 0.0258 - learning_rate: 2.5032e-05\n",
      "Epoch 446/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0162 - val_loss: 0.0259 - learning_rate: 2.2528e-05\n",
      "Epoch 447/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0161 - val_loss: 0.0253 - learning_rate: 2.2528e-05\n",
      "Epoch 448/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0162 - val_loss: 0.0260 - learning_rate: 2.2528e-05\n",
      "Epoch 449/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0161 - val_loss: 0.0257 - learning_rate: 2.2528e-05\n",
      "Epoch 450/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0161 - val_loss: 0.0254 - learning_rate: 2.2528e-05\n",
      "Epoch 451/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0162 - val_loss: 0.0255 - learning_rate: 2.2528e-05\n",
      "Epoch 452/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0162 - val_loss: 0.0257 - learning_rate: 2.2528e-05\n",
      "Epoch 453/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0161 - val_loss: 0.0264 - learning_rate: 2.2528e-05\n",
      "Epoch 454/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0162 - val_loss: 0.0260 - learning_rate: 2.2528e-05\n",
      "Epoch 455/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0162\n",
      "Epoch 455: ReduceLROnPlateau reducing learning rate to 2.0275563474569936e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0161 - val_loss: 0.0258 - learning_rate: 2.2528e-05\n",
      "Epoch 456/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0161 - val_loss: 0.0260 - learning_rate: 2.0276e-05\n",
      "Epoch 457/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0162 - val_loss: 0.0259 - learning_rate: 2.0276e-05\n",
      "Epoch 458/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0161 - val_loss: 0.0259 - learning_rate: 2.0276e-05\n",
      "Epoch 459/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0161 - val_loss: 0.0262 - learning_rate: 2.0276e-05\n",
      "Epoch 460/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0161 - val_loss: 0.0260 - learning_rate: 2.0276e-05\n",
      "Epoch 461/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0161 - val_loss: 0.0259 - learning_rate: 2.0276e-05\n",
      "Epoch 462/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0161 - val_loss: 0.0262 - learning_rate: 2.0276e-05\n",
      "Epoch 463/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0161 - val_loss: 0.0261 - learning_rate: 2.0276e-05\n",
      "Epoch 464/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0161 - val_loss: 0.0261 - learning_rate: 2.0276e-05\n",
      "Epoch 465/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0162\n",
      "Epoch 465: ReduceLROnPlateau reducing learning rate to 1.8248007290821987e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0161 - val_loss: 0.0260 - learning_rate: 2.0276e-05\n",
      "Epoch 466/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0161 - val_loss: 0.0259 - learning_rate: 1.8248e-05\n",
      "Epoch 467/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0161 - val_loss: 0.0262 - learning_rate: 1.8248e-05\n",
      "Epoch 468/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0161 - val_loss: 0.0262 - learning_rate: 1.8248e-05\n",
      "Epoch 469/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0161 - val_loss: 0.0265 - learning_rate: 1.8248e-05\n",
      "Epoch 470/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0161 - val_loss: 0.0261 - learning_rate: 1.8248e-05\n",
      "Epoch 471/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0160 - val_loss: 0.0259 - learning_rate: 1.8248e-05\n",
      "Epoch 472/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0161 - val_loss: 0.0266 - learning_rate: 1.8248e-05\n",
      "Epoch 473/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0161 - val_loss: 0.0259 - learning_rate: 1.8248e-05\n",
      "Epoch 474/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0161 - val_loss: 0.0263 - learning_rate: 1.8248e-05\n",
      "Epoch 475/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0161\n",
      "Epoch 475: ReduceLROnPlateau reducing learning rate to 1.6423206398030745e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0161 - val_loss: 0.0261 - learning_rate: 1.8248e-05\n",
      "Epoch 476/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0161 - val_loss: 0.0255 - learning_rate: 1.6423e-05\n",
      "Epoch 477/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0161 - val_loss: 0.0259 - learning_rate: 1.6423e-05\n",
      "Epoch 478/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0161 - val_loss: 0.0258 - learning_rate: 1.6423e-05\n",
      "Epoch 479/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0160 - val_loss: 0.0264 - learning_rate: 1.6423e-05\n",
      "Epoch 480/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0160 - val_loss: 0.0260 - learning_rate: 1.6423e-05\n",
      "Epoch 481/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0161 - val_loss: 0.0260 - learning_rate: 1.6423e-05\n",
      "Epoch 482/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0160 - val_loss: 0.0259 - learning_rate: 1.6423e-05\n",
      "Epoch 483/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0160 - val_loss: 0.0261 - learning_rate: 1.6423e-05\n",
      "Epoch 484/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0161 - val_loss: 0.0261 - learning_rate: 1.6423e-05\n",
      "Epoch 485/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0161\n",
      "Epoch 485: ReduceLROnPlateau reducing learning rate to 1.4780885430809576e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0160 - val_loss: 0.0255 - learning_rate: 1.6423e-05\n",
      "Epoch 486/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0161 - val_loss: 0.0264 - learning_rate: 1.4781e-05\n",
      "Epoch 487/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0160 - val_loss: 0.0260 - learning_rate: 1.4781e-05\n",
      "Epoch 488/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0160 - val_loss: 0.0263 - learning_rate: 1.4781e-05\n",
      "Epoch 489/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0160 - val_loss: 0.0265 - learning_rate: 1.4781e-05\n",
      "Epoch 490/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0160 - val_loss: 0.0260 - learning_rate: 1.4781e-05\n",
      "Epoch 491/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0160 - val_loss: 0.0262 - learning_rate: 1.4781e-05\n",
      "Epoch 492/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0160 - val_loss: 0.0262 - learning_rate: 1.4781e-05\n",
      "Epoch 493/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0160 - val_loss: 0.0258 - learning_rate: 1.4781e-05\n",
      "Epoch 494/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0160 - val_loss: 0.0264 - learning_rate: 1.4781e-05\n",
      "Epoch 495/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0161\n",
      "Epoch 495: ReduceLROnPlateau reducing learning rate to 1.3302796560310526e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0160 - val_loss: 0.0260 - learning_rate: 1.4781e-05\n",
      "Epoch 496/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 158ms/step - loss: 0.0160 - val_loss: 0.0260 - learning_rate: 1.3303e-05\n",
      "Epoch 497/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0160 - val_loss: 0.0262 - learning_rate: 1.3303e-05\n",
      "Epoch 498/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0160 - val_loss: 0.0260 - learning_rate: 1.3303e-05\n",
      "Epoch 499/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0160 - val_loss: 0.0261 - learning_rate: 1.3303e-05\n",
      "Epoch 500/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - loss: 0.0160 - val_loss: 0.0264 - learning_rate: 1.3303e-05\n",
      "Epoch 501/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0160 - val_loss: 0.0262 - learning_rate: 1.3303e-05\n",
      "Epoch 502/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0160 - val_loss: 0.0260 - learning_rate: 1.3303e-05\n",
      "Epoch 503/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0265 - learning_rate: 1.3303e-05\n",
      "Epoch 504/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0160 - val_loss: 0.0266 - learning_rate: 1.3303e-05\n",
      "Epoch 505/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0160\n",
      "Epoch 505: ReduceLROnPlateau reducing learning rate to 1.1972517313552089e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0264 - learning_rate: 1.3303e-05\n",
      "Epoch 506/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0159 - val_loss: 0.0261 - learning_rate: 1.1973e-05\n",
      "Epoch 507/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0159 - val_loss: 0.0265 - learning_rate: 1.1973e-05\n",
      "Epoch 508/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0160 - val_loss: 0.0263 - learning_rate: 1.1973e-05\n",
      "Epoch 509/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0160 - val_loss: 0.0262 - learning_rate: 1.1973e-05\n",
      "Epoch 510/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0263 - learning_rate: 1.1973e-05\n",
      "Epoch 511/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0264 - learning_rate: 1.1973e-05\n",
      "Epoch 512/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0160 - val_loss: 0.0262 - learning_rate: 1.1973e-05\n",
      "Epoch 513/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0160 - val_loss: 0.0263 - learning_rate: 1.1973e-05\n",
      "Epoch 514/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0160 - val_loss: 0.0267 - learning_rate: 1.1973e-05\n",
      "Epoch 515/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0160\n",
      "Epoch 515: ReduceLROnPlateau reducing learning rate to 1.077526558219688e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0159 - val_loss: 0.0260 - learning_rate: 1.1973e-05\n",
      "Epoch 516/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0160 - val_loss: 0.0262 - learning_rate: 1.0775e-05\n",
      "Epoch 517/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0159 - val_loss: 0.0268 - learning_rate: 1.0775e-05\n",
      "Epoch 518/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0263 - learning_rate: 1.0775e-05\n",
      "Epoch 519/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0159 - val_loss: 0.0261 - learning_rate: 1.0775e-05\n",
      "Epoch 520/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0159 - val_loss: 0.0264 - learning_rate: 1.0775e-05\n",
      "Epoch 521/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0159 - val_loss: 0.0262 - learning_rate: 1.0775e-05\n",
      "Epoch 522/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0262 - learning_rate: 1.0775e-05\n",
      "Epoch 523/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0159 - val_loss: 0.0263 - learning_rate: 1.0775e-05\n",
      "Epoch 524/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0265 - learning_rate: 1.0775e-05\n",
      "Epoch 525/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0160\n",
      "Epoch 525: ReduceLROnPlateau reducing learning rate to 9.697739187686238e-06.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0265 - learning_rate: 1.0775e-05\n",
      "Epoch 526/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0159 - val_loss: 0.0268 - learning_rate: 9.6977e-06\n",
      "Epoch 527/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0159 - val_loss: 0.0267 - learning_rate: 9.6977e-06\n",
      "Epoch 528/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0159 - val_loss: 0.0264 - learning_rate: 9.6977e-06\n",
      "Epoch 529/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0264 - learning_rate: 9.6977e-06\n",
      "Epoch 530/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0159 - val_loss: 0.0265 - learning_rate: 9.6977e-06\n",
      "Epoch 531/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0159 - val_loss: 0.0266 - learning_rate: 9.6977e-06\n",
      "Epoch 532/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0265 - learning_rate: 9.6977e-06\n",
      "Epoch 533/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 158ms/step - loss: 0.0159 - val_loss: 0.0267 - learning_rate: 9.6977e-06\n",
      "Epoch 534/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0262 - learning_rate: 9.6977e-06\n",
      "Epoch 535/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0159\n",
      "Epoch 535: ReduceLROnPlateau reducing learning rate to 8.727965268917615e-06.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0159 - val_loss: 0.0263 - learning_rate: 9.6977e-06\n",
      "Epoch 536/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0263 - learning_rate: 8.7280e-06\n",
      "Epoch 537/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0262 - learning_rate: 8.7280e-06\n",
      "Epoch 538/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0159 - val_loss: 0.0265 - learning_rate: 8.7280e-06\n",
      "Epoch 539/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0159 - val_loss: 0.0269 - learning_rate: 8.7280e-06\n",
      "Epoch 540/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0267 - learning_rate: 8.7280e-06\n",
      "Epoch 541/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0158 - val_loss: 0.0263 - learning_rate: 8.7280e-06\n",
      "Epoch 542/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0262 - learning_rate: 8.7280e-06\n",
      "Epoch 543/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0158 - val_loss: 0.0265 - learning_rate: 8.7280e-06\n",
      "Epoch 544/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0158 - val_loss: 0.0264 - learning_rate: 8.7280e-06\n",
      "Epoch 545/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0159\n",
      "Epoch 545: ReduceLROnPlateau reducing learning rate to 7.855168496462283e-06.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0267 - learning_rate: 8.7280e-06\n",
      "Epoch 546/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0158 - val_loss: 0.0264 - learning_rate: 7.8552e-06\n",
      "Epoch 547/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0158 - val_loss: 0.0263 - learning_rate: 7.8552e-06\n",
      "Epoch 548/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0158 - val_loss: 0.0264 - learning_rate: 7.8552e-06\n",
      "Epoch 549/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0158 - val_loss: 0.0268 - learning_rate: 7.8552e-06\n",
      "Epoch 550/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0159 - val_loss: 0.0267 - learning_rate: 7.8552e-06\n",
      "Epoch 551/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0158 - val_loss: 0.0266 - learning_rate: 7.8552e-06\n",
      "Epoch 552/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0158 - val_loss: 0.0260 - learning_rate: 7.8552e-06\n",
      "Epoch 553/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0158 - val_loss: 0.0266 - learning_rate: 7.8552e-06\n",
      "Epoch 554/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0159 - val_loss: 0.0265 - learning_rate: 7.8552e-06\n",
      "Epoch 555/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0159\n",
      "Epoch 555: ReduceLROnPlateau reducing learning rate to 7.069651564961533e-06.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0159 - val_loss: 0.0265 - learning_rate: 7.8552e-06\n",
      "Epoch 556/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0159 - val_loss: 0.0265 - learning_rate: 7.0697e-06\n",
      "Epoch 557/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0158 - val_loss: 0.0261 - learning_rate: 7.0697e-06\n",
      "Epoch 558/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0158 - val_loss: 0.0266 - learning_rate: 7.0697e-06\n",
      "Epoch 559/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0158 - val_loss: 0.0264 - learning_rate: 7.0697e-06\n",
      "Epoch 560/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0158 - val_loss: 0.0265 - learning_rate: 7.0697e-06\n",
      "Epoch 561/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0158 - val_loss: 0.0268 - learning_rate: 7.0697e-06\n",
      "Epoch 562/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0158 - val_loss: 0.0266 - learning_rate: 7.0697e-06\n",
      "Epoch 563/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0158 - val_loss: 0.0268 - learning_rate: 7.0697e-06\n",
      "Epoch 564/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0158 - val_loss: 0.0271 - learning_rate: 7.0697e-06\n",
      "Epoch 565/800\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0159\n",
      "Epoch 565: ReduceLROnPlateau reducing learning rate to 6.362686326610856e-06.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 0.0158 - val_loss: 0.0267 - learning_rate: 7.0697e-06\n",
      "Epoch 566/800\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0159"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model with the custom callback\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 72\u001b[0m, in \u001b[0;36mModelBuilder.train_model\u001b[0;34m(self, train_dataset, val_dataset, epochs, callbacks_list)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_dataset, val_dataset, epochs, callbacks_list):\n\u001b[0;32m---> 72\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with the custom callback\n",
    "history = model_builder.train_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    epochs=800,\n",
    "    callbacks_list=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the losses from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "train_loss_x_midpoints = history.history.get('x_midpoints_reshape_loss', train_loss)\n",
    "val_loss_x_midpoints = history.history.get('val_x_midpoints_reshape_loss', val_loss)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2,1)\n",
    "plt.plot(train_loss_x_midpoints, label='Train Loss x_midpoints_reshape')\n",
    "plt.plot(val_loss_x_midpoints, label='Validation Loss x_midpoints_reshape')\n",
    "plt.xlabel('Epochs')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder.model.save(\"/home/da886/Analysis/13originalmodelgeneralizedindex6.keras\")\n",
    "# loaded_model = tf.keras.models.load_model(\n",
    "# \"/home/da886/Final Electron counting project/Trained weights/Fixed weights/13overfitoriginalmodelgeneralized.keras\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, batch shape: (800, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728066487.757032  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.758002  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.758345  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.758668  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.758847  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.759019  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.759565  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.759706  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.759970  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.760222  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.760471  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.760530  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.760675  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.761331  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.761605  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.761983  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.762138  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.762208  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.762647  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.762768  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.762968  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.763352  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.763509  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.763655  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.763875  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.764346  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.764447  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.764577  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.765359  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.765374  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.765402  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.766211  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.766212  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.766245  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.767103  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.767120  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.767247  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.767958  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.767958  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.768087  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.768741  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.768791  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.769148  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.769572  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.769603  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.769748  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.770472  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.770507  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.770654  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.771312  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.771370  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.771801  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.772189  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.772916  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.772932  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.773446  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.773758  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.774453  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.774928  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.775749  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.788035  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.788457  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.788755  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.789067  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.789366  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.789655  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.789951  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.790270  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.790567  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.790881  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.791188  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.791509  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.791686  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.791818  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.792235  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.792370  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.792647  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.792906  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.792943  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.793141  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.793760  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.793835  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.793855  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.794462  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.794535  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.794557  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.795243  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.795317  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.795341  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.796048  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.796129  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.796156  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.796817  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.796890  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.796918  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.797598  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.797667  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.797695  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.798492  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.798512  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.798533  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.799195  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.799236  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.799486  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.799946  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.799980  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.800394  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.800694  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.800787  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.801131  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.801499  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.801590  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.801768  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.802193  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.802206  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.802900  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.802930  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.803565  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.803586  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.804253  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.804274  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.805081  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.805154  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.805772  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.805806  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.806447  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.806465  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.807691  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.808376  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.808384  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.808857  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.809281  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.809550  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.809823  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.810555  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.810575  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.811014  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.811433  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.817234  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.817562  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.817833  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.818101  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.818366  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.818644  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.818905  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.819149  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.819404  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.819671  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.819930  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.820180  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.820653  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.821122  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.821509  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.821927  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.822389  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.822850  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.823348  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.827027  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.827354  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.827629  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.827894  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.828152  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.828225  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.828493  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.828923  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.829013  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.829284  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.829776  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.829783  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.829894  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.830427  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.830522  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.830529  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.831067  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.831239  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.831313  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.831524  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.831987  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.832009  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.832151  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.832699  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.832725  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.832831  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.833471  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.833485  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.833555  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.834015  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.834148  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.834247  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.834416  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.834764  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.834910  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.834957  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.835299  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.835410  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.835957  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.835963  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.836056  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.836431  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.836782  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.836926  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.836993  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.837480  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.837724  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.837759  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.838264  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.838341  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.838548  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.838711  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.839066  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.839365  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.839502  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.840240  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.840278  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.840694  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.840892  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.841383  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.841600  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.844510  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.844769  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.845029  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.845291  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.845560  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.845831  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.846109  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.846402  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.846668  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.846937  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.847220  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.847504  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.848028  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.848037  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.848052  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.848639  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.848676  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.848771  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.849305  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.849347  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.849446  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.849988  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.850030  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.850114  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.850672  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.850709  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.850800  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.851286  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.851331  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.851417  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.851978  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.852018  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.852107  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.852661  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.852700  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.852791  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.853200  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.853478  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.853513  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.853673  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.854024  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.854294  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.854314  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.854614  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.854759  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.855189  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.855305  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.855350  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.855848  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.855883  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.856519  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.856539  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.857057  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.857076  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.857557  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.857661  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.858073  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.858174  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.858622  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.858721  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.859163  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.859278  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.859765  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.859869  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.860362  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.860471  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.861120  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.861156  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.861732  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.862261  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.862413  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.862711  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.863021  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.863336  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.863734  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.863814  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.864169  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.864362  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.864539  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.864984  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.865070  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.865303  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.865587  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.865953  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.866039  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.866869  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.867453  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.867834  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.868199  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.868492  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.868815  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.868937  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.869366  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.869477  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.869698  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.870141  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.870274  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.870474  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.870791  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.871182  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.871285  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.871568  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.872112  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.872124  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.872957  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.873537  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.874741  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.875331  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.876010  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.876746  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.877457  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.881585  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.881958  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.882267  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.882578  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.882883  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.883212  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.883514  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.883832  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.884157  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.884400  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.884593  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.884814  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.885007  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.885215  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.885414  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.885588  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.885877  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.886299  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.886380  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.886676  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.887030  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.887130  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.887367  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.887685  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.888086  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.888170  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.888480  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.888784  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.889114  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.889678  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.889898  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.890040  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.890144  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.890489  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.890594  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.890923  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.891076  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.891473  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.891552  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.891665  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.891877  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.892483  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.892502  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.892525  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.892803  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.893102  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.893735  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.893768  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.893799  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.894126  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.894657  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.894667  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.894976  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.895279  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.895610  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.896220  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.896566  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.896934  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.897330  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.897811  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.898363  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.899134  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.899743  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.901598  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.901987  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.902322  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.902631  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.902949  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.903286  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.903595  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.903915  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.904243  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.904547  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.904881  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.905234  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.906004  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.906434  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.906943  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.907036  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.907295  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.907601  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.908043  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.908155  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.908406  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.908714  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.909311  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.909322  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.909653  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.909959  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.910298  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.910769  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.910875  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.911561  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.911804  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.912485  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.913749  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.913761  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.914855  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.914852  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.915202  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.915525  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.915847  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.916581  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.916603  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.917013  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.917578  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.917710  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.917997  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.918350  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.918695  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.919033  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.919610  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.919629  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.920033  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.920442  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.920851  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.921281  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.921709  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.922422  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.923174  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.924405  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.925189  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.932526  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.932961  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.933379  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.933877  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.934312  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.934809  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.935289  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.935771  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.936234  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.936747  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.937152  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.937370  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.937583  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.937991  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.938076  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.938547  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.938623  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.938886  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.939141  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.939314  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.939780  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.939853  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.940133  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.940468  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.940575  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.941000  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.941112  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.941374  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.941858  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.941936  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.942334  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.942513  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.943083  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.943200  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.943790  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.943810  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.944196  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.944500  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.944516  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.944969  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.945084  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.945328  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.945751  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.945852  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.946243  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.946605  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.946732  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.946841  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.947206  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.947850  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.947892  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.948187  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.948313  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.948678  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.949199  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.949315  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.949637  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.950074  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.950302  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.950518  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.950964  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.951425  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.952147  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.953004  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.954235  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.955191  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.957270  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.957782  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.957916  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.958388  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.958480  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.958960  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.959040  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.959562  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.959637  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.959965  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.960164  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.960411  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.960752  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.960928  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.961387  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.961465  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.961963  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.962034  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.962409  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.962580  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.962854  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.962857  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.963314  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.963614  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.963662  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.963860  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.964090  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.964489  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.965127  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.965142  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.965699  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.965804  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.966126  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.966498  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.967063  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.967078  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.967479  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.968069  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.968173  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.968629  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.968734  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.969934  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.970491  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.970570  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.971596  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.972006  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.972862  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.973194  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.974796  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.974951  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.975125  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.976444  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.976557  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.977375  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.979212  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.980714  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066487.981830  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.022746  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.023165  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.023558  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.023945  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.024347  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.024749  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.025163  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.025566  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.025992  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.026430  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.027110  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.027119  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.027813  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.027823  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.028502  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.028516  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.029030  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.029147  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.029466  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.029855  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.029975  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.030640  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.030656  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.031065  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.031302  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.031543  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.032259  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.032274  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.032722  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.033172  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.033644  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.033905  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.034210  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.034766  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.035340  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.036147  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.036246  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.036822  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.037934  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.038435  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.040565  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.042498  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.047833  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.048411  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.048908  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.049395  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.049994  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.050481  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.051018  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.051565  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.052055  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.052210  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.052750  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.052883  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.053611  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.053628  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.054380  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.054399  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.054998  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.055486  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.056017  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.056562  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.056879  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.057072  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.057614  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.058170  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.058715  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.059506  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.061159  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.062072  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.063758  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.064088  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.064378  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.064609  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.065088  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.065561  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.066057  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.066307  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.066603  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.066804  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.067113  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.067617  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.068158  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.068642  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.068814  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.069304  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.069478  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.070078  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.070671  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.071048  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.071481  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.072232  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.073042  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.073494  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.073954  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.074360  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.074921  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.078455  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.082990  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.085209  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.094771  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.095446  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.096124  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.096854  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.097583  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.098452  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.099326  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.103396  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.106711  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.111168  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.115473  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.119615  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.123821  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.132454  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.165183  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.165892  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.166584  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.167290  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.168015  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.168829  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.168984  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.169705  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.169881  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.170823  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.170841  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.171878  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.171903  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.172944  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.172968  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.173747  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.173925  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.174647  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.174816  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.175580  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.175749  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.176380  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.176794  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.177207  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.177988  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.178155  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.179273  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.179298  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.180147  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.180460  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.181185  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.181715  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.182209  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.183055  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.184155  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.184273  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.185240  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.187647  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.188183  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.191536  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.201762  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.202572  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.203302  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.204023  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.204747  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.205228  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.205685  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.206041  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.206770  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.206882  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.207601  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.208316  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.209253  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.210184  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.211390  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.214753  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.216418  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.219768  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.221388  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.224701  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.225713  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.228980  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.230271  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.233501  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.234917  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.238093  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.244422  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.247582  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.296386  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.297050  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.297705  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.298365  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.299035  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.299802  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.300488  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.301201  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.301992  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.302716  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.303430  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.304181  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.305071  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.305970  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.306901  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.308118  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.309365  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.310629  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.312146  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.313752  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.317943  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.331418  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.331833  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.332216  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.332646  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.333074  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.333549  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.334025  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.335301  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.336600  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.337906  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.340183  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.341854  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.344120  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.346009  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.385694  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.386084  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.386487  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.386879  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.387265  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.387649  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.388048  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.388447  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.388841  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.389218  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.389602  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.390009  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.390421  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.390828  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.391300  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.391791  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.392341  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.392847  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.393377  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.394027  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.394633  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.396328  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.397977  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.406364  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.406746  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.407087  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.407434  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.407773  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.408118  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.408464  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.408848  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.409267  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.410588  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.411892  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.413217  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.415880  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.417407  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.421153  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.424327  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.425842  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.426597  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.427337  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.427693  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.428076  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.428474  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.428855  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.429224  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.429732  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.429961  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.430704  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.430821  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.431642  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.431752  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.432638  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.432718  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.433790  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.433798  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.434856  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.434878  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.435961  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.435972  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.436927  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.437027  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.437805  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.438019  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.438839  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.439074  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.439239  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.439451  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.439995  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.440012  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.440442  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.440614  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.440806  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.441291  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.441312  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.441659  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.442090  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.442157  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.442779  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.442800  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.443446  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.443722  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.443880  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.444189  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.444355  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.444773  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.445472  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.445555  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.445772  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.446064  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.446651  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.447731  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.447746  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.447777  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.448497  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.449216  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.449617  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.450209  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.452852  318934 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.461264  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.461712  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.462104  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.462541  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.462975  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.463096  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.463732  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.463765  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.464443  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.464445  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.464908  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.465341  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.466063  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.466076  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.466569  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.467594  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.467903  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.469397  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.469521  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.470901  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.471207  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.472754  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.473533  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.475613  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.475628  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.477292  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.477504  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.479151  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.523214  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.523609  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.523990  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.524381  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.524961  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.525083  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.525493  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.525609  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.526171  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.526186  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.526854  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.526876  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.527541  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.527558  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.528205  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.528227  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.528895  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.528916  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.529585  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.529601  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.530256  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.530272  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.530949  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.530961  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.531647  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.531659  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.532269  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.532373  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.532739  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.532969  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.533218  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.533643  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.533751  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.534487  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.534503  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.535202  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.535315  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.535758  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.536057  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.536340  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.536991  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.537845  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.537960  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.539827  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.539845  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.541506  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.548218  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.548614  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.548956  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.549297  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.549643  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.549995  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.550004  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.550636  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.550662  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.551200  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.551317  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.551600  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.551932  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.552043  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.552396  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.552748  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.553250  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.553354  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.553710  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.554652  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.555019  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.555988  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.556320  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.557635  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.558682  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.560373  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.560475  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.562020  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.564142  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.565771  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.567343  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.568937  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.582018  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.582380  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.582700  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.583092  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.583709  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.583715  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.584330  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.584350  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.584951  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.584963  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.585504  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.585642  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.586018  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.586145  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728066488.586610  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.586722  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.587095  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.587204  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.587588  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.587693  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.588088  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.588207  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.589002  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.589018  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.589406  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.589613  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.589863  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.590482  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.590493  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.591184  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.591278  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.591769  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.592016  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.592384  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.592751  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.593130  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.593855  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.593962  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.594682  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.595670  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.596532  318882 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728066488.598318  318878 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 3, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 4, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 5, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 6, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 7, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 8, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 9, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 10, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 11, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 12, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 13, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 14, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 15, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 16, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 17, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 18, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 19, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 20, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 21, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 22, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 23, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 24, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 25, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 26, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 27, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 28, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 29, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 30, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 31, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 32, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 33, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 34, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 35, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 36, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 37, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 38, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 39, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 40, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 41, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 42, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 43, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 44, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 45, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 46, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 47, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 48, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 49, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Processing batch 50, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the function for visualizing midpoints\n",
    "def visualize_midpoints(image, midpoints, title=\"Predicted Midpoint Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualizes midpoints on an image without using a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "    - title: The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    midpoints_np = midpoints\n",
    "\n",
    "    # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot midpoints directly, only if they are not (0, 0)\n",
    "    for i, (x, y) in enumerate(midpoints_np):\n",
    "        if x >= 3 and y >= 3:  # Only plot if the point is not (0, 0)\n",
    "            plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create the validation dataset\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n",
    "# val_dataset = val_dataset.batch(800)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)\n",
    "# # Initialize lists to collect the data\n",
    "all_images = []\n",
    "all_true_midpoints = []\n",
    "all_pred_midpoints = []\n",
    "\n",
    "# # Loop through each batch in the validation dataset, predict, and collect results\n",
    "# for i, (data_batch, midpoints_batch) in enumerate(val_dataset):\n",
    "\n",
    "for i, (data_batch, midpoints_batch) in enumerate(train_dataset):\n",
    "    print(f\"Processing batch {i + 1}, batch shape: {data_batch.shape}\")\n",
    "    \n",
    "    # Get the model predictions\n",
    "    predictions = model_builder.model.predict(data_batch)\n",
    "\n",
    "    # Extend the lists to store data from each batch\n",
    "    all_images.extend(data_batch.numpy())  # Store all images\n",
    "    all_true_midpoints.extend(midpoints_batch.numpy())  # Store all true midpoints\n",
    "    all_pred_midpoints.extend(predictions)  # Store all predicted midpoints\n",
    "\n",
    "# Convert lists to arrays for easier indexing\n",
    "all_images = np.array(all_images)\n",
    "all_true_midpoints = np.array(all_true_midpoints)\n",
    "all_pred_midpoints = np.array(all_pred_midpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    }
   ],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 64, 64), (40000, 1, 13, 2), (40000, 1, 13, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape,all_pred_midpoints.shape,all_true_midpoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select an index to visualize from the entire dataset\n",
    "index_to_visualize = np.random.randint(0, len(all_images))\n",
    "\n",
    "# index_to_visualize = 11548\n",
    "# Visualize the selected image with predicted and true midpoints\n",
    "visualize_midpoints(all_images[index_to_visualize], all_pred_midpoints[index_to_visualize, 0, :, :] * 64, title=\"Predicted Midpoints\")\n",
    "visualize_midpoints(all_images[index_to_visualize], all_true_midpoints[index_to_visualize, 0, :, :] * 64, title=\"Ground Truth Midpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727987790.870206 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.871400 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.872067 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.872712 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.873559 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.874510 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.875561 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.876804 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.877854 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.879073 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.880299 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.881769 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.883039 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.884296 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.885748 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.887023 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.888511 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.890158 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.892064 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.894231 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.896168 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.898290 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.901208 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.901814 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.902518 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.903972 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.905381 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.906860 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.908515 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.912093 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.916212 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.918848 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.930667 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.931202 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.931689 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.932237 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.932814 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.933316 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.933853 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.936608 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.939334 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.940827 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.943196 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.945838 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.948405 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.952766 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.001814 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.002470 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.003129 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.003868 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.004613 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.005381 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.006176 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.006979 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.007795 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.008622 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.009669 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.010496 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.011393 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.012164 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.012925 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.013733 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.015239 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.016582 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.017393 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.018348 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.019543 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.021131 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.029539 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.030168 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.030753 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.031421 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.032017 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.032668 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.033255 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.033927 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.034556 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.035442 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.036230 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.037101 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.039795 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.042402 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.047626 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.052807 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.056236 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.058672 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.062151 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.159653 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.160319 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.161007 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.161684 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.162386 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.163074 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.163768 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.164530 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.165324 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.166154 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.167019 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.167917 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.168873 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.169954 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.171134 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.172412 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.174841 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.175977 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.177298 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.179624 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.181227 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.183236 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.186109 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.195168 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.196054 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.196914 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.197960 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.198982 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.199915 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.200798 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.201625 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.202592 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.204037 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.205301 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.206732 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.211842 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.216787 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.220731 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.230886 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.237332 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.247366 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.253884 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.447912 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.448869 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.449817 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.450789 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.451791 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.452831 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.453862 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.454933 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.456127 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.457385 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.458634 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.459923 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.461312 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.462947 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.464687 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.468648 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.470465 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.472443 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.474602 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.477068 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.480830 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.492597 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.493966 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.495314 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.496805 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.498100 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.499739 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.501069 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.502694 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.504159 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.505472 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.506960 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.508507 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.516300 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.523327 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.533305 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.543030 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.553792 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.564742 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.584985 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.973086 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.974584 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.976170 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.977667 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.979244 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.980896 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.982651 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.984344 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.986346 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.988693 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.990761 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.992879 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.995022 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.997869 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.000960 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.004175 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.011326 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.014895 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.019317 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.023306 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.030581 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.047279 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.049626 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.052061 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.054707 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.057049 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.059957 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.062262 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.065252 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.067488 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.069765 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.072401 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.075139 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.088106 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.103944 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.124083 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.143285 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.164453 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.185967 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.226324 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.000868 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.003409 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.005944 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.008463 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.011177 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.013992 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.017039 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.019856 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.023268 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.026269 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.029924 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.033604 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.037661 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.042994 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.048508 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.054024 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.067084 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.073985 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.081928 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.095369 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.099564 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.103798 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.109320 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.113690 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.117950 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.122896 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.127108 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.133086 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.137469 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.142654 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.148069 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.173793 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.205537 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.244497 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.282103 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.321445 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.364379 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.454275 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987794.997166 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.001658 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.006203 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.010756 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.015630 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.020796 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.026629 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.032004 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.038583 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.044474 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.051733 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.059066 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.066953 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.077911 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.088652 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.099662 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.124653 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.137768 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.153249 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.173911 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.182201 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.190322 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.198402 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.209276 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.217618 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.227357 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.235358 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.246541 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.254558 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.264109 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.274345 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.320817 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.381165 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.458291 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.532474 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.610161 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.713147 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.877972 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987798.956832 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987798.964830 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987798.972755 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987798.981115 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987798.990432 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.000054 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.010438 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.020328 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.031321 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.042182 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.055467 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.068825 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.083444 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.102657 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.123169 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.142135 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.186985 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.211683 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.240566 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.274301 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.280377 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.282585 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.284767 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.287019 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.289888 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.292548 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.294686 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.297628 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.299887 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.302461 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.305093 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.320907 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.340637 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.359465 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.378404 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.397897 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.437902 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.477626 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.187021 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.189272 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.191443 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.193713 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.196166 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.198622 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.201237 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.203627 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.206317 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.209010 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.212212 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.215390 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.218973 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.223595 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.229009 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.233744 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.277414 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.289645 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.295827 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.303001 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.322073 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.323274 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.324426 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.325470 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.326389 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.333843 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.341211 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.347170 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.355304 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.362810 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.369973 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.380867 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.468016 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.468944 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.469869 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.470806 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.471753 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.472704 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.473667 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.474691 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.475678 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.476783 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.477893 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.479190 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.480645 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.482158 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.483682 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.485276 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.487351 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.493692 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.495931 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 31ms/step - loss: 0.0114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01135531347244978"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbAAAAHDCAYAAABF+E9FAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAABT+UlEQVR4nO3deVxUVf8H8M+wI8ggqCAqiLngvi887oahZWaipWaiLZa5pvaoT7llSWaWuVbWzyU1S3u0rNTM1MxQk7Q090JxA9NkcGM/vz98mBiZixw415mLn/frNa/izJ1zz7n3zny9937vOSYhhAAREZHBuDi6AURERMXBAEZERIbEAEZERIbEAEZERIbEAEZERIbEAEZERIbEAEZERIbEAEZERIbEAEZERIbEAEa6mzp1Kkwmk9Syly5d0rlVRGR0DGCKLF26FCaTCfv27XN0UwxhxowZWL9+vfJ6Bw0aBF9fX+X1ltQ333yDqVOnFnn5jh07wmQyoWbNmnbf37JlC0wmE0wmE9auXWvz3sGDB9G7d2+EhYXBy8sLlStXRpcuXTBv3jyb5apVq2at4/ZX165dpfsIwPr5Z555xu77L7/8snWZ2/+RsmHDBnTo0AEVK1ZEmTJlUL16dTz22GPYtGmTdZlTp05pttlkMuGNN94oVrsB4MiRI+jatSt8fX0REBCAJ598En/99VeRP//ll1+iadOm8PLyQmhoKKZMmYLs7OwCy6WmpmLIkCGoUKECfHx80KlTJ/zyyy/FrvPChQuYMGECOnXqhLJly8JkMmH79u1SfTcqN0c3gEq/V155BRMmTLApmzFjBnr37o2ePXs6plF32TfffIMFCxZIBTEvLy+cPHkSe/fuRcuWLW3eW7lyJby8vJCenm5T/tNPP6FTp04IDQ3Fs88+i+DgYJw5cwa7d+/Gu+++ixEjRtgs37hxY4wdO7bAukNCQoreOTvt/vzzz7Fw4UJ4eHjYvPfJJ5/Ybfdbb72Fl156CR06dMDEiRNRpkwZnDx5Et999x1Wr15dIKD269cPDz74YIF1N2nSpFhtPnv2LNq3bw+z2YwZM2bg2rVreOutt3Dw4EHs3bu3QD9ut3HjRvTs2RMdO3bEvHnzcPDgQbz22mu4ePEiFi1aZF0uNzcXDz30EH799Ve89NJLKF++PBYuXIiOHTsiISHB5h8sRa3z2LFjmDlzJmrWrIkGDRogPj6+WNvAkAQpsWTJEgFA/Pzzz45uiiH4+PiI2NjYAuVTpkwRAMRff/1VrHpjY2OFj49PCVun3rBhw4TM161Dhw6iXr16onbt2mL06NE27928eVP4+fmJmJgYAUCsWbPG+t6DDz4oKlSoIK5cuVKgzpSUFJu/w8LCxEMPPSTXkTsAIHr27ClcXFzE+vXrbd7btWuXAGBtd94+zsrKEn5+fqJLly5268zf7sTERAFAzJo1S2m7hw4dKry9vcXp06etZVu2bBEAxPvvv3/Hz9etW1c0atRIZGVlWctefvllYTKZxJEjR6xln376aYF9dvHiReHv7y/69etXrDrT0tLE5cuXhRBCrFmzRgAQ27ZtK3rnDYyXEHWUdzkrKSkJ3bt3h6+vLypXrowFCxYAuHWpp3PnzvDx8UFYWBhWrVpl8/m///4b48aNQ4MGDeDr6ws/Pz9069YNv/76a4F1nT59Gj169ICPjw8qVqyIF198EZs3b7Z7OWHPnj3o2rUrzGYzypQpgw4dOmDXrl2F9kUIgfLly2PMmDHWstzcXPj7+8PV1RWpqanW8pkzZ8LNzQ3Xrl0DUPAemMlkwvXr17Fs2TLrpZ9BgwbZrC81NRWDBg2Cv78/zGYzBg8ejBs3bhTaRhlF2QanT5/GCy+8gNq1a8Pb2xuBgYHo06cPTp06ZbNcVlYWpk2bhpo1a8LLywuBgYFo27YttmzZAuDWcZC3z/Nf7iqKfv364dNPP0Vubq61bMOGDbhx4wYee+yxAsv/8ccfqFevHvz9/Qu8V7FixSKts6QqV66M9u3bFzieV65ciQYNGqB+/fo25ZcuXUJaWhratGljt77itttiseDo0aOwWCx3XPbzzz9H9+7dERoaai2LiopCrVq18NlnnxX62cOHD+Pw4cMYMmQI3Nz+uaj1wgsvQAhhc4l37dq1CAoKQq9evaxlFSpUwGOPPYYvvvgCGRkZ0nWWLVsWAQEBd+xjacQAprOcnBx069YNVatWxZtvvolq1aph+PDhWLp0Kbp27YrmzZtj5syZKFu2LAYOHIjExETrZ//880+sX78e3bt3x9tvv42XXnoJBw8eRIcOHXD+/HnrctevX0fnzp3x3XffYeTIkXj55Zfx008/Yfz48QXa8/3336N9+/ZIS0vDlClTMGPGDKSmpqJz587Yu3evZj9MJhPatGmDH374wVr222+/WX8c8v/479y5E02aNNG8F/Xxxx/D09MT7dq1w8cff4yPP/4Yzz33nM0yjz32GK5evYq4uDg89thjWLp0KaZNm3aHrV00Rd0GP//8M3766Sf07dsXc+fOxfPPP4+tW7eiY8eONsF06tSpmDZtGjp16oT58+fj5ZdfRmhoqPW+xnPPPYcuXbpY+573Kor+/fvjwoULNv8IWbVqFe6//367P+xhYWFISEjAoUOHilR/VlYWLl26VOB18+bNIn2+sHZv2LDB+o+Y7OxsrFmzBv379y+wbMWKFeHt7Y0NGzbg77//LlL9N27csNvu/PeH1q1bhzp16mDdunWF1nXu3DlcvHgRzZs3L/Bey5YtsX///kI/n/f+7Z8PCQlBlSpVbD6/f/9+NG3aFC4utj+9LVu2xI0bN3D8+HHpOu9pDj4DLDXsXUKMjY0VAMSMGTOsZVeuXBHe3t7CZDKJ1atXW8uPHj0qAIgpU6ZYy9LT00VOTo7NehITE4Wnp6d49dVXrWWzZ88WAGwu2dy8eVNERETYXE7Izc0VNWvWFNHR0SI3N9e67I0bN0R4eLjmJZw8s2bNEq6uriItLU0IIcTcuXNFWFiYaNmypRg/frwQQoicnBzh7+8vXnzxRevn8i4L5nenS4hPPfWUTfmjjz4qAgMDC22fEHe+hCizDW7cuFHg8/Hx8QKAWL58ubWsUaNGd7wUV9xLiEII0bx5c/H0008LIW4dPx4eHmLZsmVi27ZtBS5Hffvtt8LV1VW4urqKyMhI8e9//1ts3rxZZGZmFlhHWFiYAGD3FRcXV+S25gdADBs2TPz999/Cw8NDfPzxx0IIIb7++mthMpnEqVOn7F4mnjx5sgAgfHx8RLdu3cTrr78uEhISCtSfdwlR6xUfH29dNu87uWTJkkLb/PPPPxfYp3leeuklAUCkp6drfn7WrFkCgEhKSirwXosWLUTr1q2tf/v4+BQ4toW4tX0AiE2bNknXmR8vIZJy+TOy/P39Ubt2bfj4+NhcAqpduzb8/f3x559/Wss8PT2t/1LLycnB5cuX4evri9q1a9tkLW3atAmVK1dGjx49rGVeXl549tlnbdpx4MABnDhxAv3798fly5et/2q9fv067r//fvzwww82l6pu165dO+Tk5OCnn34CcOtMq127dmjXrh127twJADh06BBSU1PRrl274mwqq+eff77Aui9fvoy0tLQS1SuzDby9va2fy8rKwuXLl1GjRg34+/vbbH9/f3/8/vvvOHHiRInapqV///7473//i8zMTKxduxaurq549NFH7S7bpUsXxMfHo0ePHvj111/x5ptvIjo6GpUrV8aXX35ZYPlWrVphy5YtBV79+vUrUZvLlSuHrl274pNPPgFw66zxX//6F8LCwuwuP23aNKxatQpNmjTB5s2b8fLLL6NZs2Zo2rQpjhw5UmD5IUOG2G133bp1rcsMGjQIQogCl6dvl3e26enpWeA9Ly8vm2WK8/n8n71582aR1iNT572MWYg68/LyQoUKFWzKzGYzqlSpUuA+iNlsxpUrV6x/5+bm4t1338XChQuRmJiInJwc63uBgYHW/z99+jTuu+++AvXVqFHD5u+8H9jY2FjN9losFpQrV87ue02bNkWZMmWwc+dOREdHY+fOnZg2bRqCg4Mxb948pKenWwNZ27ZtNddRFPnvRQCwtunKlSvw8/Mrdr0y2+DmzZuIi4vDkiVLcO7cOYh8k5fnv6/y6quv4pFHHkGtWrVQv359dO3aFU8++SQaNmxY7Hbm17dvX4wbNw4bN27EypUr0b17d5QtW1Zz+RYtWlgD3q+//op169bhnXfeQe/evXHgwAGbH/ny5csjKipKSTtv179/fzz55JNISkrC+vXr8eabbxa6fL9+/dCvXz+kpaVhz549WLp0KVatWoWHH34Yhw4dsv7IA0DNmjWVtTvvHyp595/yy8uWzP+PGdnP5/+st7d3kdYjU+e9jAFMZ66urlLl+X8kZ8yYgUmTJuGpp57C9OnTERAQABcXF4wePbrQMyUteZ+ZNWsWGjdubHeZwp6hcnd3R6tWrfDDDz/g5MmTSE5ORrt27RAUFISsrCzs2bMHO3fuRERERIGgLaso26c4ZLbBiBEjsGTJEowePRqRkZEwm80wmUzo27evzfZv3749/vjjD3zxxRf49ttv8eGHH+Kdd97Be++9p/k8lIxKlSqhY8eOmD17Nnbt2oXPP/+8SJ/z8PBAixYt0KJFC9SqVQuDBw/GmjVrMGXKlBK3qSh69OgBT09PxMbGIiMjw27SiT1+fn7o0qULunTpAnd3dyxbtgx79uxBhw4ddGlnpUqVANx6nup2Fy5cQEBAgN0zIXufr1q1aoHP538EolKlSprrAf55fEGmznsZA5gTW7t2LTp16oSPPvrIpjw1NRXly5e3/h0WFobDhw9DCGFzFnby5Embz913330Abv1AFPdfr+3atcPMmTPx3XffoXz58oiIiIDJZEK9evWwc+dO7Ny5E927d79jPUXNwlNNZhusXbsWsbGxmD17trUsPT3dJuMyT0BAAAYPHozBgwfj2rVraN++PaZOnWoNYCXtb//+/fHMM8/A39/f7vNPd5KXDGDvx1Mv3t7e6NmzJ1asWIFu3brZHLNF1bx5cyxbtkzXdleuXBkVKlSwOwjB3r17Nf+hkyfv/X379tkElvPnz+Ps2bMYMmSIzbI7d+5Ebm6uTSLHnj17UKZMGdSqVUu6znsZ74E5MVdX1wJnHGvWrMG5c+dsyqKjo3Hu3Dmbexzp6elYvHixzXLNmjXDfffdh7feesuaHZZfUUYdaNeuHTIyMjBnzhy0bdvW+sOcl1F4/vz5It3/8vHxsRsI9CazDext/3nz5tlcygWAy5cv2/zt6+uLGjVq2Fz+8fHxAYBi97l3796YMmWK3YeD89u2bZvds9RvvvkGwK17rbJk0tFvN27cOEyZMgWTJk3SXObGjRuaD99u3LgRgP7tjomJwVdffYUzZ85Yy7Zu3Yrjx4+jT58+1rKsrCwcPXrUJqDWq1cPERER+OCDD2yOjUWLFsFkMqF3797Wst69eyMlJQX//e9/rWWXLl3CmjVr8PDDD1vP9GTqvJfxDMyJde/eHa+++ioGDx6Mf/3rXzh48CBWrlyJ6tWr2yz33HPPYf78+ejXrx9GjRqFSpUqWUdqAP7517+Liws+/PBDdOvWDfXq1cPgwYNRuXJlnDt3Dtu2bYOfnx82bNhQaJsiIyPh5uaGY8eO2fwrsH379tbRAYoSwJo1a4bvvvsOb7/9NkJCQhAeHo5WrVpJbR8tWVlZeO211wqUBwQE4IUXXijyNujevTs+/vhjmM1m1K1bF/Hx8fjuu+9s7j8CQN26ddGxY0c0a9YMAQEB2LdvH9auXYvhw4fb9BcARo4ciejoaLi6uqJv375F7pPZbC7SKB4jRozAjRs38OijjyIiIgKZmZn46aef8Omnn6JatWoYPHiwzfLnzp3DihUrCtTj6+trHSVl3bp1GDx4MJYsWXLHhIjbNWrUCI0aNSp0mRs3buBf//oXWrduja5du6Jq1apITU3F+vXrsXPnTvTs2bPACBu//PKL3Xbfd999iIyMlG73f/7zH6xZswadOnXCqFGjcO3aNcyaNQsNGjSw2Wbnzp1DnTp1EBsbi6VLl1rLZ82ahR49euCBBx5A3759cejQIcyfPx/PPPMM6tSpY12ud+/eaN26NQYPHozDhw9bR+LIyckp8JhIUesEYD3ef//9dwC3Htf48ccfAdwaCafUclwCZOmilUZvL6U7f4p0frePjJCeni7Gjh0rKlWqJLy9vUWbNm1EfHy86NChg+jQoYPNZ//880/x0EMPCW9vb1GhQgUxduxY8fnnnwsAYvfu3TbL7t+/X/Tq1UsEBgYKT09PERYWJh577DGxdevWIvW1RYsWAoDYs2ePtezs2bMCgKhatWqB5e2l0R89elS0b99eeHt7CwDWlHqtkTjytm9iYmKhbct7dMHe67777pPaBleuXBGDBw8W5cuXF76+viI6OlocPXpUhIWF2TwC8Nprr4mWLVsKf39/4e3tLSIiIsTrr79uk7qenZ0tRowYISpUqCBMJtMdU+q1jpH87KXRb9y4UTz11FMiIiJC+Pr6Cg8PD1GjRg0xYsQIuyNxaG2rsLAw63JFTUcX4p80+sLcvo+zsrLE4sWLRc+ePUVYWJjw9PQUZcqUEU2aNBGzZs0SGRkZ1s/eKY0+/36RabcQQhw6dEg88MADokyZMsLf31888cQTIjk52WaZvPXbewRk3bp1onHjxsLT01NUqVJFvPLKK3YfX/j777/F008/LQIDA0WZMmVEhw4dNEfwKWqdhW2T0swkRAnvipPTmjNnDl588UWcPXsWlStXdnRziIiUYgArJW7evGmTWpueno4mTZogJyfH+nQ/EVFpwntgpUSvXr0QGhqKxo0bw2KxYMWKFTh69ChWrlzp6KYREemCAayUiI6OxocffoiVK1ciJycHdevWxerVq/H44487umlERLrgJUQiIjIkPgdGRESGxABGRESGpNs9sAULFmDWrFlITk5Go0aNMG/evCKN35Wbm4vz58+jbNmyDhtuiIiIHEMIgatXryIkJKTAvGn2FlZu9erVwsPDQ/zf//2f+P3338Wzzz4r/P39CzxIac+ZM2cKfSiPL7744ouv0v86c+bMHeOFLkkcrVq1QosWLTB//nwAt86qqlatihEjRmDChAmFftZisdidDl0lraguO8K71hmiqk2afyrx/PLPOlsUqvrrbPTe/s5I9pjQ2vda20h222nVr1Wu1c57cV9S4VJTU2E2mwtdRvklxMzMTCQkJGDixInWMhcXF0RFRdkdsDMjI8Nm0NOrV6+qblIBqi5N6v2l07udjvrRULVeo7df5bpVLa/VB9ljSFW5owKYqu3mbJxtOxemKPtAeRLHpUuXkJOTg6CgIJvyoKAgJCcnF1g+Li4OZrPZ+rp97hsiIiJ7HJ6FOHHiRFgsFusr/3QGREREWpRfQixfvjxcXV2RkpJiU56SkoLg4OACy3t6ehY62ykREZE9ygOYh4cHmjVrhq1bt1rnE8rNzcXWrVtt5ke6G2RvMGtdB9ZKdlCVBKF1rTcrK0tqeb3vIalKBlFVv97bXzbRQfa40lpvYf1SlQShtQ7Zez+3T+6pVX+ZMmWKNSOzoxj9/qqqelxdXe2Wa+33osjNzcWFCxekk9Hs0eU5sDFjxiA2NhbNmzdHy5YtMWfOHFy/fr3AZHpEVLqZTCYMHjwYDz/8MDw8PPhsJ0EIgUuXLmHs2LFFmgW+MLoEsMcffxx//fUXJk+ejOTkZDRu3BibNm0qkNhBRKXb4MGD0bdvX90fjSFjKVu2LIYOHYrp06eX6KzW6QbzTUtLu2Puf1FpXdKRPS3W+3kp2dN92eW1+it7eUnv58kc9byaqsstd+MSoqo0elWXEAvrm4+PD1asWMHJVMmuCxcuYODAgUhNTbX7vsVigZ+fX6F1ODwLkYhKp8DAQHh4eDi6GeSk3Nzc7hig7oQBjIh0YTKZeM+LNKk4Pkr1hJayl0n0HiVA61+jmZmZUvXIZsGVJGOoKGS3j7u7u91yraxLLarqUXUVXdWl18K+1KoyOFUNMaXVVjc3N+uwV/mXcbI7FmRwPAMjIiolPvjgA/Tv3/+urvP8+fNo0aIFjh07dlfXC5TyMzAiouK6dOkSli5dil27duHixYvw9fVFlSpV0K1bN3Tv3h1eXl6ObuIdTZ06FdeuXcNbb73llPWVFAMYEdFtzp49i2eeeQZly5bFCy+8gBo1asDd3R1//PEH1q1bhwoVKqBDhw4FPpedna05Y4AzM2q7eQmRiOg2M2fOhKurK5YvX44uXbogPDwcVapUQYcOHTBnzhy0b98eANCiRQusXbsWY8aMQbt27fB///d/AIC1a9eiZ8+eiIyMRExMDL755htr3fYuuV29ehUtWrRAQkICACAhIQEtWrTA3r17MXDgQLRt2xZPPfUUTp06ZdPOpUuXIjo6Gh06dMD06dNtZvb44IMP8PXXX2PHjh1o0aKFtf689X/77bcYMmQI2rRpg40bN9q9/Lhq1Sr06NGj0PrynDt3Ds8//zzatm2L/v3747ffflOwJwrHAEZETu/QlUP45uw3OHTlkO7rSk1NxZ49e9CnTx94e3vbXSZ/YsrixYvRsWNHfPLJJ+jRowe2bduG2bNn44knnsDq1avRq1cvvPrqq9i3b590WxYtWoRRo0Zh+fLlcHNzw/Tp063vbdmyBYsXL8YLL7yAZcuWoXz58vj888+t7w8YMABRUVGIjIzExo0bsXHjRjRs2ND6/oIFC9C3b1989tlniIyMvGNb7lTfokWLMGDAAKxcuRKhoaF45ZVXlAwXVRhDnTOqeshSKytP1QPFWmSzDbUU5wFYmXr0zmaUzRLUux69535StV8KW7fsOlQ9yKwlKyvLun+Ksr0K++7NOzIPy/9cbi0bWH0gRtQZoaSd9pw9exZCCISFhdmUR0VFWb/Dffr0wYgRt9oQHR1tPUsBgJdffhndu3dHnz59AABhYWE4dOgQVqxYgebNm0u1ZejQoWjWrBkAIDY2FqNHj0ZGRgY8PT2tAfORRx6xLrt3717rWViZMmXg6emJrKwsu+NQ9u3bF507dy5yW+5U34ABA9C2bVsAwJAhQ/D444/j7NmzqFatmlSfZfAMjIic1qErh2yCFwAs/3P5XTkTu93SpUuxcuVKVK9e3eYfo3Xq1LFZ7tSpU2jUqJFNWcOGDZGYmCi9zpo1a1r/Py9oXLlyxbqe+vXr2yzfoEGDItddt25d6fYUpkaNGtb/z2vr33//rXQdt2MAIyKnlXQ9SapchSpVqsBkMuH06dMFyqtWrVpg+iety4xa7F3h0LrUZi+xQtXQardnUdo7C5a56pK/rXl16f3cHwMYETmtUJ9QqXIV/P390apVK6xZswY3b96U/ny1atXw66+/2pT99ttvqF69urV+4Faafp7jx48Xaz2HDtmeid7+t7u7e5GDULly5XD58mWboHP7s10y9d0NDGBE5LTql6uPgdUH2pTFVo9F/XL1NT6hxvjx45GdnY2BAwfi22+/RWJiIk6dOoVvvvkGp06d0rxPDABPPvkkvvrqK6xduxZJSUlYuXIltm3bhgEDBgC4debToEEDLFu2DImJiUhISMCiRYuk29i3b19s2LABX375JU6fPo33338ff/75p80yISEhOHnyJE6dOoXU1NRCkyqaNWuGK1euYPny5Th79iw+++wzxMfHF7u+u8FQSRxEdO8ZUWcEOgV3QtL1JIT6hOoevIBblwtXrlyJJUuWYMGCBbh48SI8PDwQHh6OAQMGWBM07OnYsSPGjh2LFStWYPbs2QgJCcHkyZOtyRgAMGnSJEyfPh1PPvkkwsLCMHLkSOkJfx944AGcO3cO8+bNQ2ZmJjp16oSYmBiboNOzZ08kJCQgNjYWN27cwHvvvYdKlSrZrS88PBzjx4/HkiVL8NFHH6Fz584YMGAA1q1bV6z67gZDTaeiNS2ILK0H9vI/Q1EUsu2RPfXWe3oR2bEfZetx1KUGR82mq2p8QWdUnGMlLCwMCxcuNNRMzGRLz+/SpUuXMGzYsAL3GoUQyM3N5XQqRERUejGAERGRITGAERGRITGAERGRITGAERGRIRkqjV4r+042I0Z2edksO1XjyamaOVp2u8mO/agqK1JrhmWtZ01kM6QcldWpRSsbVtUYj4B2n7WoGlOxOHWR89E7UzYnJ6dE2co8AyMiIkNiACMiIkNiACMiIkNiACMicpCpU6di3Lhx1r+fe+45zJ49u0R1qqjDKAyVxEFEdDdMnToVX3/9NYBbyTbBwcF48MEHMXjwYM3kGxXefPPNItefkJCA559/Ht9//z3Kli1brDqMzlC9VJVdpio7Su+sNq16ZGdMVjVGn94ZSVrZd1pjTjrTtA6AfHtk9y8gn3mpajZoI43bqEpkZCQmT56MrKws7Nq1yxoYBg8ebLNcVlaWZgatlrztfPt/tcaBlaGiDqMwVAAjIrpbPDw8rAMR9+7dG9u3b8fOnTtx+vRpXLt2DXXr1sWaNWvg4eGBL774AsnJyXj33Xexe/duuLi4oHHjxhg7dixCQkIA3PoHzty5c/Hll1/C1dUVPXr0KPAPg+eeew61atXC2LFjAQCZmZl4//33sWnTJly5cgVBQUEYNGgQWrRogeeffx4A0LlzZwDAQw89hKlTpxaoIy0tDbNnz8bOnTuRmZmJpk2bYty4cQgNvTWn2oYNG/D2229jxowZePvtt5GSkoJGjRphypQp1v4nJCRg7ty5+PPPP+Hm5obq1avjtddec+hI9AADGBEZgM+hQ/BMSkJGaCiu19d/OhV7PD09YbFYAAA///wzfHx8MH/+fAC3nlUcOXIkGjRogMWLF8PV1RUfffQRRo4ciU8++QTu7u5YuXIlvvrqK0yaNAnVq1fHihUrsH37djRv3lxznVOmTMHBgwcxbtw41KxZE+fPn0dqaiqCgoIwc+ZMjB8/HmvXroWPj0+BGZbzTJs2DWfOnMHs2bPh4+ODefPmYfTo0fjss8+slxrT09OxYsUKTJs2DS4uLpg8eTLmzJmD1157DdnZ2Rg3bhx69uyJ119/HVlZWfj999+VPe9aEgxgROTUKs+bh0rLl1v/vjBwIM6NGHHX1i+EwN69e7F792489thjuHLlCry8vPDKK69YLx1+8803yM3NxSuvvGL9YZ8yZQo6deqEhIQEtG7dGp988gkGDRqEzp07w2QyYeLEidi9e7fmek+fPo3vvvsO8+fPR6tWrQDcmqcsT96lwoCAAJt7YPklJSXhhx9+wIcffohGjRoBAKZPn47u3btj+/btiIqKAnArAE+cONFaf58+ffDhhx8CAK5fv45r166hbdu21vfDw8OLtzEVYwAjIqflc+iQTfACgErLlyO1Uyfdz8R+/PFHtG/fHtnZ2cjNzUXXrl0xZMgQzJw5EzVq1LC573XixAmcPXsWHTp0sKkjMzMTZ8+exbVr13Dp0iXUq1fP+p6bmxvq1KmjeX/x+PHjcHV1tZkIU1ZiYiJcXV1RP9+28vf3R1hYGBITE61lXl5eNsGxfPnyuHLlCoBbgbJ79+4YOXIkWrZsiZYtW6JLly5OMc8bAxgROS3PpCTNcr0DWLNmzTBhwgS4u7ujfPnyNpl93t7eNsvevHkTERERmD59eoF6ypUrV6z1e3p6FutzxXF71qLJZLIJrFOmTEHfvn3x008/YcuWLXjvvfcwf/58NGjQ4K610R6nDWAmk6nANVZVWYVaGUNaWXCqxk5UNWajqmw3LVpZf7JjKuo9s7NsdqJsO1Vl3snWX9h6i5O5aI+qcSe1uLi4KJlBPeN/iQZFLVfJ29sbVatWLdKytWvXxpYtW1CuXDn4+vraXaZ8+fL4/fff0bRpUwghkJ2djSNHjiAiIsLuPq9RowZyc3ORkJBgvYSYX17QKez3IDw8HDk5OTh06JD1EmJqaipOnz6N6tWrF6lv+ftYu3ZtDB48GE899RQ2b95c4gDm4uJS4NgVQhT5u8cHmYnIaV2vXx8XBg60KbsQG+uwRA4t3bp1g7+/P8aNG4f9+/fj3LlzSEhIwFtvvYWUlBQAQN++fbFs2TJs374dp06dwsyZM3Ht2jXNOkNCQvDQQw9h+vTp2L59u7XOLVu2AAAqVaoEk8mEH3/8EVeuXMGNGzcK1BEaGooOHTrg9ddfx4EDB3D8+HFMnjwZFStWLHC5U8u5c+cwf/58/Pbbb7hw4QJ2796NpKQkVKtWTX5DKea0Z2BERABwbsQIpHbq5PAsxMJ4eXnh/fffx/z58/Hvf/8bN27cQIUKFdCiRQv4+PgAAJ544glcunQJU6dOhYuLCx5++GF07Nix0CA2YcIELFy4EDNnzoTFYkFwcDAGDRoEAKhYsSKGDBmC+fPn49VXX8WDDz6IqVOnFqhj8uTJmD17Nl588UVkZWWhSZMmmDNnTpEfdvby8sLp06cxfvx4WCwWlC9fHn369EGvXr2kt5NqJuFkTyimpaXBbDZLXUKUJXsJUYvsZRUn29SanO0SotZ6VT3g7GyXEAvbbqoe5pe9hCjLxcUFYWFhWLBggVPc7Cfnc+nSJbzwwgs4ffq0TXneJUSLxQI/P79C6+AlRCIiMiQGMCIiMiSnvQcmk4kiS+WMt85E1aUwrUtwqrI3ZS93yWYnynK2S7vFuYQoe3ld7+9ASWfaVY1jPDone7/zMvuEZ2BERGRIDGBERGRIDGBEpIvc3FxeoiNNKm4TMYARkS4uXLiAS5cuIT093dFNISeTk5MDi8WCv/76q0T1OG0SBxEZW3Z2NsaOHYuhQ4eiefPmcHNzc4opOMix8p7xev3113Hz5s0S1eW0DzLbo+qBUL0fUFW1vGxWnhbZ/qqawVm2fq0sx4yMDKn6Zen9wLWs4mQhatF7X2rJ3weTyQSz2XzHh1JVrzc/rX5pPQyvtd1KawazLNmxN/N/N4QQ+Ouvv+4YvIryIDPPwIhIV0IIpKamIjU1Vfd7Ygxgd0dJApjSduhSKxERkc4YwIiIyJAYwIiIyJCkA9gPP/yAhx9+GCEhITCZTFi/fr3N+0IITJ48GZUqVYK3tzeioqJw4sQJVe0lIiICUIwkjuvXr6NRo0Z46qmn7M4H8+abb2Lu3LlYtmwZwsPDMWnSJERHR+Pw4cPw8vIqUWNVzWisit7t0TvbUKt+rfJatWrZLT9+/LjdctkZtLWyDfXOpNN7v8gq7Aa5qtm49e6Dqu+eVpKFbP15x+iBSwdwKu0UqvlVQ+PyjTWPab3HcXRUdqiqcUhlxznVi3QA69atG7p162b3PSEE5syZg1deeQWPPPIIAGD58uUICgrC+vXr0bdv35K1loiomN7c/yYWH15s/fvZus86sDWkgtJwmZiYiOTkZERFRVnLzGYzWrVqhfj4eLufycjIQFpams2LnFfDmzfRw2JBwxI+gEh0Nx24dMAmeAHA4sOLISo71WOwJEnpc2DJyckAgKCgIJvyoKAg63u3i4uLw7Rp01Q2g3Qy5uJFPPv339a/54f74K1KnG2XnN+ptFP23wgEWp4VqAXgOIC9HCnEUByehThx4kRYLBbr68yZM45uEtnRUgib4AUAwxOvI6juaeTer89DikSqVPOrZrc87g9gN4DluPXfOOcamIjuQGkACw4OBgCkpKTYlKekpFjfu52npyf8/PxsXuR8amp8sWtdBtAGvBRDTq1x+cYF7nnNcO+JCddslxuPW/9YI2NQegkxPDwcwcHB2Lp1Kxo3bgzg1tiGe/bswdChQ1Wuyoaq4WNkM4CcLctRz/pPmEyAneWPB/6vrnIC4kwJp0aQzJDSm97tkR3GCNA/O06rTbLr1Xt2cNn11qxZ89b/VAYQCOAycPjcevvLAtgjtVZ1x4qjhtrSItserf7KZCfKTLMiHcCuXbuGkydPWv9OTEzEgQMHEBAQgNDQUIwePRqvvfYaatasaU2jDwkJQc+ePWVXRU5kr8mED8qVw5ArV6xlcW2AvVX+98dlx7SLSMq5/71w656XPVrl5HykA9i+ffvQqVMn699jxowBAMTGxmLp0qX497//jevXr2PIkCFITU1F27ZtsWnTphI/A0aO93bFiviubFkEBF/C/oY3/gleO2H9USAyir0A3gAwIV9Z3P/KyRgMNZ2KltJ6CdFRtLZPjRo1rP9/M/AmMstmwuOqB5J+SlKyXl5CLHy9gLrR0LW+M1rrdtQlRFnFWW9L4J8sxGKuV/ZYcdSxruoSsRbZwRHsybuEyOlUSDfel73hfdnb0c0gKrG94FmXUTk8jZ6IiKg4nPoM7PbTTlWX8lSdLmvNIJydnW23XO+ZfLVotVPrcpRWe/QelFlrvbKXfFVtT733i1b9d+PStNY69M5y1OJsl49lqcrW0yJ76U/rt0ZredkxDJ3ldgvPwIiIyJAYwIiIyJAYwIiIyJAYwIiIyJAYwIiIyJCcOguxqJkrqmY3lX0IUnZ5R82qKptZ5uZm/7CQza6UfZBcq52OyoyTpSqT7m5k3mntA0dlRsr22VEPSmvRe716P0iu6pi729mkPAMjIiJDYgAjIiJDYgAjIiJDYgAjIiJDYgAjIiJDcuosxKKSzfoz+uypsrOqytIaI1HvWXZl69c740nv+mWzW4tTlxZHZXaqOoZkjwlVmcGq2i87Pqls5q6jxpCUnT7GXr+EEJoZzwXqLXrTiIiInAcDGBERGRIDGBERGRIDGBERGRIDGBERGVKpyEKUnRlZK1NGNsNIq37ZDCNZsu2XzQxSNR6e3vXrTdUsu47cDqqy5mQzYh2VBaeqX1r7THZGY1Xjkxp9PFAtJf1N5BkYEREZEgMYEREZEgMYEREZEgMYEREZEgMYEREZklNnIRZ1TLjMzEypelWNcad3ppJshpfsGHp6z4Krd1ahUbIiHZWRB6jrg6PGG1VFtp2yWX96z7qt92zxqtzt/cszMCIiMiQGMCIiMiQGMCIiMiQGMCIiMiQGMCIiMiSnzkK8nd5ZYVqznqoaz0w2S1B2/Dlny8rTe7ZbR41VaCSO6pve21pVVp6z7WNV46g6KgtRi17HIc/AiIjIkBjAiIjIkBjAiIjIkAx1D4yIiqYlgFoATgqBvZL3XomMgmdgRKVMHIA9AD4GEC8EZjhZogKRKibhZNPgpqWlwWw2w83NrUAmjWwmjqenp93yjIwMu+V6Z+6oypzSyuhRlYGlank3N/sn+Kpmpi6ttDLRgDtvu5a4Fbxul/nDDxAtW1r/9vLysvt52UxZVd8N2VnVtdYrm0nsqO92aaUiczqvzGKxwM/Pr9D18RIiUSlSS6M88efN2FXmBGoG1ETLkJYaSxEZCwMYUSlyXKN84JHXsffqrf8f22rsXWsPkZ54D4yoFNkL4I3byuLaAHur/PP37D2zgcp3s1VE+mAAIyplJgJoBeBJABuWvoz/dLGzUODdbRORHhjAiEqhvQBWAPBvH21/gct3szVE+nDae2Ba2Uf2eHh42C3XyjbUWl52ZmfZjBvZcb9kxwCUzRKUrV+2HqNnG2pltGmNgakqy7Sw7Sa7jvbV2wNRANrmK9wJ4JzmKpSsV7YerT7LZtzqnW0oO6afo8ai1Pu3SYuqmbuLur+cNoARkSLfATiCW5cNL0M6eBE5KwYwonvBOTBwUanDe2BERGRIDGBERGRIUgEsLi4OLVq0QNmyZVGxYkX07NkTx44ds1kmPT0dw4YNQ2BgIHx9fRETE4OUlBSljSYiIpIaC7Fr167o27cvWrRogezsbPznP//BoUOHcPjwYfj4+AAAhg4diq+//hpLly6F2WzG8OHD4eLigl27dhVpHXljITqT0jxjrz2OGtdNK+tPi97ZmHqTzXIs7meMQPY75mz7Um96z8KuRdVvXHHaX5SxECFK4OLFiwKA2LFjhxBCiNTUVOHu7i7WrFljXebIkSMCgIiPjy9SnRaLRQBwqpeLi4vdl6PbpdfLZDLZfem9XldXV6mX7H5xVL9k+6v6M0Z4GX1f6v1S1V+t7az3b1xx2m+xWO4YL0p0D8xisQAAAgICAAAJCQnIyspCVFSUdZmIiAiEhoYiPj6+JKsiIiKyUew0+tzcXIwePRpt2rRB/fr1AQDJycnw8PCAv7+/zbJBQUFITk62W09GRobNA8dpaWnFbRIREd1Din0GNmzYMBw6dAirV68uUQPi4uJgNputr6pVq5aoPiIiujcUK4ANHz4cX331FbZt24YqVf4Z5jo4OBiZmZlITU21WT4lJQXBwcF265o4cSIsFov1debMmeI0iYiI7jFSlxCFEBgxYgTWrVuH7du3Izw83Ob9Zs2awd3dHVu3bkVMTAwA4NixY0hKSkJkZKTdOj09PTVnTr49c0XonGEkmykjmzXnbJlijsqu1Jp9V++xE2WPH70z3YpzPBj9GJKd8VmL1j7QewxA2WNC1XdM1TEnu91kqaqnqKQC2LBhw7Bq1Sp88cUXKFu2rPW+ltlshre3N8xmM55++mmMGTMGAQEB8PPzw4gRIxAZGYnWrVvr0gEiIro3ST0HphVdlyxZgkGDBgG49SDz2LFj8cknnyAjIwPR0dFYuHCh5iXE2+V/DsxZzsC0yD5TYfR/PaviqDMwWffas0bFoeoMTO8zJKOfganiqO2jpbDvUlGeA5MKYHcDA9jdwwBWOAawO2MAu4UBrPB6tJQ0gHEsRCIiMiQGMCIiMiSnng/s9tNLvcfxkr00pHVJULadqsiOk6e1vN7jn6ma0VhvpflSoapt7ahsOlWzjMvSe/uoomr7yP5G3O3vDM/AiIjIkBjAiIjIkBjAiIjIkBjAiIjIkBjAiIjIkJw6C/F2RpkBWVU7ZR/4lX1QWmt5rfVmZ2dL1S877pqbm/3DUau/Hh4edsszMzOL0Dr1VD2gXdjDoLJZXrIZsXo/kKsq+1H2gVwtqrIWZbePqtnHtaiayVrV4At6ZRjzDIyIiAyJAYyIiAyJAYyIiAyJAYyIiAyJAYyIiAzJUFmIqjJZZMcMdBSt7DVV2W5a202rHr3Hz5OtRysr0lH7V1W2YWGZg7J9kB2PUoveM/nK0nu8Ttl+ybZH72PRUftFi8zxI/M7wDMwIiIyJAYwIiIyJAYwIiIyJAYwIiIyJAYwIiIyJENlIaoiO96bVlabVtaZqiw4rXpkxyTUotVfre2jNVah1tiDes+aa5SxMbWoHH9O1SzgqsY8VEX2GPL29rZbnpGRYbdcq1/ONvajLL2zRmWzN/U6fngGRkREhsQARkREhsQARkREhsQARkREhsQARkREhmSoLERVmTuyGTGOGudM7/HeZNup99iDzpYBp7fiZA5qbQvZGXgdlR2nKjNVazzQmzdvSrVH9phTlX3nbNmJquqRrZ8zMhMR0T2JAYyIiAyJAYyIiAyJAYyIiAyJAYyIiAzJUFmIelOVkaQ1ZqBWVp7sDMWy45npnb2panw1vbMu9c7w0qL3mJDFWYdsPVpUfWdkqZr9WvaYk91nznYsypLdv7LjydrLbOaMzEREVOoxgBERkSExgBERkSExgBERkSExgBERkSExCzEfVeOWyWZIaY3rprVerRmQZWllBslmRWqVy46RKJvxJFu/1vbUWq/sWI6yGXZa2aqFHT9a69A6hmSPFdlsOlUzFOs93qWqrD/ZY1TvbENVWaBa7VQ1bixnZCYiIsqHAYyIiAyJAYyIiAyJAYyIiAyJAYyIiAypVGQh6p2JoyqTSGY8sOKsVzYrT9X2UZXFp/dM2VrtVzWDtuz20co2LCybUWsdWtmGHh4edsu1+qxV7mxj92ltU72zKLW+Y1oclV2pagxGreNHNrtVZiZrIUSR28kzMCIiMiQGMCIiMiQGMCIiMiQGMCIiMiSpALZo0SI0bNgQfn5+8PPzQ2RkJDZu3Gh9Pz09HcOGDUNgYCB8fX0RExODlJQU5Y0mIiIyCYm0lA0bNsDV1RU1a9aEEALLli3DrFmzsH//ftSrVw9Dhw7F119/jaVLl8JsNmP48OFwcXHBrl27itygtLQ0mM1muLi4FMhQkR3jTjYrTHaWUVVZfKrIttPZqBrbUIujtr/serXqAeTH3CusLpn6tWjVr7VvtPalqnEzZTOJtcaQlB3PVO/fFFWM9BthsVjg5+dX6DJSAcyegIAAzJo1C71790aFChWwatUq9O7dGwBw9OhR1KlTB/Hx8WjdunWR6mMAKz4jHZz2MIAVXg/AAHan9TKAFc5IvxFFCWDFvgeWk5OD1atX4/r164iMjERCQgKysrIQFRVlXSYiIgKhoaGIj48v7mqIiIjskn6Q+eDBg4iMjER6ejp8fX2xbt061K1bFwcOHICHhwf8/f1tlg8KCkJycrJmfRkZGcjIyLD+nZaWJtskIiK6B0mfgdWuXRsHDhzAnj17MHToUMTGxuLw4cPFbkBcXBzMZrP1VbVq1WLXRURE9w7pAObh4YEaNWqgWbNmiIuLQ6NGjfDuu+8iODgYmZmZSE1NtVk+JSUFwcHBmvVNnDgRFovF+jpz5ox0J4iI6N5T4rEQc3NzkZGRgWbNmsHd3R1bt25FTEwMAODYsWNISkpCZGSk5uc9PT3h6elpt96SUnXD0lHJGqpmf5Vtp+wNdS2yN9pV3UjWe3w4vWcVLs7YjKr2maPG+pNN1JH9TmrRStaQ/e7pPY6nKnr/lt3tBDapADZx4kR069YNoaGhuHr1KlatWoXt27dj8+bNMJvNePrppzFmzBgEBATAz88PI0aMQGRkZJEzEImIiIpKKoBdvHgRAwcOxIULF2A2m9GwYUNs3rwZXbp0AQC88847cHFxQUxMDDIyMhAdHY2FCxfq0nAiIrq3lfg5MNXyngOTITNUP6Du9N3ZLiGqei7KUZcQtai6JGjUyyRF4WyXEFV99xy1j430vJQKzvjd0PU5MCIiIkdiACMiIkMy1IzMjspq06L3JSOtyzmyWYhaZGdSlr084GyXW1T1V6vczc3+10lrOxQn21C2D7KXFmXbZC+DGIDN4AQl4WwZpUa/tFimTBm75Vr7S/Z4uNuX0XkGRkREhsQARkREhsQARkREhsQARkREhsQARkREhsQARkREhuTUafRFHVlC75E4HJU6m52dLbW83gOQqkqR1Xu0BNkUcdn2yD42oJXKXpztILvPZGc0lq1fK/3aUbOea1H1W2CUdHmt/t64cUPX9er96M/teAZGRESGxABGRESGxABGRESGxABGRESGxABGRESG5NRZiLdnqMhmG6rKOpPNeJKlKqNKNqPH3d3dbrlW9qNW/R4eHnbLMzMzperRIrt/ZcnOiyabhaiqncUhm32n6tiSzUaT/Q6oyqBVlY2p97xlqjJl9Xa3M7Z5BkZERIbEAEZERIbEAEZERIbEAEZERIbEAEZERIbktFmIJpOpQOaNbAaTqowqvTmqPVlZWUrq0co21Nr+WplKstl9elPVHkceh1qZplr7TItsH7SOLWf7TqrKMJZtv97LOyorUmu/y37ni4pnYEREZEgMYEREZEgMYEREZEgMYEREZEgMYEREZEhOm4UohChyhoqqmXxVjSum9+yyztZf2Qwm2bEBZbMZVY09KDvDstZ6VWbYyR5bstmGWlT1wVFj9+l9rMjSao8W2e2m9+zmsvVzLEQiIqJ8GMCIiMiQGMCIiMiQGMCIiMiQGMCIiMiQnDYL0R5Vs31qLa93/Y6aCdpRYwnKkt3+emeQyWYb3g2yx67es5Ubhd7fAdnt5qjvpKpjWu/M6aLiGRgRERkSAxgRERkSAxgRERkSAxgRERkSAxgRERmSobIQVZHNxJHNMFKVzWiUzC9V7VSVmaVqf6lyNzL7VG07oxxzpZWq2eVVjUOqxVmOE56BERGRITGAERGRITGAERGRITGAERGRITGAERGRIZXqLERVs7DKjvul9zhneo9npveMzKq4u7vbLc/KypKqR9VM2aoUtl6jz8btKM42S7oWrfU6auxEZ9+/PAMjIiJDYgAjIiJDYgAjIiJDKlEAe+ONN2AymTB69GhrWXp6OoYNG4bAwED4+voiJiYGKSkpJW0nERGRjWIHsJ9//hnvv/8+GjZsaFP+4osvYsOGDVizZg127NiB8+fPo1evXiVuKBERkQ1RDFevXhU1a9YUW7ZsER06dBCjRo0SQgiRmpoq3N3dxZo1a6zLHjlyRAAQ8fHxRarbYrEIAAKAMJlMNq+8cmd53d6+u9VOVet1tnqcbT/q3S9XV1e7r7uxbmc7FmW3kaPa4+LiYvflqO0mW4+q9araDoW9LBbLHeNFsc7Ahg0bhoceeghRUVE25QkJCcjKyrIpj4iIQGhoKOLj44uzKiIiIruknwNbvXo1fvnlF/z8888F3ktOToaHhwf8/f1tyoOCgpCcnGy3voyMDGRkZFj/TktLk20SERHdg6TOwM6cOYNRo0Zh5cqV8PLyUtKAuLg4mM1m66tq1apK6iUiotJNKoAlJCTg4sWLaNq0Kdzc3ODm5oYdO3Zg7ty5cHNzQ1BQEDIzM5GammrzuZSUFAQHB9utc+LEibBYLNbXmTNnit0ZIiK6d0hdQrz//vtx8OBBm7LBgwcjIiIC48ePR9WqVeHu7o6tW7ciJiYGAHDs2DEkJSUhMjLSbp2enp7w9PQsZvOJiOheJRXAypYti/r169uU+fj4IDAw0Fr+9NNPY8yYMQgICICfnx9GjBiByMhItG7dWl2rb6NqnDPZsRNlxwlz1MzOWrTWKzvWolY9WlTNiK1Ftj2yy6saH07V7LiA/LiQes9arWqbym4j2fVq0fu7p+oY0nt5LbK/rarWezvlg/m+8847cHFxQUxMDDIyMhAdHY2FCxeqXg0REd3jTEKv0FhMaWlpMJvNAApGc1VnKqrOwFSt11FnYFpUjXavqn5HjQyuxRlH6Ha2MzDZY9TZtqne3z1Hfbf1pnI/WiwW+Pn5FboMx0IkIiJDYgAjIiJDYgAjIiJDcuoZmYt63VTV9XbZezyy65W9v6DVTr3vUam6F6WqflX3QfTOGlW13uLQe5tqLa9q2znbNtX6bqu6d+WoLD6t3w6t+lX9xmmx11+ZOngGRkREhsQARkREhsQARkREhsQARkREhsQARkREhuTUWYh60cqs0RrNQCvDSzZDRyuDSVUGkCqyWZFa7XTUOG2q6lfVHtlMvcKyPbW2td7HitH3paMyUFVRlXmscvxNe/QenajA+orWLCIiIufCAEZERIbEAEZERIbEAEZERIbEAEZERIZ0T2YhatGaO0kVVePAaVGVaeUss63m0coOzc7Otlsu2x7Z7FC991dhGYWy837JrtvJpgfUpPf8ZKqOIdn6ZeckdDay262k2bM8AyMiIkNiACMiIkNiACMiIkNiACMiIkNiACMiIkMyVBaiqswjR2Vg6T1+m1a5h4eH3fLMzEyp9jgqQ0p2dlxV7ZHN3pStR3ZMTkA721B2DDpHZb6qIvsd0BpLUJbWsaUqY1XVsetss4mrmsm6QL0l+jQREZGDMIAREZEhMYAREZEhMYAREZEhMYAREZEhGSoLUTZjRXYMPVl6Z2CpyhiSzTbUYpTx2LTIZg9q0TvDrrDjU9VYiLL0PtZVZdzK0jtjVRVVma+yMzvL9svNzX5IUfWbezuegRERkSExgBERkSExgBERkSExgBERkSEZKomDiMjZtQRQC8BxAHsd3JbSzmkDmMlkKpB5o5WJo5VBo5WZJZvRo2q2Vb3Jrlc2I0lvemfY6Z3RJqs427+kY8cVd92qMmKLMwu1CrLjTmodc9OnTy9Qdkacwa9nf4Vfph+G7T6DR44etb73BoCJdurRO+tS1finsvTOhr2d0wYwIiJntzlnM37Ej0AI0PIs8MhR2/cnAFgHnonphffAiIiK4Yw4cyt4/U+ty/aXq3WX2nMvYgAjIiqGy8I2Yh0PtL/c8bvQlnsVAxgRUTEEmmwj1t4qwBttbJeJAy8f6on3wIiIiqGqqSraoq3NZcTlTevgWpkqqJSWhgt+fnh9yxYHtrD0MwlHpWBpSEtLg9lsdsi6tTKztDKYtMb9UjVrruzyemfxOfvsrKo5avy/wrJktY45VbNrq9oHqrad7HdS1Xq1lrf3HcsNyUWOOQe4DOCc1GpKzNmOUZXfYYvFAj8/v0KX4RkYEVEJuJx3Qc5pYw90bVS8B0ZERIbEAEZERIbEAEZERIbEAEZERIZkqCQOrcwXrYwqrXHdtJaXzdyRnWVUNttQtj2y2YaqxmOTnflaqx69szRll3eyBF0A8tmGqrLUVB0rsvvA2WZMlv2O6T3eqOx3Urb9svv3bo+vyjMwIiIyJAYwIiIyJAYwIiIyJAYwIiIyJKkANnXqVOtEk3mviIgI6/vp6ekYNmwYAgMD4evri5iYGKSkpChvNBERkXQWYr169fDdd9/9U0G+sdlefPFFfP3111izZg3MZjOGDx+OXr16YdeuXUoaq5X5Ipvh4mwz88qOHyabtah3vxyVmSU7Tp7e4+eponI8OVV9UFWPs413KUv22NUq13vGZFXjnzoqa7SopAOYm5sbgoODC5RbLBZ89NFHWLVqFTp37gwAWLJkCerUqYPdu3ejdevWJW8tERHR/0jfAztx4gRCQkJQvXp1PPHEE0hKSgIAJCQkICsrC1FRUdZlIyIiEBoaivj4eM36MjIykJaWZvMiIiK6E6kA1qpVKyxduhSbNm3CokWLkJiYiHbt2uHq1atITk6Gh4cH/P39bT4TFBSE5ORkzTrj4uJgNputr6pVqxarI0REdG+RuoTYrVs36/83bNgQrVq1QlhYGD777DN4e3sXqwETJ07EmDFjrH+npaUxiBER0R2VKI3e398ftWrVwsmTJxEcHIzMzEykpqbaLJOSkmL3nlkeT09P+Pn52byIiIjupERjIV67dg1//PEHnnzySTRr1gzu7u7YunUrYmJiAADHjh1DUlISIiMjlTRWNiOmODPe2qOVgSVbj6pZTGWX11rvqFGj7Ja/8847dsu1tr8WvbMiZTOtnG0maJVZjrKZlKq+S1r0nhHYURm3qjJltbINZbMT9c6gdfasUakANm7cODz88MMICwvD+fPnMWXKFLi6uqJfv34wm814+umnMWbMGAQEBMDPzw8jRoxAZGQkMxCJiEg5qQB29uxZ9OvXD5cvX0aFChXQtm1b7N69GxUqVABw61/uLi4uiImJQUZGBqKjo7Fw4UJdGk5ERPc2qQC2evXqQt/38vLCggULsGDBghI1ivTRUgjUAnAcwF7JS0JERM7GUPOBUfHFCYHx+f5+o7zAAdcLqJRTyWFtIiIqCQ7mew9oeVvwAoAJfwGJlk+x02unQ9pERFRShjoDk82I0TtTSXYmaNn1qsoUq31r5QXKa10GVlRJwJH/HoFb8j+Hwpw5c6TaqcXZsv5UrdeR/VKVdabqu6SKbL/0zr5TlXUpm7WoasZt2d8mZxsPtKh4BnYPOK5VHnjrv7nlnDtVlojIHgawe8BekwkzbyuLawPsrXLr/12u8DAgIuMx1CVEKr7/uLhgvRCoUVfgeOQ/wctjr4fN5UMiIqPgL9c9ZK/JhL1HTBBpAqYAwPumN4MXERkWf73uQaZzJuAc4ObL3U9ExnVP/oKpyrhRNfuo1mDHjz/+uN3yd999V6p+rYwz2bnXZDOeHJVtKNserfHqtI4HvWd2LiwDTnZ8T0fNQi27D2TXq3d2nLNl36mahd3Zvqslxbv3RERkSAxgRERkSAxgRERkSAxgRERkSAxgRERkSCbhZOk2aWlpMJvNdt9TNQOyo2ZzlRUQEGC3/OrVq3bLs7OzpepXlR2naqZpvcnOKO2osRMLO871Pka1MjJlM25VZbvpndmp9/ikqjhq7EdH/iZaLBb4+fkVugzPwIiIyJAYwIiIyJAYwIiIyJAYwIiIyJAYwIiIyJBKxViIjpp5WdU4c1r1X7lyRUk9jsr8kqWVAafVr6ysLKn6ZbeDqqxFlbMfa20jrXLZGX5Vzdir6lhxVD2yGc9a9D6mVXFzsx8KtDKbnWWsRZ6BERGRITGAERGRITGAERGRITGAERGRITGAERGRIZWKLERZeo/ppypDR3YWVkdlG2ot7+7ubrdcK9NKKwNO1czXsv2VzTJVNY5gYbTq0nssPr3HHnS2mYJVZVdq7S9nm4FaVfbj3d5fPAMjIiJDYgAjIiJDYgAjIiJDYgAjIiJDYgAjIiJDMlQWot7joumdaSWboeNsmWVatLINZWeIdjay4+GpzDbU4owz56qg97Gu93imRp/9XdVxJZt5XFI8AyMiIkNiACMiIkNiACMiIkNiACMiIkNiACMiIkMyVBaiLNmxBPXOQtSi90zKWlRlQslmGOm9X7Q42/hzxaEqC06Lqnpkx/fUIntMONuYilq02i87nqbe45nK0vot0Gu/8AyMiIgMiQGMiIgMiQGMiIgMiQGMiIgMiQGMiIgMqVRnIarKPNJ7/DlVWYuOyn6Upap+VRlbWlRliskqLFNPNitP72NXdls4WzagFr2z+LT2sewxpGo/6n2c6LXfeQZGRESGxABGRESGxABGRESGxABGRESGJB3Azp07hwEDBiAwMBDe3t5o0KAB9u3bZ31fCIHJkyejUqVK8Pb2RlRUFE6cOKG00URERFJZiFeuXEGbNm3QqVMnbNy4ERUqVMCJEydQrlw56zJvvvkm5s6di2XLliE8PByTJk1CdHQ0Dh8+DC8vrxI1VnYcNVWzreo9Jp6qjCdHjd0nm90nu7wW2cwmvTOqVI3xeDcy9VRloKrKvJT9Tjoqg1bVep0tG1PVmJmq6i9yO4REzRMmTMCuXbuwc+dOu+8LIRASEoKxY8di3LhxAACLxYKgoCAsXboUffv2veM60tLSYDab7b7nqADmbJxt4FZHBTBHBXKt9jvbP4wA+bY66of1XgtgRnc3ApjFYoGfn1+hy0hFhC+//BLNmzdHnz59ULFiRTRp0gSLFy+2vp+YmIjk5GRERUVZy8xmM1q1aoX4+Hi7dWZkZCAtLc3mRUREdCdSAezPP//EokWLULNmTWzevBlDhw7FyJEjsWzZMgBAcnIyACAoKMjmc0FBQdb3bhcXFwez2Wx9Va1atTj9ICKie4xUAMvNzUXTpk0xY8YMNGnSBEOGDMGzzz6L9957r9gNmDhxIiwWi/V15syZYtdFRET3DqkAVqlSJdStW9emrE6dOkhKSgIABAcHAwBSUlJslklJSbG+dztPT0/4+fnZvIiIiO5EKguxTZs2OHbsmE3Z8ePHERYWBgAIDw9HcHAwtm7disaNGwO4lZSxZ88eDB06tMSNVXUz3FE3+Z1tvc42lqOqjDa9yW5Pd3d3u+XZ2dl2ywu7Qa4qWUC2HtnkBa0xErWWVzXjs96cLVvPUUklTpPwJiTs3btXuLm5iddff12cOHFCrFy5UpQpU0asWLHCuswbb7wh/P39xRdffCF+++038cgjj4jw8HBx8+bNIq3DYrEIAHZfJpPJ7ktreUe99G6nVv1G2T6urq52X45ul14vd3d3uy+t/eXi4qL5ctSxKNserX1slGNU1fbU+7uq6jhxxpfFYrljvJAKYEIIsWHDBlG/fn3h6ekpIiIixAcffGDzfm5urpg0aZIICgoSnp6e4v777xfHjh0rcv0MYMWv3yjbhwGMAczZj1FV25MBrPivogQwqefA7obCngNz1KU5WXq38248g6EnvacjcTaOvISo6lh0tkuIjiK7PUvrJcS7QflzYERERM6CAYyIiAzJUDMyq8pe07qko1WP1mm9bLnWerVO92XbI3u5QlZpHQdOb1lZWVLLF+dymqpLW6ou5amaFVtrea1y2XEq9R5PU2t52XEzZfurRdV2cJbbGDwDIyIiQ2IAIyIiQ2IAIyIiQ2IAIyIiQ2IAIyIiQzJUFqJsZpNW5otWVpjemVlaD65q8fDwsFuu1X69HwbVe4ZrrYdftZYvrROWFods9prsNnJUtptsv2Sz+7SoOoZUZQ86W5apo7bn7XgGRkREhsQARkREhsQARkREhsQARkREhuR0SRzFuannqBuTetcvmwThKHpvf1Xb7V7kqG1hlO+SquWdrR5n+w7o9bvudAHs6tWrjm6C05AdQ8/o7rUxEh3J2QKMs9XvbO61/gK3YoHW1Fp5nG4+sNzcXJw/fx5ly5bF1atXUbVqVZw5c+aO88KUFmlpafdUn9nf0o39Ld306K8QAlevXkVISIjmYxF5nO4MzMXFBVWqVAHwz7MDfn5+98TBkN+91mf2t3Rjf0s31f2905lXHiZxEBGRITGAERGRITl1APP09MSUKVPg6enp6KbcNfdan9nf0o39Ld0c3V+nS+IgIiIqCqc+AyMiItLCAEZERIbEAEZERIbEAEZERIbk1AFswYIFqFatGry8vNCqVSvs3bvX0U1S4ocffsDDDz+MkJAQmEwmrF+/3uZ9IQQmT56MSpUqwdvbG1FRUThx4oRjGqtAXFwcWrRogbJly6JixYro2bMnjh07ZrNMeno6hg0bhsDAQPj6+iImJgYpKSkOanHJLFq0CA0bNrQ+3BkZGYmNGzda3y9NfbXnjTfegMlkwujRo61lpanPU6dOhclksnlFRERY3y9Nfc1z7tw5DBgwAIGBgfD29kaDBg2wb98+6/uO+s1y2gD26aefYsyYMZgyZQp++eUXNGrUCNHR0bh48aKjm1Zi169fR6NGjbBgwQK777/55puYO3cu3nvvPezZswc+Pj6Ijo5Genr6XW6pGjt27MCwYcOwe/dubNmyBVlZWXjggQdw/fp16zIvvvgiNmzYgDVr1mDHjh04f/48evXq5cBWF1+VKlXwxhtvICEhAfv27UPnzp3xyCOP4PfffwdQuvp6u59//hnvv/8+GjZsaFNe2vpcr149XLhwwfr68ccfre+Vtr5euXIFbdq0gbu7OzZu3IjDhw9j9uzZKFeunHUZh/1mCSfVsmVLMWzYMOvfOTk5IiQkRMTFxTmwVeoBEOvWrbP+nZubK4KDg8WsWbOsZampqcLT01N88sknDmihehcvXhQAxI4dO4QQt/rn7u4u1qxZY13myJEjAoCIj493VDOVKleunPjwww9LdV+vXr0qatasKbZs2SI6dOggRo0aJYQofft3ypQpolGjRnbfK219FUKI8ePHi7Zt22q+78jfLKc8A8vMzERCQgKioqKsZS4uLoiKikJ8fLwDW6a/xMREJCcn2/TdbDajVatWpabvFosFABAQEAAASEhIQFZWlk2fIyIiEBoaavg+5+TkYPXq1bh+/ToiIyNLdV+HDRuGhx56yKZvQOncvydOnEBISAiqV6+OJ554AklJSQBKZ1+//PJLNG/eHH369EHFihXRpEkTLF682Pq+I3+znDKAXbp0CTk5OQgKCrIpDwoKQnJysoNadXfk9a+09j03NxejR49GmzZtUL9+fQC3+uzh4QF/f3+bZY3c54MHD8LX1xeenp54/vnnsW7dOtStW7dU9hUAVq9ejV9++QVxcXEF3ittfW7VqhWWLl2KTZs2YdGiRUhMTES7du1w9erVUtdXAPjzzz+xaNEi1KxZE5s3b8bQoUMxcuRILFu2DIBjf7OcbjR6Kt2GDRuGQ4cO2dwzKI1q166NAwcOwGKxYO3atYiNjcWOHTsc3SxdnDlzBqNGjcKWLVvg5eXl6Oborlu3btb/b9iwIVq1aoWwsDB89tln8Pb2dmDL9JGbm4vmzZtjxowZAIAmTZrg0KFDeO+99xAbG+vQtjnlGVj58uXh6upaIHMnJSUFwcHBDmrV3ZHXv9LY9+HDh+Orr77Ctm3brFPmALf6nJmZidTUVJvljdxnDw8P1KhRA82aNUNcXBwaNWqEd999t1T2NSEhARcvXkTTpk3h5uYGNzc37NixA3PnzoWbmxuCgoJKXZ/z8/f3R61atXDy5MlSuX8rVaqEunXr2pTVqVPHetnUkb9ZThnAPDw80KxZM2zdutValpubi61btyIyMtKBLdNfeHg4goODbfqelpaGPXv2GLbvQggMHz4c69atw/fff4/w8HCb95s1awZ3d3ebPh87dgxJSUmG7fPtcnNzkZGRUSr7ev/99+PgwYM4cOCA9dW8eXM88cQT1v8vbX3O79q1a/jjjz9QqVKlUrl/27RpU+Cxl+PHjyMsLAyAg3+zdE0RKYHVq1cLT09PsXTpUnH48GExZMgQ4e/vL5KTkx3dtBK7evWq2L9/v9i/f78AIN5++22xf/9+cfr0aSGEEG+88Ybw9/cXX3zxhfjtt9/EI488IsLDw8XNmzcd3PLiGTp0qDCbzWL79u3iwoUL1teNGzesyzz//PMiNDRUfP/992Lfvn0iMjJSREZGOrDVxTdhwgSxY8cOkZiYKH777TcxYcIEYTKZxLfffiuEKF191ZI/C1GI0tXnsWPHiu3bt4vExESxa9cuERUVJcqXLy8uXrwohChdfRVCiL179wo3Nzfx+uuvixMnToiVK1eKMmXKiBUrVliXcdRvltMGMCGEmDdvnggNDRUeHh6iZcuWYvfu3Y5ukhLbtm0TAAq8YmNjhRC30lInTZokgoKChKenp7j//vvFsWPHHNvoErDXVwBiyZIl1mVu3rwpXnjhBVGuXDlRpkwZ8eijj4oLFy44rtEl8NRTT4mwsDDh4eEhKlSoIO6//35r8BKidPVVy+0BrDT1+fHHHxeVKlUSHh4eonLlyuLxxx8XJ0+etL5fmvqaZ8OGDaJ+/frC09NTREREiA8++MDmfUf9ZnE6FSIiMiSnvAdGRER0JwxgRERkSAxgRERkSAxgRERkSAxgRERkSAxgRERkSAxgRERkSAxgRERkSAxgRERkSAxgRERkSAxgRERkSAxgRERkSP8P6tmwDZcRgWQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables to track the min and max MSE\n",
    "min_mse = float('inf')\n",
    "max_mse = float('-inf')\n",
    "min_mse_index = -1\n",
    "max_mse_index = -1\n",
    "\n",
    "# Loop through each prediction to calculate the MSE\n",
    "for i in range(len(all_pred_midpoints)):\n",
    "    mse = np.mean((all_pred_midpoints[i] - all_true_midpoints[i]) **2)\n",
    "    \n",
    "    if mse < min_mse:\n",
    "        min_mse = mse\n",
    "        min_mse_index = i\n",
    "    \n",
    "    if mse > max_mse:\n",
    "        max_mse = mse\n",
    "        max_mse_index = i\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot an image with its centers\n",
    "def plot_image_with_centers(image, true_center, predicted_center, title):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  # Display the image\n",
    "\n",
    "    # Plot the actual center (Groundtruth)\n",
    "    plt.scatter(true_center[:, 0], true_center[:, 1], color='green', label='Groundtruth', s=10)\n",
    "\n",
    "    # Plot the predicted center\n",
    "    plt.scatter(predicted_center[:, 0], predicted_center[:, 1], color='red', label='Predictions', s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the image with the least MSE\n",
    "plot_image_with_centers(all_images[min_mse_index],\n",
    "                        all_true_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Least MSE. MSE: {min_mse:.4f}')\n",
    "\n",
    "# Plotting the image with the largest MSE\n",
    "plot_image_with_centers(all_images[max_mse_index],\n",
    "                        all_true_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Largest MSE. MSE: {max_mse:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11548"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mse_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
