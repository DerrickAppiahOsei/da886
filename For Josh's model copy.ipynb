{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Set CUDA device order and visible devices\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7,8,9\"\n",
    "\n",
    "# # Set the device\n",
    "# device = '/cpu:0'\n",
    "# if tf.config.experimental.list_physical_devices('GPU'):\n",
    "#     try:\n",
    "#         # Restrict TensorFlow to only use the second GPU\n",
    "#         gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#         if gpus:\n",
    "#             tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "#             device = '/gpu:0'\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "\n",
    "# print(\"device\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 19:27:19.838577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79196 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:45:00.0, compute capability: 8.0\n",
      "2024-10-08 19:27:19.852347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79196 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:46:00.0, compute capability: 8.0\n",
      "2024-10-08 19:27:19.853817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79194 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:49:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # Only GPUs 0 and 1 will be visible to TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\",\"/gpu:2\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# DataLoader Class Definition\n",
    "# -----------------------------\n",
    "class DataLoader:\n",
    "    def __init__(self, h5_filename):\n",
    "        self.h5_filename = h5_filename\n",
    "        self.images, self.centers = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with h5py.File(self.h5_filename, 'r') as f:\n",
    "            images = np.array(f['images'])\n",
    "            centers = np.array(f['centers_training'])\n",
    "        return images, centers\n",
    "\n",
    "    def plot_image_with_centers(self, image_index=None):\n",
    "        if image_index is None:\n",
    "            image_index = np.random.randint(0, len(self.images))\n",
    "\n",
    "        image = self.images[image_index]\n",
    "        centers = self.centers[image_index]\n",
    "\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        valid_centers = centers[centers[:, 0] == 1]\n",
    "        for center in valid_centers:\n",
    "            plt.scatter(center[1], center[2], c='red', marker='x')  # center[1] is x and center[2] is y\n",
    "        plt.title('Image with Valid Centers Marked')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_centers(centers):\n",
    "        return centers[np.lexsort((centers[:, 0], centers[:, 1]))]\n",
    "\n",
    "    def normalize_data(self):\n",
    "        normalized_images = self.images / np.max(self.images)\n",
    "        sorted_centers = np.array([self.sort_centers(image_centers[:, 1:]) for image_centers in self.centers])\n",
    "        normalized_centers = sorted_centers / 64\n",
    "\n",
    "        normalized_midpoints = tf.expand_dims(normalized_centers, axis=1)\n",
    "        return normalized_images, normalized_midpoints.numpy()\n",
    "\n",
    "    def split_data(self, train_size=0.8, random_state=42):\n",
    "        normalized_images, normalized_midpoints_np = self.normalize_data()\n",
    "        return train_test_split(normalized_images, normalized_midpoints_np, train_size=train_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Utility Function Definition\n",
    "# -----------------------------\n",
    "def plot_transposed_images_with_midpoints(dataset, image_indices=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Extracts multiple images and their midpoints from the given dataset, transposes the images, \n",
    "    corrects the midpoints, and plots the transposed images with the corrected midpoints.\n",
    "\n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The dataset from which to extract the images and midpoints.\n",
    "    - image_indices (list): The indices of the images in the batch to visualize. Default is [0, 1, 2, 3].\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract a sample image batch and its corresponding midpoints from the dataset\n",
    "    sample_image_batch, sample_midpoints_batch = next(iter(dataset))\n",
    "\n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(image_indices):\n",
    "            # Select the specified image and corresponding midpoints from the batch\n",
    "            sample_image = np.array(sample_image_batch[image_indices[i]])\n",
    "            sample_midpoints = np.array(sample_midpoints_batch[image_indices[i]])\n",
    "\n",
    "            # Transpose the image\n",
    "            transposed_image = sample_image.T\n",
    "\n",
    "            # Correct the midpoints by swapping the x and y coordinates\n",
    "            transposed_midpoints_corrected = sample_midpoints[:, :, [1, 0]]\n",
    "\n",
    "            # Plot the transposed image with corrected midpoints\n",
    "            ax.imshow(transposed_image, cmap='gray')\n",
    "            ax.scatter(\n",
    "                transposed_midpoints_corrected[:, :, 0] * 64, \n",
    "                transposed_midpoints_corrected[:, :, 1] * 64, \n",
    "                c='red', marker='o', s=5\n",
    "            )\n",
    "            ax.set_title(f'Image {image_indices[i]} for this batch')\n",
    "        else:\n",
    "            ax.axis('off')  # If fewer than 4 images are requested, hide the unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Loss and Callback Definitions\n",
    "# -----------------------------\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(exponent):\n",
    "    def loss(y_true, y_pred):\n",
    "        diff = tf.abs(y_true - y_pred)\n",
    "        powered_diff = tf.pow(diff, exponent)\n",
    "        return tf.reduce_mean(powered_diff)\n",
    "    return loss\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DynamicExponentCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_exponent, increment, update_frequency):\n",
    "        super().__init__()\n",
    "        self.exponent = initial_exponent\n",
    "        self.increment = increment\n",
    "        self.update_frequency = update_frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.update_frequency == 0:\n",
    "            self.exponent += self.increment\n",
    "            print(f\"\\nEpoch {epoch + 1}: Increasing exponent to {self.exponent}\")\n",
    "            self.model.loss = self.custom_loss(self.exponent)\n",
    "\n",
    "    def custom_loss(self, exponent):\n",
    "        def loss(y_true, y_pred):\n",
    "            diff = tf.abs(y_true - y_pred)\n",
    "            powered_diff = tf.pow(diff, exponent)\n",
    "            return tf.reduce_mean(powered_diff)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'initial_exponent': self.exponent,\n",
    "            'increment': self.increment,\n",
    "            'update_frequency': self.update_frequency,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my NEW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# class ModelBuilder:\n",
    "#     def __init__(self, input_shape=(64, 64, 1), num_classes=3, num_coordinates=2, learning_rate=3e-5, weights_path=None, l2_reg=0.001):\n",
    "#         self.input_shape = input_shape\n",
    "#         self.num_classes = num_classes\n",
    "#         self.num_coordinates = num_coordinates\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.l2_reg = l2_reg\n",
    "#         self.model = self.build_model()\n",
    "\n",
    "#         # Load weights if a path is provided\n",
    "#         if weights_path is not None:\n",
    "#             self.model.load_weights(weights_path)\n",
    "\n",
    "#         self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "#         # self.optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "#     def build_model(self):\n",
    "#         l2 = regularizers.l2(self.l2_reg)\n",
    "        \n",
    "#         x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "#         # First branch\n",
    "#         x_1 = layers.Conv2D(64, kernel_size=6, strides=1, padding='same', activation='relu')(x_input)\n",
    "#         x_1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=3, padding='same', activation='relu', kernel_regularizer=l2)(x_1)\n",
    "#         # x_1 = layers.Dropout(0.1)(x_1)\n",
    "#         # x_1 = layers.BatchNormalization()(x_1)\n",
    "\n",
    "#         # Second branch\n",
    "#         x_2 = layers.Conv2D(32, kernel_size=8, strides=3, padding='same', activation='relu')(x_input)\n",
    "#         x_2 = layers.Conv2D(64, kernel_size=4, strides=1, padding='same', activation='relu')(x_2)\n",
    "#         x_2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_2)\n",
    "#         # x_2 = layers.Dropout(0.1)(x_2)\n",
    "#         # x_2 = layers.BatchNormalization()(x_2)\n",
    "\n",
    "#         # Concatenate branches\n",
    "#         x_3 = layers.concatenate([x_1, x_2])\n",
    "#         x_3 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_3)\n",
    "#         # x_3 = layers.Dropout(0.1)(x_3)\n",
    "#         # x_3 = layers.BatchNormalization()(x_3)\n",
    "\n",
    "#         # Third branch\n",
    "#         x_4 = layers.Conv2D(64, kernel_size=19, strides=5, padding='same', activation='relu', kernel_regularizer=l2)(x_input)\n",
    "        \n",
    "#         # Flatten and concatenate\n",
    "#         x_3 = layers.Flatten()(x_3)\n",
    "#         x_4 = layers.Flatten()(x_4)\n",
    "#         x = layers.Concatenate()([x_3, x_4])\n",
    "\n",
    "#         # Dense layers with L2 regularization\n",
    "#         x = layers.Dense(256, activation='relu', kernel_regularizer=l2)(x)\n",
    "#         # x = layers.Dropout(0.1)(x)\n",
    "\n",
    "#         # Output layer for midpoints\n",
    "#         x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "#         x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "#         return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "#     def compile_model(self, loss_function):\n",
    "#         self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "#     def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "#         history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "#         return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, input_shape=(64, 64, 1), num_classes=13, num_coordinates=2, learning_rate=1e-3, weights_path=None,l1_reg=0.001,l2_reg =0.01):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_coordinates = num_coordinates\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # Load weights if a path is provided\n",
    "        if weights_path is not None:\n",
    "            self.model.load_weights(weights_path)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        # self.optimizer =tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        l1 = regularizers.l1(self.l1_reg)\n",
    "        l2 = regularizers.l2(self.l2_reg)\n",
    "\n",
    "    \n",
    "        x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=5, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='linear', name='x_midpoints')(x)\n",
    "        x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "        return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "    def compile_model(self, loss_function):\n",
    "        self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "    def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "        history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Main Script Execution\n",
    "# -----------------------------\n",
    "\n",
    "# Load data\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_Mixed_13.h5'             \n",
    "h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KNoFalsePositivesFixed-index6_13.h5'\n",
    "data_loader = DataLoader(h5_filename)\n",
    "images, centers = data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa8ac3a1dd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=np.random.randint(0,len(centers))\n",
    "data_loader.plot_image_with_centers(l)\n",
    "plt.imshow(images[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data and split it into training and validation sets\n",
    "train_images, val_images, train_midpoints, val_midpoints = data_loader.split_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: (24000, 64, 64), Train Midpoints: (24000, 1, 13, 2)\n",
      "Validation Images: (6000, 64, 64), Validation Midpoints: (6000, 1, 13, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 500\n",
    "train_dataset = train_dataset.shuffle(buffer_size=8000, reshuffle_each_iteration=True).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=8000).batch(batch_size)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f'Train Images: {train_images.shape}, Train Midpoints: {train_midpoints.shape}')\n",
    "print(f'Validation Images: {val_images.shape}, Validation Midpoints: {val_midpoints.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_transposed_images_with_midpoints(train_dataset, image_indices=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=13, verbose=1, mode='min', min_lr=7e-6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> \n",
       "\n",
       " max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " batch_normalization              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> \n",
       "\n",
       " conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> \n",
       "\n",
       " conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> \n",
       "\n",
       " batch_normalization_1            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> \n",
       "\n",
       " conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> \n",
       "\n",
       " batch_normalization_2            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> \n",
       "\n",
       " max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " batch_normalization_3            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
       "\n",
       " max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " batch_normalization_4            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
       "\n",
       " max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " batch_normalization_5            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,056</span> \n",
       "\n",
       " max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " batch_normalization_6            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " x_midpoints (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">26,650</span> \n",
       "\n",
       " x_midpoints_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer (\u001b[38;5;33mInputLayer\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d (\u001b[38;5;33mConv2D\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m640\u001b[0m \n",
       "\n",
       " max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " batch_normalization              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m256\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m36,928\u001b[0m \n",
       "\n",
       " conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m73,856\u001b[0m \n",
       "\n",
       " conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)           \u001b[38;5;34m147,584\u001b[0m \n",
       "\n",
       " batch_normalization_1            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)               \u001b[38;5;34m512\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m295,168\u001b[0m \n",
       "\n",
       " conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m590,080\u001b[0m \n",
       "\n",
       " batch_normalization_2            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)             \u001b[38;5;34m1,024\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)         \u001b[38;5;34m1,180,160\u001b[0m \n",
       "\n",
       " max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " batch_normalization_3            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)             \u001b[38;5;34m2,048\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)         \u001b[38;5;34m2,359,808\u001b[0m \n",
       "\n",
       " max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " batch_normalization_4            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)               \u001b[38;5;34m2,048\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)           \u001b[38;5;34m2,359,808\u001b[0m \n",
       "\n",
       " max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " batch_normalization_5            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)               \u001b[38;5;34m2,048\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m3,277,056\u001b[0m \n",
       "\n",
       " max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " batch_normalization_6            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)               \u001b[38;5;34m1,024\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " flatten (\u001b[38;5;33mFlatten\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                        \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " x_midpoints (\u001b[38;5;33mDense\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)                     \u001b[38;5;34m26,650\u001b[0m \n",
       "\n",
       " x_midpoints_reshape (\u001b[38;5;33mReshape\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m2\u001b[0m)                    \u001b[38;5;34m0\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,356,698</span> (39.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,356,698\u001b[0m (39.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,352,218</span> (39.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,352,218\u001b[0m (39.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,480</span> (17.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,480\u001b[0m (17.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# dynamic_exponent_callback = DynamicExponentCallback(2, 1, 50)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # Instantiate the model builder\n",
    "    # model_builder = ModelBuilder(weights_path= \"/home/da886/Weights from Josh's model/Josh's5fixedMSE45overfit-1.keras\")\n",
    "    model_builder = ModelBuilder()\n",
    "\n",
    "    # Build the model\n",
    "    model_builder.build_model()\n",
    "\n",
    "    # Display the model architecture\n",
    "    model_builder.model.summary()\n",
    "\n",
    "    # Compile the model using the custom loss function\n",
    "    # model_builder.compile_model(loss_function=dynamic_exponent_callback.custom_loss(2))\n",
    "    model_builder.compile_model(loss_function=tf.keras.losses.MeanSquaredError()) \n",
    "    \n",
    "    # model_builder.compile_model(loss_function=custom_loss(3))e\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 21:17:11.027321: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-07 21:17:11.039600: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-07 21:17:11.066419: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1728335831.161143 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.161143 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.163488 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.227322 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.227414 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.227466 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.227886 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.228100 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.228201 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.234382 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.234387 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.234760 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.257719 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.257886 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.258019 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.260187 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.260180 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.260654 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.261102 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.261110 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.261497 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.261867 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.261877 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.262284 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.264327 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.264377 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.264947 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.283094 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.283094 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.284144 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.284158 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.284270 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.285022 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.285117 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.285247 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.285998 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.286110 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.286121 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.286912 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.287094 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.287189 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.287881 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.288136 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.288147 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.289409 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.290220 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.290213 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.290895 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.292285 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.292295 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.292696 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.294820 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.294891 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.295213 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.297642 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.298074 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.298174 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.301324 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.301411 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.301828 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.303520 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.303526 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.303613 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.311781 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.311854 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.311977 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.314627 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.314658 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.314845 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.717978 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.718633 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.719029 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.719225 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.719811 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.719920 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.720528 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.720642 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.721128 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.721603 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.721890 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.722643 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.722818 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.723679 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.723858 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.724667 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.724876 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.725732 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.726236 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.727279 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.727746 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.728976 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.729590 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.729625 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.730290 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.730914 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.731140 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.731505 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.732146 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.732978 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.733985 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.734987 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.735972 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.737016 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.738721 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.739316 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.739771 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.740245 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.740989 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.740994 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.741003 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.741609 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.741625 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.742253 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.742268 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.742927 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.742940 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.743603 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.743623 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.744124 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.744683 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.744869 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.745269 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.746301 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.746576 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.746980 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.747227 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.747622 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.747839 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.748246 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.748461 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.748876 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.749979 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.750051 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.750582 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.751040 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.751516 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.752024 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.752534 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.753050 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.754737 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.755595 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.756285 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.756992 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.756979 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.757118 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.757953 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.758022 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.758030 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.758883 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.758954 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.758968 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.760001 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.760760 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.760834 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.760947 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.762394 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.762812 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.762824 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.763101 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.764149 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.765050 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.765737 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.765764 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.765971 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.767036 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.767050 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.767884 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.768361 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.768377 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.769010 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.769855 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.769955 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.770263 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.771710 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.780910 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.781187 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.781593 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.781872 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.782204 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.782303 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.782582 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.783121 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.783164 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.783326 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.783999 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.784118 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.784197 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.784806 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.785011 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.785186 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.785444 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.786361 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.786693 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.786869 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.788023 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.788353 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.788526 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.789669 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.790037 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.790209 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.791338 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.791719 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.791891 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.793001 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.793643 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.793742 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.794818 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.795301 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.795519 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.796484 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.813894 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.814151 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.814447 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.814699 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.815060 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.815366 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.815426 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.815736 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.815965 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.816151 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.816485 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.816672 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.816867 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.817199 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.817415 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.817578 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.817923 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.818169 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.818345 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.818907 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.819027 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.819227 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.819736 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.819904 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.820012 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.820481 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.820885 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.820951 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.821793 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.822591 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.822709 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.822786 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.823483 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.823705 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.823900 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.824304 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.824536 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.824769 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.825191 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.825466 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.825628 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.826225 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.826632 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.826708 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.827742 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.828123 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.828527 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.829065 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.829501 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.829673 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.830219 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.830745 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.830823 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.831315 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.832019 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.832041 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.832304 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.833163 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.833242 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.834266 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.834437 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.835249 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.836345 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.837347 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.838147 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.839342 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.839445 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.840037 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.841344 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.841570 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.842260 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.843580 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.843988 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.844688 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.846026 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.854846 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.855438 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.855758 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.856353 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.856425 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.856765 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.857464 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.857564 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.857741 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.858625 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.858748 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.858828 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.859488 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.859739 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.860124 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.860590 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.860877 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.861968 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.863104 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.863888 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.864980 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.866122 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.866926 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.868016 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.869155 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.869986 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.871080 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.872193 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.873052 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.874144 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.875239 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.876117 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.877210 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.878476 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.879380 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.880485 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.915154 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.915961 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.916185 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.916824 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.916999 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.917505 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.917789 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.917960 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.918297 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.918750 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.918946 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.919136 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.919747 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.919964 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.920145 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.920783 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.920993 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.921169 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.921906 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.922203 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.922277 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.922886 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.923393 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.923411 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.923895 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.924470 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.924570 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.925036 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.925617 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.925686 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.926227 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.926816 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.926893 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.927425 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.928023 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.928139 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.928633 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.929253 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.929432 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.930114 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.930505 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.930684 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.931730 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.932280 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.932364 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.933211 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.933771 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.934379 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.935350 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.935449 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.935875 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.936851 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.937263 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.937502 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.938463 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.938912 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.939314 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.940292 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.940967 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.941951 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.942274 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.944326 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.945344 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.946872 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.948942 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.949961 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.950308 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.952405 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.953419 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.954409 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.956531 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.957561 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.967740 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.969134 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.969571 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.970266 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.970478 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.970987 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.971635 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.971882 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.972160 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.973034 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.973262 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.973548 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.974418 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.974639 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.975181 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.976181 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.976192 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.976572 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.977682 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.977818 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.977991 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.979012 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.979313 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.979522 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.980563 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.980741 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.981035 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.982180 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.982313 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.982484 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.983540 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.983993 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.985040 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.988002 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.989777 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.990789 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.993769 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.995643 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.996606 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335831.999383 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.001369 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.002278 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.005173 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.007250 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.008116 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.010775 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.012969 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.013775 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.016971 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.019210 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.019985 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.023024 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.025380 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.026082 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.095641 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.096961 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.098435 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.098850 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.099423 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.099920 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.100194 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.100760 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.101622 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.101816 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.102253 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.103231 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.103401 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.103750 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.105153 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.105266 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.105434 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.106709 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.106931 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.107096 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.108379 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.108783 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.108951 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.110417 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.110554 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.110662 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.112418 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.112536 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.112632 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.114366 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.114557 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.114738 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.116366 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.116575 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.116778 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.118399 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.118638 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.120529 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.120675 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.120782 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.123167 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.124512 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.124594 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.126041 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.127295 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.127366 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.128683 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.130314 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.130333 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.130989 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.133076 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.133146 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.135406 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.135585 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.139241 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.142533 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.143592 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.143942 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.145597 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.146849 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.147270 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.149884 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.150404 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.152004 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.156246 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.156920 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.158208 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.162540 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.163193 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.174834 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.177025 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.178953 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.179276 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.179926 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.181132 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.181483 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.182154 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.183553 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.183567 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.184119 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.185773 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.186420 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.186519 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.188009 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.188520 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.188733 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.190781 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.191025 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.191475 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.192906 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.193625 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.193727 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.195419 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.195800 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.196241 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.197893 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.198236 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.198709 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.200077 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.200891 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.202523 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.203366 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.209737 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.213993 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.215113 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.221164 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.225523 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.226645 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.232668 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.237222 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.238302 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.243785 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.248489 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.249621 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.254826 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.259743 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.260905 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.266937 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.271978 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.273077 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.278632 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.283790 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.284894 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.424311 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.426502 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.428871 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.430001 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.430555 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.431181 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.432228 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.432765 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.433775 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.434627 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.435160 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.436300 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.436953 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.437474 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.438976 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.439530 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.440066 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.441489 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.442042 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.442585 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.444199 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.444700 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.445280 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.447101 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.447281 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.447795 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.450052 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.450571 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.450669 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.452911 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.453463 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.453963 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.456241 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.456698 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.457539 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.459617 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.459974 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.462948 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.463212 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.463632 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.467481 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.468625 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.469135 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.472254 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.473307 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.473837 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.477116 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.478239 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.478787 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.481134 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.483211 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.483733 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.487322 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.487798 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.495880 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.501985 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.502306 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.502738 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.507871 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.508515 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.508919 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.514482 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.514857 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.526231 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.530165 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.532879 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.533196 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.534105 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.536861 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.537145 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.537576 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.540925 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.541108 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.542691 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.544493 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.544684 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.546566 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.549819 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.549901 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.551230 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.553822 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.553902 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.555216 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.558522 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.558609 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.559296 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.562379 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.562595 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.563922 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.566534 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.566713 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.568720 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.571212 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.571454 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.576038 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.576304 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.592772 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.600299 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.600511 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.616294 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.623981 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.624448 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.638559 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.646381 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.647131 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.660998 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.668903 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.669672 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.682888 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.690705 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.691680 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.706130 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.713846 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.714800 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.730098 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.737816 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335832.738541 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.018010 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.022171 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.026124 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.026287 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.027966 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.030553 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.030655 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.032160 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.034600 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.035511 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.036068 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.038948 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.040122 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.040376 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.043771 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.044927 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.045424 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.048323 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.050140 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.050240 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.053012 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.055017 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.055202 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.058468 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.060352 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.060533 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.063461 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.065307 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.066817 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.068871 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.070698 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.073426 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.075541 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.077273 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.080424 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.082391 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.083957 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.088162 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.089632 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.091029 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.097370 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.097629 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.098828 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.107059 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.107255 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.108159 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.116418 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.117195 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.117894 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.126633 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.127262 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.128326 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.138816 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.139228 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.139970 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.150705 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.151074 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.161972 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.173055 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.173527 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.196148 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.198188 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.200142 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.202275 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.204372 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.206486 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.208113 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.208441 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.208842 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.210359 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.210546 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.211171 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.212444 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.212548 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.213498 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.214753 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.214833 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.216003 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.216889 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.217565 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.218546 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.219047 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.219675 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.221171 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.221428 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.221699 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.223766 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.224270 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.224452 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.226179 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.226420 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.227636 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.228920 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.229001 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.231158 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.231385 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.231560 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.234208 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.235002 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.237396 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.239426 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.240601 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.243521 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.244299 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.244456 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.248489 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.249588 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.253134 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.255716 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.256042 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.257955 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.261742 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.263146 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.268053 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.269181 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.273207 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.275165 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.280051 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.285184 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.286658 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.291838 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.298763 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.303077 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.303916 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.304239 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.304671 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.305668 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.306430 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.307204 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.307998 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.308766 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.309655 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.310526 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.311288 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.314760 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.316703 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.316715 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.317550 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.318308 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.318413 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.319404 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.320165 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.320943 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.321771 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.321952 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.322560 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.323457 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.324327 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.325096 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.325644 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.328607 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.329378 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.332057 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.333168 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.335647 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.338093 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.339354 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.343106 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.346910 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.351078 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.379656 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.380443 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.381263 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.382023 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.382798 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.383579 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.384368 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.385230 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.386050 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.386862 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.387788 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.388720 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.389847 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.390998 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.392196 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.393027 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.393443 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.393829 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.394638 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.395028 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.395409 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.396182 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.396586 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.396965 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.397758 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.398621 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.399685 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.399694 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.400513 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.401454 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.402385 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.403089 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.403519 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.404684 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.405890 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.407135 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.407405 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.408731 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.410293 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.413251 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.416570 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.420919 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.424963 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.425455 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.425911 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.426383 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.426856 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.428540 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.430957 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.433719 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.436430 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.438505 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.439001 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.439460 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.439929 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.440359 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.440457 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.442159 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.443014 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.444600 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.446159 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.447375 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.450088 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.453885 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.456145 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.456793 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.456807 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.457263 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.457712 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.458188 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.458669 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.459190 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.459626 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.459969 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.460228 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.460682 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.461284 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.461847 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.462417 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.462989 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.464759 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.465361 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.466988 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.467713 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.468547 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.469575 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.470022 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.470482 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.470929 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.471382 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.471866 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.472338 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.472862 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.473308 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.473892 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.474340 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.474936 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.475211 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.475517 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.476090 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.476189 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.476796 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.476970 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.478276 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.478582 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.479184 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.480384 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.480815 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.481641 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.482623 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.482702 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.483662 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.484993 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.487244 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.489375 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.489551 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.491092 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.492341 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.494748 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.497871 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.500812 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.503837 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.507201 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.510900 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.515100 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.519421 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.524335 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.530029 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.535882 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.547210 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.565632 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.566465 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.567237 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.568239 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.569011 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.569802 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.570607 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.571384 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.572286 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.573169 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.573956 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.577523 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.581010 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.584599 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.588309 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.592067 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.595894 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.600113 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.641880 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.642661 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.643482 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.644246 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.645016 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.645793 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.646580 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.647440 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.648269 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.649078 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.650007 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.650929 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.652047 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.653208 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.654404 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.655810 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.657776 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.659357 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.662301 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.665615 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.669931 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.687654 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.688144 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.688597 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.689074 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.689625 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.691338 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.693770 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.696504 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.699236 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.703046 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.705726 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.708884 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.718980 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.719443 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.719890 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.720344 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.720822 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.721323 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.721849 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.722286 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.722875 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.723326 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.723931 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.724502 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.725078 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.725658 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.727434 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.728034 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.729682 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.730409 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.731245 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.732266 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.737918 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335833.739625 2784172 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.262174 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.262206 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.262771 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.266621 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.266724 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.266853 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.267415 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.267643 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.267657 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.267966 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.268333 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.268500 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.268613 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.268909 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.269107 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.274170 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.274341 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.274425 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.274902 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.275300 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.275334 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.275500 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.276073 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.276217 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.276297 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.276741 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.276973 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.277077 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.277331 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.277555 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.282552 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.282700 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.282818 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.283347 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.283538 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.283621 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.284099 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.284415 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.284537 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.284742 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.285115 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.285415 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.285511 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.285736 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.286286 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.286390 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.286512 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.286866 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.288137 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.288254 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.288568 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.290136 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.290190 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.290468 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.292530 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.292612 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.292721 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.294709 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.294842 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.294939 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.311244 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.311262 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.311533 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.320223 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.320252 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.320389 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.350988 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.351554 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.352014 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.352579 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.353105 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.353728 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.354282 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.355097 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.355412 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.355826 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.355927 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.356359 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.357074 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.357173 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.357265 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.357692 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.357909 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.358005 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.358344 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.358700 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.358716 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.359306 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.359407 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.360248 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.360647 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.361185 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.361303 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.361690 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.362146 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.363153 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.363500 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.363695 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.363764 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.363987 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.364176 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.364606 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.364677 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.365240 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.365358 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.365587 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.366195 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.366206 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.366435 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.366803 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.366955 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.367027 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.367517 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.367596 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.368526 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.368832 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.368949 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.369121 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.369696 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.370907 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.371184 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.371193 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.371626 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.371948 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.372054 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.372254 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.372605 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.372814 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.372977 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.379416 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.379439 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.379535 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.385248 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.385249 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.385452 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.416983 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.417365 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.417482 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.417544 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.417956 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.418071 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.419758 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.419755 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.419865 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.420413 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.420522 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.420592 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.421009 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.421219 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.421236 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.421504 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.421919 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.421941 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.422055 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.422621 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.422717 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.422827 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.423430 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.423545 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.423556 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.424124 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.424254 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.424270 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.424714 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.425092 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.425113 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.425386 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.425642 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.425933 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.426105 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.426209 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.426467 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.426887 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.426967 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.427075 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.427754 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.427757 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.427867 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.428589 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.428613 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.428682 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.429364 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.429384 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.429405 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.430185 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.430204 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.430223 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.430967 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.431132 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.431146 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.431721 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.431876 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.431894 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.432373 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.432684 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.432703 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.433035 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.433372 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.433513 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.433676 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.433924 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.434135 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.434302 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.434884 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.434898 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.435145 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.436142 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.437284 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.437377 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.437651 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.441347 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.441496 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.441514 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.443035 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.443199 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.443220 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.448246 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.448747 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.448843 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.452571 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.453121 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.453281 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.456872 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.457442 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.457614 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.461161 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.461742 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.461916 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.484090 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.484997 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.485490 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.485577 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.486440 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.486540 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.487030 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.487244 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.487515 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.487853 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.488013 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.488625 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.488801 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.488972 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.489267 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.489728 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.489831 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.490934 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.491570 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.491708 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.491949 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.492207 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.492340 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.492508 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.494514 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.494670 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.494689 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.495314 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.495550 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.495569 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.496064 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.496412 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.496492 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.498842 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.498854 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.498875 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.500992 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.501200 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.501273 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.505297 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.505591 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.505672 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.520827 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.520837 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.520864 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.521964 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.522039 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.522051 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.524609 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.524730 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.524832 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.525533 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.525685 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.525766 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.526330 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.526620 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.526720 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.527114 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.527425 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.527601 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.527890 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.528224 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.528402 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.528657 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.529016 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.529192 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.529416 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.529799 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.529978 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.530226 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.530633 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.530812 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.531008 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.531433 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.531611 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.531854 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.532305 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.532487 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.532687 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.533155 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.533326 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.533588 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.534079 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.534263 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.534459 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.534964 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.535129 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.535440 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.535961 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.536136 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.536497 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.537036 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.537212 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.537661 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.538233 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.538408 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.541065 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.541609 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.541797 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.544479 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.545010 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.545235 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.547888 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.548421 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.548649 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.554094 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.554573 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.554817 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.565643 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.566035 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.566311 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.603823 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.603839 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.604063 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.604739 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.604866 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.604966 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.605565 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.605859 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.605959 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.606379 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.606732 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.606831 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.607206 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.607542 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.607716 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.607979 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.608350 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.608525 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.608793 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.609187 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.609361 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.609600 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.610017 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.610193 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.610432 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.610851 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.611029 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.611323 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.611758 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.611933 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.612188 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.612638 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.612811 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.613167 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.613634 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.613811 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.614130 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.614597 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.614770 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.615151 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.615641 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.615819 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.616157 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.616662 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.616831 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.617281 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.617805 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.617983 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.618549 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.619074 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.619250 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.619914 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.620443 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.620612 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.623334 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.623840 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.624057 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.626266 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.626743 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.626997 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.629832 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.630267 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.630539 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.645427 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.645683 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.646028 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.646328 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.646568 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.646924 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.647170 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.647402 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.647759 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.648036 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.648279 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.648623 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.648904 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.649141 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.649492 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.649802 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.650033 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.650386 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.650694 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.650914 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.651271 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.651587 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.651783 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.652139 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.652543 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.652709 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.653059 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.653584 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.653680 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.653973 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.654704 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.654748 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.654909 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.655744 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.655863 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.655974 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.656659 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.656952 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.657061 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.657748 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.658064 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.658237 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.658887 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.659233 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.659402 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.659918 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.660294 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.660472 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.660959 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.661354 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.661525 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.661949 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.662365 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.662543 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.663085 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.663509 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.663678 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.664131 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.664576 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.664751 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.666052 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.666514 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.666707 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.667226 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.667707 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.667906 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.668301 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.668771 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.668985 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.671958 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.672404 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.672637 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.675571 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.675983 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.676251 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.680093 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.680457 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.680797 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.684645 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.684962 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.685334 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.689198 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.689464 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.689875 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.693748 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.693972 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.694371 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.753509 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.753859 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.754273 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.754767 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.754773 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.755058 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.755670 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.755702 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.755902 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.756795 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.756830 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.756925 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.757735 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.757899 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.758062 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.758589 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.758954 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.759189 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.759626 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.760095 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.760343 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.760763 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.761271 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.761609 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.761941 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.762550 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.762886 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.763218 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.763842 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.764371 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.764538 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.765534 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.765548 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.766027 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.766579 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.767073 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.769221 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.770279 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.770792 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.778029 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.779311 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.779976 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.780377 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.781273 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.781890 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.782360 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.783213 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.783816 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.784307 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.785168 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.785945 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.786258 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.787313 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.788030 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.788206 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.789385 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.790186 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.790363 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.791514 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.792470 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.792570 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.793683 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.794719 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.794824 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.795821 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.797103 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.797117 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.798092 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.799129 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.799378 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.800347 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.801312 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.801684 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.802644 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.803271 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.804241 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.805175 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.805548 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.806730 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.807741 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.808105 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.809299 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.810481 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.810656 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.812009 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.813457 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.813531 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.814954 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.816695 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.816775 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.818189 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.820068 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.820354 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.821535 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.823442 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.824867 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.826797 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.829212 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.831170 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.831579 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.833898 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.835919 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.843374 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.844965 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.847213 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.850748 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.853065 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.855094 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.862512 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.865026 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.867263 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.879632 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.879783 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.881689 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.882264 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.883960 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.884339 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.886354 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.886646 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.888800 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.889083 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.891526 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.891955 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.892722 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.894684 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.895346 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.898067 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.898824 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.901538 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.902607 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.905283 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.906357 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.909007 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.910486 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.913147 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.914886 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.917542 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.919965 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.922643 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.923317 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.926022 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.937644 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.940518 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.954369 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.957339 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.958096 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.961080 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.961790 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.964779 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.965583 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.968588 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.969541 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.972666 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.973249 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.976474 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.977300 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.980652 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.981188 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.984657 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.985073 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.988656 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.989250 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.993288 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.993300 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.997360 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335836.998306 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.002063 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.002686 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.006738 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.006994 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.011704 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.012020 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.016806 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.017073 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.022280 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.023109 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.028388 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.030661 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.035907 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.042836 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.044815 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.046940 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.048995 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.051126 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.052787 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.053264 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.055528 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.057780 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.058094 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.060066 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.062547 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.065141 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.067936 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.070984 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.074319 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.075784 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.077661 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.081023 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.081231 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.085346 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.090065 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.095937 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.098201 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.103927 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.107986 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.122680 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.126463 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.128707 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.129024 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.131516 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.134040 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.136489 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.138895 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.141526 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.144000 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.146726 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.147917 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.149467 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.152879 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.154178 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.155479 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.158815 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.162117 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.164665 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.167887 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.171318 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.171767 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.174563 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.178312 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.178422 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.181878 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.188856 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.192354 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.196055 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.209868 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.223374 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.237109 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.250847 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.264354 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.278091 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.467100 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.470908 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.475010 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.474996 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.479008 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.479090 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.483081 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.483262 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.487043 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.487475 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.491246 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.491978 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.495416 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.496432 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.499988 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.500996 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.504505 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.506061 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.509144 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.511450 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.514215 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.514626 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.516680 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.516887 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.518944 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.519682 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.521312 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.523162 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.523734 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.525167 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.526854 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.530082 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.530322 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.531500 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.534094 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.536876 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.538193 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.538487 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.542566 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.543760 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.545344 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.547658 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.551085 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.552302 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.552585 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.561169 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.562257 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.565781 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.570873 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.573978 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.582391 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.582539 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.586351 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.590113 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.593947 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.597972 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.598410 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.601749 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.605887 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.606074 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.610003 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.614123 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.618550 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.622629 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.627893 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.631908 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.631993 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.636758 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.637208 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.639021 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.641519 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.642035 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.643904 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.646332 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.647597 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.648726 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.651153 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.653507 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.653790 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.656004 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.658360 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.660786 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.661494 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.663263 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.665723 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.668085 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.670935 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.673067 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.676440 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.678302 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.681487 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.683921 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.684001 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.686934 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.689119 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.692367 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.694628 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.696856 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.700143 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.701438 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.704694 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.706891 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.707216 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.709352 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.712123 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.714837 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.718422 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.720106 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.725405 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.726451 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.729906 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.732763 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.733489 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.739705 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.740921 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.746556 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.747957 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.754696 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.754892 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.755343 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.763779 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.764094 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.771342 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.772640 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.778500 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.778882 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.779981 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.787571 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.803743 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.804120 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.813000 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.831281 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.840329 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.858364 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.867627 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.885192 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.894579 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.912087 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.921579 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.946827 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335837.956596 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.099153 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.102998 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.106956 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.110897 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.115111 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.119332 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.123846 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.128304 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.132853 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.137996 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.143495 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.149023 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.155357 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.162290 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.169183 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.176108 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.184957 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.194559 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.206128 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.229932 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.262752 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.267982 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.272777 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.277677 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.282744 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.287673 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.292536 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.297600 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.302882 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.308446 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.313556 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.319081 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.324590 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.329133 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.333771 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.339278 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.344578 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.350951 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.358012 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.365501 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.372602 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.379546 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.388441 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.397280 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.404584 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.412153 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.418504 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.422402 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.426820 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.431355 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.433123 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.436043 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.437072 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.437445 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.441538 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.442330 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.446126 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.449433 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.450862 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.456222 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.456977 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.463454 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.464106 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.464409 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.471232 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.471405 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.478755 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.480209 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.487001 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.491521 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.491531 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.496058 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.504181 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.507389 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.518475 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.520091 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.535249 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.545536 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.551070 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.580802 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.592003 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.596913 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.599122 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.601565 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.603894 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.606110 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.608380 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.608461 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.610919 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.613480 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.613495 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.615743 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.616014 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.618153 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.618790 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.620517 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.621076 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.622768 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.623349 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.625139 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.626244 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.627639 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.628920 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.630022 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.631960 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.632591 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.635449 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.635553 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.637866 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.639556 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.640159 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.643084 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.645781 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.648847 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.651396 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.652242 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.656372 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.663436 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.668194 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.675134 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.680054 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.688648 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.691702 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.701815 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.705277 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.714695 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.718442 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.731292 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.863703 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.865977 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.868271 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.870583 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.872995 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.875357 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.877943 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.880488 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.881531 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.883178 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.883823 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.886190 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.886201 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.888524 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.889120 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.890953 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.892060 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.893330 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.895538 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.895933 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.898463 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.899678 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.901072 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.903459 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.903852 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.906681 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.907350 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.909529 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.912284 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.912888 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.917060 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.918416 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.920780 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.924423 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.924634 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.929541 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.935597 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.936520 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.941577 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.953671 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.957361 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.960097 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.962754 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.965664 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.968163 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.971392 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.974491 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.975249 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.977292 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.978843 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.980051 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.982453 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.983077 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.985677 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.986764 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.989032 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.990945 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.993050 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.994352 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.996797 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335838.998969 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.000541 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.003619 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.005015 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.008261 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.009350 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.012152 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.012890 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.016058 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.017647 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.021190 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.022459 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.024519 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.027297 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.027858 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.031375 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.032945 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.035379 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.038765 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.040516 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.043872 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.044590 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.047281 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.050883 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.052392 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.053372 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.056091 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.057299 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.058259 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.061762 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.064130 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.066334 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.068788 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.070475 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.071050 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.075696 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.077167 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.081474 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.084515 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.088481 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.091635 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.095113 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.099167 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.101280 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.107440 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.108669 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.115068 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.116549 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.125974 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.127912 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.128859 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.140845 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.143277 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.146539 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.164225 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.171811 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.228963 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.234183 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.236499 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.238983 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.241401 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.243716 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.246154 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.248705 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.251134 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.253773 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.256642 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.259012 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.261352 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.264348 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.267103 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.270256 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.273741 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.278000 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.290090 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.302372 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.314387 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.328099 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.341294 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.354188 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.379092 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.381406 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.383870 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.386392 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.389074 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.392328 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.395844 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.399593 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.402264 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.403653 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.404607 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.407079 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.409735 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.409822 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.412530 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.415522 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.415833 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.419381 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.422486 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.423168 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.427250 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.433006 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.434633 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.438753 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.445688 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.457982 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.460598 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.476840 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.484199 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.500497 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.503475 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.503965 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.505334 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.505777 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.506675 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.508184 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.508285 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.509580 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.510626 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.511011 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.512458 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.513077 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.513867 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.515164 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.515456 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.516562 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.518111 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.518301 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.519809 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.520661 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.521427 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.523278 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.523479 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.525461 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.526114 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.527206 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.527572 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.529103 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.529241 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.529330 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.530471 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.531554 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.531858 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.532346 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.533264 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.534686 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.535910 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.536158 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.537582 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.537751 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.538899 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.540163 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.540332 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.541978 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.543515 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.543696 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.543906 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.545134 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.547162 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.547763 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.549162 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.549561 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.550896 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.552875 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.552938 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.555250 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.556420 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.559027 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.561439 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.563146 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.565125 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.567377 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.569757 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.573300 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.577311 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.580163 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.586873 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.593481 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.597930 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.600662 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.603346 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.606313 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.608846 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.612093 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.615976 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.619605 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.623240 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.627584 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.631813 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.635230 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.639850 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.644555 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.645027 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.646441 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.647886 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.649418 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.649433 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.650890 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.652404 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.653339 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.653933 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.655506 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.657155 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.657327 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.658819 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.660531 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.662616 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.662624 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.664542 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.666002 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.666628 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.668907 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.669274 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.669415 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.670701 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.671556 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.672164 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.673615 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.674697 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.674710 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.675091 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.676614 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.678147 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.679724 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.680519 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.680721 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.681362 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.683019 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.684741 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.686328 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.686766 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.688733 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.690827 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.692607 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.693098 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.693336 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.694970 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.695749 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.696531 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.697805 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.698106 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.698847 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.699919 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.701538 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.703153 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.705191 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.705199 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.706925 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.709221 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.710522 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.711535 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.714053 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.716559 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.717985 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.718378 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.719642 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.720488 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.721230 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.722934 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.722938 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.723246 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.724769 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.725635 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.726416 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.728046 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.728155 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.729983 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.730831 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.731751 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.733617 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.734121 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.736469 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.736828 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.736998 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.739053 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.741202 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.741625 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.743469 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.745601 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.747829 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.747932 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.750774 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.750860 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.753118 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.754803 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.755944 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.758774 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.761770 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.761995 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.766451 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.768420 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.768740 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.773078 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.775704 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.780141 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.784576 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.785978 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.787192 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.793452 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.794241 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.801269 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.810231 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.819189 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.912651 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.914194 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.915736 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.917494 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.919366 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.921357 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.923468 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.925713 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.928532 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.931626 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.935473 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.939089 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.940607 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.942335 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.942339 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.944103 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.945976 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.947973 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.949806 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.950093 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.952353 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.955176 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.958274 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.960407 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.962284 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.969007 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.974360 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.976569 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.987171 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.992559 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.993480 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.994328 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.995213 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.996117 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.997022 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.997950 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.998792 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335839.999688 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.000630 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.001155 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.001633 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.002589 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.003804 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.004802 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.005992 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.007064 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.008231 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.009595 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.012985 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.015974 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.018935 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.019388 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.020298 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.021165 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.022056 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.022593 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.023099 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.023241 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.024015 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.024955 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.025587 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.025820 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.026260 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.026725 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.027675 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.028076 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.028673 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.029629 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.030608 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.030852 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.031858 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.033063 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.033315 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.034152 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.035326 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.036635 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.036798 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.040271 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.040291 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.043303 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.044045 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.046317 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.048124 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.050042 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.053805 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.053979 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.059894 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.063750 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.064677 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.065617 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.066546 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.067027 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.067508 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.068495 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.069470 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.070476 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.071501 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.072539 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.073618 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.074865 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.076104 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.077430 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.078831 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.079393 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.080488 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.082134 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.085199 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.088930 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.091700 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.092635 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.093583 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.094517 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.095452 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.096434 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.097418 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.098266 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.098433 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.099436 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.099533 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.100396 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.100586 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.101628 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.101731 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.102680 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.102987 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.103814 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.104235 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.104987 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.105658 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.105783 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.106159 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.107074 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.107282 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.108410 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.108718 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.109753 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.110382 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.111184 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.112399 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.113572 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.113677 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.114923 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.116163 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.117465 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.117560 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.119123 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.120617 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.122087 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.122703 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.123767 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.125746 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.126955 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.128009 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.128336 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.128964 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.130090 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.130507 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.131142 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.132268 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.133438 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.134086 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.134618 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.135747 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.136884 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.137657 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.138229 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.139671 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.140898 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.141240 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.142137 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.143391 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.144694 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.144876 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.145899 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.147481 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.149001 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.149399 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.150225 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.150508 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.151625 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.152214 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.152987 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.153916 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.154286 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.154462 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.155859 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.156880 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.157303 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.158777 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.159113 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.159273 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.160197 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.161508 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.162729 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.162930 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.164580 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.166088 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.166329 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.167714 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.169797 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.169950 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.171821 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.173687 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.173768 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.175721 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.178100 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.178276 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.182808 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.184292 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.188172 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.190291 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.196265 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.203213 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.210018 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.216702 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.218768 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.219871 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.220956 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.222134 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.223380 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.224668 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.225985 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.227559 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.235637 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.237877 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.240636 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.243785 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.247822 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.247841 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.248971 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.250068 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.251249 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.252502 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.253295 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.253812 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.255136 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.256553 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.259777 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.264515 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.266594 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.269193 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.272163 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.275976 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.277559 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.278283 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.279059 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.279881 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.280653 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.281692 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.281699 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.282405 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.283089 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.283866 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.284689 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.285553 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.286374 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.287248 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.288287 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.288380 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.289391 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.290654 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.291798 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.292502 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.292939 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.293932 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.294939 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.295386 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.296626 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.296852 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.298434 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.298535 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.300132 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.300398 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.301678 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.302376 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.303251 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.304870 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.306127 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.306536 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.306858 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.307637 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.308297 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.308506 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.309291 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.310168 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.310350 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.310890 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.311576 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.312425 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.312498 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.313342 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.314206 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.314565 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.315045 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.315925 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.316930 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.317107 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.318124 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.319399 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.319609 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.320565 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.321083 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.321851 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.321935 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.322579 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.322763 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.323275 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.324171 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.324176 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.324989 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.325946 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.326047 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.326757 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.327864 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.327876 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.328756 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.328952 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.329633 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.329865 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.330540 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.331384 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.331855 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.332404 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.333413 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.334395 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.335720 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.336649 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.338353 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.340343 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.341777 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.343434 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.345020 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.346610 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.347332 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.348339 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.348496 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.349345 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.350279 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.350383 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.350692 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.351434 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.351530 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.351950 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.352260 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.352440 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.352957 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.353392 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.353701 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.353874 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.354219 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.354533 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.355043 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.355371 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.355652 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.355888 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.356186 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.356863 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.357075 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.358173 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.358201 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.358283 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.359295 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.359307 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.360315 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.360428 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.360629 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.361207 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.361376 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.362230 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.362437 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.363321 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.363410 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.363690 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.364413 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.364948 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.365795 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.365963 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.366694 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.366799 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.367818 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.368057 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.368520 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.369421 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.369944 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.370525 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.370856 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.372218 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.372779 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.374700 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.374919 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.376629 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.377248 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.377512 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.378703 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.378710 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.379677 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.380080 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.380600 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.381102 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.381528 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.382437 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.382904 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.383431 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.383594 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.384257 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.385072 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.385949 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.386121 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.386604 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.386930 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.387912 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.388879 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.389397 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.389888 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.390568 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.390791 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.391842 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.393102 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.394351 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.395969 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.397185 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.397373 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.398732 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.400166 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.402085 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.404047 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.404214 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.405974 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.407894 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.410281 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.411212 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.412687 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.415720 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.418217 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.418535 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.419525 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.420216 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.420998 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.421824 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.422742 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.423579 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.424321 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.425305 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.425398 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.429926 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.431931 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.434383 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.434395 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.437306 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.439786 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.443295 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.448679 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.449207 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.449371 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.449773 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.450285 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.450376 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.450894 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.451134 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.451476 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.452124 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.452209 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.452693 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.453095 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.453292 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.454075 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.454084 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.454697 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.454945 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.455242 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.455943 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.456696 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.457439 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.458675 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.459783 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.459790 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.460751 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.461780 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.461878 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.462815 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.463794 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.464310 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.465469 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.467452 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.467461 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.469956 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.471331 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.479152 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.479719 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.480276 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.480930 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.481033 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.481754 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.481765 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.482498 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.482510 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.483256 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.483267 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.483913 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.484015 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.484749 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.484750 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.485587 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.485600 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.486248 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.486353 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.487082 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.487179 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.488032 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.488042 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.488760 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.488877 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.489411 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.490181 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.490278 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.490896 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.491262 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.491517 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.492460 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.492470 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.493453 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.493887 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.494496 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.495465 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.495570 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.497343 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.499142 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.501536 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.502398 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.502575 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.503131 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.503860 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.504627 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.505389 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.506123 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.506861 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.507614 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.508386 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.509005 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.509642 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.510423 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.511052 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.511771 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.512109 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.512623 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.512728 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.513267 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.513784 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.514285 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.514387 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.514990 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.515616 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.515816 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.516274 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.516892 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.517129 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.517517 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.518141 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.518442 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.518794 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.519441 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.519547 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.520253 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.520865 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.521319 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.521628 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.523057 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.523215 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.524508 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.525089 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.527083 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.530533 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.531374 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.532099 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.532827 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.533592 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.534351 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.535088 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.535833 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.536590 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.537363 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.537979 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.538611 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.539401 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.540030 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.540750 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.541483 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.542431 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.543206 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.543217 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.543807 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.544445 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.544738 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.545076 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.545717 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.546055 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.546416 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.547311 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.547403 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.548085 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.548312 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.549312 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.550193 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.552270 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.552284 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.554158 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.554626 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.556152 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.556500 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.558475 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.560866 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.562740 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.564306 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.565860 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.567641 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.569185 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.569521 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.570310 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.570806 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.571737 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.571810 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.572543 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.572555 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.573151 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.573304 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.574026 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.574064 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.574164 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.574663 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.574999 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.575310 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.576101 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.576222 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.576409 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.576919 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.577444 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.577699 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.578409 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.578927 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.579279 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.581735 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.582440 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.582540 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.584082 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.585950 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.586503 2784217 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.586599 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.587952 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.590342 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.593432 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.597687 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.598804 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.599292 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.600826 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.601009 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.601559 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.602298 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.603121 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.604223 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.605437 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.606384 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.609834 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.611624 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.613772 2784210 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.625562 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.643844 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.644749 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.645604 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.646498 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.647400 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.648295 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.649136 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.650073 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.650972 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.651920 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.652911 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.653864 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.655086 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.656088 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.657282 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.658350 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.659513 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.660872 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.664228 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.667227 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.670222 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.673886 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.677561 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.714860 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.715787 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.716727 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.717654 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.718592 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.719566 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.720543 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.721550 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.722570 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.723605 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.724678 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.725917 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.727157 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.728470 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.729856 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.731462 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.733104 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.736170 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.739871 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.749287 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.750323 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.751270 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.752394 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.753436 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.754561 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.755730 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.756894 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.757996 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.759131 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.760460 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.761923 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.763142 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.764364 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.765617 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.766873 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.768055 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.769633 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.771142 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.772628 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.774316 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.776316 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.778929 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.781106 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.784729 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.788350 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.791969 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.795588 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.800160 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.804730 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.810140 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.869956 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.871063 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.872165 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.873343 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.874583 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.875876 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.877187 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.878599 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.886538 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.888620 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.891223 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.894200 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.898010 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.903504 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.909988 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.927804 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.928523 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.929305 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.930128 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.930907 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.931739 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.932442 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.933128 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.933907 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.934729 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.935582 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.936406 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.937283 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.938387 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.939401 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.940669 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.941824 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.942958 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.944952 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.946640 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.948318 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.950279 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.952246 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.971106 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.971789 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.972480 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.973166 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.973863 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.974672 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.975486 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.976286 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.977159 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.978021 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.978880 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.979780 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.980619 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.981628 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.982633 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.983620 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.984944 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.985884 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.987594 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.989602 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.996542 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.997509 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.998471 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335840.999380 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.000299 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.001206 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.002145 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.002956 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.003768 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.004601 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.005568 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.006547 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.007509 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.008501 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.009384 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.010432 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.011676 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.012931 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.014547 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.015903 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.017262 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.018682 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.020605 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.022528 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.024452 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.026376 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.028762 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.031147 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.033937 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.036934 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.067153 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.067843 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.068622 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.069452 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.070371 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.071216 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.071949 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.072811 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.077397 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.079433 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.081822 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.084738 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.087248 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.096451 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.097012 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.097568 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.098082 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.098583 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.099170 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.099729 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.100292 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.100868 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.101477 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.102012 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.102709 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.103462 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.104201 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.105447 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.106416 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.107377 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.108355 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.109378 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.110364 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.112024 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.113812 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.117170 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.126738 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.127266 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.127786 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.128295 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/48\u001b[0m \u001b[37m\u001b[0m \u001b[1m22:51\u001b[0m 29s/step - loss: 2.1473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728335841.128811 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.129411 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.130030 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.130663 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.131278 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.131876 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.132495 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.133124 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.133773 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.134475 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.135085 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.135824 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.137211 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.138645 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.144557 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.145379 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.146106 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.146828 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.147592 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.148349 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.149085 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.149826 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.150575 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.151349 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.151962 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.152593 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.153382 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.154007 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.154725 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.155450 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.157004 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.158515 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.159822 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.161131 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.162013 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.163885 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.165767 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.167644 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.169617 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.185032 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.185624 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.186182 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.186819 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.187427 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.188067 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.188750 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.191723 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.192497 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.193715 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.196484 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.198574 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.200451 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.202408 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.204796 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.212035 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.213134 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.213636 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.215129 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.215840 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.216574 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.217393 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.218484 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.219694 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.220645 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.224064 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335841.228001 2784221 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 3.4169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 21:17:24.974825: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-07 21:17:24.974922: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-07 21:17:24.975079: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "W0000 00:00:1728335847.910769 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.910766 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.911059 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.911679 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.911769 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.911917 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.912330 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.912655 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.912789 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.913025 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.913360 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.913590 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.913830 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.914072 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.914299 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.914528 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.914787 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.914995 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.915220 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.915447 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.915677 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.915950 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.916189 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.916441 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.916674 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.916912 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.917136 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.917444 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.917707 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.917887 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.922597 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.922798 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.922938 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.923426 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.923698 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.923825 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.924057 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.924501 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.924641 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.924868 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.925393 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.925414 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.925925 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.926424 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.926595 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.926788 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.927228 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.927476 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.927699 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.928160 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.928363 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.928651 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.929120 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.929378 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.929607 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.930040 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.930304 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.930616 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.931093 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.931323 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.931552 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.932037 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.932249 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.932532 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.933088 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.933316 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.934428 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.935134 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.935162 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.935300 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.936016 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.936020 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.936143 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.936725 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.936921 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.936950 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.937452 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.937695 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.937883 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.938421 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.938627 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.939116 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.939854 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.940056 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.940092 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.940691 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.940909 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.941105 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.941662 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.941885 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.942080 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.942639 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.942950 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.943036 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.943431 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.943737 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.944080 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.944461 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.944768 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.946177 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.946557 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.946833 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.948087 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.948488 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.948744 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.949266 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.949707 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.949927 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.950888 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.951351 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.951529 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.968910 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.969010 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.969275 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.969604 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.969722 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.969925 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.970134 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.970263 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.970432 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.970674 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.971065 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.971163 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.971268 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.971764 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.971962 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.971973 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.972264 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.972675 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.972704 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.972877 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.973184 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.974091 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.974265 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.974562 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.976006 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.976176 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.976445 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.978525 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.978696 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.978901 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.981021 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.981253 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.981443 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.983000 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.983248 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.983426 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.985298 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.985570 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.985737 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.987540 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.987906 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335847.988026 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.030560 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.030579 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.030666 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.031295 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.031412 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.031459 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.031908 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.032068 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.032141 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.032448 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.032746 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.032859 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.033023 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.033306 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.033510 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.033615 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.033851 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.034106 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.034298 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.034464 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.034711 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.034917 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.035088 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.035310 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.035519 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.035697 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.035885 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.036195 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.036320 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.036485 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.036811 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.037043 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.037142 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.037457 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.037833 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.037929 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.038112 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.038556 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.038655 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.038880 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.039381 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.039497 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.039668 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.040087 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.040283 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.040454 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.040827 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.041063 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.041231 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.041576 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.041797 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.042402 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.042751 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.042969 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.043468 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.043816 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.044038 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.045351 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.045698 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.045922 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.046694 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.047054 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.047265 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.054410 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.054759 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.054926 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.054987 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.055385 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.055773 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.055796 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.055970 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.056462 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.056647 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.056723 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.057201 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.057408 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.057481 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.057758 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.058127 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.058230 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.058407 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.058694 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.058821 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.058994 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.059326 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.059545 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.059659 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.059919 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.060165 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.060341 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.060728 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.060998 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.061171 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.061453 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.061748 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.061924 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.062235 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.062642 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.062750 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.064473 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.064884 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.065068 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.066834 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.067253 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.067429 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.069110 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.069544 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.069720 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.073666 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.074108 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.074275 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.078233 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.078684 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.078860 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.081088 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.081711 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.084004 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.084727 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.084828 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.087721 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.169314 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.169445 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.169958 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.170141 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.170592 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.170794 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.171233 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.171430 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.171887 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.172083 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.172594 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.172815 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.172857 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.173263 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.173566 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.173632 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.173965 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.174236 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.174405 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.174709 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.174885 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.175133 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.175600 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.175705 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.175906 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.176539 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.176669 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.176768 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.177194 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.177604 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.177703 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.177901 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.178589 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.178777 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.178781 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.179850 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.179882 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.179983 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.180674 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.181040 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.181136 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.181490 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.182337 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.182372 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.182511 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.183815 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.183895 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.183908 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.184829 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.185285 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.185295 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.185892 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.187362 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.187428 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.187441 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.188514 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.189926 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.190023 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.190304 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.192464 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.192769 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.192845 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.197304 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.201419 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.201725 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.202242 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.202545 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.203028 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.203335 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.203961 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.204280 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.204888 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.205218 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.205724 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.206053 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.206270 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.206523 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.206861 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.207131 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.207293 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.207631 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.207933 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.208165 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.208515 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.208880 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.209456 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.209922 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.209930 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.210609 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.210783 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.211070 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.211595 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.211862 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.212457 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.212533 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.213412 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.214691 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.215419 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.215828 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.216041 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.217085 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.219793 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.220506 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.220679 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.224031 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.224787 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.225082 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.229345 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.232794 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.233654 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.234681 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.238116 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.239024 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.243500 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.246885 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.247875 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.252312 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.252494 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.253313 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.257953 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.420411 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.421288 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.422167 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.422978 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.423337 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.423860 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.424238 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.424816 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.425125 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.425735 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.425955 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.426675 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.426857 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.427992 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.428010 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.428315 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.428936 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.429433 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.429450 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.429874 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.430330 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.430553 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.430955 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.431172 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.431676 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.432112 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.432284 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.432786 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.433088 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.433398 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.434047 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.434221 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.434536 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.434992 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.435882 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.435928 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.436107 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.437527 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.437695 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.437709 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.438805 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.439057 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.439432 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.439940 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.440663 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.441070 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.441290 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.442539 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.442614 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.444151 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.444415 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.444643 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.445754 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.447468 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.447789 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.449374 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.449556 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.452674 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.452844 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.453913 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.457027 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.457687 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.462057 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.464399 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.465595 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.466901 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.467621 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.468222 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.468832 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.469357 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.470018 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.470776 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.471345 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.471952 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.472474 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.472816 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.473389 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.473978 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.474163 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.474671 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.475188 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.475400 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.475833 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.476681 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.476842 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.477129 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.478096 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.478174 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.478465 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.479275 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.479611 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.480586 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.480815 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.481953 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.482267 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.483549 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.484761 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.484944 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.486080 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.487429 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.488432 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.491505 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.493867 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.495128 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.499953 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.500496 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.503752 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.508145 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.509268 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.512116 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.516990 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.517754 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.521120 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.526158 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.526881 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.530398 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.536170 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.543790 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.548565 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.555131 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.880832 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.882176 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.883538 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.884806 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.886170 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.887683 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.889175 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.889443 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.890786 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.890885 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.892254 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.892509 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.893538 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.894522 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.894921 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.896425 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.896578 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.896864 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.898084 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.898450 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.898464 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.899581 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.899848 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.900298 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.901186 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.901377 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.902615 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.902788 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.903411 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.904151 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.905223 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.905486 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.905662 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.907215 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.907302 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.908294 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.909157 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.909228 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.911225 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.911397 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.911652 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.913024 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.914349 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.914748 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.914923 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.916752 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.917184 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.919164 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.920252 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.920851 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.921809 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.923605 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.924588 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.927685 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.929434 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.929751 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.931094 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.937363 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.938313 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.944204 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.946018 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.946234 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.948327 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.950636 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.952632 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.953021 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.955201 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.955435 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.957338 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.957518 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.959681 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.960067 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.961076 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.961708 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.961993 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.963135 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.963979 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.964249 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.965257 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.966373 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.966472 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.967595 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.968716 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.969050 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.969660 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.971010 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.972211 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.973042 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.974254 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.975341 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.976820 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.977718 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.978773 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.980229 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.980780 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.983052 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.985410 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.989401 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.993359 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335848.997312 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.002654 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.010253 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.010814 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.019746 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.026508 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.028067 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.036256 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.043788 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.044684 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.053845 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.061664 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.062236 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.071702 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.081123 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.098566 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.107669 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.119263 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.775075 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.777294 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.779462 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.781653 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.784000 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.786396 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.787725 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.788812 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.789977 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.791345 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.792188 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.793985 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.794397 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.796130 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.796902 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.797008 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.798369 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.799344 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.800087 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.800585 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.801768 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.802817 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.803200 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.804334 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.805175 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.806472 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.806997 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.807624 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.810099 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.810174 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.811110 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.812755 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.813191 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.815395 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.815701 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.816315 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.818329 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.819609 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.820465 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.821392 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.824402 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.824571 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.826336 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.827862 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.829107 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.832710 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.832731 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.833972 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.837438 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.839953 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.842317 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.846309 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.848315 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.854677 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.855317 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.858831 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.862348 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.866836 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.868933 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.870532 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.872519 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.874101 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.876108 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.877460 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.877496 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.880684 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.881069 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.881581 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.884407 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.884694 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.886250 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.888001 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.889340 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.889841 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.891432 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.893085 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.894125 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.895565 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.896742 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.898615 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.900444 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.900462 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.904190 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.904672 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.908622 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.909466 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.913289 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.913373 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.917702 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.921835 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.922291 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.937201 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.946096 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.948572 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.964593 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.973523 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.981832 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335849.998386 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335850.007296 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335850.013602 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335850.030457 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335850.039292 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335850.045506 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335850.061992 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335850.071365 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335850.081196 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335850.097364 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335850.107550 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335850.159747 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335850.178364 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335850.187435 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.507373 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.511189 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.515035 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.518923 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.523067 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.527382 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.531678 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.535642 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.536272 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.539539 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.540433 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.541145 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.543460 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.544288 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.546848 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.547443 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.548181 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.551647 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.552118 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.552982 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.556034 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.556316 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.559231 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.560361 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.560671 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.564966 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.565228 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.565793 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.569714 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.570368 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.575066 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.575067 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.576145 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.580881 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.582300 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.584479 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.587061 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.588631 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.593409 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.594164 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.595357 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.600118 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.604612 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.605799 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.609391 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.614135 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.618057 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.618942 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.623931 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.628785 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.635691 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.640552 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.648303 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.652017 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.653060 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.654032 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.656078 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.658118 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.660098 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.662453 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.664697 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.666941 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.669356 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.671587 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.673961 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.676893 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.679847 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.682374 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.683281 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.685287 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.685767 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.687239 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.687415 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.689287 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.689629 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.690769 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.691280 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.691713 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.693831 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.693998 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.695853 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.696397 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.698359 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.698438 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.700625 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.701062 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.703074 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.703137 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.703250 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.705676 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.705757 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.707526 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.708167 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.708244 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.710573 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.712004 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.713642 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.716753 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.717774 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.719375 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.722552 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.722826 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.723975 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.727962 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.740305 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.740390 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.741256 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.742070 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.742787 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.743534 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.744278 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.744755 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.745195 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.746100 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.749260 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.750795 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.755076 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.755247 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.757204 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.760380 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.761298 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.765228 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.768508 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.769707 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.774042 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.778736 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.779555 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.780277 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.781034 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.781781 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.782734 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.782916 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.783660 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.784898 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.788394 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.792786 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.797846 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.802503 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.802744 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.807128 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.811491 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.820321 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.840623 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.932949 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.933710 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.934444 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.935172 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.935938 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.936762 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.937548 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.938304 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.939056 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.939898 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.940676 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.941477 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.942364 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.943256 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.944333 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.945534 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.946754 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.948267 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.949778 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.952753 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.956974 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.967617 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.971154 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.971915 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.972648 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.973369 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.974129 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.974966 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.975755 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.976351 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.976540 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.976856 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.977535 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.977553 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.978015 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.978389 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.978896 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.979182 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.979991 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.980888 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.981800 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.981898 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.982984 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.984340 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.984352 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.985585 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.986689 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.987133 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.988658 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.990567 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.991649 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.993177 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.995894 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.996167 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335851.998712 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.007083 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.015845 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.016336 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.016818 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.017287 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.018157 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.019250 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.019711 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.020164 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.020606 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.021066 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.021167 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.021816 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.022291 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.022809 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.023264 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.023429 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.023722 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.024313 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.024914 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.025489 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.025764 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.026062 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.026639 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.027235 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.029058 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.029657 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.029820 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.030656 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.031694 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.032251 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.034808 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.037396 2784179 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.037559 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.058074 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.058538 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.058990 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.059431 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.059895 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.060544 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.061015 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.061525 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.061950 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.062397 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.062983 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.063578 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.064148 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.064704 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.065283 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.065875 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.067687 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.068403 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.069240 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.070271 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.075930 2784208 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.488387 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.490501 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.492547 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.494542 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.496720 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.498886 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.501257 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.503482 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.505772 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.508553 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.511460 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.513959 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.517251 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.522086 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.533745 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.538000 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.542334 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.547969 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.559859 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.560678 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.561405 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.562163 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.562923 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.563838 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.564759 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.569510 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.573878 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.578951 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.583886 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.588308 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.592738 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.601549 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.751976 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.752745 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.753494 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.754222 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.754988 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.755817 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.756614 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.757376 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.758119 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.758970 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.759750 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.760550 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.761438 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.762316 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.763393 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.764585 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.765794 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.767332 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.768846 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.771832 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.776049 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.786679 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.795241 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.795730 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.796223 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.796687 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.797553 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.800314 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.802609 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.804925 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.808770 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.811374 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.813937 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.816568 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.837087 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.837552 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.838012 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.838450 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.838922 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.839572 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.840042 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.840560 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.840984 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.841430 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.842022 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.842617 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.843187 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.843750 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.844329 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.844922 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.846726 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.847443 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.848281 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.849310 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728335852.854920 2784192 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 253ms/step - loss: 3.3712 - val_loss: 2.0678 - learning_rate: 0.0010\n",
      "Epoch 2/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 21:17:33.078653: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 21:17:37.358109: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - loss: 0.0599 - val_loss: 0.9899 - learning_rate: 0.0010\n",
      "Epoch 3/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 0.0408 - val_loss: 1.9264 - learning_rate: 0.0010\n",
      "Epoch 4/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 21:17:44.161600: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0324 - val_loss: 1.9825 - learning_rate: 0.0010\n",
      "Epoch 5/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0278 - val_loss: 1.7505 - learning_rate: 0.0010\n",
      "Epoch 6/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0251"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 21:17:59.327343: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - loss: 0.0251 - val_loss: 1.4857 - learning_rate: 0.0010\n",
      "Epoch 7/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 122ms/step - loss: 0.0229 - val_loss: 1.5278 - learning_rate: 0.0010\n",
      "Epoch 8/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0215 - val_loss: 1.7289 - learning_rate: 0.0010\n",
      "Epoch 9/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0202 - val_loss: 2.0054 - learning_rate: 0.0010\n",
      "Epoch 10/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0200 - val_loss: 2.2020 - learning_rate: 0.0010\n",
      "Epoch 11/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0196 - val_loss: 2.4973 - learning_rate: 0.0010\n",
      "Epoch 12/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 21:18:28.814729: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0190 - val_loss: 2.6672 - learning_rate: 0.0010\n",
      "Epoch 13/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0185 - val_loss: 2.3772 - learning_rate: 0.0010\n",
      "Epoch 14/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0179 - val_loss: 1.8331 - learning_rate: 0.0010\n",
      "Epoch 15/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0177\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0177 - val_loss: 1.1997 - learning_rate: 0.0010\n",
      "Epoch 16/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0173 - val_loss: 0.5704 - learning_rate: 9.0000e-04\n",
      "Epoch 17/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 0.0169 - val_loss: 0.0941 - learning_rate: 9.0000e-04\n",
      "Epoch 18/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0170 - val_loss: 0.0465 - learning_rate: 9.0000e-04\n",
      "Epoch 19/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 0.0167 - val_loss: 0.0340 - learning_rate: 9.0000e-04\n",
      "Epoch 20/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 0.0170 - val_loss: 0.0211 - learning_rate: 9.0000e-04\n",
      "Epoch 21/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0167 - val_loss: 0.0179 - learning_rate: 9.0000e-04\n",
      "Epoch 22/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0165"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 21:19:28.184969: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0165 - val_loss: 0.0185 - learning_rate: 9.0000e-04\n",
      "Epoch 23/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0163 - val_loss: 0.0164 - learning_rate: 9.0000e-04\n",
      "Epoch 24/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 0.0163 - val_loss: 0.0169 - learning_rate: 9.0000e-04\n",
      "Epoch 25/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0163 - val_loss: 0.0170 - learning_rate: 9.0000e-04\n",
      "Epoch 26/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - loss: 0.0162 - val_loss: 0.0195 - learning_rate: 9.0000e-04\n",
      "Epoch 27/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 135ms/step - loss: 0.0163 - val_loss: 0.0162 - learning_rate: 9.0000e-04\n",
      "Epoch 28/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0161 - val_loss: 0.0167 - learning_rate: 9.0000e-04\n",
      "Epoch 29/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 0.0158 - val_loss: 0.0167 - learning_rate: 9.0000e-04\n",
      "Epoch 30/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0159 - val_loss: 0.0166 - learning_rate: 9.0000e-04\n",
      "Epoch 31/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0158 - val_loss: 0.0171 - learning_rate: 9.0000e-04\n",
      "Epoch 32/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0157 - val_loss: 0.0173 - learning_rate: 9.0000e-04\n",
      "Epoch 33/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 0.0157 - val_loss: 0.0174 - learning_rate: 9.0000e-04\n",
      "Epoch 34/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 0.0156 - val_loss: 0.0165 - learning_rate: 9.0000e-04\n",
      "Epoch 35/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0157 - val_loss: 0.0161 - learning_rate: 9.0000e-04\n",
      "Epoch 36/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 0.0155 - val_loss: 0.0164 - learning_rate: 9.0000e-04\n",
      "Epoch 37/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0153 - val_loss: 0.0160 - learning_rate: 9.0000e-04\n",
      "Epoch 38/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 0.0155 - val_loss: 0.0167 - learning_rate: 9.0000e-04\n",
      "Epoch 39/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 0.0155 - val_loss: 0.0160 - learning_rate: 9.0000e-04\n",
      "Epoch 40/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0155 - val_loss: 0.0172 - learning_rate: 9.0000e-04\n",
      "Epoch 41/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0151 - val_loss: 0.0177 - learning_rate: 9.0000e-04\n",
      "Epoch 42/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 0.0150 - val_loss: 0.0156 - learning_rate: 9.0000e-04\n",
      "Epoch 43/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0151 - val_loss: 0.0158 - learning_rate: 9.0000e-04\n",
      "Epoch 44/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 21:21:25.552786: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0149 - val_loss: 0.0157 - learning_rate: 9.0000e-04\n",
      "Epoch 45/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 0.0151 - val_loss: 0.0162 - learning_rate: 9.0000e-04\n",
      "Epoch 46/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0150 - val_loss: 0.0153 - learning_rate: 9.0000e-04\n",
      "Epoch 47/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0150 - val_loss: 0.0159 - learning_rate: 9.0000e-04\n",
      "Epoch 48/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0150 - val_loss: 0.0167 - learning_rate: 9.0000e-04\n",
      "Epoch 49/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0148 - val_loss: 0.0161 - learning_rate: 9.0000e-04\n",
      "Epoch 50/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0150 - val_loss: 0.0158 - learning_rate: 9.0000e-04\n",
      "Epoch 51/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0146 - val_loss: 0.0155 - learning_rate: 9.0000e-04\n",
      "Epoch 52/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0147 - val_loss: 0.0183 - learning_rate: 9.0000e-04\n",
      "Epoch 53/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - loss: 0.0146 - val_loss: 0.0169 - learning_rate: 9.0000e-04\n",
      "Epoch 54/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - loss: 0.0145 - val_loss: 0.0164 - learning_rate: 9.0000e-04\n",
      "Epoch 55/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 0.0144 - val_loss: 0.0163 - learning_rate: 9.0000e-04\n",
      "Epoch 56/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0143 - val_loss: 0.0154 - learning_rate: 9.0000e-04\n",
      "Epoch 57/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0144 - val_loss: 0.0163 - learning_rate: 9.0000e-04\n",
      "Epoch 58/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0145 - val_loss: 0.0153 - learning_rate: 9.0000e-04\n",
      "Epoch 59/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0139\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 0.0139 - val_loss: 0.0167 - learning_rate: 9.0000e-04\n",
      "Epoch 60/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0136 - val_loss: 0.0149 - learning_rate: 8.1000e-04\n",
      "Epoch 61/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0135 - val_loss: 0.0148 - learning_rate: 8.1000e-04\n",
      "Epoch 62/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0132 - val_loss: 0.0152 - learning_rate: 8.1000e-04\n",
      "Epoch 63/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 0.0134 - val_loss: 0.0145 - learning_rate: 8.1000e-04\n",
      "Epoch 64/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0131 - val_loss: 0.0154 - learning_rate: 8.1000e-04\n",
      "Epoch 65/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 0.0131 - val_loss: 0.0163 - learning_rate: 8.1000e-04\n",
      "Epoch 66/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0132 - val_loss: 0.0152 - learning_rate: 8.1000e-04\n",
      "Epoch 67/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 0.0133 - val_loss: 0.0149 - learning_rate: 8.1000e-04\n",
      "Epoch 68/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0129 - val_loss: 0.0154 - learning_rate: 8.1000e-04\n",
      "Epoch 69/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 0.0130 - val_loss: 0.0144 - learning_rate: 8.1000e-04\n",
      "Epoch 70/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step - loss: 0.0127 - val_loss: 0.0167 - learning_rate: 8.1000e-04\n",
      "Epoch 71/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 0.0128 - val_loss: 0.0150 - learning_rate: 8.1000e-04\n",
      "Epoch 72/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0128 - val_loss: 0.0149 - learning_rate: 8.1000e-04\n",
      "Epoch 73/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0126 - val_loss: 0.0147 - learning_rate: 8.1000e-04\n",
      "Epoch 74/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 0.0128 - val_loss: 0.0149 - learning_rate: 8.1000e-04\n",
      "Epoch 75/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 0.0124 - val_loss: 0.0146 - learning_rate: 8.1000e-04\n",
      "Epoch 76/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0127 - val_loss: 0.0142 - learning_rate: 8.1000e-04\n",
      "Epoch 77/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0121 - val_loss: 0.0136 - learning_rate: 8.1000e-04\n",
      "Epoch 78/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 0.0123 - val_loss: 0.0141 - learning_rate: 8.1000e-04\n",
      "Epoch 79/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 0.0119 - val_loss: 0.0142 - learning_rate: 8.1000e-04\n",
      "Epoch 80/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0120 - val_loss: 0.0147 - learning_rate: 8.1000e-04\n",
      "Epoch 81/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 0.0123 - val_loss: 0.0168 - learning_rate: 8.1000e-04\n",
      "Epoch 82/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0118 - val_loss: 0.0141 - learning_rate: 8.1000e-04\n",
      "Epoch 83/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0117 - val_loss: 0.0133 - learning_rate: 8.1000e-04\n",
      "Epoch 84/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 0.0116 - val_loss: 0.0144 - learning_rate: 8.1000e-04\n",
      "Epoch 85/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0117 - val_loss: 0.0143 - learning_rate: 8.1000e-04\n",
      "Epoch 86/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0117"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 21:25:22.362787: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0117 - val_loss: 0.0161 - learning_rate: 8.1000e-04\n",
      "Epoch 87/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0115 - val_loss: 0.0143 - learning_rate: 8.1000e-04\n",
      "Epoch 88/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 0.0117 - val_loss: 0.0142 - learning_rate: 8.1000e-04\n",
      "Epoch 89/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0113 - val_loss: 0.0149 - learning_rate: 8.1000e-04\n",
      "Epoch 90/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0111 - val_loss: 0.0151 - learning_rate: 8.1000e-04\n",
      "Epoch 91/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0111 - val_loss: 0.0142 - learning_rate: 8.1000e-04\n",
      "Epoch 92/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 0.0110 - val_loss: 0.0142 - learning_rate: 8.1000e-04\n",
      "Epoch 93/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0109 - val_loss: 0.0144 - learning_rate: 8.1000e-04\n",
      "Epoch 94/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0112 - val_loss: 0.0148 - learning_rate: 8.1000e-04\n",
      "Epoch 95/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0108 - val_loss: 0.0160 - learning_rate: 8.1000e-04\n",
      "Epoch 96/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0107\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 0.0107 - val_loss: 0.0149 - learning_rate: 8.1000e-04\n",
      "Epoch 97/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0102 - val_loss: 0.0146 - learning_rate: 7.2900e-04\n",
      "Epoch 98/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0097 - val_loss: 0.0145 - learning_rate: 7.2900e-04\n",
      "Epoch 99/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0095 - val_loss: 0.0161 - learning_rate: 7.2900e-04\n",
      "Epoch 100/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 0.0098 - val_loss: 0.0160 - learning_rate: 7.2900e-04\n",
      "Epoch 101/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0091 - val_loss: 0.0181 - learning_rate: 7.2900e-04\n",
      "Epoch 102/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0094 - val_loss: 0.0153 - learning_rate: 7.2900e-04\n",
      "Epoch 103/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0091 - val_loss: 0.0157 - learning_rate: 7.2900e-04\n",
      "Epoch 104/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 0.0090 - val_loss: 0.0142 - learning_rate: 7.2900e-04\n",
      "Epoch 105/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 0.0091 - val_loss: 0.0161 - learning_rate: 7.2900e-04\n",
      "Epoch 106/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0090 - val_loss: 0.0150 - learning_rate: 7.2900e-04\n",
      "Epoch 107/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0088 - val_loss: 0.0152 - learning_rate: 7.2900e-04\n",
      "Epoch 108/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0088 - val_loss: 0.0151 - learning_rate: 7.2900e-04\n",
      "Epoch 109/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0086\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0086 - val_loss: 0.0154 - learning_rate: 7.2900e-04\n",
      "Epoch 110/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0081 - val_loss: 0.0187 - learning_rate: 6.5610e-04\n",
      "Epoch 111/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 0.0078 - val_loss: 0.0142 - learning_rate: 6.5610e-04\n",
      "Epoch 112/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0075 - val_loss: 0.0156 - learning_rate: 6.5610e-04\n",
      "Epoch 113/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0074 - val_loss: 0.0143 - learning_rate: 6.5610e-04\n",
      "Epoch 114/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0070 - val_loss: 0.0160 - learning_rate: 6.5610e-04\n",
      "Epoch 115/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0068 - val_loss: 0.0172 - learning_rate: 6.5610e-04\n",
      "Epoch 116/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0067 - val_loss: 0.0162 - learning_rate: 6.5610e-04\n",
      "Epoch 117/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0065 - val_loss: 0.0160 - learning_rate: 6.5610e-04\n",
      "Epoch 118/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0067 - val_loss: 0.0164 - learning_rate: 6.5610e-04\n",
      "Epoch 119/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0063 - val_loss: 0.0160 - learning_rate: 6.5610e-04\n",
      "Epoch 120/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0063 - val_loss: 0.0157 - learning_rate: 6.5610e-04\n",
      "Epoch 121/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 0.0059 - val_loss: 0.0158 - learning_rate: 6.5610e-04\n",
      "Epoch 122/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0058\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0058 - val_loss: 0.0160 - learning_rate: 6.5610e-04\n",
      "Epoch 123/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0054 - val_loss: 0.0149 - learning_rate: 5.9049e-04\n",
      "Epoch 124/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 0.0048 - val_loss: 0.0152 - learning_rate: 5.9049e-04\n",
      "Epoch 125/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0047 - val_loss: 0.0182 - learning_rate: 5.9049e-04\n",
      "Epoch 126/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0045 - val_loss: 0.0168 - learning_rate: 5.9049e-04\n",
      "Epoch 127/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0044 - val_loss: 0.0151 - learning_rate: 5.9049e-04\n",
      "Epoch 128/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0043 - val_loss: 0.0153 - learning_rate: 5.9049e-04\n",
      "Epoch 129/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0042 - val_loss: 0.0158 - learning_rate: 5.9049e-04\n",
      "Epoch 130/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0041 - val_loss: 0.0164 - learning_rate: 5.9049e-04\n",
      "Epoch 131/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 0.0041 - val_loss: 0.0166 - learning_rate: 5.9049e-04\n",
      "Epoch 132/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0041 - val_loss: 0.0156 - learning_rate: 5.9049e-04\n",
      "Epoch 133/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0037 - val_loss: 0.0161 - learning_rate: 5.9049e-04\n",
      "Epoch 134/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0038 - val_loss: 0.0147 - learning_rate: 5.9049e-04\n",
      "Epoch 135/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0037\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0037 - val_loss: 0.0159 - learning_rate: 5.9049e-04\n",
      "Epoch 136/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0031 - val_loss: 0.0147 - learning_rate: 5.3144e-04\n",
      "Epoch 137/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0030 - val_loss: 0.0155 - learning_rate: 5.3144e-04\n",
      "Epoch 138/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 0.0030 - val_loss: 0.0148 - learning_rate: 5.3144e-04\n",
      "Epoch 139/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 0.0028 - val_loss: 0.0144 - learning_rate: 5.3144e-04\n",
      "Epoch 140/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0027 - val_loss: 0.0150 - learning_rate: 5.3144e-04\n",
      "Epoch 141/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0026 - val_loss: 0.0143 - learning_rate: 5.3144e-04\n",
      "Epoch 142/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0026 - val_loss: 0.0148 - learning_rate: 5.3144e-04\n",
      "Epoch 143/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0026 - val_loss: 0.0158 - learning_rate: 5.3144e-04\n",
      "Epoch 144/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 0.0027 - val_loss: 0.0155 - learning_rate: 5.3144e-04\n",
      "Epoch 145/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0026 - val_loss: 0.0158 - learning_rate: 5.3144e-04\n",
      "Epoch 146/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0024 - val_loss: 0.0148 - learning_rate: 5.3144e-04\n",
      "Epoch 147/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 0.0026 - val_loss: 0.0141 - learning_rate: 5.3144e-04\n",
      "Epoch 148/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0023\n",
      "Epoch 148: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0023 - val_loss: 0.0142 - learning_rate: 5.3144e-04\n",
      "Epoch 149/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0022 - val_loss: 0.0140 - learning_rate: 4.7830e-04\n",
      "Epoch 150/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0021 - val_loss: 0.0160 - learning_rate: 4.7830e-04\n",
      "Epoch 151/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0019 - val_loss: 0.0144 - learning_rate: 4.7830e-04\n",
      "Epoch 152/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 0.0019 - val_loss: 0.0152 - learning_rate: 4.7830e-04\n",
      "Epoch 153/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0020 - val_loss: 0.0150 - learning_rate: 4.7830e-04\n",
      "Epoch 154/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0021 - val_loss: 0.0148 - learning_rate: 4.7830e-04\n",
      "Epoch 155/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0021 - val_loss: 0.0143 - learning_rate: 4.7830e-04\n",
      "Epoch 156/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0019 - val_loss: 0.0149 - learning_rate: 4.7830e-04\n",
      "Epoch 157/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0019 - val_loss: 0.0147 - learning_rate: 4.7830e-04\n",
      "Epoch 158/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0019 - val_loss: 0.0138 - learning_rate: 4.7830e-04\n",
      "Epoch 159/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 0.0020 - val_loss: 0.0139 - learning_rate: 4.7830e-04\n",
      "Epoch 160/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0018 - val_loss: 0.0143 - learning_rate: 4.7830e-04\n",
      "Epoch 161/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0020\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0020 - val_loss: 0.0144 - learning_rate: 4.7830e-04\n",
      "Epoch 162/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0019 - val_loss: 0.0144 - learning_rate: 4.3047e-04\n",
      "Epoch 163/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0018 - val_loss: 0.0139 - learning_rate: 4.3047e-04\n",
      "Epoch 164/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0016 - val_loss: 0.0136 - learning_rate: 4.3047e-04\n",
      "Epoch 165/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 0.0016 - val_loss: 0.0149 - learning_rate: 4.3047e-04\n",
      "Epoch 166/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0016 - val_loss: 0.0143 - learning_rate: 4.3047e-04\n",
      "Epoch 167/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0016 - val_loss: 0.0142 - learning_rate: 4.3047e-04\n",
      "Epoch 168/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 0.0017 - val_loss: 0.0142 - learning_rate: 4.3047e-04\n",
      "Epoch 169/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0015 - val_loss: 0.0149 - learning_rate: 4.3047e-04\n",
      "Epoch 170/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0019 - val_loss: 0.0140 - learning_rate: 4.3047e-04\n",
      "Epoch 171/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0017 - val_loss: 0.0144 - learning_rate: 4.3047e-04\n",
      "Epoch 172/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 21:33:14.732669: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0017 - val_loss: 0.0146 - learning_rate: 4.3047e-04\n",
      "Epoch 173/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0015 - val_loss: 0.0143 - learning_rate: 4.3047e-04\n",
      "Epoch 174/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0016\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0016 - val_loss: 0.0143 - learning_rate: 4.3047e-04\n",
      "Epoch 175/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - loss: 0.0016 - val_loss: 0.0144 - learning_rate: 3.8742e-04\n",
      "Epoch 176/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - loss: 0.0015 - val_loss: 0.0143 - learning_rate: 3.8742e-04\n",
      "Epoch 177/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 120ms/step - loss: 0.0015 - val_loss: 0.0146 - learning_rate: 3.8742e-04\n",
      "Epoch 178/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0016 - val_loss: 0.0137 - learning_rate: 3.8742e-04\n",
      "Epoch 179/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0014 - val_loss: 0.0136 - learning_rate: 3.8742e-04\n",
      "Epoch 180/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 0.0014 - val_loss: 0.0137 - learning_rate: 3.8742e-04\n",
      "Epoch 181/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0014 - val_loss: 0.0137 - learning_rate: 3.8742e-04\n",
      "Epoch 182/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 0.0013 - val_loss: 0.0137 - learning_rate: 3.8742e-04\n",
      "Epoch 183/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0014 - val_loss: 0.0136 - learning_rate: 3.8742e-04\n",
      "Epoch 184/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 0.0016 - val_loss: 0.0145 - learning_rate: 3.8742e-04\n",
      "Epoch 185/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0016 - val_loss: 0.0143 - learning_rate: 3.8742e-04\n",
      "Epoch 186/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 0.0014 - val_loss: 0.0145 - learning_rate: 3.8742e-04\n",
      "Epoch 187/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0015\n",
      "Epoch 187: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0015 - val_loss: 0.0138 - learning_rate: 3.8742e-04\n",
      "Epoch 188/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 0.0014 - val_loss: 0.0133 - learning_rate: 3.4868e-04\n",
      "Epoch 189/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0012 - val_loss: 0.0138 - learning_rate: 3.4868e-04\n",
      "Epoch 190/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 0.0013 - val_loss: 0.0135 - learning_rate: 3.4868e-04\n",
      "Epoch 191/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0013 - val_loss: 0.0138 - learning_rate: 3.4868e-04\n",
      "Epoch 192/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0013 - val_loss: 0.0134 - learning_rate: 3.4868e-04\n",
      "Epoch 193/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 0.0013 - val_loss: 0.0131 - learning_rate: 3.4868e-04\n",
      "Epoch 194/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0013 - val_loss: 0.0139 - learning_rate: 3.4868e-04\n",
      "Epoch 195/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0012 - val_loss: 0.0138 - learning_rate: 3.4868e-04\n",
      "Epoch 196/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0013 - val_loss: 0.0134 - learning_rate: 3.4868e-04\n",
      "Epoch 197/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0013 - val_loss: 0.0136 - learning_rate: 3.4868e-04\n",
      "Epoch 198/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 0.0013 - val_loss: 0.0139 - learning_rate: 3.4868e-04\n",
      "Epoch 199/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0014 - val_loss: 0.0136 - learning_rate: 3.4868e-04\n",
      "Epoch 200/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 0.0015 - val_loss: 0.0137 - learning_rate: 3.4868e-04\n",
      "Epoch 201/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 0.0014 - val_loss: 0.0138 - learning_rate: 3.4868e-04\n",
      "Epoch 202/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0015 - val_loss: 0.0135 - learning_rate: 3.4868e-04\n",
      "Epoch 203/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0015 - val_loss: 0.0136 - learning_rate: 3.4868e-04\n",
      "Epoch 204/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0014 - val_loss: 0.0140 - learning_rate: 3.4868e-04\n",
      "Epoch 205/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0014 - val_loss: 0.0136 - learning_rate: 3.4868e-04\n",
      "Epoch 206/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0014\n",
      "Epoch 206: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 0.0014 - val_loss: 0.0138 - learning_rate: 3.4868e-04\n",
      "Epoch 207/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 0.0014 - val_loss: 0.0145 - learning_rate: 3.1381e-04\n",
      "Epoch 208/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0013 - val_loss: 0.0134 - learning_rate: 3.1381e-04\n",
      "Epoch 209/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 0.0013 - val_loss: 0.0132 - learning_rate: 3.1381e-04\n",
      "Epoch 210/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0012 - val_loss: 0.0136 - learning_rate: 3.1381e-04\n",
      "Epoch 211/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0012 - val_loss: 0.0134 - learning_rate: 3.1381e-04\n",
      "Epoch 212/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0012 - val_loss: 0.0136 - learning_rate: 3.1381e-04\n",
      "Epoch 213/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0012 - val_loss: 0.0132 - learning_rate: 3.1381e-04\n",
      "Epoch 214/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0012 - val_loss: 0.0135 - learning_rate: 3.1381e-04\n",
      "Epoch 215/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0012 - val_loss: 0.0136 - learning_rate: 3.1381e-04\n",
      "Epoch 216/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0013 - val_loss: 0.0131 - learning_rate: 3.1381e-04\n",
      "Epoch 217/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 0.0012 - val_loss: 0.0134 - learning_rate: 3.1381e-04\n",
      "Epoch 218/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0012 - val_loss: 0.0134 - learning_rate: 3.1381e-04\n",
      "Epoch 219/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0012\n",
      "Epoch 219: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0012 - val_loss: 0.0135 - learning_rate: 3.1381e-04\n",
      "Epoch 220/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0012 - val_loss: 0.0140 - learning_rate: 2.8243e-04\n",
      "Epoch 221/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0011 - val_loss: 0.0134 - learning_rate: 2.8243e-04\n",
      "Epoch 222/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0011 - val_loss: 0.0135 - learning_rate: 2.8243e-04\n",
      "Epoch 223/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 9.6887e-04 - val_loss: 0.0133 - learning_rate: 2.8243e-04\n",
      "Epoch 224/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 9.7915e-04 - val_loss: 0.0139 - learning_rate: 2.8243e-04\n",
      "Epoch 225/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0011 - val_loss: 0.0127 - learning_rate: 2.8243e-04\n",
      "Epoch 226/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0011 - val_loss: 0.0138 - learning_rate: 2.8243e-04\n",
      "Epoch 227/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 9.8309e-04 - val_loss: 0.0138 - learning_rate: 2.8243e-04\n",
      "Epoch 228/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 9.9327e-04 - val_loss: 0.0137 - learning_rate: 2.8243e-04\n",
      "Epoch 229/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0010 - val_loss: 0.0132 - learning_rate: 2.8243e-04\n",
      "Epoch 230/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0010 - val_loss: 0.0132 - learning_rate: 2.8243e-04\n",
      "Epoch 231/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 0.0011 - val_loss: 0.0137 - learning_rate: 2.8243e-04\n",
      "Epoch 232/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0012 - val_loss: 0.0139 - learning_rate: 2.8243e-04\n",
      "Epoch 233/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 0.0011 - val_loss: 0.0136 - learning_rate: 2.8243e-04\n",
      "Epoch 234/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0010 - val_loss: 0.0135 - learning_rate: 2.8243e-04\n",
      "Epoch 235/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0011 - val_loss: 0.0138 - learning_rate: 2.8243e-04\n",
      "Epoch 236/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0011 - val_loss: 0.0134 - learning_rate: 2.8243e-04\n",
      "Epoch 237/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0012 - val_loss: 0.0133 - learning_rate: 2.8243e-04\n",
      "Epoch 238/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0011\n",
      "Epoch 238: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 0.0011 - val_loss: 0.0135 - learning_rate: 2.8243e-04\n",
      "Epoch 239/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0010 - val_loss: 0.0135 - learning_rate: 2.5419e-04\n",
      "Epoch 240/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0010 - val_loss: 0.0134 - learning_rate: 2.5419e-04\n",
      "Epoch 241/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 9.7080e-04 - val_loss: 0.0130 - learning_rate: 2.5419e-04\n",
      "Epoch 242/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 9.4033e-04 - val_loss: 0.0137 - learning_rate: 2.5419e-04\n",
      "Epoch 243/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 9.8048e-04 - val_loss: 0.0131 - learning_rate: 2.5419e-04\n",
      "Epoch 244/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 9.8653e-04 - val_loss: 0.0129 - learning_rate: 2.5419e-04\n",
      "Epoch 245/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 9.3586e-04 - val_loss: 0.0132 - learning_rate: 2.5419e-04\n",
      "Epoch 246/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 9.9074e-04 - val_loss: 0.0130 - learning_rate: 2.5419e-04\n",
      "Epoch 247/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0010 - val_loss: 0.0134 - learning_rate: 2.5419e-04\n",
      "Epoch 248/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 9.7684e-04 - val_loss: 0.0127 - learning_rate: 2.5419e-04\n",
      "Epoch 249/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 8.9226e-04 - val_loss: 0.0133 - learning_rate: 2.5419e-04\n",
      "Epoch 250/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 9.5677e-04 - val_loss: 0.0129 - learning_rate: 2.5419e-04\n",
      "Epoch 251/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 9.4499e-04\n",
      "Epoch 251: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 9.4627e-04 - val_loss: 0.0130 - learning_rate: 2.5419e-04\n",
      "Epoch 252/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 8.5452e-04 - val_loss: 0.0133 - learning_rate: 2.2877e-04\n",
      "Epoch 253/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 7.6519e-04 - val_loss: 0.0128 - learning_rate: 2.2877e-04\n",
      "Epoch 254/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 8.1840e-04 - val_loss: 0.0128 - learning_rate: 2.2877e-04\n",
      "Epoch 255/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 8.6608e-04 - val_loss: 0.0129 - learning_rate: 2.2877e-04\n",
      "Epoch 256/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.9231e-04 - val_loss: 0.0127 - learning_rate: 2.2877e-04\n",
      "Epoch 257/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 8.0879e-04 - val_loss: 0.0127 - learning_rate: 2.2877e-04\n",
      "Epoch 258/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.8054e-04 - val_loss: 0.0134 - learning_rate: 2.2877e-04\n",
      "Epoch 259/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 8.3805e-04 - val_loss: 0.0128 - learning_rate: 2.2877e-04\n",
      "Epoch 260/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.7979e-04 - val_loss: 0.0130 - learning_rate: 2.2877e-04\n",
      "Epoch 261/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 8.4115e-04 - val_loss: 0.0127 - learning_rate: 2.2877e-04\n",
      "Epoch 262/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 8.2821e-04 - val_loss: 0.0135 - learning_rate: 2.2877e-04\n",
      "Epoch 263/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 8.4360e-04 - val_loss: 0.0128 - learning_rate: 2.2877e-04\n",
      "Epoch 264/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 8.5182e-04\n",
      "Epoch 264: ReduceLROnPlateau reducing learning rate to 0.00020589114428730683.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 8.5171e-04 - val_loss: 0.0129 - learning_rate: 2.2877e-04\n",
      "Epoch 265/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 8.2048e-04 - val_loss: 0.0132 - learning_rate: 2.0589e-04\n",
      "Epoch 266/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 7.5277e-04 - val_loss: 0.0125 - learning_rate: 2.0589e-04\n",
      "Epoch 267/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.1725e-04 - val_loss: 0.0126 - learning_rate: 2.0589e-04\n",
      "Epoch 268/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 7.1462e-04 - val_loss: 0.0128 - learning_rate: 2.0589e-04\n",
      "Epoch 269/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 6.6526e-04 - val_loss: 0.0130 - learning_rate: 2.0589e-04\n",
      "Epoch 270/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 7.0630e-04 - val_loss: 0.0128 - learning_rate: 2.0589e-04\n",
      "Epoch 271/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 6.6022e-04 - val_loss: 0.0127 - learning_rate: 2.0589e-04\n",
      "Epoch 272/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 6.5915e-04 - val_loss: 0.0133 - learning_rate: 2.0589e-04\n",
      "Epoch 273/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 7.4406e-04 - val_loss: 0.0128 - learning_rate: 2.0589e-04\n",
      "Epoch 274/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 7.3650e-04 - val_loss: 0.0130 - learning_rate: 2.0589e-04\n",
      "Epoch 275/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 7.5609e-04 - val_loss: 0.0125 - learning_rate: 2.0589e-04\n",
      "Epoch 276/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 6.7860e-04 - val_loss: 0.0128 - learning_rate: 2.0589e-04\n",
      "Epoch 277/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 7.7309e-04 - val_loss: 0.0128 - learning_rate: 2.0589e-04\n",
      "Epoch 278/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 7.7028e-04 - val_loss: 0.0127 - learning_rate: 2.0589e-04\n",
      "Epoch 279/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 7.3033e-04\n",
      "Epoch 279: ReduceLROnPlateau reducing learning rate to 0.00018530203378759326.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 7.2924e-04 - val_loss: 0.0127 - learning_rate: 2.0589e-04\n",
      "Epoch 280/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 6.9984e-04 - val_loss: 0.0126 - learning_rate: 1.8530e-04\n",
      "Epoch 281/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 6.9484e-04 - val_loss: 0.0128 - learning_rate: 1.8530e-04\n",
      "Epoch 282/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 6.7935e-04 - val_loss: 0.0126 - learning_rate: 1.8530e-04\n",
      "Epoch 283/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 6.6137e-04 - val_loss: 0.0127 - learning_rate: 1.8530e-04\n",
      "Epoch 284/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 6.4309e-04 - val_loss: 0.0127 - learning_rate: 1.8530e-04\n",
      "Epoch 285/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - loss: 6.5274e-04 - val_loss: 0.0128 - learning_rate: 1.8530e-04\n",
      "Epoch 286/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 6.1896e-04 - val_loss: 0.0125 - learning_rate: 1.8530e-04\n",
      "Epoch 287/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 6.4468e-04 - val_loss: 0.0129 - learning_rate: 1.8530e-04\n",
      "Epoch 288/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 6.6918e-04 - val_loss: 0.0124 - learning_rate: 1.8530e-04\n",
      "Epoch 289/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 6.8978e-04 - val_loss: 0.0129 - learning_rate: 1.8530e-04\n",
      "Epoch 290/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 6.7356e-04 - val_loss: 0.0129 - learning_rate: 1.8530e-04\n",
      "Epoch 291/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 6.6266e-04 - val_loss: 0.0132 - learning_rate: 1.8530e-04\n",
      "Epoch 292/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 6.4985e-04\n",
      "Epoch 292: ReduceLROnPlateau reducing learning rate to 0.00016677183302817866.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 6.5065e-04 - val_loss: 0.0128 - learning_rate: 1.8530e-04\n",
      "Epoch 293/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 5.7579e-04 - val_loss: 0.0125 - learning_rate: 1.6677e-04\n",
      "Epoch 294/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 5.7775e-04 - val_loss: 0.0124 - learning_rate: 1.6677e-04\n",
      "Epoch 295/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 5.5739e-04 - val_loss: 0.0124 - learning_rate: 1.6677e-04\n",
      "Epoch 296/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 5.0788e-04 - val_loss: 0.0126 - learning_rate: 1.6677e-04\n",
      "Epoch 297/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - loss: 5.4936e-04 - val_loss: 0.0124 - learning_rate: 1.6677e-04\n",
      "Epoch 298/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 5.4419e-04 - val_loss: 0.0127 - learning_rate: 1.6677e-04\n",
      "Epoch 299/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 5.6394e-04 - val_loss: 0.0126 - learning_rate: 1.6677e-04\n",
      "Epoch 300/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 6.4221e-04 - val_loss: 0.0127 - learning_rate: 1.6677e-04\n",
      "Epoch 301/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 5.4474e-04 - val_loss: 0.0125 - learning_rate: 1.6677e-04\n",
      "Epoch 302/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 5.7376e-04 - val_loss: 0.0124 - learning_rate: 1.6677e-04\n",
      "Epoch 303/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 5.8169e-04 - val_loss: 0.0124 - learning_rate: 1.6677e-04\n",
      "Epoch 304/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 5.2887e-04 - val_loss: 0.0126 - learning_rate: 1.6677e-04\n",
      "Epoch 305/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 5.3918e-04 - val_loss: 0.0126 - learning_rate: 1.6677e-04\n",
      "Epoch 306/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 4.9623e-04 - val_loss: 0.0127 - learning_rate: 1.6677e-04\n",
      "Epoch 307/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 5.8984e-04 - val_loss: 0.0128 - learning_rate: 1.6677e-04\n",
      "Epoch 308/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 5.6169e-04\n",
      "Epoch 308: ReduceLROnPlateau reducing learning rate to 0.00015009464841568844.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 5.6156e-04 - val_loss: 0.0128 - learning_rate: 1.6677e-04\n",
      "Epoch 309/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 5.7368e-04 - val_loss: 0.0127 - learning_rate: 1.5009e-04\n",
      "Epoch 310/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 5.2746e-04 - val_loss: 0.0125 - learning_rate: 1.5009e-04\n",
      "Epoch 311/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - loss: 4.7783e-04 - val_loss: 0.0127 - learning_rate: 1.5009e-04\n",
      "Epoch 312/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 5.1512e-04 - val_loss: 0.0126 - learning_rate: 1.5009e-04\n",
      "Epoch 313/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 5.1795e-04 - val_loss: 0.0127 - learning_rate: 1.5009e-04\n",
      "Epoch 314/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 4.7152e-04 - val_loss: 0.0124 - learning_rate: 1.5009e-04\n",
      "Epoch 315/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 4.8287e-04 - val_loss: 0.0123 - learning_rate: 1.5009e-04\n",
      "Epoch 316/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 5.2349e-04 - val_loss: 0.0124 - learning_rate: 1.5009e-04\n",
      "Epoch 317/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 5.0531e-04 - val_loss: 0.0123 - learning_rate: 1.5009e-04\n",
      "Epoch 318/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 5.1485e-04 - val_loss: 0.0125 - learning_rate: 1.5009e-04\n",
      "Epoch 319/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 5.0555e-04 - val_loss: 0.0127 - learning_rate: 1.5009e-04\n",
      "Epoch 320/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 5.3905e-04 - val_loss: 0.0126 - learning_rate: 1.5009e-04\n",
      "Epoch 321/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 5.1117e-04\n",
      "Epoch 321: ReduceLROnPlateau reducing learning rate to 0.0001350851875031367.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 5.1337e-04 - val_loss: 0.0126 - learning_rate: 1.5009e-04\n",
      "Epoch 322/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 5.0224e-04 - val_loss: 0.0128 - learning_rate: 1.3509e-04\n",
      "Epoch 323/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 5.2928e-04 - val_loss: 0.0123 - learning_rate: 1.3509e-04\n",
      "Epoch 324/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 4.3333e-04 - val_loss: 0.0128 - learning_rate: 1.3509e-04\n",
      "Epoch 325/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 4.1945e-04 - val_loss: 0.0125 - learning_rate: 1.3509e-04\n",
      "Epoch 326/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 4.0960e-04 - val_loss: 0.0130 - learning_rate: 1.3509e-04\n",
      "Epoch 327/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 4.2468e-04 - val_loss: 0.0125 - learning_rate: 1.3509e-04\n",
      "Epoch 328/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 4.6346e-04 - val_loss: 0.0124 - learning_rate: 1.3509e-04\n",
      "Epoch 329/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 4.5715e-04 - val_loss: 0.0125 - learning_rate: 1.3509e-04\n",
      "Epoch 330/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - loss: 4.5190e-04 - val_loss: 0.0124 - learning_rate: 1.3509e-04\n",
      "Epoch 331/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 4.3048e-04 - val_loss: 0.0125 - learning_rate: 1.3509e-04\n",
      "Epoch 332/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 4.2450e-04 - val_loss: 0.0124 - learning_rate: 1.3509e-04\n",
      "Epoch 333/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 4.5401e-04 - val_loss: 0.0126 - learning_rate: 1.3509e-04\n",
      "Epoch 334/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 4.4772e-04\n",
      "Epoch 334: ReduceLROnPlateau reducing learning rate to 0.00012157666351413355.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 4.4716e-04 - val_loss: 0.0123 - learning_rate: 1.3509e-04\n",
      "Epoch 335/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 4.2381e-04 - val_loss: 0.0125 - learning_rate: 1.2158e-04\n",
      "Epoch 336/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 3.6748e-04 - val_loss: 0.0128 - learning_rate: 1.2158e-04\n",
      "Epoch 337/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 4.1446e-04 - val_loss: 0.0125 - learning_rate: 1.2158e-04\n",
      "Epoch 338/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 3.9690e-04 - val_loss: 0.0124 - learning_rate: 1.2158e-04\n",
      "Epoch 339/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 3.7501e-04 - val_loss: 0.0122 - learning_rate: 1.2158e-04\n",
      "Epoch 340/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 4.1847e-04 - val_loss: 0.0124 - learning_rate: 1.2158e-04\n",
      "Epoch 341/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 4.1482e-04 - val_loss: 0.0124 - learning_rate: 1.2158e-04\n",
      "Epoch 342/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 3.8004e-04 - val_loss: 0.0127 - learning_rate: 1.2158e-04\n",
      "Epoch 343/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 21:48:43.489885: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 3.9968e-04 - val_loss: 0.0123 - learning_rate: 1.2158e-04\n",
      "Epoch 344/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 3.9986e-04 - val_loss: 0.0122 - learning_rate: 1.2158e-04\n",
      "Epoch 345/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 4.4231e-04 - val_loss: 0.0126 - learning_rate: 1.2158e-04\n",
      "Epoch 346/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 3.7533e-04 - val_loss: 0.0123 - learning_rate: 1.2158e-04\n",
      "Epoch 347/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 3.8774e-04 - val_loss: 0.0122 - learning_rate: 1.2158e-04\n",
      "Epoch 348/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 3.9437e-04 - val_loss: 0.0123 - learning_rate: 1.2158e-04\n",
      "Epoch 349/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 4.2905e-04 - val_loss: 0.0125 - learning_rate: 1.2158e-04\n",
      "Epoch 350/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 4.2260e-04 - val_loss: 0.0121 - learning_rate: 1.2158e-04\n",
      "Epoch 351/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - loss: 4.1062e-04 - val_loss: 0.0124 - learning_rate: 1.2158e-04\n",
      "Epoch 352/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 4.2116e-04\n",
      "Epoch 352: ReduceLROnPlateau reducing learning rate to 0.00010941899454337544.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 4.2219e-04 - val_loss: 0.0126 - learning_rate: 1.2158e-04\n",
      "Epoch 353/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 3.7386e-04 - val_loss: 0.0123 - learning_rate: 1.0942e-04\n",
      "Epoch 354/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 3.5956e-04 - val_loss: 0.0124 - learning_rate: 1.0942e-04\n",
      "Epoch 355/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 3.8684e-04 - val_loss: 0.0123 - learning_rate: 1.0942e-04\n",
      "Epoch 356/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 3.4419e-04 - val_loss: 0.0125 - learning_rate: 1.0942e-04\n",
      "Epoch 357/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 3.7805e-04 - val_loss: 0.0120 - learning_rate: 1.0942e-04\n",
      "Epoch 358/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 3.6024e-04 - val_loss: 0.0124 - learning_rate: 1.0942e-04\n",
      "Epoch 359/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 3.3368e-04 - val_loss: 0.0125 - learning_rate: 1.0942e-04\n",
      "Epoch 360/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 3.8005e-04 - val_loss: 0.0128 - learning_rate: 1.0942e-04\n",
      "Epoch 361/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 4.3059e-04 - val_loss: 0.0124 - learning_rate: 1.0942e-04\n",
      "Epoch 362/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 3.6285e-04 - val_loss: 0.0123 - learning_rate: 1.0942e-04\n",
      "Epoch 363/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - loss: 3.6950e-04 - val_loss: 0.0125 - learning_rate: 1.0942e-04\n",
      "Epoch 364/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 3.7048e-04 - val_loss: 0.0122 - learning_rate: 1.0942e-04\n",
      "Epoch 365/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 3.4511e-04 - val_loss: 0.0125 - learning_rate: 1.0942e-04\n",
      "Epoch 366/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 3.6606e-04 - val_loss: 0.0124 - learning_rate: 1.0942e-04\n",
      "Epoch 367/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 3.3971e-04 - val_loss: 0.0128 - learning_rate: 1.0942e-04\n",
      "Epoch 368/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 3.5147e-04 - val_loss: 0.0122 - learning_rate: 1.0942e-04\n",
      "Epoch 369/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 3.5591e-04 - val_loss: 0.0122 - learning_rate: 1.0942e-04\n",
      "Epoch 370/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 3.9138e-04\n",
      "Epoch 370: ReduceLROnPlateau reducing learning rate to 9.847709443420172e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - loss: 3.9138e-04 - val_loss: 0.0123 - learning_rate: 1.0942e-04\n",
      "Epoch 371/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step - loss: 3.3462e-04 - val_loss: 0.0121 - learning_rate: 9.8477e-05\n",
      "Epoch 372/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 2.9851e-04 - val_loss: 0.0122 - learning_rate: 9.8477e-05\n",
      "Epoch 373/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 2.8665e-04 - val_loss: 0.0123 - learning_rate: 9.8477e-05\n",
      "Epoch 374/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 3.4776e-04 - val_loss: 0.0121 - learning_rate: 9.8477e-05\n",
      "Epoch 375/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 3.1414e-04 - val_loss: 0.0124 - learning_rate: 9.8477e-05\n",
      "Epoch 376/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 2.8440e-04 - val_loss: 0.0121 - learning_rate: 9.8477e-05\n",
      "Epoch 377/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 2.8517e-04 - val_loss: 0.0121 - learning_rate: 9.8477e-05\n",
      "Epoch 378/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 2.9286e-04 - val_loss: 0.0124 - learning_rate: 9.8477e-05\n",
      "Epoch 379/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 3.2613e-04 - val_loss: 0.0123 - learning_rate: 9.8477e-05\n",
      "Epoch 380/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 3.2248e-04 - val_loss: 0.0121 - learning_rate: 9.8477e-05\n",
      "Epoch 381/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - loss: 2.9209e-04 - val_loss: 0.0123 - learning_rate: 9.8477e-05\n",
      "Epoch 382/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - loss: 3.0827e-04 - val_loss: 0.0124 - learning_rate: 9.8477e-05\n",
      "Epoch 383/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 3.3434e-04\n",
      "Epoch 383: ReduceLROnPlateau reducing learning rate to 8.862938630045391e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 3.3489e-04 - val_loss: 0.0124 - learning_rate: 9.8477e-05\n",
      "Epoch 384/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 3.1722e-04 - val_loss: 0.0123 - learning_rate: 8.8629e-05\n",
      "Epoch 385/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 3.0691e-04 - val_loss: 0.0122 - learning_rate: 8.8629e-05\n",
      "Epoch 386/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 3.0890e-04 - val_loss: 0.0123 - learning_rate: 8.8629e-05\n",
      "Epoch 387/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - loss: 3.0651e-04 - val_loss: 0.0123 - learning_rate: 8.8629e-05\n",
      "Epoch 388/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 3.2189e-04 - val_loss: 0.0123 - learning_rate: 8.8629e-05\n",
      "Epoch 389/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 2.9640e-04 - val_loss: 0.0120 - learning_rate: 8.8629e-05\n",
      "Epoch 390/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 3.0399e-04 - val_loss: 0.0121 - learning_rate: 8.8629e-05\n",
      "Epoch 391/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - loss: 2.9296e-04 - val_loss: 0.0123 - learning_rate: 8.8629e-05\n",
      "Epoch 392/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 2.8576e-04 - val_loss: 0.0122 - learning_rate: 8.8629e-05\n",
      "Epoch 393/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 3.1184e-04 - val_loss: 0.0123 - learning_rate: 8.8629e-05\n",
      "Epoch 394/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 3.2033e-04 - val_loss: 0.0121 - learning_rate: 8.8629e-05\n",
      "Epoch 395/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 2.5770e-04 - val_loss: 0.0122 - learning_rate: 8.8629e-05\n",
      "Epoch 396/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 2.9440e-04\n",
      "Epoch 396: ReduceLROnPlateau reducing learning rate to 7.976644701557234e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 2.9361e-04 - val_loss: 0.0119 - learning_rate: 8.8629e-05\n",
      "Epoch 397/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 2.5388e-04 - val_loss: 0.0123 - learning_rate: 7.9766e-05\n",
      "Epoch 398/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 2.4661e-04 - val_loss: 0.0122 - learning_rate: 7.9766e-05\n",
      "Epoch 399/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 2.7088e-04 - val_loss: 0.0123 - learning_rate: 7.9766e-05\n",
      "Epoch 400/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 2.8295e-04 - val_loss: 0.0123 - learning_rate: 7.9766e-05\n",
      "Epoch 401/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - loss: 2.4027e-04 - val_loss: 0.0121 - learning_rate: 7.9766e-05\n",
      "Epoch 402/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 2.4571e-04 - val_loss: 0.0123 - learning_rate: 7.9766e-05\n",
      "Epoch 403/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 2.5005e-04 - val_loss: 0.0123 - learning_rate: 7.9766e-05\n",
      "Epoch 404/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 2.5948e-04 - val_loss: 0.0123 - learning_rate: 7.9766e-05\n",
      "Epoch 405/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 2.8121e-04 - val_loss: 0.0121 - learning_rate: 7.9766e-05\n",
      "Epoch 406/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 2.6773e-04 - val_loss: 0.0123 - learning_rate: 7.9766e-05\n",
      "Epoch 407/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 2.5610e-04 - val_loss: 0.0121 - learning_rate: 7.9766e-05\n",
      "Epoch 408/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 2.6352e-04 - val_loss: 0.0121 - learning_rate: 7.9766e-05\n",
      "Epoch 409/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 2.8511e-04\n",
      "Epoch 409: ReduceLROnPlateau reducing learning rate to 7.178980231401511e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 2.8485e-04 - val_loss: 0.0122 - learning_rate: 7.9766e-05\n",
      "Epoch 410/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 2.4689e-04 - val_loss: 0.0121 - learning_rate: 7.1790e-05\n",
      "Epoch 411/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 2.4494e-04 - val_loss: 0.0121 - learning_rate: 7.1790e-05\n",
      "Epoch 412/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 2.3586e-04 - val_loss: 0.0123 - learning_rate: 7.1790e-05\n",
      "Epoch 413/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 2.4247e-04 - val_loss: 0.0121 - learning_rate: 7.1790e-05\n",
      "Epoch 414/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 2.3872e-04 - val_loss: 0.0120 - learning_rate: 7.1790e-05\n",
      "Epoch 415/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 2.4348e-04 - val_loss: 0.0122 - learning_rate: 7.1790e-05\n",
      "Epoch 416/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 2.3963e-04 - val_loss: 0.0125 - learning_rate: 7.1790e-05\n",
      "Epoch 417/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 2.4406e-04 - val_loss: 0.0120 - learning_rate: 7.1790e-05\n",
      "Epoch 418/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 2.2464e-04 - val_loss: 0.0123 - learning_rate: 7.1790e-05\n",
      "Epoch 419/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 2.1765e-04 - val_loss: 0.0122 - learning_rate: 7.1790e-05\n",
      "Epoch 420/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 2.3539e-04 - val_loss: 0.0121 - learning_rate: 7.1790e-05\n",
      "Epoch 421/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 2.4785e-04 - val_loss: 0.0121 - learning_rate: 7.1790e-05\n",
      "Epoch 422/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 2.1977e-04\n",
      "Epoch 422: ReduceLROnPlateau reducing learning rate to 6.461082011810504e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 2.2000e-04 - val_loss: 0.0121 - learning_rate: 7.1790e-05\n",
      "Epoch 423/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 2.1266e-04 - val_loss: 0.0119 - learning_rate: 6.4611e-05\n",
      "Epoch 424/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 2.3405e-04 - val_loss: 0.0121 - learning_rate: 6.4611e-05\n",
      "Epoch 425/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 2.1683e-04 - val_loss: 0.0122 - learning_rate: 6.4611e-05\n",
      "Epoch 426/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 2.1575e-04 - val_loss: 0.0123 - learning_rate: 6.4611e-05\n",
      "Epoch 427/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 2.0674e-04 - val_loss: 0.0123 - learning_rate: 6.4611e-05\n",
      "Epoch 428/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 2.2595e-04 - val_loss: 0.0121 - learning_rate: 6.4611e-05\n",
      "Epoch 429/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 2.0756e-04 - val_loss: 0.0122 - learning_rate: 6.4611e-05\n",
      "Epoch 430/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step - loss: 1.9606e-04 - val_loss: 0.0123 - learning_rate: 6.4611e-05\n",
      "Epoch 431/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 2.1196e-04 - val_loss: 0.0123 - learning_rate: 6.4611e-05\n",
      "Epoch 432/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 2.0062e-04 - val_loss: 0.0123 - learning_rate: 6.4611e-05\n",
      "Epoch 433/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 2.1589e-04 - val_loss: 0.0121 - learning_rate: 6.4611e-05\n",
      "Epoch 434/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 2.2100e-04 - val_loss: 0.0123 - learning_rate: 6.4611e-05\n",
      "Epoch 435/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 2.4531e-04\n",
      "Epoch 435: ReduceLROnPlateau reducing learning rate to 5.8149741380475466e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 2.4520e-04 - val_loss: 0.0123 - learning_rate: 6.4611e-05\n",
      "Epoch 436/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 2.0582e-04 - val_loss: 0.0122 - learning_rate: 5.8150e-05\n",
      "Epoch 437/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step - loss: 2.1778e-04 - val_loss: 0.0122 - learning_rate: 5.8150e-05\n",
      "Epoch 438/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.9966e-04 - val_loss: 0.0121 - learning_rate: 5.8150e-05\n",
      "Epoch 439/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 2.4176e-04 - val_loss: 0.0123 - learning_rate: 5.8150e-05\n",
      "Epoch 440/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 2.0756e-04 - val_loss: 0.0122 - learning_rate: 5.8150e-05\n",
      "Epoch 441/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.9400e-04 - val_loss: 0.0121 - learning_rate: 5.8150e-05\n",
      "Epoch 442/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 2.0118e-04 - val_loss: 0.0119 - learning_rate: 5.8150e-05\n",
      "Epoch 443/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - loss: 2.1704e-04 - val_loss: 0.0121 - learning_rate: 5.8150e-05\n",
      "Epoch 444/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - loss: 1.9506e-04 - val_loss: 0.0121 - learning_rate: 5.8150e-05\n",
      "Epoch 445/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 2.1802e-04 - val_loss: 0.0121 - learning_rate: 5.8150e-05\n",
      "Epoch 446/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.9610e-04 - val_loss: 0.0123 - learning_rate: 5.8150e-05\n",
      "Epoch 447/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 2.1288e-04 - val_loss: 0.0121 - learning_rate: 5.8150e-05\n",
      "Epoch 448/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 2.2161e-04\n",
      "Epoch 448: ReduceLROnPlateau reducing learning rate to 5.233476658759173e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 2.2157e-04 - val_loss: 0.0123 - learning_rate: 5.8150e-05\n",
      "Epoch 449/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 1.9227e-04 - val_loss: 0.0122 - learning_rate: 5.2335e-05\n",
      "Epoch 450/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 1.7866e-04 - val_loss: 0.0120 - learning_rate: 5.2335e-05\n",
      "Epoch 451/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.7376e-04 - val_loss: 0.0120 - learning_rate: 5.2335e-05\n",
      "Epoch 452/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.8996e-04 - val_loss: 0.0122 - learning_rate: 5.2335e-05\n",
      "Epoch 453/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 2.0295e-04 - val_loss: 0.0123 - learning_rate: 5.2335e-05\n",
      "Epoch 454/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.8772e-04 - val_loss: 0.0120 - learning_rate: 5.2335e-05\n",
      "Epoch 455/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 1.8549e-04 - val_loss: 0.0122 - learning_rate: 5.2335e-05\n",
      "Epoch 456/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 1.7645e-04 - val_loss: 0.0121 - learning_rate: 5.2335e-05\n",
      "Epoch 457/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.8912e-04 - val_loss: 0.0120 - learning_rate: 5.2335e-05\n",
      "Epoch 458/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.8067e-04 - val_loss: 0.0121 - learning_rate: 5.2335e-05\n",
      "Epoch 459/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step - loss: 1.8967e-04 - val_loss: 0.0123 - learning_rate: 5.2335e-05\n",
      "Epoch 460/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.6990e-04 - val_loss: 0.0120 - learning_rate: 5.2335e-05\n",
      "Epoch 461/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 1.9693e-04\n",
      "Epoch 461: ReduceLROnPlateau reducing learning rate to 4.7101289601414466e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.9688e-04 - val_loss: 0.0122 - learning_rate: 5.2335e-05\n",
      "Epoch 462/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 1.8160e-04 - val_loss: 0.0122 - learning_rate: 4.7101e-05\n",
      "Epoch 463/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.6559e-04 - val_loss: 0.0123 - learning_rate: 4.7101e-05\n",
      "Epoch 464/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.7442e-04 - val_loss: 0.0121 - learning_rate: 4.7101e-05\n",
      "Epoch 465/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.7136e-04 - val_loss: 0.0121 - learning_rate: 4.7101e-05\n",
      "Epoch 466/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 1.6406e-04 - val_loss: 0.0122 - learning_rate: 4.7101e-05\n",
      "Epoch 467/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.8888e-04 - val_loss: 0.0121 - learning_rate: 4.7101e-05\n",
      "Epoch 468/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.7541e-04 - val_loss: 0.0122 - learning_rate: 4.7101e-05\n",
      "Epoch 469/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.7951e-04 - val_loss: 0.0123 - learning_rate: 4.7101e-05\n",
      "Epoch 470/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.6806e-04 - val_loss: 0.0122 - learning_rate: 4.7101e-05\n",
      "Epoch 471/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.6708e-04 - val_loss: 0.0122 - learning_rate: 4.7101e-05\n",
      "Epoch 472/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.9047e-04 - val_loss: 0.0122 - learning_rate: 4.7101e-05\n",
      "Epoch 473/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.6498e-04 - val_loss: 0.0123 - learning_rate: 4.7101e-05\n",
      "Epoch 474/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.6520e-04 - val_loss: 0.0118 - learning_rate: 4.7101e-05\n",
      "Epoch 475/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.8834e-04 - val_loss: 0.0122 - learning_rate: 4.7101e-05\n",
      "Epoch 476/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.9763e-04 - val_loss: 0.0119 - learning_rate: 4.7101e-05\n",
      "Epoch 477/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.6789e-04 - val_loss: 0.0121 - learning_rate: 4.7101e-05\n",
      "Epoch 478/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 1.5073e-04 - val_loss: 0.0121 - learning_rate: 4.7101e-05\n",
      "Epoch 479/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 1.6654e-04 - val_loss: 0.0121 - learning_rate: 4.7101e-05\n",
      "Epoch 480/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.6929e-04 - val_loss: 0.0121 - learning_rate: 4.7101e-05\n",
      "Epoch 481/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.6824e-04 - val_loss: 0.0121 - learning_rate: 4.7101e-05\n",
      "Epoch 482/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - loss: 1.6990e-04 - val_loss: 0.0122 - learning_rate: 4.7101e-05\n",
      "Epoch 483/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - loss: 1.6949e-04 - val_loss: 0.0122 - learning_rate: 4.7101e-05\n",
      "Epoch 484/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - loss: 1.8647e-04 - val_loss: 0.0122 - learning_rate: 4.7101e-05\n",
      "Epoch 485/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 119ms/step - loss: 1.9145e-04 - val_loss: 0.0123 - learning_rate: 4.7101e-05\n",
      "Epoch 486/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.7084e-04 - val_loss: 0.0122 - learning_rate: 4.7101e-05\n",
      "Epoch 487/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 1.8661e-04\n",
      "Epoch 487: ReduceLROnPlateau reducing learning rate to 4.239116096869111e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.8647e-04 - val_loss: 0.0120 - learning_rate: 4.7101e-05\n",
      "Epoch 488/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 1.6328e-04 - val_loss: 0.0121 - learning_rate: 4.2391e-05\n",
      "Epoch 489/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.6948e-04 - val_loss: 0.0120 - learning_rate: 4.2391e-05\n",
      "Epoch 490/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.5283e-04 - val_loss: 0.0123 - learning_rate: 4.2391e-05\n",
      "Epoch 491/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - loss: 1.5923e-04 - val_loss: 0.0122 - learning_rate: 4.2391e-05\n",
      "Epoch 492/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 134ms/step - loss: 1.4937e-04 - val_loss: 0.0119 - learning_rate: 4.2391e-05\n",
      "Epoch 493/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.5322e-04 - val_loss: 0.0122 - learning_rate: 4.2391e-05\n",
      "Epoch 494/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 1.7349e-04 - val_loss: 0.0121 - learning_rate: 4.2391e-05\n",
      "Epoch 495/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.4539e-04 - val_loss: 0.0122 - learning_rate: 4.2391e-05\n",
      "Epoch 496/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 1.8124e-04 - val_loss: 0.0122 - learning_rate: 4.2391e-05\n",
      "Epoch 497/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.5639e-04 - val_loss: 0.0120 - learning_rate: 4.2391e-05\n",
      "Epoch 498/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.6924e-04 - val_loss: 0.0121 - learning_rate: 4.2391e-05\n",
      "Epoch 499/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.5481e-04 - val_loss: 0.0120 - learning_rate: 4.2391e-05\n",
      "Epoch 500/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 1.6064e-04\n",
      "Epoch 500: ReduceLROnPlateau reducing learning rate to 3.815204618149437e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.6073e-04 - val_loss: 0.0119 - learning_rate: 4.2391e-05\n",
      "Epoch 501/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.5191e-04 - val_loss: 0.0121 - learning_rate: 3.8152e-05\n",
      "Epoch 502/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.4694e-04 - val_loss: 0.0123 - learning_rate: 3.8152e-05\n",
      "Epoch 503/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.5516e-04 - val_loss: 0.0121 - learning_rate: 3.8152e-05\n",
      "Epoch 504/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.6943e-04 - val_loss: 0.0122 - learning_rate: 3.8152e-05\n",
      "Epoch 505/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.4417e-04 - val_loss: 0.0119 - learning_rate: 3.8152e-05\n",
      "Epoch 506/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.5700e-04 - val_loss: 0.0121 - learning_rate: 3.8152e-05\n",
      "Epoch 507/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.6737e-04 - val_loss: 0.0123 - learning_rate: 3.8152e-05\n",
      "Epoch 508/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.6223e-04 - val_loss: 0.0122 - learning_rate: 3.8152e-05\n",
      "Epoch 509/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 1.6652e-04 - val_loss: 0.0121 - learning_rate: 3.8152e-05\n",
      "Epoch 510/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 1.5057e-04 - val_loss: 0.0122 - learning_rate: 3.8152e-05\n",
      "Epoch 511/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 1.6189e-04 - val_loss: 0.0121 - learning_rate: 3.8152e-05\n",
      "Epoch 512/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.3603e-04 - val_loss: 0.0119 - learning_rate: 3.8152e-05\n",
      "Epoch 513/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 1.5660e-04\n",
      "Epoch 513: ReduceLROnPlateau reducing learning rate to 3.4336842873017304e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.5616e-04 - val_loss: 0.0122 - learning_rate: 3.8152e-05\n",
      "Epoch 514/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.4218e-04 - val_loss: 0.0122 - learning_rate: 3.4337e-05\n",
      "Epoch 515/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.3607e-04 - val_loss: 0.0121 - learning_rate: 3.4337e-05\n",
      "Epoch 516/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.3871e-04 - val_loss: 0.0121 - learning_rate: 3.4337e-05\n",
      "Epoch 517/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.5032e-04 - val_loss: 0.0119 - learning_rate: 3.4337e-05\n",
      "Epoch 518/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.4711e-04 - val_loss: 0.0121 - learning_rate: 3.4337e-05\n",
      "Epoch 519/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.4819e-04 - val_loss: 0.0122 - learning_rate: 3.4337e-05\n",
      "Epoch 520/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 1.4903e-04 - val_loss: 0.0121 - learning_rate: 3.4337e-05\n",
      "Epoch 521/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 1.4252e-04 - val_loss: 0.0122 - learning_rate: 3.4337e-05\n",
      "Epoch 522/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 1.3371e-04 - val_loss: 0.0121 - learning_rate: 3.4337e-05\n",
      "Epoch 523/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.3732e-04 - val_loss: 0.0118 - learning_rate: 3.4337e-05\n",
      "Epoch 524/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.3478e-04 - val_loss: 0.0121 - learning_rate: 3.4337e-05\n",
      "Epoch 525/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 1.5705e-04 - val_loss: 0.0122 - learning_rate: 3.4337e-05\n",
      "Epoch 526/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 1.4621e-04\n",
      "Epoch 526: ReduceLROnPlateau reducing learning rate to 3.0903160222806036e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.4639e-04 - val_loss: 0.0123 - learning_rate: 3.4337e-05\n",
      "Epoch 527/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 1.2030e-04 - val_loss: 0.0122 - learning_rate: 3.0903e-05\n",
      "Epoch 528/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 1.3065e-04 - val_loss: 0.0121 - learning_rate: 3.0903e-05\n",
      "Epoch 529/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.3141e-04 - val_loss: 0.0121 - learning_rate: 3.0903e-05\n",
      "Epoch 530/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.3043e-04 - val_loss: 0.0121 - learning_rate: 3.0903e-05\n",
      "Epoch 531/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 1.1811e-04 - val_loss: 0.0120 - learning_rate: 3.0903e-05\n",
      "Epoch 532/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.3110e-04 - val_loss: 0.0121 - learning_rate: 3.0903e-05\n",
      "Epoch 533/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.3137e-04 - val_loss: 0.0120 - learning_rate: 3.0903e-05\n",
      "Epoch 534/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.3836e-04 - val_loss: 0.0119 - learning_rate: 3.0903e-05\n",
      "Epoch 535/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.2946e-04 - val_loss: 0.0121 - learning_rate: 3.0903e-05\n",
      "Epoch 536/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 1.4028e-04 - val_loss: 0.0120 - learning_rate: 3.0903e-05\n",
      "Epoch 537/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.3225e-04 - val_loss: 0.0121 - learning_rate: 3.0903e-05\n",
      "Epoch 538/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.2866e-04 - val_loss: 0.0120 - learning_rate: 3.0903e-05\n",
      "Epoch 539/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 1.4482e-04\n",
      "Epoch 539: ReduceLROnPlateau reducing learning rate to 2.7812844200525434e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.4490e-04 - val_loss: 0.0122 - learning_rate: 3.0903e-05\n",
      "Epoch 540/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 1.1569e-04 - val_loss: 0.0121 - learning_rate: 2.7813e-05\n",
      "Epoch 541/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 1.2024e-04 - val_loss: 0.0121 - learning_rate: 2.7813e-05\n",
      "Epoch 542/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.2051e-04 - val_loss: 0.0120 - learning_rate: 2.7813e-05\n",
      "Epoch 543/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.1768e-04 - val_loss: 0.0119 - learning_rate: 2.7813e-05\n",
      "Epoch 544/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.1395e-04 - val_loss: 0.0119 - learning_rate: 2.7813e-05\n",
      "Epoch 545/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.2285e-04 - val_loss: 0.0121 - learning_rate: 2.7813e-05\n",
      "Epoch 546/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.4023e-04 - val_loss: 0.0121 - learning_rate: 2.7813e-05\n",
      "Epoch 547/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 1.0810e-04 - val_loss: 0.0121 - learning_rate: 2.7813e-05\n",
      "Epoch 548/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.3758e-04 - val_loss: 0.0121 - learning_rate: 2.7813e-05\n",
      "Epoch 549/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 1.2015e-04 - val_loss: 0.0120 - learning_rate: 2.7813e-05\n",
      "Epoch 550/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.1777e-04 - val_loss: 0.0121 - learning_rate: 2.7813e-05\n",
      "Epoch 551/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.3401e-04 - val_loss: 0.0121 - learning_rate: 2.7813e-05\n",
      "Epoch 552/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 1.1743e-04\n",
      "Epoch 552: ReduceLROnPlateau reducing learning rate to 2.5031560107890984e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 1.1737e-04 - val_loss: 0.0119 - learning_rate: 2.7813e-05\n",
      "Epoch 553/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.2002e-04 - val_loss: 0.0122 - learning_rate: 2.5032e-05\n",
      "Epoch 554/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.1827e-04 - val_loss: 0.0120 - learning_rate: 2.5032e-05\n",
      "Epoch 555/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 1.3411e-04 - val_loss: 0.0119 - learning_rate: 2.5032e-05\n",
      "Epoch 556/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.1718e-04 - val_loss: 0.0118 - learning_rate: 2.5032e-05\n",
      "Epoch 557/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.0677e-04 - val_loss: 0.0120 - learning_rate: 2.5032e-05\n",
      "Epoch 558/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.1198e-04 - val_loss: 0.0121 - learning_rate: 2.5032e-05\n",
      "Epoch 559/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 1.0949e-04 - val_loss: 0.0120 - learning_rate: 2.5032e-05\n",
      "Epoch 560/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.1756e-04 - val_loss: 0.0122 - learning_rate: 2.5032e-05\n",
      "Epoch 561/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.1809e-04 - val_loss: 0.0122 - learning_rate: 2.5032e-05\n",
      "Epoch 562/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 1.0680e-04 - val_loss: 0.0122 - learning_rate: 2.5032e-05\n",
      "Epoch 563/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.1640e-04 - val_loss: 0.0121 - learning_rate: 2.5032e-05\n",
      "Epoch 564/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.1758e-04 - val_loss: 0.0121 - learning_rate: 2.5032e-05\n",
      "Epoch 565/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 1.1826e-04\n",
      "Epoch 565: ReduceLROnPlateau reducing learning rate to 2.2528404588229024e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.1812e-04 - val_loss: 0.0121 - learning_rate: 2.5032e-05\n",
      "Epoch 566/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.1932e-04 - val_loss: 0.0120 - learning_rate: 2.2528e-05\n",
      "Epoch 567/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.1297e-04 - val_loss: 0.0119 - learning_rate: 2.2528e-05\n",
      "Epoch 568/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.1547e-04 - val_loss: 0.0121 - learning_rate: 2.2528e-05\n",
      "Epoch 569/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.2635e-04 - val_loss: 0.0123 - learning_rate: 2.2528e-05\n",
      "Epoch 570/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 1.1324e-04 - val_loss: 0.0119 - learning_rate: 2.2528e-05\n",
      "Epoch 571/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.1171e-04 - val_loss: 0.0119 - learning_rate: 2.2528e-05\n",
      "Epoch 572/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 1.0832e-04 - val_loss: 0.0122 - learning_rate: 2.2528e-05\n",
      "Epoch 573/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.0666e-04 - val_loss: 0.0119 - learning_rate: 2.2528e-05\n",
      "Epoch 574/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.0727e-04 - val_loss: 0.0121 - learning_rate: 2.2528e-05\n",
      "Epoch 575/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.0775e-04 - val_loss: 0.0121 - learning_rate: 2.2528e-05\n",
      "Epoch 576/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 1.1340e-04 - val_loss: 0.0121 - learning_rate: 2.2528e-05\n",
      "Epoch 577/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.0684e-04 - val_loss: 0.0121 - learning_rate: 2.2528e-05\n",
      "Epoch 578/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 1.1470e-04\n",
      "Epoch 578: ReduceLROnPlateau reducing learning rate to 2.0275563474569936e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.1470e-04 - val_loss: 0.0119 - learning_rate: 2.2528e-05\n",
      "Epoch 579/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 1.1204e-04 - val_loss: 0.0119 - learning_rate: 2.0276e-05\n",
      "Epoch 580/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 1.0316e-04 - val_loss: 0.0122 - learning_rate: 2.0276e-05\n",
      "Epoch 581/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.0691e-04 - val_loss: 0.0122 - learning_rate: 2.0276e-05\n",
      "Epoch 582/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.0114e-04 - val_loss: 0.0121 - learning_rate: 2.0276e-05\n",
      "Epoch 583/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.0855e-04 - val_loss: 0.0121 - learning_rate: 2.0276e-05\n",
      "Epoch 584/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.1171e-04 - val_loss: 0.0121 - learning_rate: 2.0276e-05\n",
      "Epoch 585/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.0070e-04 - val_loss: 0.0121 - learning_rate: 2.0276e-05\n",
      "Epoch 586/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.1610e-04 - val_loss: 0.0121 - learning_rate: 2.0276e-05\n",
      "Epoch 587/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.1473e-04 - val_loss: 0.0120 - learning_rate: 2.0276e-05\n",
      "Epoch 588/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.0738e-04 - val_loss: 0.0123 - learning_rate: 2.0276e-05\n",
      "Epoch 589/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.0405e-04 - val_loss: 0.0122 - learning_rate: 2.0276e-05\n",
      "Epoch 590/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.0452e-04 - val_loss: 0.0121 - learning_rate: 2.0276e-05\n",
      "Epoch 591/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 9.8872e-05\n",
      "Epoch 591: ReduceLROnPlateau reducing learning rate to 1.8248007290821987e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 9.9015e-05 - val_loss: 0.0122 - learning_rate: 2.0276e-05\n",
      "Epoch 592/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 9.3660e-05 - val_loss: 0.0122 - learning_rate: 1.8248e-05\n",
      "Epoch 593/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 9.9625e-05 - val_loss: 0.0121 - learning_rate: 1.8248e-05\n",
      "Epoch 594/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 1.0711e-04 - val_loss: 0.0120 - learning_rate: 1.8248e-05\n",
      "Epoch 595/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 1.0473e-04 - val_loss: 0.0122 - learning_rate: 1.8248e-05\n",
      "Epoch 596/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 9.9487e-05 - val_loss: 0.0119 - learning_rate: 1.8248e-05\n",
      "Epoch 597/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 9.7609e-05 - val_loss: 0.0123 - learning_rate: 1.8248e-05\n",
      "Epoch 598/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 9.7695e-05 - val_loss: 0.0121 - learning_rate: 1.8248e-05\n",
      "Epoch 599/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.0388e-04 - val_loss: 0.0120 - learning_rate: 1.8248e-05\n",
      "Epoch 600/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 1.0727e-04 - val_loss: 0.0122 - learning_rate: 1.8248e-05\n",
      "Epoch 601/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.1354e-04 - val_loss: 0.0121 - learning_rate: 1.8248e-05\n",
      "Epoch 602/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 1.0284e-04 - val_loss: 0.0121 - learning_rate: 1.8248e-05\n",
      "Epoch 603/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 9.8692e-05 - val_loss: 0.0120 - learning_rate: 1.8248e-05\n",
      "Epoch 604/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 1.0460e-04\n",
      "Epoch 604: ReduceLROnPlateau reducing learning rate to 1.6423206398030745e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.0473e-04 - val_loss: 0.0121 - learning_rate: 1.8248e-05\n",
      "Epoch 605/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 9.6761e-05 - val_loss: 0.0120 - learning_rate: 1.6423e-05\n",
      "Epoch 606/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step - loss: 9.3519e-05 - val_loss: 0.0119 - learning_rate: 1.6423e-05\n",
      "Epoch 607/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 9.2265e-05 - val_loss: 0.0120 - learning_rate: 1.6423e-05\n",
      "Epoch 608/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 100ms/step - loss: 1.0311e-04 - val_loss: 0.0120 - learning_rate: 1.6423e-05\n",
      "Epoch 609/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 121ms/step - loss: 8.9218e-05 - val_loss: 0.0120 - learning_rate: 1.6423e-05\n",
      "Epoch 610/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 9.6451e-05 - val_loss: 0.0120 - learning_rate: 1.6423e-05\n",
      "Epoch 611/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 9.6238e-05 - val_loss: 0.0121 - learning_rate: 1.6423e-05\n",
      "Epoch 612/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 9.4468e-05 - val_loss: 0.0119 - learning_rate: 1.6423e-05\n",
      "Epoch 613/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 1.0126e-04 - val_loss: 0.0122 - learning_rate: 1.6423e-05\n",
      "Epoch 614/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 9.3427e-05 - val_loss: 0.0121 - learning_rate: 1.6423e-05\n",
      "Epoch 615/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 8.7676e-05 - val_loss: 0.0121 - learning_rate: 1.6423e-05\n",
      "Epoch 616/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 9.5523e-05 - val_loss: 0.0121 - learning_rate: 1.6423e-05\n",
      "Epoch 617/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 8.7913e-05\n",
      "Epoch 617: ReduceLROnPlateau reducing learning rate to 1.4780885430809576e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 8.8071e-05 - val_loss: 0.0119 - learning_rate: 1.6423e-05\n",
      "Epoch 618/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 8.6143e-05 - val_loss: 0.0124 - learning_rate: 1.4781e-05\n",
      "Epoch 619/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 9.2633e-05 - val_loss: 0.0121 - learning_rate: 1.4781e-05\n",
      "Epoch 620/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 9.4699e-05 - val_loss: 0.0120 - learning_rate: 1.4781e-05\n",
      "Epoch 621/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 8.8648e-05 - val_loss: 0.0120 - learning_rate: 1.4781e-05\n",
      "Epoch 622/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 8.5720e-05 - val_loss: 0.0123 - learning_rate: 1.4781e-05\n",
      "Epoch 623/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 8.3839e-05 - val_loss: 0.0120 - learning_rate: 1.4781e-05\n",
      "Epoch 624/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 8.6587e-05 - val_loss: 0.0121 - learning_rate: 1.4781e-05\n",
      "Epoch 625/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 9.0503e-05 - val_loss: 0.0121 - learning_rate: 1.4781e-05\n",
      "Epoch 626/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 9.6043e-05 - val_loss: 0.0120 - learning_rate: 1.4781e-05\n",
      "Epoch 627/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 9.4019e-05 - val_loss: 0.0121 - learning_rate: 1.4781e-05\n",
      "Epoch 628/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 9.0392e-05 - val_loss: 0.0121 - learning_rate: 1.4781e-05\n",
      "Epoch 629/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 8.9883e-05 - val_loss: 0.0119 - learning_rate: 1.4781e-05\n",
      "Epoch 630/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 9.2136e-05\n",
      "Epoch 630: ReduceLROnPlateau reducing learning rate to 1.3302796560310526e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 9.2104e-05 - val_loss: 0.0122 - learning_rate: 1.4781e-05\n",
      "Epoch 631/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 9.4923e-05 - val_loss: 0.0120 - learning_rate: 1.3303e-05\n",
      "Epoch 632/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 8.7155e-05 - val_loss: 0.0121 - learning_rate: 1.3303e-05\n",
      "Epoch 633/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 9.5724e-05 - val_loss: 0.0118 - learning_rate: 1.3303e-05\n",
      "Epoch 634/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 8.1738e-05 - val_loss: 0.0119 - learning_rate: 1.3303e-05\n",
      "Epoch 635/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 8.2887e-05 - val_loss: 0.0121 - learning_rate: 1.3303e-05\n",
      "Epoch 636/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 8.8119e-05 - val_loss: 0.0120 - learning_rate: 1.3303e-05\n",
      "Epoch 637/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 8.8987e-05 - val_loss: 0.0123 - learning_rate: 1.3303e-05\n",
      "Epoch 638/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 8.2315e-05 - val_loss: 0.0120 - learning_rate: 1.3303e-05\n",
      "Epoch 639/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 8.6665e-05 - val_loss: 0.0119 - learning_rate: 1.3303e-05\n",
      "Epoch 640/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 9.0002e-05 - val_loss: 0.0122 - learning_rate: 1.3303e-05\n",
      "Epoch 641/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 8.5416e-05 - val_loss: 0.0122 - learning_rate: 1.3303e-05\n",
      "Epoch 642/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 9.2901e-05 - val_loss: 0.0122 - learning_rate: 1.3303e-05\n",
      "Epoch 643/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 9.1569e-05\n",
      "Epoch 643: ReduceLROnPlateau reducing learning rate to 1.1972517313552089e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 9.1406e-05 - val_loss: 0.0121 - learning_rate: 1.3303e-05\n",
      "Epoch 644/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 8.2252e-05 - val_loss: 0.0120 - learning_rate: 1.1973e-05\n",
      "Epoch 645/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 8.5068e-05 - val_loss: 0.0121 - learning_rate: 1.1973e-05\n",
      "Epoch 646/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 8.4878e-05 - val_loss: 0.0120 - learning_rate: 1.1973e-05\n",
      "Epoch 647/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 8.3426e-05 - val_loss: 0.0120 - learning_rate: 1.1973e-05\n",
      "Epoch 648/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.9800e-05 - val_loss: 0.0120 - learning_rate: 1.1973e-05\n",
      "Epoch 649/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 8.3987e-05 - val_loss: 0.0120 - learning_rate: 1.1973e-05\n",
      "Epoch 650/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 7.3273e-05 - val_loss: 0.0118 - learning_rate: 1.1973e-05\n",
      "Epoch 651/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 8.4195e-05 - val_loss: 0.0120 - learning_rate: 1.1973e-05\n",
      "Epoch 652/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 8.9650e-05 - val_loss: 0.0121 - learning_rate: 1.1973e-05\n",
      "Epoch 653/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.5391e-05 - val_loss: 0.0123 - learning_rate: 1.1973e-05\n",
      "Epoch 654/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 8.7041e-05 - val_loss: 0.0119 - learning_rate: 1.1973e-05\n",
      "Epoch 655/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 7.9540e-05 - val_loss: 0.0121 - learning_rate: 1.1973e-05\n",
      "Epoch 656/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 8.3978e-05\n",
      "Epoch 656: ReduceLROnPlateau reducing learning rate to 1.077526558219688e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 8.4068e-05 - val_loss: 0.0119 - learning_rate: 1.1973e-05\n",
      "Epoch 657/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.5584e-05 - val_loss: 0.0121 - learning_rate: 1.0775e-05\n",
      "Epoch 658/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.4227e-05 - val_loss: 0.0121 - learning_rate: 1.0775e-05\n",
      "Epoch 659/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 8.1866e-05 - val_loss: 0.0119 - learning_rate: 1.0775e-05\n",
      "Epoch 660/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 7.3836e-05 - val_loss: 0.0121 - learning_rate: 1.0775e-05\n",
      "Epoch 661/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 8.0950e-05 - val_loss: 0.0120 - learning_rate: 1.0775e-05\n",
      "Epoch 662/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 8.4131e-05 - val_loss: 0.0121 - learning_rate: 1.0775e-05\n",
      "Epoch 663/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.9061e-05 - val_loss: 0.0119 - learning_rate: 1.0775e-05\n",
      "Epoch 664/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 8.5854e-05 - val_loss: 0.0120 - learning_rate: 1.0775e-05\n",
      "Epoch 665/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.7896e-05 - val_loss: 0.0121 - learning_rate: 1.0775e-05\n",
      "Epoch 666/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 7.3733e-05 - val_loss: 0.0120 - learning_rate: 1.0775e-05\n",
      "Epoch 667/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 8.4862e-05 - val_loss: 0.0120 - learning_rate: 1.0775e-05\n",
      "Epoch 668/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.4833e-05 - val_loss: 0.0120 - learning_rate: 1.0775e-05\n",
      "Epoch 669/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 7.2478e-05\n",
      "Epoch 669: ReduceLROnPlateau reducing learning rate to 9.697739187686238e-06.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 7.2559e-05 - val_loss: 0.0120 - learning_rate: 1.0775e-05\n",
      "Epoch 670/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.8217e-05 - val_loss: 0.0121 - learning_rate: 9.6977e-06\n",
      "Epoch 671/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.9989e-05 - val_loss: 0.0122 - learning_rate: 9.6977e-06\n",
      "Epoch 672/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.5884e-05 - val_loss: 0.0120 - learning_rate: 9.6977e-06\n",
      "Epoch 673/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.4951e-05 - val_loss: 0.0120 - learning_rate: 9.6977e-06\n",
      "Epoch 674/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 8.5007e-05 - val_loss: 0.0122 - learning_rate: 9.6977e-06\n",
      "Epoch 675/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 8.3101e-05 - val_loss: 0.0122 - learning_rate: 9.6977e-06\n",
      "Epoch 676/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.5280e-05 - val_loss: 0.0120 - learning_rate: 9.6977e-06\n",
      "Epoch 677/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.3446e-05 - val_loss: 0.0118 - learning_rate: 9.6977e-06\n",
      "Epoch 678/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.5384e-05 - val_loss: 0.0118 - learning_rate: 9.6977e-06\n",
      "Epoch 679/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.6552e-05 - val_loss: 0.0121 - learning_rate: 9.6977e-06\n",
      "Epoch 680/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 7.4079e-05 - val_loss: 0.0121 - learning_rate: 9.6977e-06\n",
      "Epoch 681/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 8.0405e-05 - val_loss: 0.0120 - learning_rate: 9.6977e-06\n",
      "Epoch 682/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 8.3879e-05\n",
      "Epoch 682: ReduceLROnPlateau reducing learning rate to 8.727965268917615e-06.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 8.4042e-05 - val_loss: 0.0122 - learning_rate: 9.6977e-06\n",
      "Epoch 683/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 8.2100e-05 - val_loss: 0.0121 - learning_rate: 8.7280e-06\n",
      "Epoch 684/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 7.8175e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 22:20:02.938237: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.8089e-05 - val_loss: 0.0122 - learning_rate: 8.7280e-06\n",
      "Epoch 685/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7529e-05 - val_loss: 0.0119 - learning_rate: 8.7280e-06\n",
      "Epoch 686/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.1337e-05 - val_loss: 0.0119 - learning_rate: 8.7280e-06\n",
      "Epoch 687/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.0523e-05 - val_loss: 0.0118 - learning_rate: 8.7280e-06\n",
      "Epoch 688/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.6944e-05 - val_loss: 0.0119 - learning_rate: 8.7280e-06\n",
      "Epoch 689/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 7.1836e-05 - val_loss: 0.0122 - learning_rate: 8.7280e-06\n",
      "Epoch 690/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.6438e-05 - val_loss: 0.0119 - learning_rate: 8.7280e-06\n",
      "Epoch 691/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.5863e-05 - val_loss: 0.0118 - learning_rate: 8.7280e-06\n",
      "Epoch 692/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 7.3956e-05 - val_loss: 0.0121 - learning_rate: 8.7280e-06\n",
      "Epoch 693/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 7.9927e-05 - val_loss: 0.0120 - learning_rate: 8.7280e-06\n",
      "Epoch 694/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.1107e-05 - val_loss: 0.0120 - learning_rate: 8.7280e-06\n",
      "Epoch 695/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 7.2589e-05\n",
      "Epoch 695: ReduceLROnPlateau reducing learning rate to 7.855168496462283e-06.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.2649e-05 - val_loss: 0.0119 - learning_rate: 8.7280e-06\n",
      "Epoch 696/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.6273e-05 - val_loss: 0.0121 - learning_rate: 7.8552e-06\n",
      "Epoch 697/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.4204e-05 - val_loss: 0.0121 - learning_rate: 7.8552e-06\n",
      "Epoch 698/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.7504e-05 - val_loss: 0.0120 - learning_rate: 7.8552e-06\n",
      "Epoch 699/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 7.6406e-05 - val_loss: 0.0120 - learning_rate: 7.8552e-06\n",
      "Epoch 700/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.5229e-05 - val_loss: 0.0121 - learning_rate: 7.8552e-06\n",
      "Epoch 701/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.5690e-05 - val_loss: 0.0121 - learning_rate: 7.8552e-06\n",
      "Epoch 702/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.7892e-05 - val_loss: 0.0122 - learning_rate: 7.8552e-06\n",
      "Epoch 703/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 7.3567e-05 - val_loss: 0.0119 - learning_rate: 7.8552e-06\n",
      "Epoch 704/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.1899e-05 - val_loss: 0.0119 - learning_rate: 7.8552e-06\n",
      "Epoch 705/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.1642e-05 - val_loss: 0.0120 - learning_rate: 7.8552e-06\n",
      "Epoch 706/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.4793e-05 - val_loss: 0.0121 - learning_rate: 7.8552e-06\n",
      "Epoch 707/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.2189e-05 - val_loss: 0.0120 - learning_rate: 7.8552e-06\n",
      "Epoch 708/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 7.3973e-05\n",
      "Epoch 708: ReduceLROnPlateau reducing learning rate to 7.069651564961533e-06.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.4118e-05 - val_loss: 0.0121 - learning_rate: 7.8552e-06\n",
      "Epoch 709/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.7415e-05 - val_loss: 0.0122 - learning_rate: 7.0697e-06\n",
      "Epoch 710/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.8716e-05 - val_loss: 0.0121 - learning_rate: 7.0697e-06\n",
      "Epoch 711/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.8195e-05 - val_loss: 0.0120 - learning_rate: 7.0697e-06\n",
      "Epoch 712/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.6174e-05 - val_loss: 0.0120 - learning_rate: 7.0697e-06\n",
      "Epoch 713/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 7.3800e-05 - val_loss: 0.0121 - learning_rate: 7.0697e-06\n",
      "Epoch 714/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.0589e-05 - val_loss: 0.0121 - learning_rate: 7.0697e-06\n",
      "Epoch 715/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 7.6874e-05 - val_loss: 0.0120 - learning_rate: 7.0697e-06\n",
      "Epoch 716/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.8089e-05 - val_loss: 0.0123 - learning_rate: 7.0697e-06\n",
      "Epoch 717/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.6057e-05 - val_loss: 0.0118 - learning_rate: 7.0697e-06\n",
      "Epoch 718/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.9645e-05 - val_loss: 0.0119 - learning_rate: 7.0697e-06\n",
      "Epoch 719/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.9584e-05 - val_loss: 0.0118 - learning_rate: 7.0697e-06\n",
      "Epoch 720/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 7.4108e-05 - val_loss: 0.0121 - learning_rate: 7.0697e-06\n",
      "Epoch 721/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 7.1556e-05\n",
      "Epoch 721: ReduceLROnPlateau reducing learning rate to 7e-06.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 124ms/step - loss: 7.1632e-05 - val_loss: 0.0120 - learning_rate: 7.0697e-06\n",
      "Epoch 722/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 7.3207e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 723/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 6.9239e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 724/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.6642e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 725/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 6.6158e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 726/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7770e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 727/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.6238e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 728/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.0865e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 729/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.4698e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 730/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.6616e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 731/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.0888e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 732/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.2652e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 733/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.1240e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 734/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.8107e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 735/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.6649e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 736/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 7.5049e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 737/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.2856e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 738/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.0512e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 739/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.2468e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 740/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.5076e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 741/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.1985e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 742/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.5860e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 743/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 7.4710e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 744/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.9352e-05 - val_loss: 0.0123 - learning_rate: 7.0000e-06\n",
      "Epoch 745/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.4758e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 746/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.6376e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 747/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.2513e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 748/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 7.5749e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 749/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 6.2000e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 750/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.0855e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 751/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.3636e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 752/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.7488e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 753/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.3375e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 754/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.2117e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 755/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 7.6183e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 756/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 7.5908e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 757/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.1865e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 758/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.5330e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 759/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.3630e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 760/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.0067e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 761/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.5237e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 762/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.8925e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 763/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.7348e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 764/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 7.0484e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 765/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.2424e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 766/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.0884e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 767/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - loss: 7.1994e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 768/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - loss: 7.3247e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 769/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.1355e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 770/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.0791e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 771/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.7516e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 772/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.5894e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 773/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.8243e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 774/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.1936e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 775/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 7.0236e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 776/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.4868e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 777/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.6733e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 778/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 7.2944e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 779/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.1106e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 780/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 7.1700e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 781/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 7.3680e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 782/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7946e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 783/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.6504e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 784/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 6.8519e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 785/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.6316e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 786/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7397e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 787/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7322e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 788/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.2707e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 789/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.1064e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 790/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.1564e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 791/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.5877e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 792/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.9234e-05 - val_loss: 0.0117 - learning_rate: 7.0000e-06\n",
      "Epoch 793/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.7129e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 794/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.0750e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 795/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 7.3114e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 796/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 6.9331e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 797/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.0742e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 798/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 7.0772e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 799/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.8784e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 800/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.6009e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 801/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.6028e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 802/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 6.8793e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 803/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.6765e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 804/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.4118e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 805/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 7.1539e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 806/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7427e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 807/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.3206e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 808/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.4113e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 809/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.8357e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 810/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - loss: 7.6002e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 811/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 134ms/step - loss: 6.6980e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 812/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.3846e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 813/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 7.1171e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 814/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 7.0737e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 815/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 6.6891e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 816/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.7556e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 817/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.3743e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 818/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7082e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 819/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 7.0065e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 820/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.9614e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 821/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.7185e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 822/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.3317e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 823/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7117e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 824/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.5340e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 825/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.6478e-05 - val_loss: 0.0117 - learning_rate: 7.0000e-06\n",
      "Epoch 826/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 7.2850e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 827/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.5951e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 828/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 7.3722e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 829/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 7.1619e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 830/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.4073e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 831/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.4233e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 832/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.3939e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 833/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.9749e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 834/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.6805e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 835/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.5545e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 836/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.7420e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 837/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.0776e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 838/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.4670e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 839/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.9389e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 840/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 7.0511e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 841/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7291e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 842/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.1172e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 843/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 7.9150e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 844/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.3514e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 845/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.6231e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 846/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.2079e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 847/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.1451e-05 - val_loss: 0.0117 - learning_rate: 7.0000e-06\n",
      "Epoch 848/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.4375e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 849/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7333e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 850/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 6.6820e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 851/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.4641e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 852/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.6431e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 853/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.8390e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 854/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.5560e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 855/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.4340e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 856/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.2238e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 857/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 7.2807e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 858/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.6000e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 859/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.2543e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 860/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.8382e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 861/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.3499e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 862/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 7.0836e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 863/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.9079e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 864/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.5487e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 865/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 6.8173e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 866/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 7.4246e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 867/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.6044e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 868/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.5514e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 869/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.1461e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 870/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.5386e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 871/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - loss: 6.3995e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 872/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 134ms/step - loss: 7.3865e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 873/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.9201e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 874/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 6.6354e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 875/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 6.9236e-05 - val_loss: 0.0117 - learning_rate: 7.0000e-06\n",
      "Epoch 876/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.8463e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 877/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.4750e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 878/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.1987e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 879/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 7.1101e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 880/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.0658e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 881/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.0972e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 882/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.8241e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 883/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.7112e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 884/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7434e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 885/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.7448e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 886/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 6.4684e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 887/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 7.3905e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 888/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.8164e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 889/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.0234e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 890/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 7.1903e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 891/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.0555e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 892/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.6441e-05 - val_loss: 0.0117 - learning_rate: 7.0000e-06\n",
      "Epoch 893/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.6630e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 894/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.7605e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 895/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 6.9675e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 896/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - loss: 6.7283e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 897/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - loss: 7.5780e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 898/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.0377e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 899/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.7580e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 900/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.9375e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 901/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.4212e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 902/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 6.5416e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 903/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.0698e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 904/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.4494e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 905/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 7.0322e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 906/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.9340e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 907/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.5986e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 908/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 7.0255e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 909/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.0358e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 910/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.5640e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 911/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 6.6683e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 912/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 6.5518e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 913/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.5700e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 914/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7721e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 915/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step - loss: 6.7147e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 916/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 7.5284e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 917/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.3809e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 918/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.9950e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 919/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.8669e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 920/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.6013e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 921/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.0423e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 922/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.2493e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 923/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 5.7276e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 924/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.6768e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 925/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - loss: 7.0143e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 926/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 119ms/step - loss: 6.4488e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 927/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.3423e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 928/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.3730e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 929/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7730e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 930/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.7438e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 931/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 6.2694e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 932/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 7.7613e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 933/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7394e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 934/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 6.3277e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 935/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.8804e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 936/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.9644e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 937/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.0006e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 938/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.1049e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 939/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.8854e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 940/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.0320e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 941/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.2629e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 942/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.5920e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 943/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.8671e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 944/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 6.7325e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 945/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 7.2012e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 946/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.3160e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 947/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.8675e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 948/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.1653e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 949/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.3974e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 950/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.5402e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 951/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.4903e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 952/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.6540e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 953/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.0437e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 954/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.3134e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 955/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.9510e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 956/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7076e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 957/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 6.1200e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 958/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.9239e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 959/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 6.2760e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 960/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 6.4821e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 961/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 7.0361e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 962/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - loss: 6.2514e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 963/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - loss: 6.4252e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 964/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.0653e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 965/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.0499e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 966/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.8352e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 967/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.9771e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 968/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - loss: 6.8431e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 969/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.3621e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 970/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.9173e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 971/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.9320e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 972/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.9796e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 973/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.6029e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 974/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.4627e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 975/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 6.7663e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 976/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.5216e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 977/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.1704e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 978/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.7460e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 979/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.5445e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 980/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.6478e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 981/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.4037e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 982/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.9948e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 983/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7989e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 984/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 6.8023e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 985/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.9295e-05 - val_loss: 0.0123 - learning_rate: 7.0000e-06\n",
      "Epoch 986/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.7219e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 987/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.9741e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 988/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.6507e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 989/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.6529e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 990/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.4196e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 991/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.6703e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 992/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7648e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 993/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7805e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 994/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 6.9909e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 995/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 6.7193e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 996/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.8784e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 997/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.4408e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 998/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.6455e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 999/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.0203e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 1000/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.6980e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1001/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.1513e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1002/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 7.1880e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1003/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 7.2278e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1004/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.4393e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1005/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.5316e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1006/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 6.2450e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1007/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 6.3931e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1008/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.9415e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1009/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.8795e-05 - val_loss: 0.0123 - learning_rate: 7.0000e-06\n",
      "Epoch 1010/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.6771e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1011/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 6.9055e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1012/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.7750e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1013/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.3852e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1014/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.8391e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1015/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.7556e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1016/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.7433e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1017/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 7.6530e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1018/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.6744e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1019/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 6.8747e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1020/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - loss: 6.8009e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1021/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - loss: 6.5516e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1022/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - loss: 6.3505e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1023/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.2953e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 1024/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.4746e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1025/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.5588e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 1026/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.4602e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 1027/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 6.3660e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1028/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 7.1636e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1029/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.2282e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 1030/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.3056e-05 - val_loss: 0.0116 - learning_rate: 7.0000e-06\n",
      "Epoch 1031/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.3255e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1032/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.1589e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1033/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.0810e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1034/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.6320e-05 - val_loss: 0.0117 - learning_rate: 7.0000e-06\n",
      "Epoch 1035/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.2237e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1036/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.6612e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1037/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 7.0429e-05 - val_loss: 0.0123 - learning_rate: 7.0000e-06\n",
      "Epoch 1038/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.3279e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1039/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.8062e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1040/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.5314e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 1041/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.6189e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1042/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 6.0742e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1043/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.2238e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1044/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.3682e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1045/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step - loss: 6.8626e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1046/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.4482e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1047/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.0689e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1048/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 7.3574e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1049/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.8068e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 1050/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.6824e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1051/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.2781e-05 - val_loss: 0.0124 - learning_rate: 7.0000e-06\n",
      "Epoch 1052/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 7.3415e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1053/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.3536e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 1054/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.8078e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 1055/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.5864e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 1056/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 6.2997e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 1057/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.8412e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1058/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.6790e-05 - val_loss: 0.0124 - learning_rate: 7.0000e-06\n",
      "Epoch 1059/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.6544e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1060/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.6459e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1061/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.4413e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 1062/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 6.5778e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1063/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.6378e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 1064/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.0798e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1065/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.9608e-05 - val_loss: 0.0123 - learning_rate: 7.0000e-06\n",
      "Epoch 1066/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.6336e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1067/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - loss: 7.1560e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1068/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.6671e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1069/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.4882e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1070/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.3671e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1071/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.8808e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1072/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 6.7370e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1073/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.3527e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1074/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.4908e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1075/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.2424e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1076/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.3206e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1077/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.7986e-05 - val_loss: 0.0118 - learning_rate: 7.0000e-06\n",
      "Epoch 1078/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.7576e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1079/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.8188e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1080/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.6859e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1081/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.9500e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1082/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.9238e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1083/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7024e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1084/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.9252e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1085/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.8544e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1086/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 7.2480e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1087/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.4245e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1088/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.4892e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1089/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 6.7380e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 1090/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.5419e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 1091/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.5497e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1092/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.6617e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1093/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.2995e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1094/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 6.5660e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n",
      "Epoch 1095/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - loss: 7.0287e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1096/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 6.6471e-05 - val_loss: 0.0121 - learning_rate: 7.0000e-06\n",
      "Epoch 1097/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 7.0996e-05 - val_loss: 0.0122 - learning_rate: 7.0000e-06\n",
      "Epoch 1098/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 6.0054e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1099/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 6.5091e-05 - val_loss: 0.0119 - learning_rate: 7.0000e-06\n",
      "Epoch 1100/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 6.2475e-05 - val_loss: 0.0120 - learning_rate: 7.0000e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with the custom callback\n",
    "history = model_builder.train_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    epochs=1100,\n",
    "    callbacks_list=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the losses from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "train_loss_x_midpoints = history.history.get('x_midpoints_reshape_loss', train_loss)\n",
    "val_loss_x_midpoints = history.history.get('val_x_midpoints_reshape_loss', val_loss)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2,1)\n",
    "plt.plot(train_loss_x_midpoints, label='Train Loss x_midpoints_reshape')\n",
    "plt.plot(val_loss_x_midpoints, label='Validation Loss x_midpoints_reshape')\n",
    "plt.xlabel('Epochs')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder.model.save(\"/home/da886/Analysis/30KNoFalsePositivesFixed-index6_13__overfitlonger.keras\")\n",
    "# loaded_model = tf.keras.models.load_model(\n",
    "# \"/home/da886/Final Electron counting project/Trained weights/Fixed weights/13overfitoriginalmodelgeneralized.keras\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 19:26:47.032735: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-08 19:26:47.048495: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-08 19:26:47.062384: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-08 19:26:47.066425: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-08 19:26:47.079888: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-08 19:26:47.654521: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m\n\u001b[1;32m     35\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# # Create the validation dataset\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# val_dataset = val_dataset.batch(800)\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((\u001b[43mtrain_images\u001b[49m, train_midpoints))\n\u001b[1;32m     41\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m800\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# inputs,targets = next(iter(train_dataset))\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# outputs = model_builder.model.predict(inputs)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# # Initialize lists to collect the data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the function for visualizing midpoints\n",
    "def visualize_midpoints(image, midpoints, title=\"Predicted Midpoint Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualizes midpoints on an image without using a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "    - title: The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    midpoints_np = midpoints\n",
    "\n",
    "    # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot midpoints directly, only if they are not (0, 0)\n",
    "    for i, (x, y) in enumerate(midpoints_np):\n",
    "        if x >= 3 and y >= 3:  # Only plot if the point is not (0, 0)\n",
    "            plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# # Create the validation dataset\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n",
    "# val_dataset = val_dataset.batch(800)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)\n",
    "# # Initialize lists to collect the data\n",
    "all_images = []\n",
    "all_true_midpoints = []\n",
    "all_pred_midpoints = []\n",
    "\n",
    "# # Loop through each batch in the validation dataset, predict, and collect results\n",
    "# for i, (data_batch, midpoints_batch) in enumerate(val_dataset):\n",
    "\n",
    "for i, (data_batch, midpoints_batch) in enumerate(train_dataset):\n",
    "    print(f\"Processing batch {i + 1}, batch shape: {data_batch.shape}\")\n",
    "    \n",
    "    # Get the model predictions\n",
    "    predictions = model_builder.model.predict(data_batch)\n",
    "\n",
    "    # Extend the lists to store data from each batch\n",
    "    all_images.extend(data_batch.numpy())  # Store all images\n",
    "    all_true_midpoints.extend(midpoints_batch.numpy())  # Store all true midpoints\n",
    "    all_pred_midpoints.extend(predictions)  # Store all predicted midpoints\n",
    "\n",
    "# Convert lists to arrays for easier indexing\n",
    "all_images = np.array(all_images)\n",
    "all_true_midpoints = np.array(all_true_midpoints)\n",
    "all_pred_midpoints = np.array(all_pred_midpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24000, 64, 64), (24000, 1, 13, 2), (24000, 1, 13, 2))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape,all_pred_midpoints.shape,all_true_midpoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select an index to visualize from the entire dataset\n",
    "index_to_visualize = np.random.randint(0, len(all_images))\n",
    "\n",
    "# index_to_visualize = 11548\n",
    "# Visualize the selected image with predicted and true midpoints\n",
    "visualize_midpoints(all_images[index_to_visualize], all_pred_midpoints[index_to_visualize, 0, :, :] * 64, title=\"Predicted Midpoints\")\n",
    "visualize_midpoints(all_images[index_to_visualize], all_true_midpoints[index_to_visualize, 0, :, :] * 64, title=\"Ground Truth Midpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00016376097, 0.9970034)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_pred_midpoints),np.max(all_pred_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13964641, 0.84375)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_true_midpoints),np.max(all_true_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables to track the min and max MSE\n",
    "min_mse = float('inf')\n",
    "max_mse = float('-inf')\n",
    "min_mse_index = -1\n",
    "max_mse_index = -1\n",
    "\n",
    "# Loop through each prediction to calculate the MSE\n",
    "for i in range(len(all_pred_midpoints)):\n",
    "    mse = np.mean((all_pred_midpoints[i] - all_true_midpoints[i]) **2)\n",
    "    \n",
    "    if mse < min_mse:\n",
    "        min_mse = mse\n",
    "        min_mse_index = i\n",
    "    \n",
    "    if mse > max_mse:\n",
    "        max_mse = mse\n",
    "        max_mse_index = i\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot an image with its centers\n",
    "def plot_image_with_centers(image, true_center, predicted_center, title):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  # Display the image\n",
    "\n",
    "    # Plot the actual center (Groundtruth)\n",
    "    plt.scatter(true_center[:, 0], true_center[:, 1], color='green', label='Groundtruth', s=10)\n",
    "\n",
    "    # Plot the predicted center\n",
    "    plt.scatter(predicted_center[:, 0], predicted_center[:, 1], color='red', label='Predictions', s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the image with the least MSE\n",
    "plot_image_with_centers(all_images[min_mse_index],\n",
    "                        all_true_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Least MSE. MSE: {min_mse:.4f}')\n",
    "\n",
    "# Plotting the image with the largest MSE\n",
    "plot_image_with_centers(all_images[max_mse_index],\n",
    "                        all_true_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Largest MSE. MSE: {max_mse:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5266"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mse_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
