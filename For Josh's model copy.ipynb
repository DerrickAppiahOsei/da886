{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Set CUDA device order and visible devices\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7,8,9\"\n",
    "\n",
    "# # Set the device\n",
    "# device = '/cpu:0'\n",
    "# if tf.config.experimental.list_physical_devices('GPU'):\n",
    "#     try:\n",
    "#         # Restrict TensorFlow to only use the second GPU\n",
    "#         gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#         if gpus:\n",
    "#             tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "#             device = '/gpu:0'\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "\n",
    "# print(\"device\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 17:08:19.495868: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-11 17:08:19.510512: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-11 17:08:19.523732: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-11 17:08:19.527781: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-11 17:08:19.540451: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-11 17:08:20.170518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 17:08:25.022583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79196 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:45:00.0, compute capability: 8.0\n",
      "2024-10-11 17:08:25.024119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79196 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:46:00.0, compute capability: 8.0\n",
      "2024-10-11 17:08:25.025447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79194 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:49:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # Only GPUs 0 and 1 will be visible to TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\",\"/gpu:2\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# DataLoader Class Definition\n",
    "# -----------------------------\n",
    "class DataLoader:\n",
    "    def __init__(self, h5_filename):\n",
    "        self.h5_filename = h5_filename\n",
    "        self.images, self.centers = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with h5py.File(self.h5_filename, 'r') as f:\n",
    "            images = np.array(f['images'])\n",
    "            centers = np.array(f['centers_training'])\n",
    "        return images, centers\n",
    "\n",
    "    def plot_image_with_centers(self, image_index=None):\n",
    "        if image_index is None:\n",
    "            image_index = np.random.randint(0, len(self.images))\n",
    "\n",
    "        image = self.images[image_index]\n",
    "        centers = self.centers[image_index]\n",
    "\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        valid_centers = centers[centers[:, 0] == 1]\n",
    "        for center in valid_centers:\n",
    "            plt.scatter(center[1], center[2], c='red', marker='o',s=5)  # center[1] is x and center[2] is y\n",
    "        plt.title('Image with Valid Centers Marked')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_centers(centers):\n",
    "        return centers[np.lexsort((centers[:, 0], centers[:, 1]))]\n",
    "\n",
    "    def normalize_data(self):\n",
    "        normalized_images = self.images / np.max(self.images)\n",
    "        sorted_centers = np.array([self.sort_centers(image_centers[:, 1:]) for image_centers in self.centers])\n",
    "        normalized_centers = sorted_centers / np.max(centers)\n",
    "\n",
    "        normalized_midpoints = tf.expand_dims(normalized_centers, axis=1)\n",
    "        return normalized_images, normalized_midpoints.numpy()\n",
    "\n",
    "    def split_data(self, train_size=0.8, random_state=42):\n",
    "        normalized_images, normalized_midpoints_np = self.normalize_data()\n",
    "        return train_test_split(normalized_images, normalized_midpoints_np, train_size=train_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Utility Function Definition\n",
    "# -----------------------------\n",
    "def plot_transposed_images_with_midpoints(dataset, image_indices=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Extracts multiple images and their midpoints from the given dataset, transposes the images, \n",
    "    corrects the midpoints, and plots the transposed images with the corrected midpoints.\n",
    "\n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The dataset from which to extract the images and midpoints.\n",
    "    - image_indices (list): The indices of the images in the batch to visualize. Default is [0, 1, 2, 3].\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract a sample image batch and its corresponding midpoints from the dataset\n",
    "    sample_image_batch, sample_midpoints_batch = next(iter(dataset))\n",
    "\n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(image_indices):\n",
    "            # Select the specified image and corresponding midpoints from the batch\n",
    "            sample_image = np.array(sample_image_batch[image_indices[i]])\n",
    "            sample_midpoints = np.array(sample_midpoints_batch[image_indices[i]])\n",
    "\n",
    "            # Transpose the image\n",
    "            transposed_image = sample_image.T\n",
    "\n",
    "            # Correct the midpoints by swapping the x and y coordinates\n",
    "            transposed_midpoints_corrected = sample_midpoints[:, :, [1, 0]]\n",
    "\n",
    "            # Plot the transposed image with corrected midpoints\n",
    "            ax.imshow(transposed_image, cmap='gray')\n",
    "            ax.scatter(\n",
    "                transposed_midpoints_corrected[:, :, 0] * 64, \n",
    "                transposed_midpoints_corrected[:, :, 1] * 64, \n",
    "                c='red', marker='o', s=5\n",
    "            )\n",
    "            ax.set_title(f'Image {image_indices[i]} for this batch')\n",
    "        else:\n",
    "            ax.axis('off')  # If fewer than 4 images are requested, hide the unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Loss and Callback Definitions\n",
    "# -----------------------------\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(exponent):\n",
    "    def loss(y_true, y_pred):\n",
    "        diff = tf.abs(y_true - y_pred)\n",
    "        powered_diff = tf.pow(diff, exponent)\n",
    "        return tf.reduce_mean(powered_diff)\n",
    "    return loss\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DynamicExponentCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_exponent, increment, update_frequency):\n",
    "        super().__init__()\n",
    "        self.exponent = initial_exponent\n",
    "        self.increment = increment\n",
    "        self.update_frequency = update_frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.update_frequency == 0:\n",
    "            self.exponent += self.increment\n",
    "            print(f\"\\nEpoch {epoch + 1}: Increasing exponent to {self.exponent}\")\n",
    "            self.model.loss = self.custom_loss(self.exponent)\n",
    "\n",
    "    def custom_loss(self, exponent):\n",
    "        def loss(y_true, y_pred):\n",
    "            diff = tf.abs(y_true - y_pred)\n",
    "            powered_diff = tf.pow(diff, exponent)\n",
    "            return tf.reduce_mean(powered_diff)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'initial_exponent': self.exponent,\n",
    "            'increment': self.increment,\n",
    "            'update_frequency': self.update_frequency,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my NEW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# class ModelBuilder:\n",
    "#     def __init__(self, input_shape=(64, 64, 1), num_classes=3, num_coordinates=2, learning_rate=3e-5, weights_path=None, l2_reg=0.001):\n",
    "#         self.input_shape = input_shape\n",
    "#         self.num_classes = num_classes\n",
    "#         self.num_coordinates = num_coordinates\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.l2_reg = l2_reg\n",
    "#         self.model = self.build_model()\n",
    "\n",
    "#         # Load weights if a path is provided\n",
    "#         if weights_path is not None:\n",
    "#             self.model.load_weights(weights_path)\n",
    "\n",
    "#         self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "#         # self.optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "#     def build_model(self):\n",
    "#         l2 = regularizers.l2(self.l2_reg)\n",
    "        \n",
    "#         x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "#         # First branch\n",
    "#         x_1 = layers.Conv2D(64, kernel_size=6, strides=1, padding='same', activation='relu')(x_input)\n",
    "#         x_1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=3, padding='same', activation='relu', kernel_regularizer=l2)(x_1)\n",
    "#         # x_1 = layers.Dropout(0.1)(x_1)\n",
    "#         # x_1 = layers.BatchNormalization()(x_1)\n",
    "\n",
    "#         # Second branch\n",
    "#         x_2 = layers.Conv2D(32, kernel_size=8, strides=3, padding='same', activation='relu')(x_input)\n",
    "#         x_2 = layers.Conv2D(64, kernel_size=4, strides=1, padding='same', activation='relu')(x_2)\n",
    "#         x_2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_2)\n",
    "#         # x_2 = layers.Dropout(0.1)(x_2)\n",
    "#         # x_2 = layers.BatchNormalization()(x_2)\n",
    "\n",
    "#         # Concatenate branches\n",
    "#         x_3 = layers.concatenate([x_1, x_2])\n",
    "#         x_3 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_3)\n",
    "#         # x_3 = layers.Dropout(0.1)(x_3)\n",
    "#         # x_3 = layers.BatchNormalization()(x_3)\n",
    "\n",
    "#         # Third branch\n",
    "#         x_4 = layers.Conv2D(64, kernel_size=19, strides=5, padding='same', activation='relu', kernel_regularizer=l2)(x_input)\n",
    "        \n",
    "#         # Flatten and concatenate\n",
    "#         x_3 = layers.Flatten()(x_3)\n",
    "#         x_4 = layers.Flatten()(x_4)\n",
    "#         x = layers.Concatenate()([x_3, x_4])\n",
    "\n",
    "#         # Dense layers with L2 regularization\n",
    "#         x = layers.Dense(256, activation='relu', kernel_regularizer=l2)(x)\n",
    "#         # x = layers.Dropout(0.1)(x)\n",
    "\n",
    "#         # Output layer for midpoints\n",
    "#         x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "#         x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "#         return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "#     def compile_model(self, loss_function):\n",
    "#         self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "#     def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "#         history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "#         return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, input_shape=(64, 64, 1), num_classes=13, num_coordinates=2, learning_rate=1e-3, weights_path=None,l1_reg=0.001,l2_reg =0.01):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_coordinates = num_coordinates\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # Load weights if a path is provided\n",
    "        if weights_path is not None:\n",
    "            self.model.load_weights(weights_path)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        # self.optimizer =tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        l1 = regularizers.l1(self.l1_reg)\n",
    "        l2 = regularizers.l2(self.l2_reg)\n",
    "\n",
    "    \n",
    "        x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=5, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        # x = layers.Conv2D(128, kernel_size=5, padding='same', activation='relu')(x)\n",
    "        # # x = layers.MaxPool2D()(x)\n",
    "        # # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='linear', name='x_midpoints')(x)\n",
    "        x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "        return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "    def compile_model(self, loss_function):\n",
    "        self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "    def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "        history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Main Script Execution\n",
    "# -----------------------------\n",
    "\n",
    "# Load data\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_Mixed_13.h5'             \n",
    "h5_filename = '/home/da886/Final Electron counting project/Images and Labels/12KFixed_Mixed_13_SparsespotsRandomIndex.h5'\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_13_SparsespotsRandomIndex.h5'\n",
    "# h5_filename ='/home/da886/Final Electron counting project/Images and Labels/30KFixed-index6_13.h5'\n",
    "data_loader = DataLoader(h5_filename)\n",
    "images, centers = data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f03c4726dd0>, 10046)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=np.random.randint(0,len(centers))\n",
    "data_loader.plot_image_with_centers(l)\n",
    "plt.imshow(images[l]),l\n",
    "# plt.grid(True),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7fcea0723590>, 16099)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[l]),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., 23., 34.],\n",
       "       [ 1., 10., 60.],\n",
       "       [ 1., 15., 35.],\n",
       "       [ 1., 45.,  6.],\n",
       "       [ 1., 16.,  6.],\n",
       "       [ 1., 44., 44.],\n",
       "       [ 1., 18., 25.],\n",
       "       [ 1., 20., 41.],\n",
       "       [ 1., 25., 56.],\n",
       "       [ 1., 28., 50.],\n",
       "       [ 1., 20., 38.],\n",
       "       [ 1., 29., 24.],\n",
       "       [ 1., 55., 46.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.random.randint(0,len(centers))\n",
    "centers[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data and split it into training and validation sets\n",
    "train_images, val_images, train_midpoints, val_midpoints = data_loader.split_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_images), np.max(train_images), np.min(train_midpoints), np.max(train_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: (9600, 64, 64), Train Midpoints: (9600, 1, 13, 2)\n",
      "Validation Images: (2400, 64, 64), Validation Midpoints: (2400, 1, 13, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 400\n",
    "train_dataset = train_dataset.shuffle(buffer_size=8000, reshuffle_each_iteration=True).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=8000).batch(batch_size)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f'Train Images: {train_images.shape}, Train Midpoints: {train_midpoints.shape}')\n",
    "print(f'Validation Images: {val_images.shape}, Validation Midpoints: {val_midpoints.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_transposed_images_with_midpoints(train_dataset, image_indices=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=10, verbose=1, mode='min', min_lr=3e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">26,650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m3,277,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │        \u001b[38;5;34m26,650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m2\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,348,762</span> (39.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,348,762\u001b[0m (39.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,348,250</span> (39.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,348,250\u001b[0m (39.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# dynamic_exponent_callback = DynamicExponentCallback(2, 1, 400)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # Instantiate the model builder\n",
    "    # model_builder = ModelBuilder(weights_path= \"/home/da886/Analysis/30KFixed_13_SparsespotsrandomSPOTS.keras\")\n",
    "    model_builder = ModelBuilder()\n",
    "\n",
    "    # Build the model\n",
    "    model_builder.build_model()\n",
    "\n",
    "    # Display the model architecture\n",
    "    model_builder.model.summary()\n",
    "\n",
    "    # Compile the model using the custom loss function\n",
    "    # model_builder.compile_model(loss_function=dynamic_exponent_callback.custom_loss(2))\n",
    "    model_builder.compile_model(loss_function=tf.keras.losses.MeanSquaredError()) \n",
    "    \n",
    "    # model_builder.compile_model(loss_function=custom_loss(3))e\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 17:09:52.093669: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-11 17:09:52.120156: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-11 17:09:52.146668: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1728666592.203119  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.211746  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.231935  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.270590  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.270618  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.270809  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.271322  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.271339  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.271544  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.277874  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.278007  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.278236  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.298210  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.298204  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.298244  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.300720  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.300726  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.301063  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.302060  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.302284  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.302430  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.302758  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.302965  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.303203  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.305300  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.305382  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.305669  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.323904  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.324074  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.324718  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.324730  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.324943  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.325570  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.325602  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.325829  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.326230  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.326448  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.326680  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.326963  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.327159  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.327432  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.327656  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.327978  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.328287  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.328463  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.330133  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.330238  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.330602  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.332351  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.332482  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.332701  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.334809  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.334908  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.335192  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.337482  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.337583  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.337895  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.340206  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.340302  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.340569  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.343605  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.343708  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.344091  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.345415  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.345495  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.345861  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.347057  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.354615  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.354616  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.354720  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.357351  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.357610  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.357673  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.450714  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.450870  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.451326  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.451441  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.451882  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.452067  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.452392  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.452587  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.452948  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.453154  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.453684  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.453893  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.454534  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.454734  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.455354  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.455565  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.456164  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.456384  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.457036  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.457301  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.458408  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.458687  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.459786  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.460389  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.467534  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.468045  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.468125  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.468586  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.468665  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.469143  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.469218  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.469708  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.469785  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.470274  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.470350  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.470842  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.470918  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.471455  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.471525  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.472342  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.472705  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.472945  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.473259  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.473473  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.473821  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.474026  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.474341  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.474571  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.474885  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.475106  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.476185  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.476262  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.483434  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.483440  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.484083  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.484090  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.484671  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.484679  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.486413  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.486488  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.488336  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.488414  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.491007  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.491078  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.491792  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.491967  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.492707  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.493005  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.493755  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.494125  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.494871  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.504677  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.505183  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.505289  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.505872  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.505945  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.506447  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.506619  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.507068  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.507243  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.507609  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.508035  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.508401  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.509409  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.509766  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.510763  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.511114  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.512092  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.512438  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.513466  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.513809  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.514794  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.515136  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.516278  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.516598  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.531487  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.531558  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.532068  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.532143  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.532676  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.532757  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.533371  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.533446  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.534092  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.534175  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.534793  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.534801  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.535470  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.535477  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.536234  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.536242  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.536944  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.537021  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.537680  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.537755  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.539559  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.539630  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.540397  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.540475  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.541196  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.541274  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.542050  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.542126  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.543028  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.543099  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.544692  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.544768  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.545591  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.545685  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.546596  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.546693  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.547536  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.547705  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.548388  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.548561  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.549478  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.550506  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.551406  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.553148  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.554029  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.554672  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.555559  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.556512  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.557372  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.558505  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.559343  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.568799  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.568799  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.569601  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.569677  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.570314  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.570532  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.571036  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.571257  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.571827  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.571990  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.572622  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.573153  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.573426  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.574272  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.575189  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.575558  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.576012  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.576865  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.577845  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.578014  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.578834  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.579824  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.580486  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.580840  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.581989  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.582894  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.583219  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.584859  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.585384  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.586093  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.587415  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.588075  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.588900  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.590261  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.591884  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.595068  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.597569  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.601852  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.604526  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.607242  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.610569  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.617807  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.618513  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.619209  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.619981  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.620769  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.621572  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.622422  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.622600  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.623348  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.623753  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.624178  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.624721  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.625035  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.625889  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.626061  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.627082  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.627257  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.628083  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.628393  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.629097  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.629494  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.630339  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.630739  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.632082  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.632158  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.633423  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.633499  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.634535  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.634834  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.636339  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.637702  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.639189  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.640903  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.643916  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.645205  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.647943  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.648643  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.651311  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.653266  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.657874  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.662827  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.662932  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.663977  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.664933  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.666063  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.667401  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.667890  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.668525  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.669617  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.670852  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.672108  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.673551  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.674917  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.679573  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.684268  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.688981  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.693571  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.698142  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.703215  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.706883  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.707461  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.708030  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.708203  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.708539  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.709089  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.709808  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.710649  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.711470  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.712279  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.713154  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.714495  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.715839  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.723523  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.723926  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.724352  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.724798  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.725259  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.725715  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.726308  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.726323  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.726807  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.727525  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.727795  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.728323  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.728886  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.728981  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.729513  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.730176  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.730353  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.730826  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.731723  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.732122  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.732720  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.733033  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.733268  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.734069  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.734531  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.734877  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.735809  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.736648  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.737192  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.737564  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.738627  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.738802  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.739753  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.740442  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.742194  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.743862  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.746775  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.748903  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.749817  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.750411  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.750968  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.751240  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.751583  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.752126  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.752915  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.753378  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.754283  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.755307  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.755635  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.756954  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.758320  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.759639  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.761107  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.763170  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.765839  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.767116  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.768309  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.768416  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.769552  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.770782  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.771282  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.772156  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.773474  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.774967  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.776196  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.776288  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.776663  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.776774  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.777280  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.777805  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.777907  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.778522  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.779104  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.779394  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.779748  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.780474  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.781206  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.781289  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.781934  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.782698  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.782983  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.783081  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.783722  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.784411  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.784767  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.785174  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.786045  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.787729  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.787825  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.788544  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.789512  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.790261  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.790589  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.791430  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.792731  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.793411  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.795005  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.796126  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.796973  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.797665  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.797730  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.799706  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.799715  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.801330  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.801708  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.803146  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.804714  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.804937  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.807205  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.807411  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.808950  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.809914  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.810962  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.811669  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.812451  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.812980  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.813306  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.814030  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.814745  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.815155  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.815267  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.815913  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.816906  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.818309  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.820737  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.821154  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.823194  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.825589  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.826055  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.828070  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.830763  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.835138  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.835804  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.837602  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.839191  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.840976  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.842733  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.844445  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.844961  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.846680  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.848660  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.850674  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.852402  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.853474  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.854404  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.860266  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.860924  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.861621  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.862527  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.862626  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.863354  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.863562  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.864172  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.865023  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.865951  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.866784  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.867641  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.868603  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.869593  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.870583  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.871591  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.872496  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.872817  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.872904  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.874562  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.875803  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.877133  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.878634  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.879991  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.882083  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.882102  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.883182  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.887471  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.890175  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.890970  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.893529  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.900132  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.905333  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.906503  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.907456  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.908590  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.909682  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.909936  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.911058  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.912152  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.913386  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.914625  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.915731  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.916960  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.919710  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.921565  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.926220  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.930892  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.935422  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.939937  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.944964  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.949846  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.997967  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666592.999788  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.001745  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.003640  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.005742  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.007787  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.008211  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.009312  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.009983  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.010549  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.011782  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.012043  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.013164  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.014261  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.014500  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.015995  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.016556  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.017270  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.018640  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.019178  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.020219  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.022010  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.022026  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.023701  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.024819  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.025378  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.028309  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.028952  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.030457  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.032483  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.032816  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.034949  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.036328  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.036862  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.037619  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.039437  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.040256  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.041405  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.043299  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.043589  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.044562  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.045434  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.047222  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.047513  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.049937  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.049949  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.051999  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.054223  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.055091  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.056507  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.057715  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.059160  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.061027  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.061935  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.062640  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.064854  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.067365  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.069345  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.072656  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.073216  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.076063  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.077309  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.078025  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.079803  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.081399  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.081770  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.083884  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.084849  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.086163  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.087888  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.089879  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.090438  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.091903  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.093714  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.093827  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.095832  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.096882  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.098920  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.099659  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.103769  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.103952  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.104969  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.106831  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.108700  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.110444  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.113532  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.113969  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.116788  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.120511  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.123145  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.124301  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.125945  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.129127  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.132012  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.132327  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.135114  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.139226  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.140899  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.142316  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.142879  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.145971  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.149166  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.150302  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.152298  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.155928  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.159613  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.160185  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.161732  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.178624  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.180104  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.197172  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.197862  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.215388  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.215801  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.233713  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.233992  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.252051  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.253063  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.270827  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.276759  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.278563  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.280501  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.282391  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.284521  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.286590  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.288775  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.290313  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.290830  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.293037  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.295329  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.298047  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.300802  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.303703  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.308032  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.311756  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.315677  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.319636  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.322936  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.337015  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.341961  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.346710  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.364244  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.367389  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.370549  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.373317  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.377396  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.380434  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.384019  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.387181  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.390260  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.393826  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.397556  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.416458  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.434735  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.453121  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.470808  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.482162  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.485509  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.488634  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.488900  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.492089  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.495960  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.499635  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.503527  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.507443  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.507695  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.511473  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.515545  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.520637  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.522790  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.525943  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.526178  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.526683  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.529308  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.531540  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.532775  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.536723  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.537847  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.540402  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.544214  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.545219  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.548511  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.552370  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.553029  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.556575  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.560510  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.561674  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.566962  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.569982  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.572666  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.579016  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.580096  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.586441  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.589391  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.594147  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.601697  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.610785  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.611345  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.620851  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.642416  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.644039  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.645702  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.647213  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.648817  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.650453  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.652557  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.654119  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.655947  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.657514  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.659365  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.661220  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.670670  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.675541  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.677191  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.678686  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.679972  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.680289  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.681914  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.684006  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.685560  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.687393  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.689018  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.689195  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.690890  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.692739  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.698644  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.702062  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.708008  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.711244  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.717528  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.720389  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.727454  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.729776  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.739192  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.748729  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.758195  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.758842  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.761562  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.764672  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.768112  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.772021  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.775679  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.779499  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.783760  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.787625  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.791811  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.796897  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.802169  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.807800  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.814084  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.821549  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.829298  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.836798  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.846339  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.854237  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.855636  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.855967  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.857628  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.859372  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.861258  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.863097  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.864939  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.866878  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.868783  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.870774  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.873132  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.875506  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.876782  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.878110  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.881017  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.884440  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.887616  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.887982  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.889328  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.890971  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.891888  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.892712  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.894598  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.896587  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.896674  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.898454  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.900416  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.901673  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.902311  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.904312  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.906422  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.906728  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.909166  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.910142  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.912025  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.912038  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.913525  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.915176  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.915268  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.916886  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.917539  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.918586  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.918978  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.920521  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.922113  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.922354  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.923920  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.925772  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.925986  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.927640  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.930609  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.935298  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.935389  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.936112  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.936800  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.936980  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.937471  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.938326  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.938986  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.939660  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.940412  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.941185  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.942044  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.942794  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.945372  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.946111  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.946294  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.947934  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.950605  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.953495  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.955119  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.956714  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.959653  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.962699  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.963907  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.964387  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.964626  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.965266  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.965912  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.966748  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.967386  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.968045  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.968790  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.969547  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.970398  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.971151  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.973831  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.973926  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.976464  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.979135  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.982009  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.983295  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.985219  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.988126  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.991127  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.993335  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.996099  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.996746  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.997384  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.998063  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.998783  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666593.999445  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.000116  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.000783  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.001482  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.002185  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.002973  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.003770  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.004709  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.005716  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.006758  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.008021  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.009071  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.010376  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.011738  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.014150  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.018130  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.024711  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.025347  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.025963  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.026642  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.027352  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.028004  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.028838  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.028921  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.029516  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.030210  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.030911  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.031701  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.032506  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.033444  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.034460  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.035513  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.036780  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.037824  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.038458  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.038924  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.039150  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.039373  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.039814  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.040263  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.041577  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.041987  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.044400  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.045527  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.047122  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.050808  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.054583  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.056074  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.057270  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.060427  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.065545  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.066004  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.066413  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.066853  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.067293  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.067786  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.068259  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.068707  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.069137  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.069254  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.069734  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.070208  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.070730  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.071172  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.071598  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.071767  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.072215  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.072729  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.073213  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.073783  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.074434  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.074551  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.076315  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.076917  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.077242  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.078453  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.079179  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.079983  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.081113  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.081195  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.083850  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.086663  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.086981  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.088114  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.094330  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.094782  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.095226  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.095666  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.096304  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.096779  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.097303  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.097730  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.098233  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.098680  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.099202  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.099727  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.100295  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.100868  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.102605  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.103206  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.104717  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.105444  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.106261  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.107277  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.112778  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.114199  207340 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.122290  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.123992  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.125630  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.127349  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.129232  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.131076  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.132920  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.134872  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.136755  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.138740  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.141114  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.143491  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.146065  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.149055  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.152493  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.156073  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.159976  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.164623  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.169326  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.180210  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.198086  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.198784  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.199410  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.200052  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.200883  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.201535  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.202191  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.202935  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.203693  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.204554  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.205314  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.207883  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.210417  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.213075  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.215928  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.219113  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.222027  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.225063  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.258617  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.259258  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.259867  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.260544  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.261251  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.261898  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.262565  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.263220  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.263903  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.264600  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.265376  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.266169  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.267097  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.268111  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.269159  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.270411  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.271444  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.272740  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.275137  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.279099  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.289579  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.299200  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.299650  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.300057  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.300489  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.300932  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.302643  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.305078  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.308481  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.311270  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.315038  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.317687  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.320826  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.328129  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.328576  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.329024  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.329469  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.329940  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.330415  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.330934  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.331365  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.331870  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.332316  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.332844  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.335231  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.335816  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.336388  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.338120  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.338713  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.340237  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.340956  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.341764  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.342765  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.348272  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666594.349698  207349 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.053067  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.053105  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.053351  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.057555  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.057770  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.057800  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.058302  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.058512  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.058536  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.064084  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.064103  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.064212  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.065029  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.065057  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.065069  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.065933  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.065948  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.065961  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.066801  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.066815  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.066824  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.067637  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.067642  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.067663  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.068488  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.068499  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.068532  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.073993  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.074205  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.074299  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.074561  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.074904  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.075063  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.075195  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.075461  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.075715  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.075935  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.076157  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.076446  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.076650  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.076877  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.077124  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.077364  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.077589  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.077832  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.078066  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.078293  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.078481  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.079552  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.079876  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.080088  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.081289  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.081651  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.081826  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.096762  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.097027  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.097290  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.098757  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.099030  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.099339  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.100692  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.100998  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.101345  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.107667  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.107928  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.108296  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.135162  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.135656  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.136082  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.136578  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.137062  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.138425  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.139269  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.139471  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.139725  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.139953  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.140277  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.140584  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.140765  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.141463  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.141603  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.141698  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.142149  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.142294  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.142398  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.142728  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.143018  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.143253  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.143494  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.144138  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.144627  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.145058  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.145221  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.145584  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.145881  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.146958  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.147261  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.147413  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.147517  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.147742  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.147941  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.148276  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.148308  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.148973  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.149001  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.149179  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.149721  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.149737  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.149979  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.150307  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.150513  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.150589  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.150921  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.151095  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.151911  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.152366  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.152516  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.152536  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.153097  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.154450  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.154728  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.154831  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.155121  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.155363  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.155587  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.155754  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.155983  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.156262  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.156716  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.161479  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.161609  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.161710  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.167429  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.167540  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.167775  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.196872  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.197324  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.197365  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.197458  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.197855  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.198036  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.199507  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.199518  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.199621  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.200243  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.200266  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.200285  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.200977  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.200999  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.201024  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.201722  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.201742  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.201763  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.202450  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.202470  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.202490  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.203234  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.203254  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.203274  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.204044  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.204065  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.204089  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.204924  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.204943  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.204963  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.205671  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.205692  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.205716  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.206414  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.206434  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.206455  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.207156  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.207175  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.207195  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.207905  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.207927  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.207947  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.208680  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.208699  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.208724  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.209441  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.209460  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.209479  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.210248  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.210267  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.210292  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.211026  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.211044  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.211063  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.211870  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.211888  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.211908  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.212713  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.212733  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.212753  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.213621  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.213648  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.213662  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.214405  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.214426  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.214450  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.215176  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.215197  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.215222  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.216261  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.216281  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.216300  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.218894  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.218911  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.218932  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.222241  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.222746  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.222824  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.223542  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.224315  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.224513  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.227747  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.227940  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.228140  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.231305  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.231477  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.232013  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.234829  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.235000  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.235508  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.238340  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.238509  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.238978  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.257211  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.257332  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.257512  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.259254  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.259380  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.259589  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.259971  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.260107  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.260284  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.261770  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.261842  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.261855  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.263566  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.263573  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.263591  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.264547  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.264562  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.264576  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.266967  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.266975  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.267135  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.267835  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.267906  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.267919  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.269895  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.270034  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.270232  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.270559  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.270779  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.270963  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.271250  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.271490  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.271668  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.273938  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.273950  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.273964  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.276259  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.276386  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.276457  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.279948  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.280807  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.280836  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.291011  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.291087  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.291342  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.291827  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.291916  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.292101  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.294426  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.294637  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.294650  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.295113  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.295439  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.295537  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.295778  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.296228  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.296373  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.296481  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.296976  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.297119  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.297297  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.297769  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.297990  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.298158  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.298530  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.298784  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.298964  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.299277  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.299664  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.299743  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.299984  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.300606  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.300628  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.300740  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.301538  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.301724  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.301741  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.302187  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.302495  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.302512  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.302872  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.303356  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.303376  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.303579  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.304214  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.304288  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.304395  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.305494  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.305564  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.305576  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.306837  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.306906  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.306919  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.308220  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.308291  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.308304  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.310998  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.311280  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.311292  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.313550  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.313921  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.314012  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.316087  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.316457  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.316634  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.321029  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.321446  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.321664  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.330194  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.330717  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.330998  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.360438  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.360873  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.361074  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.361649  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.361669  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.361859  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.362405  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.362633  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.362737  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.363302  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.363539  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.363639  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.363987  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.364352  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.364454  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.364681  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.365019  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.365237  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.365408  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.365678  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.365947  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.366124  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.366345  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.366692  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.366979  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.367078  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.367406  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.367923  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.367934  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.368139  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.368883  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.368918  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.369093  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.369732  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.369958  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.370059  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.370756  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.370987  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.371099  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.371567  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.371880  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.372065  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.372434  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.372741  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.372962  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.373303  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.373635  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.374042  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.374210  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.374683  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.375257  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.376593  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.377222  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.377802  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.379000  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.379602  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.380196  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.386326  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.386981  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.387102  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.387636  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.387916  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.387994  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.388411  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.388778  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.388881  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.389157  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.389565  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.389784  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.389950  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.390343  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.390593  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.390762  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.391120  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.391399  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.391566  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.391886  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.392206  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.392378  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.392657  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.393027  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.393204  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.393451  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.393815  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.394017  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.394220  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.394591  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.394810  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.395040  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.395414  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.395739  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.395839  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.396201  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.396662  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.396761  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.397141  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.397452  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.397706  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.398139  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.398401  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.398697  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.399026  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.399510  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.399619  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.399912  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.400562  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.400679  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.400851  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.401694  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.401734  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.401900  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.402653  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.402878  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.402982  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.403713  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.403817  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.404679  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.404763  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.405435  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.405696  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.406626  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.406715  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.406852  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.407764  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.407871  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.408688  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.410035  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.411041  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.411864  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.413172  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.414161  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.415006  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.416799  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.417812  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.418678  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.420455  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.421500  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.422381  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.424117  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.425188  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.426377  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.427779  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.428874  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.430152  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.475265  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.475928  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.476681  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.476793  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.477591  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.477601  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.478572  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.478643  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.478645  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.479465  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.479659  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.479737  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.480305  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.480416  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.480701  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.481389  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.481397  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.481701  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.482124  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.482372  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.482780  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.483017  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.483367  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.483904  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.484073  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.484443  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.485194  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.485264  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.485537  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.486181  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.486347  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.486766  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.487442  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.487653  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.488681  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.489168  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.489569  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.490647  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.492600  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.498415  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.499640  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.500018  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.501229  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.501544  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.501589  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.502777  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.503263  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.503338  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.504377  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.504958  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.505028  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.505918  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.506690  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.506768  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.507495  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.508297  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.508407  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.509071  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.509918  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.510099  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.510720  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.511503  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.511806  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.512410  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.513169  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.513547  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.514147  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.514868  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.515089  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.515675  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.516730  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.516811  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.517264  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.518274  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.518673  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.519113  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.519856  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.520675  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.521106  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.521717  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.522737  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.523120  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.523714  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.524926  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.525233  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.525728  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.527278  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.527555  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.527849  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.530174  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.530377  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.530559  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.533109  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.541217  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.541432  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.543933  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.550561  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.550765  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.553239  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.559975  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.560082  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.562481  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.570343  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.570603  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.572933  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.580362  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.580784  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.583017  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.589964  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.590654  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.592781  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.708341  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.709961  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.711157  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.711589  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.712783  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.713255  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.714112  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.714414  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.715007  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.715761  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.716081  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.716734  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.717414  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.717834  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.718605  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.719108  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.719569  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.720430  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.720861  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.721457  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.722308  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.722599  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.723295  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.724414  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.724583  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.725196  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.726459  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.726637  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.727237  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.728368  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.728792  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.729336  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.730412  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.731220  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.731486  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.732516  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.734038  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.734060  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.734683  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.736878  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.736896  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.737159  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.739685  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.739720  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.739894  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.742423  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.742593  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.743107  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.745282  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.745908  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.746824  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.748772  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.749642  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.751449  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.752549  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.754252  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.757171  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.760887  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.763613  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.766603  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.776355  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.778432  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.779124  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.780429  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.781208  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.782165  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.782472  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.783234  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.784258  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.784481  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.785294  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.786365  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.786541  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.787317  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.788432  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.788654  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.789286  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.790515  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.790689  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.791427  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.792502  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.792874  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.793442  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.794665  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.795059  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.795662  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.796702  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.797152  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.797885  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.798936  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.799353  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.799986  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.801173  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.802050  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.802249  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.803292  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.804106  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.804971  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.805541  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.806728  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.807070  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.808272  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.809321  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.809734  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.810367  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.812065  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.812387  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.813055  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.814662  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.815176  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.815687  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.817810  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.817926  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.818473  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.820580  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.821018  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.821199  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.823816  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.824259  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.826109  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.827047  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.828940  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.829535  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.831925  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.832410  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.832665  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.835479  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.835664  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.838693  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.842586  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.846294  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.849586  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.853249  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.857112  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.860478  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.864240  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.868286  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.871760  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.875237  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.879687  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.883125  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.886325  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.890860  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.894407  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.897317  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.902031  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666597.905653  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.085431  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.087107  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.088941  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.090879  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.091949  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.092860  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.093632  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.095557  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.095657  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.097285  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.097624  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.098337  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.098990  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.099612  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.100860  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.101345  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.102167  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.102824  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.104610  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.104958  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.105076  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.107537  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.108237  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.108314  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.110366  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.111527  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.112397  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.113413  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.115092  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.115199  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.116736  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.119173  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.120294  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.121895  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.124419  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.126696  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.127173  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.133349  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.138768  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.141443  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.144500  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.147514  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.148038  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.150587  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.151072  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.153601  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.153800  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.154080  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.156669  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.157270  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.157289  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.159699  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.160270  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.160505  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.162820  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.163345  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.163801  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.166055  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.166412  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.166800  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.169377  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.170011  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.170028  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.172400  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.173184  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.173408  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.175494  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.176462  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.177421  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.178992  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.179444  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.180647  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.182226  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.183612  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.184851  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.185384  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.186794  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.188678  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.189612  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.190943  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.192887  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.193075  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.194733  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.197109  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.197819  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.199020  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.200960  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.203689  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.204031  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.205325  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.209779  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.210078  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.216253  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.225549  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.231194  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.237769  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.243965  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.250120  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.256347  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.262082  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.268227  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.274534  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.281757  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.288009  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.294528  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.300745  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.307120  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.313892  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.320888  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.327373  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.334339  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.555353  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.558463  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.561578  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.564033  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.564786  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.567153  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.568194  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.570278  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.571571  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.573224  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.573486  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.575279  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.576368  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.576896  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.578934  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.579508  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.580274  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.582835  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.582913  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.583936  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.586330  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.586906  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.587565  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.589719  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.591154  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.591332  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.593358  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.595368  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.595564  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.596952  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.599533  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.600732  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.600799  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.603851  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.605000  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.606248  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.608921  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.609367  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.611724  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.613709  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.614458  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.617195  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.618745  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.619899  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.624376  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.624445  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.625382  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.629889  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.632029  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.632418  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.635426  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.640076  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.641223  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.642456  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.649280  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.650096  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.659388  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.660207  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.668043  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.678358  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.687301  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.691186  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.695045  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.695052  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.699136  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.699155  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.703208  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.703223  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.705464  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.707214  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.707313  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.709401  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.711226  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.711324  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.713332  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.715191  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.715379  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.717268  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.719057  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.719471  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.721221  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.723073  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.723786  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.725209  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.727238  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.727753  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.729128  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.731660  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.732019  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.733174  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.735705  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.736353  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.737372  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.740076  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.740696  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.741796  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.744522  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.744540  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.745900  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.748152  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.748333  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.750332  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.752292  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.752695  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.754752  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.756313  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.757301  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.758482  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.760467  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.762993  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.763014  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.765450  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.766653  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.768926  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.770891  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.771065  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.774540  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.775942  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.776913  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.780075  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.781560  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.782469  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.787149  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.787449  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.787927  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.793034  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.794197  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.794929  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.798529  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.800007  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.801942  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.805530  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.806089  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.807760  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.812514  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.813838  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.818376  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.824460  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.826217  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.834056  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.844888  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.847758  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.855764  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.866874  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.869304  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.877482  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.888768  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.890837  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.899011  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.910453  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.912172  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.920499  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.932082  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.939647  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.948293  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666598.959759  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.313749  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.316918  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.320481  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.324154  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.326657  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.327957  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.329848  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.332876  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.333440  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.337133  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.338501  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.340954  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.341026  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.344085  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.344257  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.345931  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.347887  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.349974  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.351856  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.351866  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.355708  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.356401  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.357313  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.360689  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.363119  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.363456  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.366374  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.369438  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.371920  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.372285  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.376396  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.377830  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.382316  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.384268  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.385132  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.391388  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.395116  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.400288  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.407522  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.411373  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.419496  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.436259  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.453933  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.455841  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.457703  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.459668  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.461584  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.463403  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.465279  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.466363  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.467296  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.468250  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.469186  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.470075  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.471270  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.472009  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.473110  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.473916  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.475370  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.475726  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.477243  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.477588  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.479745  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.479855  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.481605  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.482051  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.483396  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.483663  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.484529  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.485311  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.485916  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.487362  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.487382  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.487728  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.489317  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.489608  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.490814  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.491231  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.491988  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.493059  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.494182  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.494927  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.496650  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.496947  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.498812  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.499309  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.500884  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.502216  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.502692  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.503138  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.504952  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.506816  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.509179  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.511358  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.511802  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.513864  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.514040  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.516529  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.519909  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.521299  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.523580  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.531281  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.532200  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.533038  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.540921  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.542834  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.544024  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.550515  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.553135  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.554687  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.561551  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.565078  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.572323  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.582775  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.672318  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.674194  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.676029  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.677929  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.679915  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.681849  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.683965  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.685104  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.686035  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.686993  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.688154  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.688840  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.690404  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.690746  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.692892  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.692909  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.694849  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.695202  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.696976  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.697913  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.699059  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.701360  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.701375  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.703043  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.703641  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.704387  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.704926  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.705972  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.706772  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.707499  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.708283  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.708682  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.710661  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.711135  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.711480  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.712610  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.714513  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.714739  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.716355  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.716819  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.717514  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.718951  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.720626  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.721302  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.721378  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.723691  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.724597  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.726015  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.728758  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.729471  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.730925  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.732026  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.734278  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.735059  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.738193  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.742186  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.743902  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.747115  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.748645  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.750856  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.751977  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.753036  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.755434  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.757502  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.760268  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.761218  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.761610  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.763626  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.763648  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.765843  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.766536  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.768267  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.769451  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.770359  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.773090  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.773103  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.776266  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.776459  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.779091  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.779328  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.779423  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.781353  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.782268  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.783092  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.783557  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.785779  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.785994  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.786247  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.788098  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.789242  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.789417  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.790782  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.791998  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.793158  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.793977  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.795698  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.797018  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.797098  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.798851  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.800053  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.801104  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.802017  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.803576  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.803793  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.805768  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.806483  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.806997  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.809527  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.809768  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.811127  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.813595  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.813707  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.815771  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.816414  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.816780  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.819132  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.819873  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.820034  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.823873  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.823974  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.824890  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.827610  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.828685  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.829058  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.831748  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.832821  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.834471  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.837205  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.837922  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.839208  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.841950  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.842163  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.846708  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.849353  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.850877  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.852463  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.856016  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.860320  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.860402  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.862773  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.870789  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.871119  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.873808  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.881169  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.884747  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.884965  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.892302  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.898825  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.899001  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.903280  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.912836  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.917363  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666599.931426  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.087195  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.089111  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.091121  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.093182  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.095379  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.098030  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.100888  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.102185  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.103929  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.104115  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.106142  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.107236  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.108221  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.110421  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.111952  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.113111  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.115985  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.116543  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.119057  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.121656  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.122073  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.122369  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.123591  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.125626  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.126999  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.127721  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.129945  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.131508  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.131841  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.132649  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.135542  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.136949  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.138628  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.141951  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.146847  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.146866  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.151401  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.152663  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.156865  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.165452  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.166530  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.167845  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.180751  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.187493  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.188391  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.189559  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.190670  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.191820  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.192973  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.194171  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.195363  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.196463  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.197610  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.198694  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.200012  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.200422  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.201273  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.202602  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.203903  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.204224  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.205076  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.205873  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.206187  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.207436  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.207461  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.208612  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.208917  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.209807  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.210956  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.211072  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.212166  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.213265  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.214334  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.215659  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.217133  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.217149  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.218664  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.220471  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.222187  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.222353  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.223636  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.223907  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.224958  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.225496  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.226245  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.227096  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.227702  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.227864  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.229194  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.230573  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.231948  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.232734  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.233236  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.233723  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.234384  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.235463  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.236792  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.238147  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.238287  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.238456  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.239503  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.241137  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.242787  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.243101  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.243589  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.244176  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.245639  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.247539  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.248557  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.253369  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.253916  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.258089  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.259169  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.262807  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.268329  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.273743  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.279075  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.303699  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.304873  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.306010  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.307209  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.308431  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.309700  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.310982  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.312277  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.313620  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.314990  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.316360  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.318018  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.319221  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.319612  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.320398  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.321321  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.321544  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.322738  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.323201  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.323963  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.325276  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.325463  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.326575  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.328005  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.328109  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.329351  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.330722  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.332085  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.333014  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.333742  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.335332  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.337038  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.338891  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.339954  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.341188  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.341288  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.342433  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.343813  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.343823  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.344303  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.345029  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.345694  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.346311  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.347010  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.347591  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.348325  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.348610  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.348913  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.349685  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.350276  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.351184  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.351670  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.352538  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.353066  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.354046  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.354737  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.355485  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.356358  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.357425  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.358092  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.359535  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.359549  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.359966  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.360899  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.361479  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.362297  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.362369  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.363773  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.363787  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.364763  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.365188  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.365358  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.366690  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.367100  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.368040  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.368951  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.369666  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.369764  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.371256  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.371359  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.373306  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.373406  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.375400  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.375687  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.377318  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.377963  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.379416  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.380534  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.380820  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.380939  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.382205  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.382695  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.383521  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.384072  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.384552  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.384846  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.386221  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.386743  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.387733  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.388635  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.389104  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.389360  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.390627  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.390920  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.392081  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.393214  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.394004  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.394945  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.395798  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.396102  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.398014  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.399360  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.400115  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.400526  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.401649  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.403412  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.404641  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.405297  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.406115  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.407521  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.409436  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.410283  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.411826  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.411904  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.414205  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.415926  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.416822  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.418954  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.420425  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.421517  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.425784  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.426078  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.427108  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.431502  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.434208  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.437220  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.441309  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.442939  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.448651  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.455919  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.463085  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.520815  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.522083  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.523375  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.524826  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.526371  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.528003  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.529730  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.531575  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.533870  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.536484  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.536553  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.537772  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.539073  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.539622  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.540547  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.542093  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.543737  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.544886  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.545493  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.547353  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.549673  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.550803  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.552195  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.555292  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.559260  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.559304  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.560685  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.560778  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.562001  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.563471  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.565028  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.566811  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.566902  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.568580  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.570496  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.570568  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.572888  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.575404  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.575489  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.578613  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.583989  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.585399  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.586175  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.586647  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.586934  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.587720  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.588491  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.589285  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.590151  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.590226  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.591028  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.591856  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.592690  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.593535  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.594395  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.595270  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.596325  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.597208  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.598255  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.598668  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.599308  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.600413  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.601579  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.602200  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.602988  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.603719  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.604477  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.604780  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.605276  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.606037  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.606218  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.606780  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.607711  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.607812  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.608518  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.609231  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.610204  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.610241  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.610411  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.611078  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.612070  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.612920  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.613417  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.613925  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.614800  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.615719  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.616427  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.616875  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.620071  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.622519  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.623782  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.624666  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.624950  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.625577  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.625857  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.626557  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.626725  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.627490  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.627657  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.627955  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.628264  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.628720  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.629057  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.629913  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.629985  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.630662  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.631010  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.631180  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.631469  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.632293  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.632460  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.633018  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.633826  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.634653  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.635643  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.636486  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.637479  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.638354  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.638893  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.639287  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.640471  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.640645  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.642777  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.643686  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.645200  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.646156  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.648121  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.648608  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.651229  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.651629  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.654659  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.655562  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.660096  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.660872  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.661663  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.662422  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.663205  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.664012  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.664835  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.665313  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.665680  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.666539  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.667406  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.668276  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.669156  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.670198  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.671235  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.672339  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.673495  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.674847  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.676196  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.678679  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.680499  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.681128  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.681841  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.681943  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.682603  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.683268  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.683951  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.684545  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.684838  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.685230  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.685655  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.686065  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.686436  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.686777  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.687235  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.687522  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.688058  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.688249  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.688955  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.689076  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.689883  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.689989  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.690519  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.690812  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.690926  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.691415  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.691705  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.692013  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.692236  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.692597  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.693100  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.693221  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.693497  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.694182  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.694294  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.694550  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.695251  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.695614  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.696073  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.696253  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.696734  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.697272  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.697478  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.697915  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.698238  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.698839  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.699326  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.699434  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.700568  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.700703  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.700873  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.701775  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.702337  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.702799  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.703389  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.703831  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.704874  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.705917  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.706448  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.706921  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.708223  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.709475  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.710708  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.712100  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.713742  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.715021  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.716108  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.716120  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.716924  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.717296  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.718119  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.718197  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.718206  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.718814  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.719080  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.719419  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.720146  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.720224  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.720848  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.721360  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.721377  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.721571  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.722296  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.722459  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.723022  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.723413  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.723764  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.724436  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.724623  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.724701  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.725477  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.725750  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.726210  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.727091  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.727178  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.727364  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.728162  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.728234  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.729023  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.729269  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.730243  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.730557  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.730569  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.731057  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.731620  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.732449  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.732632  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.733975  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.734170  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.734332  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.735238  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.736648  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.738231  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.738242  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.739894  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.740714  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.741555  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.742030  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.742355  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.742565  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.743264  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.743840  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.744063  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.744832  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.745529  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.746232  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.746814  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.747054  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.747769  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.748588  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.749424  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.749759  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.750253  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.751007  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.751847  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.752828  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.752900  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.753951  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.754996  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.755776  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.756319  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.757448  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.758578  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.759489  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.759764  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.761331  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.762893  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.763209  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.764470  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.766034  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.767582  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.767991  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.769939  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.772394  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.774650  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.790346  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.791280  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.792207  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.793204  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.794245  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.795331  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.796430  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.797611  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.798538  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.799135  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.799811  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.800523  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.801314  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.802046  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.802687  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.803432  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.804106  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.805815  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.807128  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.807964  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.808784  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.810393  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.810743  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.813089  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.813498  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.815124  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.815866  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.816803  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.817956  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.818145  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.818985  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.820045  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.821136  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.822248  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.823619  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.823638  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.824534  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.825054  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.825546  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.825995  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.826451  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.826942  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.827438  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.827924  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.828433  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.828917  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.829456  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.830098  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.830261  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.830752  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.831389  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.831982  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.832547  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.833367  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.834272  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.834356  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.835169  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.836029  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.836757  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.836927  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.838269  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.839421  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.839719  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.839946  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.840136  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.840804  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.841460  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.842115  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.842792  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.843013  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.843484  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.844070  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.844491  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.844684  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.845380  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.846120  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.846826  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.847574  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.848403  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.849278  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.849764  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.850352  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.850640  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.851137  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.851325  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.851619  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.852094  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.852285  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.852578  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.853106  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.853654  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.854292  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.854390  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.854931  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.855587  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.855702  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.856149  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.856707  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.857054  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.857290  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.857890  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.858422  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.858682  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.859129  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.860474  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.860490  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.861652  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.865581  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.866219  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.866886  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.867313  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.867567  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.868053  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.868244  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.868699  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.868942  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.869364  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.869629  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.869998  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.870235  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.870696  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.870864  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.871342  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.871576  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.871992  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.872328  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.872659  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.873057  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.873337  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.873871  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.873981  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.874781  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.874857  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.875392  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.875802  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.875928  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.876084  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.876410  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.876740  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.877158  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.877259  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.877418  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.877866  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.878127  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.878481  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.878701  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.879336  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.879348  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.879816  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.880073  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.880767  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.881116  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.881280  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.881499  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.882375  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.882474  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.882668  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.883154  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.883315  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.884112  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.884234  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.884980  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.885076  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.885957  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.886053  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.886617  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.886842  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.887816  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.887907  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.888171  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.888940  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.889767  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.889932  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.891147  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.892816  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.899331  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.900166  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.901002  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.901976  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.902183  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.902925  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.902933  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.903531  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.903770  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.904095  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.904181  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.904496  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.904852  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.904933  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.905224  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.905606  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.905684  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.906170  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.906381  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.906464  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.907158  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.907177  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.907288  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.908138  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.908305  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.908321  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.908879  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.909217  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.909379  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.909604  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.910058  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.910340  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.910830  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.911097  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.911921  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.911946  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.912045  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.913058  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.913066  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.913535  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.913809  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.914143  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.914669  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.915193  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.915301  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.915564  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.916417  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.916706  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.916866  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.917554  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.917873  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.918376  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.918852  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.919056  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.919783  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.920278  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.921480  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.921910  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.923526  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.925147  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.926927  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.927374  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.928317  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.928881  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.928986  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.929834  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.930165  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.930720  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.931251  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.931267  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.931623  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.931914  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.932432  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.932626  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.933240  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.933736  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.933857  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.934038  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.934861  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.934934  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.935613  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.935770  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.936172  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.936447  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.937164  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.937993  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.939450  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.940010  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.940285  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.941039  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.941893  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.942789  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.943185  207338 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.943857  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.944926  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.946281  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.947418  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.948561  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.949764  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.951396  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.953013  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.954631  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.956249  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.958230  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.960256  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.960429  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.961039  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.961727  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.962441  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.962740  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.963234  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.963963  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.964603  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.965063  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.965379  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.969161  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.970823  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.972803  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.975180  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.977249  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.987633  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.988139  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.988623  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.989074  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.989750  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.989755  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.990298  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.990404  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.990803  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.991098  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.991306  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.992032  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.992045  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.992525  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.992844  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.993082  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.993829  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.993833  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.994698  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.994714  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.995450  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.995549  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.996616  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.997422  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.998215  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.999016  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.999362  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666600.999892  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.000704  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.001037  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.002063  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.003024  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.003512  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.005430  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.006286  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.007504  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.014122  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.014622  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.015095  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.015555  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.016028  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.016551  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.016756  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.017148  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.017329  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.017806  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.017915  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.018529  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.018613  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.019310  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.019321  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.019911  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.020005  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.020528  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.020633  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.021183  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.021272  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.021880  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.021966  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.022510  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.022612  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.023061  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.023280  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.023674  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.024438  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.024538  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.025096  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.025761  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.026274  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.027088  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.027903  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.028717  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.029599  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.030419  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.031406  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.031761  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.032133  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.032763  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.033215  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.033532  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.034169  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.034822  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.035458  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.036099  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.036215  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.036869  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.037540  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.038094  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.038774  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.039370  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.039967  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.040605  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.041251  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.042552  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.043935  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.044041  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.044522  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.045208  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.045219  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.045685  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.046180  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.046359  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.046721  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.047245  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.047354  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.047890  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.048431  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.048938  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.049049  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.049598  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.050160  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.050522  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.050746  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.051344  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.051880  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.052100  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.052540  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.053855  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.053943  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.055093  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.060801  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.061520  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.062160  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.062830  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.063463  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.064120  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.064760  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.065403  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.066061  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.066303  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.066965  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.066977  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.067695  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.067710  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.068364  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.068473  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.069012  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.069117  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.069698  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.069794  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.070412  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.070512  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.071346  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.071358  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.072019  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.072663  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.073064  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.073941  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.075054  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.075352  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.076178  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.077166  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.077178  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.078971  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.078981  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.080772  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.080789  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.082361  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.082773  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.084051  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.088144  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.089092  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.089533  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.090821  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.091436  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.092076  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.092782  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.093790  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.094803  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.095594  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.098023  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.098554  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.098660  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.099166  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.099729  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.100273  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.100834  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.101443  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.101785  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.102144  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.102890  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.103917  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.106199  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.107811  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.109394  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.111038  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.113016  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.118381  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.119338  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.119785  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.121153  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.121769  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.122412  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.123110  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.124124  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.125156  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.125951  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.128761  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666601.131950  207341 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3732"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 17:10:02.248659: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-11 17:10:02.248827: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-10-11 17:10:02.248920: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "W0000 00:00:1728666602.868467  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.869107  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.869635  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.870222  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.870770  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.871160  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.871364  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.871882  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.871997  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.872124  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.872566  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.872874  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.872975  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.873224  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.873766  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.873804  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.873959  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.874813  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.874831  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.874850  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.875640  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.875675  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.876472  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.876503  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.877313  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.877344  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.878199  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.878239  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.879547  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.879848  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.879929  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.880235  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.881141  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.881192  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.881477  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.881980  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.882039  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.882251  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.882859  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.883089  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.883285  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.883986  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.884141  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.884216  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.884673  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.884982  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.885146  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.885410  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.886056  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.886130  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.886395  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.887249  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.887259  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.887437  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.888269  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.888454  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.888485  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.889395  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.889606  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.889636  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.890205  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.890648  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.890680  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.891073  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.891475  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.892524  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.892770  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.892940  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.893076  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.893377  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.893589  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.893859  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.894240  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.894577  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.894648  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.895193  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.895245  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.895501  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.895732  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.896506  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.896758  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.896826  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.897192  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.897668  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.897750  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.898018  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.898480  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.899065  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.899104  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.899315  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.900129  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.900166  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.900275  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.901209  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.901387  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.901471  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.902062  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.902750  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.903252  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.903332  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.904329  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.904996  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.905153  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.905356  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.906051  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.906254  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.907491  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.907510  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.907635  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.909088  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.909277  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.909354  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.910370  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.911428  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.913036  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.929717  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.930272  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.930687  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.931130  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.931582  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.931996  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.932438  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.933693  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.934614  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.935112  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.935318  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.935487  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.935582  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.935881  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.936081  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.936325  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.936561  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.936831  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.937026  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.937470  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.937633  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.937642  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.937928  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.938376  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.938913  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.939856  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.939879  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.940615  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.941787  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.941813  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.942602  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.943799  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.943902  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.944639  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.945626  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.945944  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.946351  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.947662  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.948255  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.949565  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.950104  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.951419  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.980046  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.980460  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.980898  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.981349  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.981797  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.982283  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.982794  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.983297  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.983783  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.984283  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.984601  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.984797  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.985011  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.985700  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.985726  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.985767  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.986525  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.986564  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.986590  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.987252  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.987284  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.987397  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.987911  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.988011  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.988124  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.988571  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.988761  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.988881  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.989116  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.989353  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.989657  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.989778  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.989946  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.990350  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.990668  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.990807  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.990897  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.991208  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.991489  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.991846  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.991996  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.992156  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.992535  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.992837  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.993121  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.993668  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.993750  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.993869  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.994328  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.994553  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.995128  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.995200  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.995326  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.995968  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.996317  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.996620  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.997207  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.997619  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.998389  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.998923  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666602.999287  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.000073  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.000994  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.002155  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.002838  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.003505  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.003999  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.004513  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.004981  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.005497  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.005963  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.006492  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.006985  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.007503  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.007655  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.007995  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.008259  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.008472  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.008953  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.009057  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.009531  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.009799  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.010048  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.010362  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.010566  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.011007  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.011214  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.011289  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.011561  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.011811  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.012052  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.012652  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.012726  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.013465  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.013477  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.013562  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.014244  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.014318  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.014772  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.015416  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.015589  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.016266  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.016442  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.016960  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.018394  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.019251  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.019272  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.020261  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.021201  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.023184  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.023286  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.023982  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.025589  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.026996  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.027753  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.028017  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.030164  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.030672  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.032624  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.033085  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.035506  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.096114  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.096648  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.097179  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.097717  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.098275  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.098818  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.099377  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.099971  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.100584  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.101471  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.101624  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.102468  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.102498  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.103246  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.103473  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.103626  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.103828  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.104516  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.104553  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.104656  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.105144  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.105575  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.105623  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.105795  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.106200  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.106622  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.106665  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.106872  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.107207  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.107793  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.107878  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.107994  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.108518  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.108840  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.108959  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.109239  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.109482  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.110368  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.110381  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.110492  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.111277  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.111354  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.111899  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.112201  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.112278  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.112967  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.113161  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.114058  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.114126  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.114241  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.114935  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.115232  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.115839  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.116473  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.116488  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.116820  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.117847  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.118016  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.119234  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.120015  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.120721  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.122109  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.122686  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.124802  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.125459  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.126176  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.126829  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.127738  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.128503  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.129175  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.129886  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.130520  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.131248  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.131558  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.132533  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.132545  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.133214  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.133499  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.133591  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.133993  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.134305  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.134564  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.134806  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.135048  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.135490  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.135811  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.136220  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.136532  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.136878  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.137285  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.137628  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.138018  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.138192  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.138697  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.139016  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.139697  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.139872  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.140735  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.140846  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.141754  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.141864  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.142894  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.143822  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.144233  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.144787  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.145230  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.145734  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.146905  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.147840  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.148175  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.149775  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.149796  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.151267  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.151443  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.153101  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.154625  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.155833  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.156920  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.158000  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.160660  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.163004  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.164177  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.165131  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.168807  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.168913  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.170285  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.174731  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.177990  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.179009  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.179983  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.181068  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.182008  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.183195  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.184167  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.185332  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.186375  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.187330  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.188404  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.189513  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.195608  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.200970  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.207793  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.214407  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.221463  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.228641  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.242585  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.304069  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.304844  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.305586  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.306276  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.307042  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.307840  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.308623  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.309409  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.310309  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.311164  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.311360  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.311959  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.312302  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.312726  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.313404  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.313514  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.314546  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.314561  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.315373  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.315757  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.316173  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.317226  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.317236  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.318177  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.318597  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.319234  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.320173  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.320283  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.321229  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.321730  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.322178  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.323355  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.324393  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.324655  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.325989  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.327419  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.329048  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.329148  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.331813  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.332561  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.336572  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.340183  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.342608  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.343626  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.344617  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.345694  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.346626  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.347802  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.348762  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.349917  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.350546  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.350965  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.351571  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.351942  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.352564  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.353033  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.353679  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.354159  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.354634  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.355830  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.356798  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.357967  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.359018  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.359969  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.360283  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.361069  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.362177  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.365610  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.368319  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.372444  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.373694  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.379077  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.380583  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.386262  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.387258  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.393580  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.394480  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.401838  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.407512  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.415924  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.510938  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.512030  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.513160  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.514205  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.515350  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.516599  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.517810  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.519024  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.520440  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.522100  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.523579  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.525099  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.526608  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.528567  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.530725  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.533016  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.535485  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.538585  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.541288  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.546238  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.554187  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.566963  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.568614  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.570309  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.572144  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.573780  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.575772  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.577377  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.579453  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.581024  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.582613  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.584452  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.586356  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.597455  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.607996  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.621477  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.634542  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.648372  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.662656  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.677590  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.678714  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.679832  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.680880  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.682035  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.683286  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.684492  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.685708  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.687144  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.689066  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.689121  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.690264  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.690581  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.691275  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.691442  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.692140  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.692515  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.693931  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.693947  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.695205  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.695934  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.696442  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.697691  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.698134  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.699157  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.700450  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.700855  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.702358  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.702964  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.703925  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.705442  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.705707  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.707453  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.709635  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.710659  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.711982  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.714483  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.717231  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.722199  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.722915  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.730500  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.736284  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.738207  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.739908  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.741753  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.743379  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.744311  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.745368  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.745963  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.747001  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.747685  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.749096  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.749556  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.750686  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.751208  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.752294  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.753224  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.754154  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.754857  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.756082  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.756957  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.758520  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.760107  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.761947  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.763861  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.767018  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.774872  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.777291  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.785238  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.790560  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.798633  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.803445  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.811632  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.817285  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.825942  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.831366  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.840176  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.860098  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666603.868414  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.227233  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.229006  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.230776  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.232538  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.234452  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.236410  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.238377  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.240427  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.242566  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.244942  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.247417  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.249925  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.252588  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.256238  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.259850  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.263607  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.268245  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.273630  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.278534  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.298076  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.300887  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.303713  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.307316  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.310221  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.313062  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.315786  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.319099  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.322858  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.325656  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.328936  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.332382  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.354280  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.375135  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.401676  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.405003  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.406809  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.408573  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.410339  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.412272  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.413739  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.414245  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.415551  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.416252  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.417341  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.418339  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.419140  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.420531  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.421092  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.423108  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.423224  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.425214  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.425641  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.427283  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.427493  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.428204  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.429684  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.430885  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.432095  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.434871  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.434887  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.437430  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.438528  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.440128  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.442362  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.443866  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.447055  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.447512  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.451256  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.452017  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.452283  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.455922  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.460866  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.471854  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.474692  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.477524  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.479127  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.481118  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.481168  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.484301  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.484319  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.487328  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.487433  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.490068  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.491080  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.493349  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.494054  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.497049  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.497196  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.499949  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.500062  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.503552  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.503565  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.507036  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.507366  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.510168  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.513471  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.516926  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.528379  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.538598  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.540950  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.548908  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.559547  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.575345  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.586350  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.601012  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.612295  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.626255  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.637826  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.652826  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.664639  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.713070  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666604.726922  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.705743  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.708812  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.711897  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.714979  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.718331  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.721778  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.725279  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.728937  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.732692  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.736930  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.741435  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.746110  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.751140  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.758060  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.765177  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.772517  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.781507  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.791902  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.801454  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.836207  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.837764  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.839305  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.840833  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.842340  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.844274  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.846000  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.847458  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.849449  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.850924  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.852657  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.854481  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.864879  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.878259  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.891262  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.902055  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.914859  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.927895  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666605.955545  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.073100  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.073223  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.076182  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.076442  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.079278  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.079678  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.082392  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.082889  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.085786  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.086332  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.089266  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.089859  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.092767  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.093432  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.096476  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.097143  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.100275  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.101007  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.104587  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.105306  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.109130  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.109872  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.113781  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.114620  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.118832  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.119603  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.125800  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.126490  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.132904  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.133677  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.140208  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.141031  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.149228  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.149951  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.158870  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.159475  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.192284  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.193839  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.195388  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.196914  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.198407  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.198842  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.200546  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.200554  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.202094  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.202310  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.203663  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.203836  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.205171  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.205860  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.207089  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.207349  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.208819  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.209114  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.210280  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.210941  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.212269  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.213733  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.215469  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.217280  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.221412  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.227595  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.234898  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.240937  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.247997  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.253893  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.258865  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.264609  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.271937  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.277435  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.285412  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.290403  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.313337  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.318459  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.470888  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.472542  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.474109  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.475657  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.477418  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.479169  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.481071  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.482802  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.484674  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.486949  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.489255  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.491211  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.493724  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.497385  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.508302  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.511603  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.514949  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.519268  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.523955  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.534605  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.535285  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.535893  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.536623  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.537351  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.538112  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.538871  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.542304  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.546547  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.550130  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.553590  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.557104  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.560422  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.567339  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.687296  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.687932  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.688570  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.689169  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.689756  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.690445  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.691130  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.691758  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.692383  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.693052  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.693716  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.694401  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.695153  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.695910  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.696814  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.697826  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.698855  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.700086  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.701365  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.702784  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.705233  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.708493  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.712284  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.728172  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.728633  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.729074  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.729498  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.729919  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.730337  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.730757  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.731239  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.731974  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.733781  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.735637  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.738409  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.740368  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.744191  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.747599  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.750781  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.765695  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.766151  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.766610  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.767056  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.767525  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.768177  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.768645  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.769165  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.769600  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.770043  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.770551  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.771066  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.771559  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.772121  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.772699  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.773299  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.775079  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.775804  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.776624  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.777640  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.783182  207337 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.834532  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.836193  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.836696  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.837765  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.838364  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.839317  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.839934  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.841120  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.841487  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.842898  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.843275  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.844808  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.845057  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.846542  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.846963  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.848443  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.848695  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.850705  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.850816  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.853038  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.853224  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.855244  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.855431  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.857398  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.857769  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.859905  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.861456  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.863560  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.872377  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.874378  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.875711  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.877691  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.879080  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.881061  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.883455  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.885418  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.894363  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.895034  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.895637  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.895913  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.896354  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.896589  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.897216  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.897310  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.898218  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.898223  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.899084  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.899179  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.899857  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.900609  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.902586  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.903999  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.906812  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.908198  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.910362  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.911725  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.913804  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.915219  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.917319  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.918791  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.920654  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.922068  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.927400  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666606.928746  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.048309  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.048409  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.048974  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.049179  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.049621  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.049906  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.050217  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.050560  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.050810  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.051190  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.051499  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.051914  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.052206  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.052645  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.052850  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.053439  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.053531  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.054131  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.054288  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.054872  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.055023  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.055675  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.055776  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.056501  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.056597  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.057529  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.057532  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.058448  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.058543  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.059504  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.059596  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.060802  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.060803  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.061906  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.062075  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.063184  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.063372  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.064496  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.065817  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.066998  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.069070  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.070307  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.072865  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.074153  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.088517  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.088985  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.089401  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.089840  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.090703  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.092493  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.093802  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.094502  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.094501  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.094945  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 268ms/step - loss: 0.3660 - val_loss: 0.2462 - learning_rate: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728666607.095385  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.096262  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.097281  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.098077  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.099255  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.099926  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.101230  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.102704  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.104682  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.105071  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.106645  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.107722  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.110476  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.113116  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.122525  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.122977  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.123426  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.123865  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.124333  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.124983  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.125451  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.125968  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.126392  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.126838  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.127346  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.127894  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.128065  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.128666  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.128687  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.129331  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.129450  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.129798  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.130062  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.130281  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.130674  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.130945  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.131416  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.131935  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.132524  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.132641  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.132981  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.133493  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.133596  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.134114  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.134327  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.134664  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.135335  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.135452  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.135932  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.136533  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.138319  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.139040  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.139868  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.140997  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.141103  207329 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728666607.146549  207336 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-10-11 17:10:07.238225: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0685"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 17:10:08.895360: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0685 - val_loss: 0.2466 - learning_rate: 0.0010\n",
      "Epoch 3/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 0.0665 - val_loss: 0.2417 - learning_rate: 0.0010\n",
      "Epoch 4/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 17:10:13.172357: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0664 - val_loss: 0.2400 - learning_rate: 0.0010\n",
      "Epoch 5/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0602 - val_loss: 0.2334 - learning_rate: 0.0010\n",
      "Epoch 6/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0524"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 17:10:20.008354: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0526 - val_loss: 0.1823 - learning_rate: 0.0010\n",
      "Epoch 7/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0424 - val_loss: 0.2012 - learning_rate: 0.0010\n",
      "Epoch 8/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0390 - val_loss: 0.1932 - learning_rate: 0.0010\n",
      "Epoch 9/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0388 - val_loss: 0.1910 - learning_rate: 0.0010\n",
      "Epoch 10/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0366 - val_loss: 0.2004 - learning_rate: 0.0010\n",
      "Epoch 11/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.0363 - val_loss: 0.1923 - learning_rate: 0.0010\n",
      "Epoch 12/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 17:10:34.780194: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0358 - val_loss: 0.1946 - learning_rate: 0.0010\n",
      "Epoch 13/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0355 - val_loss: 0.1994 - learning_rate: 0.0010\n",
      "Epoch 14/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0353 - val_loss: 0.1977 - learning_rate: 0.0010\n",
      "Epoch 15/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0351 - val_loss: 0.1825 - learning_rate: 0.0010\n",
      "Epoch 16/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0348 - val_loss: 0.1719 - learning_rate: 0.0010\n",
      "Epoch 17/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 0.0339 - val_loss: 0.1694 - learning_rate: 0.0010\n",
      "Epoch 18/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 0.0343 - val_loss: 0.1705 - learning_rate: 0.0010\n",
      "Epoch 19/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0340 - val_loss: 0.1528 - learning_rate: 0.0010\n",
      "Epoch 20/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0353 - val_loss: 0.1318 - learning_rate: 0.0010\n",
      "Epoch 21/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0354 - val_loss: 0.1268 - learning_rate: 0.0010\n",
      "Epoch 22/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 17:11:04.770318: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0350 - val_loss: 0.1194 - learning_rate: 0.0010\n",
      "Epoch 23/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0336 - val_loss: 0.1152 - learning_rate: 0.0010\n",
      "Epoch 24/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 0.0336 - val_loss: 0.1042 - learning_rate: 0.0010\n",
      "Epoch 25/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0335 - val_loss: 0.0965 - learning_rate: 0.0010\n",
      "Epoch 26/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0334 - val_loss: 0.0861 - learning_rate: 0.0010\n",
      "Epoch 27/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0331 - val_loss: 0.0905 - learning_rate: 0.0010\n",
      "Epoch 28/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0330 - val_loss: 0.0529 - learning_rate: 0.0010\n",
      "Epoch 29/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0333 - val_loss: 0.0589 - learning_rate: 0.0010\n",
      "Epoch 30/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0330 - val_loss: 0.0560 - learning_rate: 0.0010\n",
      "Epoch 31/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0327 - val_loss: 0.0619 - learning_rate: 0.0010\n",
      "Epoch 32/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0331 - val_loss: 0.0369 - learning_rate: 0.0010\n",
      "Epoch 33/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0328 - val_loss: 0.0393 - learning_rate: 0.0010\n",
      "Epoch 34/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0326 - val_loss: 0.0433 - learning_rate: 0.0010\n",
      "Epoch 35/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0323 - val_loss: 0.0445 - learning_rate: 0.0010\n",
      "Epoch 36/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0322 - val_loss: 0.0420 - learning_rate: 0.0010\n",
      "Epoch 37/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0321 - val_loss: 0.0358 - learning_rate: 0.0010\n",
      "Epoch 38/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0320 - val_loss: 0.0402 - learning_rate: 0.0010\n",
      "Epoch 39/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0320 - val_loss: 0.0365 - learning_rate: 0.0010\n",
      "Epoch 40/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0322 - val_loss: 0.0373 - learning_rate: 0.0010\n",
      "Epoch 41/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0318 - val_loss: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 42/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0320 - val_loss: 0.0345 - learning_rate: 0.0010\n",
      "Epoch 43/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0315 - val_loss: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 44/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 17:12:03.301532: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0312 - val_loss: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 45/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0312 - val_loss: 0.0335 - learning_rate: 0.0010\n",
      "Epoch 46/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0311 - val_loss: 0.0328 - learning_rate: 0.0010\n",
      "Epoch 47/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0313 - val_loss: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 48/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0311 - val_loss: 0.0346 - learning_rate: 0.0010\n",
      "Epoch 49/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0310 - val_loss: 0.0345 - learning_rate: 0.0010\n",
      "Epoch 50/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0308 - val_loss: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 51/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0308 - val_loss: 0.0337 - learning_rate: 0.0010\n",
      "Epoch 52/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.0309 - val_loss: 0.0342 - learning_rate: 0.0010\n",
      "Epoch 53/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0305 - val_loss: 0.0350 - learning_rate: 0.0010\n",
      "Epoch 54/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0306 - val_loss: 0.0346 - learning_rate: 0.0010\n",
      "Epoch 55/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0301 - val_loss: 0.0344 - learning_rate: 0.0010\n",
      "Epoch 56/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0302\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0302 - val_loss: 0.0339 - learning_rate: 0.0010\n",
      "Epoch 57/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0299 - val_loss: 0.0358 - learning_rate: 9.0000e-04\n",
      "Epoch 58/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0297 - val_loss: 0.0345 - learning_rate: 9.0000e-04\n",
      "Epoch 59/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0296 - val_loss: 0.0343 - learning_rate: 9.0000e-04\n",
      "Epoch 60/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0295 - val_loss: 0.0350 - learning_rate: 9.0000e-04\n",
      "Epoch 61/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0297 - val_loss: 0.0351 - learning_rate: 9.0000e-04\n",
      "Epoch 62/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0291 - val_loss: 0.0344 - learning_rate: 9.0000e-04\n",
      "Epoch 63/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0289 - val_loss: 0.0341 - learning_rate: 9.0000e-04\n",
      "Epoch 64/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0291 - val_loss: 0.0349 - learning_rate: 9.0000e-04\n",
      "Epoch 65/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0286 - val_loss: 0.0344 - learning_rate: 9.0000e-04\n",
      "Epoch 66/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0283\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 0.0284 - val_loss: 0.0343 - learning_rate: 9.0000e-04\n",
      "Epoch 67/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0282 - val_loss: 0.0357 - learning_rate: 8.1000e-04\n",
      "Epoch 68/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0282 - val_loss: 0.0348 - learning_rate: 8.1000e-04\n",
      "Epoch 69/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0279 - val_loss: 0.0345 - learning_rate: 8.1000e-04\n",
      "Epoch 70/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0276 - val_loss: 0.0347 - learning_rate: 8.1000e-04\n",
      "Epoch 71/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0275 - val_loss: 0.0358 - learning_rate: 8.1000e-04\n",
      "Epoch 72/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0272 - val_loss: 0.0355 - learning_rate: 8.1000e-04\n",
      "Epoch 73/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0274 - val_loss: 0.0350 - learning_rate: 8.1000e-04\n",
      "Epoch 74/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 0.0268 - val_loss: 0.0360 - learning_rate: 8.1000e-04\n",
      "Epoch 75/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 0.0266 - val_loss: 0.0359 - learning_rate: 8.1000e-04\n",
      "Epoch 76/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0261\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0262 - val_loss: 0.0361 - learning_rate: 8.1000e-04\n",
      "Epoch 77/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0261 - val_loss: 0.0354 - learning_rate: 7.2900e-04\n",
      "Epoch 78/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0258 - val_loss: 0.0370 - learning_rate: 7.2900e-04\n",
      "Epoch 79/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0253 - val_loss: 0.0365 - learning_rate: 7.2900e-04\n",
      "Epoch 80/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0252 - val_loss: 0.0362 - learning_rate: 7.2900e-04\n",
      "Epoch 81/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0251 - val_loss: 0.0381 - learning_rate: 7.2900e-04\n",
      "Epoch 82/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0246 - val_loss: 0.0372 - learning_rate: 7.2900e-04\n",
      "Epoch 83/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0242 - val_loss: 0.0386 - learning_rate: 7.2900e-04\n",
      "Epoch 84/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0240 - val_loss: 0.0363 - learning_rate: 7.2900e-04\n",
      "Epoch 85/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0237 - val_loss: 0.0377 - learning_rate: 7.2900e-04\n",
      "Epoch 86/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0232"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 17:13:56.716698: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0233 - val_loss: 0.0392 - learning_rate: 7.2900e-04\n",
      "Epoch 87/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0231 - val_loss: 0.0393 - learning_rate: 6.5610e-04\n",
      "Epoch 88/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0227 - val_loss: 0.0381 - learning_rate: 6.5610e-04\n",
      "Epoch 89/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0223 - val_loss: 0.0395 - learning_rate: 6.5610e-04\n",
      "Epoch 90/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0221 - val_loss: 0.0383 - learning_rate: 6.5610e-04\n",
      "Epoch 91/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0218 - val_loss: 0.0396 - learning_rate: 6.5610e-04\n",
      "Epoch 92/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0213 - val_loss: 0.0412 - learning_rate: 6.5610e-04\n",
      "Epoch 93/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0209 - val_loss: 0.0401 - learning_rate: 6.5610e-04\n",
      "Epoch 94/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0209 - val_loss: 0.0398 - learning_rate: 6.5610e-04\n",
      "Epoch 95/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0204 - val_loss: 0.0400 - learning_rate: 6.5610e-04\n",
      "Epoch 96/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0201\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0202 - val_loss: 0.0404 - learning_rate: 6.5610e-04\n",
      "Epoch 97/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0197 - val_loss: 0.0407 - learning_rate: 5.9049e-04\n",
      "Epoch 98/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0192 - val_loss: 0.0411 - learning_rate: 5.9049e-04\n",
      "Epoch 99/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0187 - val_loss: 0.0413 - learning_rate: 5.9049e-04\n",
      "Epoch 100/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0187 - val_loss: 0.0410 - learning_rate: 5.9049e-04\n",
      "Epoch 101/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0184 - val_loss: 0.0426 - learning_rate: 5.9049e-04\n",
      "Epoch 102/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0178 - val_loss: 0.0422 - learning_rate: 5.9049e-04\n",
      "Epoch 103/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0176 - val_loss: 0.0444 - learning_rate: 5.9049e-04\n",
      "Epoch 104/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0174 - val_loss: 0.0430 - learning_rate: 5.9049e-04\n",
      "Epoch 105/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 0.0168 - val_loss: 0.0443 - learning_rate: 5.9049e-04\n",
      "Epoch 106/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0168\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0168 - val_loss: 0.0457 - learning_rate: 5.9049e-04\n",
      "Epoch 107/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 0.0163 - val_loss: 0.0446 - learning_rate: 5.3144e-04\n",
      "Epoch 108/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0159 - val_loss: 0.0449 - learning_rate: 5.3144e-04\n",
      "Epoch 109/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0157 - val_loss: 0.0436 - learning_rate: 5.3144e-04\n",
      "Epoch 110/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0152 - val_loss: 0.0453 - learning_rate: 5.3144e-04\n",
      "Epoch 111/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0150 - val_loss: 0.0454 - learning_rate: 5.3144e-04\n",
      "Epoch 112/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0143 - val_loss: 0.0453 - learning_rate: 5.3144e-04\n",
      "Epoch 113/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0145 - val_loss: 0.0470 - learning_rate: 5.3144e-04\n",
      "Epoch 114/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0140 - val_loss: 0.0453 - learning_rate: 5.3144e-04\n",
      "Epoch 115/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0137 - val_loss: 0.0453 - learning_rate: 5.3144e-04\n",
      "Epoch 116/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0132\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0133 - val_loss: 0.0453 - learning_rate: 5.3144e-04\n",
      "Epoch 117/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0131 - val_loss: 0.0471 - learning_rate: 4.7830e-04\n",
      "Epoch 118/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0125 - val_loss: 0.0465 - learning_rate: 4.7830e-04\n",
      "Epoch 119/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0124 - val_loss: 0.0477 - learning_rate: 4.7830e-04\n",
      "Epoch 120/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0121 - val_loss: 0.0471 - learning_rate: 4.7830e-04\n",
      "Epoch 121/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0119 - val_loss: 0.0474 - learning_rate: 4.7830e-04\n",
      "Epoch 122/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0116 - val_loss: 0.0477 - learning_rate: 4.7830e-04\n",
      "Epoch 123/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0113 - val_loss: 0.0474 - learning_rate: 4.7830e-04\n",
      "Epoch 124/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0110 - val_loss: 0.0505 - learning_rate: 4.7830e-04\n",
      "Epoch 125/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0108 - val_loss: 0.0481 - learning_rate: 4.7830e-04\n",
      "Epoch 126/1400\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0104\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0105 - val_loss: 0.0480 - learning_rate: 4.7830e-04\n",
      "Epoch 127/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0101 - val_loss: 0.0494 - learning_rate: 4.3047e-04\n",
      "Epoch 128/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 0.0099 - val_loss: 0.0490 - learning_rate: 4.3047e-04\n",
      "Epoch 129/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 0.0096 - val_loss: 0.0494 - learning_rate: 4.3047e-04\n",
      "Epoch 130/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0093 - val_loss: 0.0512 - learning_rate: 4.3047e-04\n",
      "Epoch 131/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 0.0093 - val_loss: 0.0500 - learning_rate: 4.3047e-04\n",
      "Epoch 132/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0090 - val_loss: 0.0511 - learning_rate: 4.3047e-04\n",
      "Epoch 133/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0088 - val_loss: 0.0500 - learning_rate: 4.3047e-04\n",
      "Epoch 134/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0084 - val_loss: 0.0519 - learning_rate: 4.3047e-04\n",
      "Epoch 135/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0084 - val_loss: 0.0519 - learning_rate: 4.3047e-04\n",
      "Epoch 136/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0081\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0081 - val_loss: 0.0524 - learning_rate: 4.3047e-04\n",
      "Epoch 137/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0080 - val_loss: 0.0521 - learning_rate: 3.8742e-04\n",
      "Epoch 138/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0077 - val_loss: 0.0526 - learning_rate: 3.8742e-04\n",
      "Epoch 139/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0075 - val_loss: 0.0532 - learning_rate: 3.8742e-04\n",
      "Epoch 140/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0073 - val_loss: 0.0525 - learning_rate: 3.8742e-04\n",
      "Epoch 141/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0073 - val_loss: 0.0528 - learning_rate: 3.8742e-04\n",
      "Epoch 142/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.0072 - val_loss: 0.0526 - learning_rate: 3.8742e-04\n",
      "Epoch 143/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - loss: 0.0069 - val_loss: 0.0534 - learning_rate: 3.8742e-04\n",
      "Epoch 144/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0068 - val_loss: 0.0541 - learning_rate: 3.8742e-04\n",
      "Epoch 145/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0066 - val_loss: 0.0533 - learning_rate: 3.8742e-04\n",
      "Epoch 146/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0065\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 0.0065 - val_loss: 0.0528 - learning_rate: 3.8742e-04\n",
      "Epoch 147/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 0.0062 - val_loss: 0.0526 - learning_rate: 3.4868e-04\n",
      "Epoch 148/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0061 - val_loss: 0.0529 - learning_rate: 3.4868e-04\n",
      "Epoch 149/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0059 - val_loss: 0.0550 - learning_rate: 3.4868e-04\n",
      "Epoch 150/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0057 - val_loss: 0.0541 - learning_rate: 3.4868e-04\n",
      "Epoch 151/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 0.0057 - val_loss: 0.0549 - learning_rate: 3.4868e-04\n",
      "Epoch 152/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0056 - val_loss: 0.0548 - learning_rate: 3.4868e-04\n",
      "Epoch 153/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.0055 - val_loss: 0.0574 - learning_rate: 3.4868e-04\n",
      "Epoch 154/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0054 - val_loss: 0.0554 - learning_rate: 3.4868e-04\n",
      "Epoch 155/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0053 - val_loss: 0.0554 - learning_rate: 3.4868e-04\n",
      "Epoch 156/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0052\n",
      "Epoch 156: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0052 - val_loss: 0.0557 - learning_rate: 3.4868e-04\n",
      "Epoch 157/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0050 - val_loss: 0.0560 - learning_rate: 3.1381e-04\n",
      "Epoch 158/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0048 - val_loss: 0.0560 - learning_rate: 3.1381e-04\n",
      "Epoch 159/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0047 - val_loss: 0.0567 - learning_rate: 3.1381e-04\n",
      "Epoch 160/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0046 - val_loss: 0.0565 - learning_rate: 3.1381e-04\n",
      "Epoch 161/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0045 - val_loss: 0.0556 - learning_rate: 3.1381e-04\n",
      "Epoch 162/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0044 - val_loss: 0.0554 - learning_rate: 3.1381e-04\n",
      "Epoch 163/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0044 - val_loss: 0.0546 - learning_rate: 3.1381e-04\n",
      "Epoch 164/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0043 - val_loss: 0.0572 - learning_rate: 3.1381e-04\n",
      "Epoch 165/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0042 - val_loss: 0.0556 - learning_rate: 3.1381e-04\n",
      "Epoch 166/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0042\n",
      "Epoch 166: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0042 - val_loss: 0.0569 - learning_rate: 3.1381e-04\n",
      "Epoch 167/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0040 - val_loss: 0.0581 - learning_rate: 2.8243e-04\n",
      "Epoch 168/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0040 - val_loss: 0.0555 - learning_rate: 2.8243e-04\n",
      "Epoch 169/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0039 - val_loss: 0.0565 - learning_rate: 2.8243e-04\n",
      "Epoch 170/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0038 - val_loss: 0.0587 - learning_rate: 2.8243e-04\n",
      "Epoch 171/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0037 - val_loss: 0.0589 - learning_rate: 2.8243e-04\n",
      "Epoch 172/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 17:17:40.097299: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0037 - val_loss: 0.0582 - learning_rate: 2.8243e-04\n",
      "Epoch 173/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0036 - val_loss: 0.0590 - learning_rate: 2.8243e-04\n",
      "Epoch 174/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 0.0035 - val_loss: 0.0578 - learning_rate: 2.8243e-04\n",
      "Epoch 175/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0034 - val_loss: 0.0577 - learning_rate: 2.8243e-04\n",
      "Epoch 176/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0033\n",
      "Epoch 176: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0033 - val_loss: 0.0591 - learning_rate: 2.8243e-04\n",
      "Epoch 177/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0033 - val_loss: 0.0594 - learning_rate: 2.5419e-04\n",
      "Epoch 178/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0033 - val_loss: 0.0579 - learning_rate: 2.5419e-04\n",
      "Epoch 179/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0031 - val_loss: 0.0610 - learning_rate: 2.5419e-04\n",
      "Epoch 180/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0031 - val_loss: 0.0600 - learning_rate: 2.5419e-04\n",
      "Epoch 181/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0031 - val_loss: 0.0585 - learning_rate: 2.5419e-04\n",
      "Epoch 182/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0030 - val_loss: 0.0593 - learning_rate: 2.5419e-04\n",
      "Epoch 183/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0030 - val_loss: 0.0580 - learning_rate: 2.5419e-04\n",
      "Epoch 184/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.0030 - val_loss: 0.0594 - learning_rate: 2.5419e-04\n",
      "Epoch 185/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0029 - val_loss: 0.0594 - learning_rate: 2.5419e-04\n",
      "Epoch 186/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0029\n",
      "Epoch 186: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 0.0029 - val_loss: 0.0609 - learning_rate: 2.5419e-04\n",
      "Epoch 187/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 0.0028 - val_loss: 0.0601 - learning_rate: 2.2877e-04\n",
      "Epoch 188/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0027 - val_loss: 0.0599 - learning_rate: 2.2877e-04\n",
      "Epoch 189/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0026 - val_loss: 0.0589 - learning_rate: 2.2877e-04\n",
      "Epoch 190/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0027 - val_loss: 0.0594 - learning_rate: 2.2877e-04\n",
      "Epoch 191/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0026 - val_loss: 0.0598 - learning_rate: 2.2877e-04\n",
      "Epoch 192/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0026 - val_loss: 0.0599 - learning_rate: 2.2877e-04\n",
      "Epoch 193/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 0.0025 - val_loss: 0.0610 - learning_rate: 2.2877e-04\n",
      "Epoch 194/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0025 - val_loss: 0.0603 - learning_rate: 2.2877e-04\n",
      "Epoch 195/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0025 - val_loss: 0.0622 - learning_rate: 2.2877e-04\n",
      "Epoch 196/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0025\n",
      "Epoch 196: ReduceLROnPlateau reducing learning rate to 0.00020589114428730683.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0025 - val_loss: 0.0594 - learning_rate: 2.2877e-04\n",
      "Epoch 197/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0024 - val_loss: 0.0601 - learning_rate: 2.0589e-04\n",
      "Epoch 198/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0024 - val_loss: 0.0584 - learning_rate: 2.0589e-04\n",
      "Epoch 199/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0023 - val_loss: 0.0613 - learning_rate: 2.0589e-04\n",
      "Epoch 200/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0023 - val_loss: 0.0601 - learning_rate: 2.0589e-04\n",
      "Epoch 201/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0023 - val_loss: 0.0608 - learning_rate: 2.0589e-04\n",
      "Epoch 202/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0023 - val_loss: 0.0622 - learning_rate: 2.0589e-04\n",
      "Epoch 203/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0022 - val_loss: 0.0623 - learning_rate: 2.0589e-04\n",
      "Epoch 204/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0021 - val_loss: 0.0601 - learning_rate: 2.0589e-04\n",
      "Epoch 205/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0021 - val_loss: 0.0603 - learning_rate: 2.0589e-04\n",
      "Epoch 206/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0021\n",
      "Epoch 206: ReduceLROnPlateau reducing learning rate to 0.00018530203378759326.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0021 - val_loss: 0.0627 - learning_rate: 2.0589e-04\n",
      "Epoch 207/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0021 - val_loss: 0.0602 - learning_rate: 1.8530e-04\n",
      "Epoch 208/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0020 - val_loss: 0.0608 - learning_rate: 1.8530e-04\n",
      "Epoch 209/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0020 - val_loss: 0.0612 - learning_rate: 1.8530e-04\n",
      "Epoch 210/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0020 - val_loss: 0.0614 - learning_rate: 1.8530e-04\n",
      "Epoch 211/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0020 - val_loss: 0.0629 - learning_rate: 1.8530e-04\n",
      "Epoch 212/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0020 - val_loss: 0.0617 - learning_rate: 1.8530e-04\n",
      "Epoch 213/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0019 - val_loss: 0.0623 - learning_rate: 1.8530e-04\n",
      "Epoch 214/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0019 - val_loss: 0.0625 - learning_rate: 1.8530e-04\n",
      "Epoch 215/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0019 - val_loss: 0.0608 - learning_rate: 1.8530e-04\n",
      "Epoch 216/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0019\n",
      "Epoch 216: ReduceLROnPlateau reducing learning rate to 0.00016677183302817866.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0019 - val_loss: 0.0605 - learning_rate: 1.8530e-04\n",
      "Epoch 217/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0019 - val_loss: 0.0633 - learning_rate: 1.6677e-04\n",
      "Epoch 218/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0018 - val_loss: 0.0631 - learning_rate: 1.6677e-04\n",
      "Epoch 219/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.0018 - val_loss: 0.0616 - learning_rate: 1.6677e-04\n",
      "Epoch 220/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0018 - val_loss: 0.0591 - learning_rate: 1.6677e-04\n",
      "Epoch 221/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0018 - val_loss: 0.0625 - learning_rate: 1.6677e-04\n",
      "Epoch 222/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0018 - val_loss: 0.0622 - learning_rate: 1.6677e-04\n",
      "Epoch 223/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0017 - val_loss: 0.0622 - learning_rate: 1.6677e-04\n",
      "Epoch 224/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0017 - val_loss: 0.0632 - learning_rate: 1.6677e-04\n",
      "Epoch 225/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0017 - val_loss: 0.0634 - learning_rate: 1.6677e-04\n",
      "Epoch 226/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0017\n",
      "Epoch 226: ReduceLROnPlateau reducing learning rate to 0.00015009464841568844.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0017 - val_loss: 0.0634 - learning_rate: 1.6677e-04\n",
      "Epoch 227/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0017 - val_loss: 0.0604 - learning_rate: 1.5009e-04\n",
      "Epoch 228/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0017 - val_loss: 0.0625 - learning_rate: 1.5009e-04\n",
      "Epoch 229/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0016 - val_loss: 0.0640 - learning_rate: 1.5009e-04\n",
      "Epoch 230/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0017 - val_loss: 0.0628 - learning_rate: 1.5009e-04\n",
      "Epoch 231/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0016 - val_loss: 0.0634 - learning_rate: 1.5009e-04\n",
      "Epoch 232/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0016 - val_loss: 0.0624 - learning_rate: 1.5009e-04\n",
      "Epoch 233/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0016 - val_loss: 0.0616 - learning_rate: 1.5009e-04\n",
      "Epoch 234/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0016 - val_loss: 0.0643 - learning_rate: 1.5009e-04\n",
      "Epoch 235/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0016 - val_loss: 0.0627 - learning_rate: 1.5009e-04\n",
      "Epoch 236/1400\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0016\n",
      "Epoch 236: ReduceLROnPlateau reducing learning rate to 0.0001350851875031367.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0016 - val_loss: 0.0615 - learning_rate: 1.5009e-04\n",
      "Epoch 237/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0015 - val_loss: 0.0645 - learning_rate: 1.3509e-04\n",
      "Epoch 238/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0015 - val_loss: 0.0615 - learning_rate: 1.3509e-04\n",
      "Epoch 239/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0015 - val_loss: 0.0638 - learning_rate: 1.3509e-04\n",
      "Epoch 240/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0015 - val_loss: 0.0626 - learning_rate: 1.3509e-04\n",
      "Epoch 241/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0014 - val_loss: 0.0621 - learning_rate: 1.3509e-04\n",
      "Epoch 242/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0015 - val_loss: 0.0630 - learning_rate: 1.3509e-04\n",
      "Epoch 243/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0015 - val_loss: 0.0635 - learning_rate: 1.3509e-04\n",
      "Epoch 244/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0014 - val_loss: 0.0623 - learning_rate: 1.3509e-04\n",
      "Epoch 245/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0014 - val_loss: 0.0647 - learning_rate: 1.3509e-04\n",
      "Epoch 246/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0015\n",
      "Epoch 246: ReduceLROnPlateau reducing learning rate to 0.00012157666351413355.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0015 - val_loss: 0.0639 - learning_rate: 1.3509e-04\n",
      "Epoch 247/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0015 - val_loss: 0.0626 - learning_rate: 1.2158e-04\n",
      "Epoch 248/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0014 - val_loss: 0.0626 - learning_rate: 1.2158e-04\n",
      "Epoch 249/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0014 - val_loss: 0.0628 - learning_rate: 1.2158e-04\n",
      "Epoch 250/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0014 - val_loss: 0.0629 - learning_rate: 1.2158e-04\n",
      "Epoch 251/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0014 - val_loss: 0.0637 - learning_rate: 1.2158e-04\n",
      "Epoch 252/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0013 - val_loss: 0.0629 - learning_rate: 1.2158e-04\n",
      "Epoch 253/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0013 - val_loss: 0.0652 - learning_rate: 1.2158e-04\n",
      "Epoch 254/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0013 - val_loss: 0.0637 - learning_rate: 1.2158e-04\n",
      "Epoch 255/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0013 - val_loss: 0.0625 - learning_rate: 1.2158e-04\n",
      "Epoch 256/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0013\n",
      "Epoch 256: ReduceLROnPlateau reducing learning rate to 0.00010941899454337544.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0013 - val_loss: 0.0639 - learning_rate: 1.2158e-04\n",
      "Epoch 257/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0013 - val_loss: 0.0621 - learning_rate: 1.0942e-04\n",
      "Epoch 258/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0013 - val_loss: 0.0634 - learning_rate: 1.0942e-04\n",
      "Epoch 259/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0013 - val_loss: 0.0647 - learning_rate: 1.0942e-04\n",
      "Epoch 260/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0012 - val_loss: 0.0652 - learning_rate: 1.0942e-04\n",
      "Epoch 261/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 0.0013 - val_loss: 0.0641 - learning_rate: 1.0942e-04\n",
      "Epoch 262/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0013 - val_loss: 0.0623 - learning_rate: 1.0942e-04\n",
      "Epoch 263/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0012 - val_loss: 0.0646 - learning_rate: 1.0942e-04\n",
      "Epoch 264/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0013 - val_loss: 0.0631 - learning_rate: 1.0942e-04\n",
      "Epoch 265/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0013 - val_loss: 0.0641 - learning_rate: 1.0942e-04\n",
      "Epoch 266/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0012\n",
      "Epoch 266: ReduceLROnPlateau reducing learning rate to 9.847709443420172e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0012 - val_loss: 0.0611 - learning_rate: 1.0942e-04\n",
      "Epoch 267/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0012 - val_loss: 0.0653 - learning_rate: 9.8477e-05\n",
      "Epoch 268/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0012 - val_loss: 0.0648 - learning_rate: 9.8477e-05\n",
      "Epoch 269/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0012 - val_loss: 0.0624 - learning_rate: 9.8477e-05\n",
      "Epoch 270/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 0.0012 - val_loss: 0.0637 - learning_rate: 9.8477e-05\n",
      "Epoch 271/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0012 - val_loss: 0.0615 - learning_rate: 9.8477e-05\n",
      "Epoch 272/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0012 - val_loss: 0.0638 - learning_rate: 9.8477e-05\n",
      "Epoch 273/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0012 - val_loss: 0.0627 - learning_rate: 9.8477e-05\n",
      "Epoch 274/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0012 - val_loss: 0.0640 - learning_rate: 9.8477e-05\n",
      "Epoch 275/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0011 - val_loss: 0.0640 - learning_rate: 9.8477e-05\n",
      "Epoch 276/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0012\n",
      "Epoch 276: ReduceLROnPlateau reducing learning rate to 8.862938630045391e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0012 - val_loss: 0.0660 - learning_rate: 9.8477e-05\n",
      "Epoch 277/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0011 - val_loss: 0.0602 - learning_rate: 8.8629e-05\n",
      "Epoch 278/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0011 - val_loss: 0.0648 - learning_rate: 8.8629e-05\n",
      "Epoch 279/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0011 - val_loss: 0.0641 - learning_rate: 8.8629e-05\n",
      "Epoch 280/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0011 - val_loss: 0.0655 - learning_rate: 8.8629e-05\n",
      "Epoch 281/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0011 - val_loss: 0.0653 - learning_rate: 8.8629e-05\n",
      "Epoch 282/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0011 - val_loss: 0.0620 - learning_rate: 8.8629e-05\n",
      "Epoch 283/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0011 - val_loss: 0.0653 - learning_rate: 8.8629e-05\n",
      "Epoch 284/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0011 - val_loss: 0.0643 - learning_rate: 8.8629e-05\n",
      "Epoch 285/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0011 - val_loss: 0.0641 - learning_rate: 8.8629e-05\n",
      "Epoch 286/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0011\n",
      "Epoch 286: ReduceLROnPlateau reducing learning rate to 7.976644701557234e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 0.0011 - val_loss: 0.0659 - learning_rate: 8.8629e-05\n",
      "Epoch 287/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0011 - val_loss: 0.0670 - learning_rate: 7.9766e-05\n",
      "Epoch 288/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0011 - val_loss: 0.0644 - learning_rate: 7.9766e-05\n",
      "Epoch 289/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0011 - val_loss: 0.0637 - learning_rate: 7.9766e-05\n",
      "Epoch 290/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0011 - val_loss: 0.0650 - learning_rate: 7.9766e-05\n",
      "Epoch 291/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0010 - val_loss: 0.0637 - learning_rate: 7.9766e-05\n",
      "Epoch 292/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.0011 - val_loss: 0.0640 - learning_rate: 7.9766e-05\n",
      "Epoch 293/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0011 - val_loss: 0.0643 - learning_rate: 7.9766e-05\n",
      "Epoch 294/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0010 - val_loss: 0.0649 - learning_rate: 7.9766e-05\n",
      "Epoch 295/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 0.0010 - val_loss: 0.0657 - learning_rate: 7.9766e-05\n",
      "Epoch 296/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0010\n",
      "Epoch 296: ReduceLROnPlateau reducing learning rate to 7.178980231401511e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0010 - val_loss: 0.0625 - learning_rate: 7.9766e-05\n",
      "Epoch 297/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 9.9872e-04 - val_loss: 0.0651 - learning_rate: 7.1790e-05\n",
      "Epoch 298/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0010 - val_loss: 0.0647 - learning_rate: 7.1790e-05\n",
      "Epoch 299/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 0.0010 - val_loss: 0.0664 - learning_rate: 7.1790e-05\n",
      "Epoch 300/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 9.8640e-04 - val_loss: 0.0656 - learning_rate: 7.1790e-05\n",
      "Epoch 301/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0010 - val_loss: 0.0656 - learning_rate: 7.1790e-05\n",
      "Epoch 302/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 9.8274e-04 - val_loss: 0.0636 - learning_rate: 7.1790e-05\n",
      "Epoch 303/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0010 - val_loss: 0.0659 - learning_rate: 7.1790e-05\n",
      "Epoch 304/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0010 - val_loss: 0.0635 - learning_rate: 7.1790e-05\n",
      "Epoch 305/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 9.9175e-04 - val_loss: 0.0658 - learning_rate: 7.1790e-05\n",
      "Epoch 306/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 9.9930e-04\n",
      "Epoch 306: ReduceLROnPlateau reducing learning rate to 6.461082011810504e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0010 - val_loss: 0.0653 - learning_rate: 7.1790e-05\n",
      "Epoch 307/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 9.8458e-04 - val_loss: 0.0660 - learning_rate: 6.4611e-05\n",
      "Epoch 308/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 9.6556e-04 - val_loss: 0.0662 - learning_rate: 6.4611e-05\n",
      "Epoch 309/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 9.6392e-04 - val_loss: 0.0627 - learning_rate: 6.4611e-05\n",
      "Epoch 310/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 9.5084e-04 - val_loss: 0.0654 - learning_rate: 6.4611e-05\n",
      "Epoch 311/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 9.8739e-04 - val_loss: 0.0658 - learning_rate: 6.4611e-05\n",
      "Epoch 312/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 9.7480e-04 - val_loss: 0.0650 - learning_rate: 6.4611e-05\n",
      "Epoch 313/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 9.7695e-04 - val_loss: 0.0654 - learning_rate: 6.4611e-05\n",
      "Epoch 314/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 9.4345e-04 - val_loss: 0.0653 - learning_rate: 6.4611e-05\n",
      "Epoch 315/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 9.4094e-04 - val_loss: 0.0652 - learning_rate: 6.4611e-05\n",
      "Epoch 316/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 9.4035e-04\n",
      "Epoch 316: ReduceLROnPlateau reducing learning rate to 5.8149741380475466e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 9.4425e-04 - val_loss: 0.0652 - learning_rate: 6.4611e-05\n",
      "Epoch 317/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 9.4184e-04 - val_loss: 0.0656 - learning_rate: 5.8150e-05\n",
      "Epoch 318/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 9.1244e-04 - val_loss: 0.0666 - learning_rate: 5.8150e-05\n",
      "Epoch 319/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 9.1683e-04 - val_loss: 0.0647 - learning_rate: 5.8150e-05\n",
      "Epoch 320/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 9.1852e-04 - val_loss: 0.0650 - learning_rate: 5.8150e-05\n",
      "Epoch 321/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 9.1474e-04 - val_loss: 0.0644 - learning_rate: 5.8150e-05\n",
      "Epoch 322/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 9.1358e-04 - val_loss: 0.0650 - learning_rate: 5.8150e-05\n",
      "Epoch 323/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 9.3956e-04 - val_loss: 0.0645 - learning_rate: 5.8150e-05\n",
      "Epoch 324/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 9.0916e-04 - val_loss: 0.0639 - learning_rate: 5.8150e-05\n",
      "Epoch 325/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 9.4273e-04 - val_loss: 0.0642 - learning_rate: 5.8150e-05\n",
      "Epoch 326/1400\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 9.2294e-04\n",
      "Epoch 326: ReduceLROnPlateau reducing learning rate to 5.233476658759173e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 9.2554e-04 - val_loss: 0.0659 - learning_rate: 5.8150e-05\n",
      "Epoch 327/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 8.9751e-04 - val_loss: 0.0665 - learning_rate: 5.2335e-05\n",
      "Epoch 328/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 8.9884e-04 - val_loss: 0.0637 - learning_rate: 5.2335e-05\n",
      "Epoch 329/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 9.2676e-04 - val_loss: 0.0662 - learning_rate: 5.2335e-05\n",
      "Epoch 330/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 8.7673e-04 - val_loss: 0.0650 - learning_rate: 5.2335e-05\n",
      "Epoch 331/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 9.0965e-04 - val_loss: 0.0672 - learning_rate: 5.2335e-05\n",
      "Epoch 332/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 8.8417e-04 - val_loss: 0.0666 - learning_rate: 5.2335e-05\n",
      "Epoch 333/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 8.8262e-04 - val_loss: 0.0646 - learning_rate: 5.2335e-05\n",
      "Epoch 334/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 8.8157e-04 - val_loss: 0.0660 - learning_rate: 5.2335e-05\n",
      "Epoch 335/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 8.8525e-04 - val_loss: 0.0656 - learning_rate: 5.2335e-05\n",
      "Epoch 336/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 8.9783e-04\n",
      "Epoch 336: ReduceLROnPlateau reducing learning rate to 4.7101289601414466e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 8.9988e-04 - val_loss: 0.0643 - learning_rate: 5.2335e-05\n",
      "Epoch 337/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 8.8511e-04 - val_loss: 0.0662 - learning_rate: 4.7101e-05\n",
      "Epoch 338/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 8.7726e-04 - val_loss: 0.0675 - learning_rate: 4.7101e-05\n",
      "Epoch 339/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 8.5966e-04 - val_loss: 0.0671 - learning_rate: 4.7101e-05\n",
      "Epoch 340/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 8.6078e-04 - val_loss: 0.0648 - learning_rate: 4.7101e-05\n",
      "Epoch 341/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 8.6456e-04 - val_loss: 0.0649 - learning_rate: 4.7101e-05\n",
      "Epoch 342/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 8.6191e-04 - val_loss: 0.0650 - learning_rate: 4.7101e-05\n",
      "Epoch 343/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 17:25:17.994485: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 8.5647e-04 - val_loss: 0.0644 - learning_rate: 4.7101e-05\n",
      "Epoch 344/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 8.5892e-04 - val_loss: 0.0648 - learning_rate: 4.7101e-05\n",
      "Epoch 345/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 8.5660e-04 - val_loss: 0.0646 - learning_rate: 4.7101e-05\n",
      "Epoch 346/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 8.5657e-04\n",
      "Epoch 346: ReduceLROnPlateau reducing learning rate to 4.239116096869111e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 8.5900e-04 - val_loss: 0.0656 - learning_rate: 4.7101e-05\n",
      "Epoch 347/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 8.5876e-04 - val_loss: 0.0660 - learning_rate: 4.2391e-05\n",
      "Epoch 348/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 8.5410e-04 - val_loss: 0.0656 - learning_rate: 4.2391e-05\n",
      "Epoch 349/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 8.5083e-04 - val_loss: 0.0652 - learning_rate: 4.2391e-05\n",
      "Epoch 350/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 8.3957e-04 - val_loss: 0.0683 - learning_rate: 4.2391e-05\n",
      "Epoch 351/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 8.2790e-04 - val_loss: 0.0649 - learning_rate: 4.2391e-05\n",
      "Epoch 352/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 8.3012e-04 - val_loss: 0.0646 - learning_rate: 4.2391e-05\n",
      "Epoch 353/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 8.2775e-04 - val_loss: 0.0656 - learning_rate: 4.2391e-05\n",
      "Epoch 354/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 8.2277e-04 - val_loss: 0.0667 - learning_rate: 4.2391e-05\n",
      "Epoch 355/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 8.2941e-04 - val_loss: 0.0626 - learning_rate: 4.2391e-05\n",
      "Epoch 356/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 8.3895e-04\n",
      "Epoch 356: ReduceLROnPlateau reducing learning rate to 3.815204618149437e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 8.4133e-04 - val_loss: 0.0657 - learning_rate: 4.2391e-05\n",
      "Epoch 357/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 8.2008e-04 - val_loss: 0.0660 - learning_rate: 3.8152e-05\n",
      "Epoch 358/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 7.9539e-04 - val_loss: 0.0659 - learning_rate: 3.8152e-05\n",
      "Epoch 359/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 8.1473e-04 - val_loss: 0.0656 - learning_rate: 3.8152e-05\n",
      "Epoch 360/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 8.0969e-04 - val_loss: 0.0641 - learning_rate: 3.8152e-05\n",
      "Epoch 361/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 8.1881e-04 - val_loss: 0.0656 - learning_rate: 3.8152e-05\n",
      "Epoch 362/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 8.1855e-04 - val_loss: 0.0660 - learning_rate: 3.8152e-05\n",
      "Epoch 363/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 8.2069e-04 - val_loss: 0.0655 - learning_rate: 3.8152e-05\n",
      "Epoch 364/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 8.1090e-04 - val_loss: 0.0668 - learning_rate: 3.8152e-05\n",
      "Epoch 365/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 8.0227e-04 - val_loss: 0.0666 - learning_rate: 3.8152e-05\n",
      "Epoch 366/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 7.9370e-04\n",
      "Epoch 366: ReduceLROnPlateau reducing learning rate to 3.4336842873017304e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.9702e-04 - val_loss: 0.0658 - learning_rate: 3.8152e-05\n",
      "Epoch 367/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 8.0567e-04 - val_loss: 0.0658 - learning_rate: 3.4337e-05\n",
      "Epoch 368/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 8.0906e-04 - val_loss: 0.0684 - learning_rate: 3.4337e-05\n",
      "Epoch 369/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 8.1191e-04 - val_loss: 0.0660 - learning_rate: 3.4337e-05\n",
      "Epoch 370/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.8244e-04 - val_loss: 0.0640 - learning_rate: 3.4337e-05\n",
      "Epoch 371/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.7084e-04 - val_loss: 0.0672 - learning_rate: 3.4337e-05\n",
      "Epoch 372/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 8.0215e-04 - val_loss: 0.0665 - learning_rate: 3.4337e-05\n",
      "Epoch 373/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 7.9251e-04 - val_loss: 0.0651 - learning_rate: 3.4337e-05\n",
      "Epoch 374/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 7.7592e-04 - val_loss: 0.0671 - learning_rate: 3.4337e-05\n",
      "Epoch 375/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 7.7649e-04 - val_loss: 0.0656 - learning_rate: 3.4337e-05\n",
      "Epoch 376/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 7.8741e-04\n",
      "Epoch 376: ReduceLROnPlateau reducing learning rate to 3.0903160222806036e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.9150e-04 - val_loss: 0.0657 - learning_rate: 3.4337e-05\n",
      "Epoch 377/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 8.1146e-04 - val_loss: 0.0660 - learning_rate: 3.0903e-05\n",
      "Epoch 378/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.8159e-04 - val_loss: 0.0655 - learning_rate: 3.0903e-05\n",
      "Epoch 379/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.6412e-04 - val_loss: 0.0656 - learning_rate: 3.0903e-05\n",
      "Epoch 380/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.8103e-04 - val_loss: 0.0653 - learning_rate: 3.0903e-05\n",
      "Epoch 381/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.7218e-04 - val_loss: 0.0651 - learning_rate: 3.0903e-05\n",
      "Epoch 382/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 7.7649e-04 - val_loss: 0.0647 - learning_rate: 3.0903e-05\n",
      "Epoch 383/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.5490e-04 - val_loss: 0.0639 - learning_rate: 3.0903e-05\n",
      "Epoch 384/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 7.7642e-04 - val_loss: 0.0656 - learning_rate: 3.0903e-05\n",
      "Epoch 385/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 7.5818e-04 - val_loss: 0.0653 - learning_rate: 3.0903e-05\n",
      "Epoch 386/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 7.6620e-04\n",
      "Epoch 386: ReduceLROnPlateau reducing learning rate to 3e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 7.6881e-04 - val_loss: 0.0651 - learning_rate: 3.0903e-05\n",
      "Epoch 387/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 7.6557e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 388/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.7983e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 389/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.5709e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 390/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.5892e-04 - val_loss: 0.0659 - learning_rate: 3.0000e-05\n",
      "Epoch 391/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 7.5559e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 392/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.6058e-04 - val_loss: 0.0659 - learning_rate: 3.0000e-05\n",
      "Epoch 393/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 7.4932e-04 - val_loss: 0.0659 - learning_rate: 3.0000e-05\n",
      "Epoch 394/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.6775e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 395/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 7.6895e-04 - val_loss: 0.0659 - learning_rate: 3.0000e-05\n",
      "Epoch 396/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 7.6232e-04 - val_loss: 0.0654 - learning_rate: 3.0000e-05\n",
      "Epoch 397/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 7.4253e-04 - val_loss: 0.0654 - learning_rate: 3.0000e-05\n",
      "Epoch 398/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.4647e-04 - val_loss: 0.0654 - learning_rate: 3.0000e-05\n",
      "Epoch 399/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 7.4456e-04 - val_loss: 0.0651 - learning_rate: 3.0000e-05\n",
      "Epoch 400/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.5443e-04 - val_loss: 0.0649 - learning_rate: 3.0000e-05\n",
      "Epoch 401/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 7.4876e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 402/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.5073e-04 - val_loss: 0.0652 - learning_rate: 3.0000e-05\n",
      "Epoch 403/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 7.4082e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 404/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.5557e-04 - val_loss: 0.0661 - learning_rate: 3.0000e-05\n",
      "Epoch 405/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.4794e-04 - val_loss: 0.0658 - learning_rate: 3.0000e-05\n",
      "Epoch 406/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.4712e-04 - val_loss: 0.0663 - learning_rate: 3.0000e-05\n",
      "Epoch 407/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.6805e-04 - val_loss: 0.0644 - learning_rate: 3.0000e-05\n",
      "Epoch 408/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.3632e-04 - val_loss: 0.0657 - learning_rate: 3.0000e-05\n",
      "Epoch 409/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 7.5574e-04 - val_loss: 0.0664 - learning_rate: 3.0000e-05\n",
      "Epoch 410/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.2976e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 411/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 7.4495e-04 - val_loss: 0.0653 - learning_rate: 3.0000e-05\n",
      "Epoch 412/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.3594e-04 - val_loss: 0.0664 - learning_rate: 3.0000e-05\n",
      "Epoch 413/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 7.3475e-04 - val_loss: 0.0652 - learning_rate: 3.0000e-05\n",
      "Epoch 414/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.4539e-04 - val_loss: 0.0663 - learning_rate: 3.0000e-05\n",
      "Epoch 415/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 7.5091e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 416/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 7.3606e-04 - val_loss: 0.0649 - learning_rate: 3.0000e-05\n",
      "Epoch 417/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 7.4130e-04 - val_loss: 0.0665 - learning_rate: 3.0000e-05\n",
      "Epoch 418/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 7.4295e-04 - val_loss: 0.0652 - learning_rate: 3.0000e-05\n",
      "Epoch 419/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 7.4068e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 420/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 7.2601e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 421/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 7.2752e-04 - val_loss: 0.0660 - learning_rate: 3.0000e-05\n",
      "Epoch 422/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 7.1337e-04 - val_loss: 0.0649 - learning_rate: 3.0000e-05\n",
      "Epoch 423/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 7.2173e-04 - val_loss: 0.0663 - learning_rate: 3.0000e-05\n",
      "Epoch 424/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.4423e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 425/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 7.0875e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 426/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 7.2145e-04 - val_loss: 0.0660 - learning_rate: 3.0000e-05\n",
      "Epoch 427/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 7.1505e-04 - val_loss: 0.0662 - learning_rate: 3.0000e-05\n",
      "Epoch 428/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.1650e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 429/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 7.0823e-04 - val_loss: 0.0657 - learning_rate: 3.0000e-05\n",
      "Epoch 430/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.1577e-04 - val_loss: 0.0657 - learning_rate: 3.0000e-05\n",
      "Epoch 431/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.1200e-04 - val_loss: 0.0657 - learning_rate: 3.0000e-05\n",
      "Epoch 432/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.1397e-04 - val_loss: 0.0655 - learning_rate: 3.0000e-05\n",
      "Epoch 433/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.1625e-04 - val_loss: 0.0660 - learning_rate: 3.0000e-05\n",
      "Epoch 434/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.1831e-04 - val_loss: 0.0641 - learning_rate: 3.0000e-05\n",
      "Epoch 435/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 7.1045e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 436/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 7.2726e-04 - val_loss: 0.0652 - learning_rate: 3.0000e-05\n",
      "Epoch 437/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 7.1706e-04 - val_loss: 0.0663 - learning_rate: 3.0000e-05\n",
      "Epoch 438/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 7.2014e-04 - val_loss: 0.0652 - learning_rate: 3.0000e-05\n",
      "Epoch 439/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 7.2040e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 440/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.0935e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 441/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 7.0141e-04 - val_loss: 0.0659 - learning_rate: 3.0000e-05\n",
      "Epoch 442/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.9391e-04 - val_loss: 0.0645 - learning_rate: 3.0000e-05\n",
      "Epoch 443/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.9929e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 444/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 7.1972e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 445/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 7.1239e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 446/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.0803e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 447/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 7.0888e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 448/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.2393e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 449/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 7.2325e-04 - val_loss: 0.0660 - learning_rate: 3.0000e-05\n",
      "Epoch 450/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.0760e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 451/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 7.1617e-04 - val_loss: 0.0650 - learning_rate: 3.0000e-05\n",
      "Epoch 452/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.0473e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 453/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.8828e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 454/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 6.9687e-04 - val_loss: 0.0664 - learning_rate: 3.0000e-05\n",
      "Epoch 455/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 7.0206e-04 - val_loss: 0.0663 - learning_rate: 3.0000e-05\n",
      "Epoch 456/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 6.9651e-04 - val_loss: 0.0660 - learning_rate: 3.0000e-05\n",
      "Epoch 457/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.9360e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 458/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 7.0328e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 459/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.0115e-04 - val_loss: 0.0651 - learning_rate: 3.0000e-05\n",
      "Epoch 460/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.9396e-04 - val_loss: 0.0654 - learning_rate: 3.0000e-05\n",
      "Epoch 461/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.9443e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 462/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.9790e-04 - val_loss: 0.0647 - learning_rate: 3.0000e-05\n",
      "Epoch 463/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.8930e-04 - val_loss: 0.0662 - learning_rate: 3.0000e-05\n",
      "Epoch 464/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.7980e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 465/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.8527e-04 - val_loss: 0.0658 - learning_rate: 3.0000e-05\n",
      "Epoch 466/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.8465e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 467/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.8307e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 468/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.9996e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 469/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 7.0414e-04 - val_loss: 0.0652 - learning_rate: 3.0000e-05\n",
      "Epoch 470/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.9661e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 471/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.8775e-04 - val_loss: 0.0660 - learning_rate: 3.0000e-05\n",
      "Epoch 472/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 7.0637e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 473/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.7776e-04 - val_loss: 0.0655 - learning_rate: 3.0000e-05\n",
      "Epoch 474/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.8542e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 475/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.7796e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 476/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 6.8370e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 477/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.8188e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 478/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 6.7927e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 479/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.9105e-04 - val_loss: 0.0662 - learning_rate: 3.0000e-05\n",
      "Epoch 480/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.7659e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 481/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.9054e-04 - val_loss: 0.0660 - learning_rate: 3.0000e-05\n",
      "Epoch 482/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 6.7853e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 483/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.6463e-04 - val_loss: 0.0662 - learning_rate: 3.0000e-05\n",
      "Epoch 484/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.9648e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 485/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.7982e-04 - val_loss: 0.0644 - learning_rate: 3.0000e-05\n",
      "Epoch 486/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.7944e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 487/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.7036e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 488/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 6.7176e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 489/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 6.6411e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 490/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.5946e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 491/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.7573e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 492/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.8914e-04 - val_loss: 0.0660 - learning_rate: 3.0000e-05\n",
      "Epoch 493/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 6.7767e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 494/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.5337e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 495/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 6.5133e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 496/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.7696e-04 - val_loss: 0.0663 - learning_rate: 3.0000e-05\n",
      "Epoch 497/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.5280e-04 - val_loss: 0.0652 - learning_rate: 3.0000e-05\n",
      "Epoch 498/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.5762e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 499/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.5802e-04 - val_loss: 0.0652 - learning_rate: 3.0000e-05\n",
      "Epoch 500/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 6.7061e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 501/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 6.7011e-04 - val_loss: 0.0665 - learning_rate: 3.0000e-05\n",
      "Epoch 502/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.6149e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 503/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.5205e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 504/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.6317e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 505/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.5088e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 506/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.6149e-04 - val_loss: 0.0664 - learning_rate: 3.0000e-05\n",
      "Epoch 507/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.8684e-04 - val_loss: 0.0651 - learning_rate: 3.0000e-05\n",
      "Epoch 508/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.4862e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 509/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 6.6325e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 510/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.6069e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 511/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.4611e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 512/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.5376e-04 - val_loss: 0.0664 - learning_rate: 3.0000e-05\n",
      "Epoch 513/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.5397e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 514/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.4417e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 515/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.6086e-04 - val_loss: 0.0659 - learning_rate: 3.0000e-05\n",
      "Epoch 516/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.3451e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 517/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.3943e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 518/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.5286e-04 - val_loss: 0.0661 - learning_rate: 3.0000e-05\n",
      "Epoch 519/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - loss: 6.5789e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 520/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.4890e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 521/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.5528e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 522/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.3826e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 523/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.3426e-04 - val_loss: 0.0665 - learning_rate: 3.0000e-05\n",
      "Epoch 524/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.5206e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 525/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 6.4768e-04 - val_loss: 0.0664 - learning_rate: 3.0000e-05\n",
      "Epoch 526/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.4195e-04 - val_loss: 0.0663 - learning_rate: 3.0000e-05\n",
      "Epoch 527/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.4167e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 528/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.4088e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 529/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.3947e-04 - val_loss: 0.0637 - learning_rate: 3.0000e-05\n",
      "Epoch 530/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.2383e-04 - val_loss: 0.0658 - learning_rate: 3.0000e-05\n",
      "Epoch 531/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.3108e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 532/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.3945e-04 - val_loss: 0.0654 - learning_rate: 3.0000e-05\n",
      "Epoch 533/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 6.3240e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 534/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.4452e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 535/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 6.1908e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 536/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.2925e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 537/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.4732e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 538/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.2485e-04 - val_loss: 0.0661 - learning_rate: 3.0000e-05\n",
      "Epoch 539/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 6.4046e-04 - val_loss: 0.0655 - learning_rate: 3.0000e-05\n",
      "Epoch 540/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.3664e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 541/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.1621e-04 - val_loss: 0.0665 - learning_rate: 3.0000e-05\n",
      "Epoch 542/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.2298e-04 - val_loss: 0.0652 - learning_rate: 3.0000e-05\n",
      "Epoch 543/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 6.3129e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 544/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.2266e-04 - val_loss: 0.0662 - learning_rate: 3.0000e-05\n",
      "Epoch 545/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 6.3326e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 546/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - loss: 6.3522e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 547/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.2085e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 548/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.2246e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 549/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.2568e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 550/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 6.0887e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 551/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.1141e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 552/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 6.3681e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 553/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.1939e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 554/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 6.1153e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 555/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.1350e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 556/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 6.1755e-04 - val_loss: 0.0664 - learning_rate: 3.0000e-05\n",
      "Epoch 557/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.1647e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 558/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.4118e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 559/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.1634e-04 - val_loss: 0.0662 - learning_rate: 3.0000e-05\n",
      "Epoch 560/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.0506e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 561/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.1279e-04 - val_loss: 0.0647 - learning_rate: 3.0000e-05\n",
      "Epoch 562/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - loss: 6.0067e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 563/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.0966e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 564/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 6.0309e-04 - val_loss: 0.0658 - learning_rate: 3.0000e-05\n",
      "Epoch 565/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 6.1598e-04 - val_loss: 0.0663 - learning_rate: 3.0000e-05\n",
      "Epoch 566/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.1081e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 567/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.0545e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 568/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.0840e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 569/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.1726e-04 - val_loss: 0.0660 - learning_rate: 3.0000e-05\n",
      "Epoch 570/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.0622e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 571/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 6.2262e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 572/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 6.1492e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 573/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 6.0295e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 574/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.2018e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 575/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.0797e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 576/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.0789e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 577/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 6.0509e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 578/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.0964e-04 - val_loss: 0.0659 - learning_rate: 3.0000e-05\n",
      "Epoch 579/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 6.1120e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 580/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 6.0561e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 581/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 6.1067e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 582/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.0446e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 583/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 6.0279e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 584/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.9015e-04 - val_loss: 0.0665 - learning_rate: 3.0000e-05\n",
      "Epoch 585/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.9798e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 586/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.9558e-04 - val_loss: 0.0661 - learning_rate: 3.0000e-05\n",
      "Epoch 587/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 6.0860e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 588/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 6.1581e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 589/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 5.8127e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 590/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 5.9654e-04 - val_loss: 0.0664 - learning_rate: 3.0000e-05\n",
      "Epoch 591/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.9552e-04 - val_loss: 0.0664 - learning_rate: 3.0000e-05\n",
      "Epoch 592/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.9255e-04 - val_loss: 0.0661 - learning_rate: 3.0000e-05\n",
      "Epoch 593/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.8789e-04 - val_loss: 0.0662 - learning_rate: 3.0000e-05\n",
      "Epoch 594/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 5.9307e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 595/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.9672e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 596/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.7831e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 597/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.8466e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 598/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 5.7884e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 599/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.0658e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 600/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 5.9334e-04 - val_loss: 0.0665 - learning_rate: 3.0000e-05\n",
      "Epoch 601/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 5.9689e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 602/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.0469e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 603/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 5.6754e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 604/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.8185e-04 - val_loss: 0.0657 - learning_rate: 3.0000e-05\n",
      "Epoch 605/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.8947e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 606/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.7874e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 607/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.8300e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 608/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.8378e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 609/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 5.7660e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 610/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.8585e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 611/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.7752e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 612/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 6.0329e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 613/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.8932e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 614/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.8564e-04 - val_loss: 0.0661 - learning_rate: 3.0000e-05\n",
      "Epoch 615/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 5.7509e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 616/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.7448e-04 - val_loss: 0.0698 - learning_rate: 3.0000e-05\n",
      "Epoch 617/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 5.7540e-04 - val_loss: 0.0662 - learning_rate: 3.0000e-05\n",
      "Epoch 618/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.7248e-04 - val_loss: 0.0697 - learning_rate: 3.0000e-05\n",
      "Epoch 619/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.6512e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 620/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.7180e-04 - val_loss: 0.0659 - learning_rate: 3.0000e-05\n",
      "Epoch 621/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.6796e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 622/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.7706e-04 - val_loss: 0.0694 - learning_rate: 3.0000e-05\n",
      "Epoch 623/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 5.8911e-04 - val_loss: 0.0693 - learning_rate: 3.0000e-05\n",
      "Epoch 624/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.7668e-04 - val_loss: 0.0665 - learning_rate: 3.0000e-05\n",
      "Epoch 625/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.6738e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 626/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.7304e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 627/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 5.7100e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 628/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.6820e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 629/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 5.6987e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 630/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.5274e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 631/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - loss: 5.7068e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 632/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.8376e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 633/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.6229e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 634/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.6632e-04 - val_loss: 0.0706 - learning_rate: 3.0000e-05\n",
      "Epoch 635/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.7223e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 636/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.6636e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 637/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 5.6373e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 638/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.7215e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 639/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.6533e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 640/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.6144e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 641/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.6000e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 642/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.7117e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 643/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 5.6342e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 644/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.6851e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 645/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.5837e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 646/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.5329e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 647/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.4306e-04 - val_loss: 0.0659 - learning_rate: 3.0000e-05\n",
      "Epoch 648/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.6051e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 649/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 5.7464e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 650/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.7254e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 651/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 5.5788e-04 - val_loss: 0.0651 - learning_rate: 3.0000e-05\n",
      "Epoch 652/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.4437e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 653/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.4168e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 654/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.5272e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 655/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.6893e-04 - val_loss: 0.0665 - learning_rate: 3.0000e-05\n",
      "Epoch 656/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.6019e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 657/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 5.5725e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 658/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.4796e-04 - val_loss: 0.0699 - learning_rate: 3.0000e-05\n",
      "Epoch 659/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 5.4415e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 660/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 5.5567e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 661/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.6716e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 662/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 5.5261e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 663/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.4644e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 664/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.4779e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 665/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.4795e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 666/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 5.4784e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 667/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.4372e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 668/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.5746e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 669/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.3711e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 670/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 5.4800e-04 - val_loss: 0.0656 - learning_rate: 3.0000e-05\n",
      "Epoch 671/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.3802e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 672/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 5.4757e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 673/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.4101e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 674/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.3916e-04 - val_loss: 0.0694 - learning_rate: 3.0000e-05\n",
      "Epoch 675/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.4354e-04 - val_loss: 0.0661 - learning_rate: 3.0000e-05\n",
      "Epoch 676/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 5.4703e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 677/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.3176e-04 - val_loss: 0.0643 - learning_rate: 3.0000e-05\n",
      "Epoch 678/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 5.5171e-04 - val_loss: 0.0699 - learning_rate: 3.0000e-05\n",
      "Epoch 679/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.6069e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 680/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.5629e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 681/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.4832e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 682/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 5.5325e-04 - val_loss: 0.0694 - learning_rate: 3.0000e-05\n",
      "Epoch 683/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.3793e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 684/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 5.2582e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 17:40:52.608153: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.2689e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 685/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.4204e-04 - val_loss: 0.0660 - learning_rate: 3.0000e-05\n",
      "Epoch 686/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.3188e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 687/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.3188e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 688/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 5.5036e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 689/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.4740e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 690/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 5.5882e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 691/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 5.2291e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 692/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.4183e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 693/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.4206e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 694/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 5.3985e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 695/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.4024e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 696/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.2970e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 697/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.3463e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 698/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.3628e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 699/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 5.2823e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 700/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.1913e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 701/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 5.3620e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 702/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - loss: 5.1529e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 703/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.3580e-04 - val_loss: 0.0664 - learning_rate: 3.0000e-05\n",
      "Epoch 704/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.3843e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 705/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.4663e-04 - val_loss: 0.0665 - learning_rate: 3.0000e-05\n",
      "Epoch 706/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 5.2448e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 707/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.1767e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 708/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 5.3120e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 709/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 5.3294e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 710/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 5.3046e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 711/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 5.2852e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 712/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.2924e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 713/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 5.1550e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 714/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 5.1249e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 715/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.2320e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 716/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.3221e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 717/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.2336e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 718/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 5.3561e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 719/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.4383e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 720/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.2562e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 721/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.3789e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 722/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.3890e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 723/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.2588e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 724/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.1747e-04 - val_loss: 0.0662 - learning_rate: 3.0000e-05\n",
      "Epoch 725/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.3740e-04 - val_loss: 0.0656 - learning_rate: 3.0000e-05\n",
      "Epoch 726/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.2611e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 727/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.1562e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 728/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.2334e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 729/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.1734e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 730/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 5.2276e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 731/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.2711e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 732/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.0881e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 733/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.2901e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 734/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 5.0768e-04 - val_loss: 0.0701 - learning_rate: 3.0000e-05\n",
      "Epoch 735/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.0841e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 736/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.1012e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 737/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.0720e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 738/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.1003e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 739/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.0654e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 740/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.1867e-04 - val_loss: 0.0647 - learning_rate: 3.0000e-05\n",
      "Epoch 741/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 5.1253e-04 - val_loss: 0.0661 - learning_rate: 3.0000e-05\n",
      "Epoch 742/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 4.9849e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 743/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.0827e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 744/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.0476e-04 - val_loss: 0.0702 - learning_rate: 3.0000e-05\n",
      "Epoch 745/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.0804e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 746/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 5.0343e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 747/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.1964e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 748/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.1693e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 749/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.0083e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 750/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 5.0598e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 751/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.1210e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 752/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 5.0649e-04 - val_loss: 0.0664 - learning_rate: 3.0000e-05\n",
      "Epoch 753/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 4.9639e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 754/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.0219e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 755/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.9969e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 756/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 4.9778e-04 - val_loss: 0.0663 - learning_rate: 3.0000e-05\n",
      "Epoch 757/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.0016e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 758/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 5.1888e-04 - val_loss: 0.0660 - learning_rate: 3.0000e-05\n",
      "Epoch 759/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 5.0564e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 760/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 4.9630e-04 - val_loss: 0.0662 - learning_rate: 3.0000e-05\n",
      "Epoch 761/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.1098e-04 - val_loss: 0.0661 - learning_rate: 3.0000e-05\n",
      "Epoch 762/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.0643e-04 - val_loss: 0.0665 - learning_rate: 3.0000e-05\n",
      "Epoch 763/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.0902e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 764/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 5.0808e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 765/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.0133e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 766/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 5.0367e-04 - val_loss: 0.0661 - learning_rate: 3.0000e-05\n",
      "Epoch 767/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.0553e-04 - val_loss: 0.0658 - learning_rate: 3.0000e-05\n",
      "Epoch 768/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 5.2120e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 769/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.9137e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 770/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 5.0006e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 771/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 5.0645e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 772/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.9576e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 773/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 4.8269e-04 - val_loss: 0.0698 - learning_rate: 3.0000e-05\n",
      "Epoch 774/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 4.8341e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 775/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 4.9392e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 776/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 5.0982e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 777/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.9965e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 778/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.9649e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 779/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.9310e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 780/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 5.0740e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 781/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.8257e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 782/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 4.9981e-04 - val_loss: 0.0663 - learning_rate: 3.0000e-05\n",
      "Epoch 783/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.0146e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 784/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 4.9382e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 785/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 4.8968e-04 - val_loss: 0.0663 - learning_rate: 3.0000e-05\n",
      "Epoch 786/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 4.9216e-04 - val_loss: 0.0699 - learning_rate: 3.0000e-05\n",
      "Epoch 787/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 4.8897e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 788/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 4.8933e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 789/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 4.9169e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 790/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.8887e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 791/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 4.9192e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 792/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.9484e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 793/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5.0095e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 794/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 4.9306e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 795/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 4.7716e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 796/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.9305e-04 - val_loss: 0.0701 - learning_rate: 3.0000e-05\n",
      "Epoch 797/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.8057e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 798/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.8204e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 799/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 4.9439e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 800/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.7344e-04 - val_loss: 0.0652 - learning_rate: 3.0000e-05\n",
      "Epoch 801/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 4.8571e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 802/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.8935e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 803/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 4.7532e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 804/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 4.8012e-04 - val_loss: 0.0703 - learning_rate: 3.0000e-05\n",
      "Epoch 805/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 4.9182e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 806/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - loss: 4.9731e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 807/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.7214e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 808/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 4.7791e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 809/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.8388e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 810/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.7897e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 811/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.8187e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 812/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.9343e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 813/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.7754e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 814/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 4.7825e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 815/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.9079e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 816/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 4.7347e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 817/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.7944e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 818/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.6569e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 819/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.7633e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 820/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 4.8395e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 821/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.6857e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 822/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.7426e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 823/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 4.6380e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 824/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 4.7605e-04 - val_loss: 0.0695 - learning_rate: 3.0000e-05\n",
      "Epoch 825/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 4.7065e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 826/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.7798e-04 - val_loss: 0.0664 - learning_rate: 3.0000e-05\n",
      "Epoch 827/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 4.7414e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 828/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.7380e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 829/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.7158e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 830/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.6390e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 831/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.6857e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 832/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.6949e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 833/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 4.6632e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 834/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.6107e-04 - val_loss: 0.0695 - learning_rate: 3.0000e-05\n",
      "Epoch 835/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.8411e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 836/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.7659e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 837/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.8049e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 838/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.7141e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 839/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 4.5922e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 840/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.8563e-04 - val_loss: 0.0693 - learning_rate: 3.0000e-05\n",
      "Epoch 841/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.6436e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 842/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.8932e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 843/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 4.6835e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 844/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.7368e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 845/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 4.6365e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 846/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 4.6327e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 847/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 4.6160e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 848/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.8398e-04 - val_loss: 0.0699 - learning_rate: 3.0000e-05\n",
      "Epoch 849/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.7306e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 850/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.6169e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 851/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 4.7613e-04 - val_loss: 0.0712 - learning_rate: 3.0000e-05\n",
      "Epoch 852/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.4866e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 853/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 4.6490e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 854/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.5962e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 855/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 4.6726e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 856/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.6176e-04 - val_loss: 0.0698 - learning_rate: 3.0000e-05\n",
      "Epoch 857/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 4.5979e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 858/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.6593e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 859/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.5062e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 860/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.5530e-04 - val_loss: 0.0659 - learning_rate: 3.0000e-05\n",
      "Epoch 861/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.5227e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 862/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.7361e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 863/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.7853e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 864/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.5545e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 865/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.6383e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 866/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.5278e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 867/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.5972e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 868/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.7260e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 869/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.5576e-04 - val_loss: 0.0657 - learning_rate: 3.0000e-05\n",
      "Epoch 870/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.6287e-04 - val_loss: 0.0721 - learning_rate: 3.0000e-05\n",
      "Epoch 871/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 4.5691e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 872/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.5192e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 873/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.5344e-04 - val_loss: 0.0697 - learning_rate: 3.0000e-05\n",
      "Epoch 874/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.5377e-04 - val_loss: 0.0661 - learning_rate: 3.0000e-05\n",
      "Epoch 875/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 4.5153e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 876/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.4988e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 877/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.5216e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 878/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.4977e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 879/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.5903e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 880/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.6294e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 881/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 4.6027e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 882/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.6600e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 883/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 4.5260e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 884/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.4596e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 885/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 4.6089e-04 - val_loss: 0.0698 - learning_rate: 3.0000e-05\n",
      "Epoch 886/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.6172e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 887/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.6552e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 888/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.4746e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 889/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 4.3823e-04 - val_loss: 0.0663 - learning_rate: 3.0000e-05\n",
      "Epoch 890/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.5762e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 891/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 4.5184e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 892/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.6430e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 893/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 4.4827e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 894/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.5273e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 895/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 4.5276e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 896/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.4305e-04 - val_loss: 0.0659 - learning_rate: 3.0000e-05\n",
      "Epoch 897/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 4.4084e-04 - val_loss: 0.0645 - learning_rate: 3.0000e-05\n",
      "Epoch 898/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.4107e-04 - val_loss: 0.0705 - learning_rate: 3.0000e-05\n",
      "Epoch 899/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.7273e-04 - val_loss: 0.0663 - learning_rate: 3.0000e-05\n",
      "Epoch 900/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.4312e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 901/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 4.3767e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 902/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.5749e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 903/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 4.3127e-04 - val_loss: 0.0664 - learning_rate: 3.0000e-05\n",
      "Epoch 904/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.5500e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 905/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.3766e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 906/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.4265e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 907/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.4295e-04 - val_loss: 0.0704 - learning_rate: 3.0000e-05\n",
      "Epoch 908/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.3904e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 909/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 4.4767e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 910/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.3734e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 911/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.5136e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 912/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.3825e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 913/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.3246e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 914/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.4134e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 915/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 4.3027e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 916/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.2684e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 917/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 4.3823e-04 - val_loss: 0.0702 - learning_rate: 3.0000e-05\n",
      "Epoch 918/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.4729e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 919/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.3423e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 920/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.4358e-04 - val_loss: 0.0647 - learning_rate: 3.0000e-05\n",
      "Epoch 921/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.4105e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 922/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 4.3469e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 923/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 4.4588e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 924/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 4.4089e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 925/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.4924e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 926/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 4.4661e-04 - val_loss: 0.0693 - learning_rate: 3.0000e-05\n",
      "Epoch 927/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.4329e-04 - val_loss: 0.0719 - learning_rate: 3.0000e-05\n",
      "Epoch 928/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 4.3923e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 929/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.4887e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 930/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.3528e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 931/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.3472e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 932/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 4.4145e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 933/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.5340e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 934/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 4.3360e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 935/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.3773e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 936/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 4.3445e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 937/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.4415e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 938/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 4.3561e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 939/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.3772e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 940/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 4.3664e-04 - val_loss: 0.0700 - learning_rate: 3.0000e-05\n",
      "Epoch 941/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.2114e-04 - val_loss: 0.0695 - learning_rate: 3.0000e-05\n",
      "Epoch 942/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 4.3676e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 943/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.3958e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 944/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 4.3520e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 945/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.3912e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 946/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 4.1509e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 947/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.3865e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 948/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 4.4250e-04 - val_loss: 0.0693 - learning_rate: 3.0000e-05\n",
      "Epoch 949/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.2249e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 950/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.2520e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 951/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.3443e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 952/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 4.3843e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 953/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 4.2434e-04 - val_loss: 0.0702 - learning_rate: 3.0000e-05\n",
      "Epoch 954/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.2098e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 955/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 4.2669e-04 - val_loss: 0.0657 - learning_rate: 3.0000e-05\n",
      "Epoch 956/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 4.2359e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 957/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 4.3702e-04 - val_loss: 0.0659 - learning_rate: 3.0000e-05\n",
      "Epoch 958/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.1881e-04 - val_loss: 0.0693 - learning_rate: 3.0000e-05\n",
      "Epoch 959/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 4.1794e-04 - val_loss: 0.0697 - learning_rate: 3.0000e-05\n",
      "Epoch 960/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.3259e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 961/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 4.2111e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 962/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.1446e-04 - val_loss: 0.0695 - learning_rate: 3.0000e-05\n",
      "Epoch 963/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.4454e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 964/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.2519e-04 - val_loss: 0.0693 - learning_rate: 3.0000e-05\n",
      "Epoch 965/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 4.1433e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 966/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.3666e-04 - val_loss: 0.0693 - learning_rate: 3.0000e-05\n",
      "Epoch 967/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.1568e-04 - val_loss: 0.0694 - learning_rate: 3.0000e-05\n",
      "Epoch 968/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.3300e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 969/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 4.3910e-04 - val_loss: 0.0661 - learning_rate: 3.0000e-05\n",
      "Epoch 970/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.1154e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 971/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 4.3688e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 972/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.3198e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 973/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.1800e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 974/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.1632e-04 - val_loss: 0.0697 - learning_rate: 3.0000e-05\n",
      "Epoch 975/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 4.1843e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 976/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.3241e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 977/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.2367e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 978/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.2456e-04 - val_loss: 0.0703 - learning_rate: 3.0000e-05\n",
      "Epoch 979/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 4.1159e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 980/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.1820e-04 - val_loss: 0.0665 - learning_rate: 3.0000e-05\n",
      "Epoch 981/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.2247e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 982/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.2196e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 983/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 4.2363e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 984/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.1577e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 985/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.3105e-04 - val_loss: 0.0700 - learning_rate: 3.0000e-05\n",
      "Epoch 986/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 4.2512e-04 - val_loss: 0.0655 - learning_rate: 3.0000e-05\n",
      "Epoch 987/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 4.2253e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 988/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.2163e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 989/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 4.0931e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 990/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.0411e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 991/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 4.1845e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 992/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.3752e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 993/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 4.5514e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 994/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.3362e-04 - val_loss: 0.0699 - learning_rate: 3.0000e-05\n",
      "Epoch 995/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 4.0151e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 996/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.1027e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 997/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 4.1778e-04 - val_loss: 0.0700 - learning_rate: 3.0000e-05\n",
      "Epoch 998/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.0869e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 999/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.0055e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 1000/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 4.0140e-04 - val_loss: 0.0665 - learning_rate: 3.0000e-05\n",
      "Epoch 1001/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 4.0076e-04 - val_loss: 0.0707 - learning_rate: 3.0000e-05\n",
      "Epoch 1002/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 4.1225e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 1003/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 4.1507e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 1004/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 4.3295e-04 - val_loss: 0.0665 - learning_rate: 3.0000e-05\n",
      "Epoch 1005/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.2785e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1006/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 4.2056e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 1007/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.2025e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 1008/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 4.1957e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 1009/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.1940e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 1010/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.1066e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 1011/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.0595e-04 - val_loss: 0.0701 - learning_rate: 3.0000e-05\n",
      "Epoch 1012/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 4.0754e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 1013/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.1201e-04 - val_loss: 0.0698 - learning_rate: 3.0000e-05\n",
      "Epoch 1014/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 4.0793e-04 - val_loss: 0.0665 - learning_rate: 3.0000e-05\n",
      "Epoch 1015/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.0873e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 1016/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 4.0698e-04 - val_loss: 0.0701 - learning_rate: 3.0000e-05\n",
      "Epoch 1017/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.3046e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 1018/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 4.1646e-04 - val_loss: 0.0698 - learning_rate: 3.0000e-05\n",
      "Epoch 1019/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 4.0050e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 1020/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 4.0345e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 1021/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.0590e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1022/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 4.0631e-04 - val_loss: 0.0665 - learning_rate: 3.0000e-05\n",
      "Epoch 1023/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - loss: 4.2250e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 1024/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 4.1368e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 1025/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.0985e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 1026/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 4.1102e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 1027/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 3.9234e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 1028/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 3.9817e-04 - val_loss: 0.0699 - learning_rate: 3.0000e-05\n",
      "Epoch 1029/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 4.0634e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 1030/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 4.1805e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1031/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.1026e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 1032/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.1010e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 1033/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 4.0411e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 1034/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.0335e-04 - val_loss: 0.0702 - learning_rate: 3.0000e-05\n",
      "Epoch 1035/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 4.0842e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 1036/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.0656e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1037/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.0011e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1038/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 3.9254e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 1039/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 4.0094e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 1040/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 3.9431e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 1041/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.1796e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1042/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 3.9990e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 1043/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.9308e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 1044/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 4.0842e-04 - val_loss: 0.0703 - learning_rate: 3.0000e-05\n",
      "Epoch 1045/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.0144e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1046/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 3.8933e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 1047/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.0532e-04 - val_loss: 0.0697 - learning_rate: 3.0000e-05\n",
      "Epoch 1048/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 3.9905e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1049/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 4.0465e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1050/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 4.0742e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 1051/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.9579e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1052/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 3.8950e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 1053/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.8699e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1054/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 3.9733e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 1055/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.9521e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1056/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 4.0893e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 1057/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 3.7734e-04 - val_loss: 0.0662 - learning_rate: 3.0000e-05\n",
      "Epoch 1058/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 3.9845e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1059/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 4.0517e-04 - val_loss: 0.0698 - learning_rate: 3.0000e-05\n",
      "Epoch 1060/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 3.9111e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 1061/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 4.0849e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1062/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 3.8619e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 1063/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.8815e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 1064/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 3.9417e-04 - val_loss: 0.0656 - learning_rate: 3.0000e-05\n",
      "Epoch 1065/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.8949e-04 - val_loss: 0.0697 - learning_rate: 3.0000e-05\n",
      "Epoch 1066/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 3.8794e-04 - val_loss: 0.0712 - learning_rate: 3.0000e-05\n",
      "Epoch 1067/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.9887e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 1068/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 3.8663e-04 - val_loss: 0.0659 - learning_rate: 3.0000e-05\n",
      "Epoch 1069/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.8498e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 1070/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 3.9209e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 1071/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - loss: 3.8725e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 1072/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 3.9098e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1073/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 3.8573e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 1074/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 3.9827e-04 - val_loss: 0.0711 - learning_rate: 3.0000e-05\n",
      "Epoch 1075/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 3.9461e-04 - val_loss: 0.0693 - learning_rate: 3.0000e-05\n",
      "Epoch 1076/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.8686e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 1077/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 3.9720e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 1078/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.7978e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 1079/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 3.9018e-04 - val_loss: 0.0693 - learning_rate: 3.0000e-05\n",
      "Epoch 1080/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.9337e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 1081/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 3.9344e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 1082/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.8776e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1083/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 3.8741e-04 - val_loss: 0.0693 - learning_rate: 3.0000e-05\n",
      "Epoch 1084/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.8918e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1085/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 3.9828e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 1086/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.9353e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 1087/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 3.9616e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 1088/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.9012e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 1089/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 3.9411e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 1090/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 4.0017e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1091/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 3.8510e-04 - val_loss: 0.0697 - learning_rate: 3.0000e-05\n",
      "Epoch 1092/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.9092e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 1093/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 3.8449e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 1094/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.7505e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 1095/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 3.8230e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 1096/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.7748e-04 - val_loss: 0.0694 - learning_rate: 3.0000e-05\n",
      "Epoch 1097/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 3.7939e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1098/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.7871e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 1099/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 3.9631e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 1100/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.9081e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1101/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 3.7878e-04 - val_loss: 0.0700 - learning_rate: 3.0000e-05\n",
      "Epoch 1102/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.7903e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1103/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 3.8405e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 1104/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.9216e-04 - val_loss: 0.0653 - learning_rate: 3.0000e-05\n",
      "Epoch 1105/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 3.7816e-04 - val_loss: 0.0699 - learning_rate: 3.0000e-05\n",
      "Epoch 1106/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 3.7957e-04 - val_loss: 0.0698 - learning_rate: 3.0000e-05\n",
      "Epoch 1107/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 3.8472e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 1108/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.7674e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 1109/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 3.8115e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 1110/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.8045e-04 - val_loss: 0.0653 - learning_rate: 3.0000e-05\n",
      "Epoch 1111/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 3.8036e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 1112/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.7398e-04 - val_loss: 0.0664 - learning_rate: 3.0000e-05\n",
      "Epoch 1113/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 3.9087e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 1114/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.8117e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1115/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 3.8730e-04 - val_loss: 0.0699 - learning_rate: 3.0000e-05\n",
      "Epoch 1116/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.7962e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 1117/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 3.8110e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1118/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.7639e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 1119/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 3.8015e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 1120/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.8429e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1121/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 3.7488e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 1122/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.8417e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 1123/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 3.9143e-04 - val_loss: 0.0708 - learning_rate: 3.0000e-05\n",
      "Epoch 1124/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.7132e-04 - val_loss: 0.0693 - learning_rate: 3.0000e-05\n",
      "Epoch 1125/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 3.7566e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 1126/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.6334e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1127/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 3.7993e-04 - val_loss: 0.0664 - learning_rate: 3.0000e-05\n",
      "Epoch 1128/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.8657e-04 - val_loss: 0.0695 - learning_rate: 3.0000e-05\n",
      "Epoch 1129/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 3.8997e-04 - val_loss: 0.0694 - learning_rate: 3.0000e-05\n",
      "Epoch 1130/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.8196e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 1131/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - loss: 3.7952e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1132/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 3.8081e-04 - val_loss: 0.0701 - learning_rate: 3.0000e-05\n",
      "Epoch 1133/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.7880e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1134/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 3.7207e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 1135/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.7662e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1136/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 3.7116e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 1137/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.7289e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 1138/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 3.7929e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1139/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.7253e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 1140/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 3.8211e-04 - val_loss: 0.0695 - learning_rate: 3.0000e-05\n",
      "Epoch 1141/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 3.7201e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 1142/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 3.7740e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 1143/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.8244e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 1144/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 3.6801e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 1145/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.6748e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 1146/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 3.6454e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 1147/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.7415e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1148/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 3.7556e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 1149/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.6649e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1150/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 3.6546e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1151/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.7416e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 1152/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 3.7184e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 1153/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.6738e-04 - val_loss: 0.0695 - learning_rate: 3.0000e-05\n",
      "Epoch 1154/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 3.7226e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 1155/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.7302e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1156/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 3.8264e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 1157/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.6428e-04 - val_loss: 0.0694 - learning_rate: 3.0000e-05\n",
      "Epoch 1158/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 3.7034e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1159/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5423e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1160/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 3.5545e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1161/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.7385e-04 - val_loss: 0.0704 - learning_rate: 3.0000e-05\n",
      "Epoch 1162/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 3.7303e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 1163/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.7637e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 1164/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 3.7181e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 1165/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.6731e-04 - val_loss: 0.0699 - learning_rate: 3.0000e-05\n",
      "Epoch 1166/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 3.6558e-04 - val_loss: 0.0662 - learning_rate: 3.0000e-05\n",
      "Epoch 1167/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.4807e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 1168/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 3.7266e-04 - val_loss: 0.0710 - learning_rate: 3.0000e-05\n",
      "Epoch 1169/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.6609e-04 - val_loss: 0.0694 - learning_rate: 3.0000e-05\n",
      "Epoch 1170/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 3.8832e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 1171/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.6413e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 1172/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 3.7648e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 1173/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.6804e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 1174/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 3.6787e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 1175/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.6763e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1176/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 3.6869e-04 - val_loss: 0.0659 - learning_rate: 3.0000e-05\n",
      "Epoch 1177/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.6508e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1178/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 3.6356e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1179/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.6444e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 1180/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 3.4811e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1181/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5907e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 1182/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5471e-04 - val_loss: 0.0657 - learning_rate: 3.0000e-05\n",
      "Epoch 1183/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 3.6382e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1184/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 3.6082e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 1185/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.6517e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 1186/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 3.6302e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 1187/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.6340e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 1188/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 3.6729e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 1189/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5502e-04 - val_loss: 0.0699 - learning_rate: 3.0000e-05\n",
      "Epoch 1190/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 3.6184e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 1191/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5834e-04 - val_loss: 0.0698 - learning_rate: 3.0000e-05\n",
      "Epoch 1192/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 3.7563e-04 - val_loss: 0.0662 - learning_rate: 3.0000e-05\n",
      "Epoch 1193/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.6365e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 1194/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 3.6855e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 1195/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.6899e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 1196/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 3.6963e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 1197/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.5283e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1198/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.6747e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1199/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 3.6080e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1200/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 3.6387e-04 - val_loss: 0.0703 - learning_rate: 3.0000e-05\n",
      "Epoch 1201/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 3.6337e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1202/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.6415e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 1203/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 3.6410e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 1204/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.6054e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 1205/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.6753e-04 - val_loss: 0.0701 - learning_rate: 3.0000e-05\n",
      "Epoch 1206/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 3.5541e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 1207/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 3.5341e-04 - val_loss: 0.0655 - learning_rate: 3.0000e-05\n",
      "Epoch 1208/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5600e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 1209/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 3.6295e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 1210/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5575e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1211/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 3.4357e-04 - val_loss: 0.0697 - learning_rate: 3.0000e-05\n",
      "Epoch 1212/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.6139e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 1213/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 3.5116e-04 - val_loss: 0.0698 - learning_rate: 3.0000e-05\n",
      "Epoch 1214/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5665e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 1215/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 3.5830e-04 - val_loss: 0.0707 - learning_rate: 3.0000e-05\n",
      "Epoch 1216/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.5426e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1217/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.6280e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1218/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 3.4703e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 1219/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.6420e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1220/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - loss: 3.4362e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 1221/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5524e-04 - val_loss: 0.0698 - learning_rate: 3.0000e-05\n",
      "Epoch 1222/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 3.5616e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 1223/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 3.5272e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1224/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 3.5771e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 1225/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.6074e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 1226/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 3.5348e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 1227/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5472e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 1228/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 3.5474e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1229/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.4490e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 1230/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - loss: 3.5853e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 1231/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.4687e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1232/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 3.5478e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 1233/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5147e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 1234/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 3.5643e-04 - val_loss: 0.0693 - learning_rate: 3.0000e-05\n",
      "Epoch 1235/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.6277e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 1236/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 3.4524e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 1237/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.5754e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 1238/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 3.4891e-04 - val_loss: 0.0710 - learning_rate: 3.0000e-05\n",
      "Epoch 1239/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5562e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1240/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 3.5201e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 1241/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.5036e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 1242/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 3.5178e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 1243/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 3.4311e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1244/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.6126e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1245/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 3.6470e-04 - val_loss: 0.0700 - learning_rate: 3.0000e-05\n",
      "Epoch 1246/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5614e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 1247/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5098e-04 - val_loss: 0.0709 - learning_rate: 3.0000e-05\n",
      "Epoch 1248/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 3.4674e-04 - val_loss: 0.0695 - learning_rate: 3.0000e-05\n",
      "Epoch 1249/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 3.4746e-04 - val_loss: 0.0699 - learning_rate: 3.0000e-05\n",
      "Epoch 1250/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 3.5141e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1251/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.5527e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 1252/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 3.5658e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 1253/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 3.4868e-04 - val_loss: 0.0648 - learning_rate: 3.0000e-05\n",
      "Epoch 1254/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.4198e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1255/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 3.4185e-04 - val_loss: 0.0694 - learning_rate: 3.0000e-05\n",
      "Epoch 1256/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.4227e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1257/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - loss: 3.4477e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 1258/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.4583e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 1259/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 3.5570e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 1260/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.4470e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 1261/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 3.6086e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 1262/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5182e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 1263/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 3.4197e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 1264/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5190e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1265/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 3.3806e-04 - val_loss: 0.0700 - learning_rate: 3.0000e-05\n",
      "Epoch 1266/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.3538e-04 - val_loss: 0.0699 - learning_rate: 3.0000e-05\n",
      "Epoch 1267/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 3.2505e-04 - val_loss: 0.0666 - learning_rate: 3.0000e-05\n",
      "Epoch 1268/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.4689e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1269/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 3.4830e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 1270/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.3748e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 1271/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - loss: 3.6087e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1272/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5832e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 1273/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 3.4338e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 1274/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5045e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 1275/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - loss: 3.5369e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 1276/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.5359e-04 - val_loss: 0.0663 - learning_rate: 3.0000e-05\n",
      "Epoch 1277/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 3.4055e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 1278/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.3253e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1279/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 3.3746e-04 - val_loss: 0.0716 - learning_rate: 3.0000e-05\n",
      "Epoch 1280/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.2145e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 1281/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 3.5072e-04 - val_loss: 0.0700 - learning_rate: 3.0000e-05\n",
      "Epoch 1282/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.4128e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1283/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 3.4670e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 1284/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.3500e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 1285/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 3.3851e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 1286/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.3635e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 1287/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 3.4990e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1288/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.4739e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 1289/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 3.3489e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 1290/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.3920e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 1291/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - loss: 3.2900e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1292/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.2883e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1293/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 3.3373e-04 - val_loss: 0.0705 - learning_rate: 3.0000e-05\n",
      "Epoch 1294/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.3420e-04 - val_loss: 0.0667 - learning_rate: 3.0000e-05\n",
      "Epoch 1295/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 3.3874e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 1296/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.3566e-04 - val_loss: 0.0704 - learning_rate: 3.0000e-05\n",
      "Epoch 1297/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 3.4141e-04 - val_loss: 0.0701 - learning_rate: 3.0000e-05\n",
      "Epoch 1298/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 3.4580e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1299/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.2806e-04 - val_loss: 0.0697 - learning_rate: 3.0000e-05\n",
      "Epoch 1300/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - loss: 3.4113e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1301/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.3358e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 1302/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 3.3188e-04 - val_loss: 0.0699 - learning_rate: 3.0000e-05\n",
      "Epoch 1303/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.3837e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1304/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - loss: 3.6487e-04 - val_loss: 0.0686 - learning_rate: 3.0000e-05\n",
      "Epoch 1305/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.4409e-04 - val_loss: 0.0693 - learning_rate: 3.0000e-05\n",
      "Epoch 1306/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 3.4417e-04 - val_loss: 0.0697 - learning_rate: 3.0000e-05\n",
      "Epoch 1307/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.3247e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1308/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 3.4704e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 1309/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.2372e-04 - val_loss: 0.0669 - learning_rate: 3.0000e-05\n",
      "Epoch 1310/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 3.2597e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 1311/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.2842e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1312/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - loss: 3.3915e-04 - val_loss: 0.0709 - learning_rate: 3.0000e-05\n",
      "Epoch 1313/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.3021e-04 - val_loss: 0.0663 - learning_rate: 3.0000e-05\n",
      "Epoch 1314/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - loss: 3.3894e-04 - val_loss: 0.0700 - learning_rate: 3.0000e-05\n",
      "Epoch 1315/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.4164e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 1316/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 3.3381e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1317/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.3822e-04 - val_loss: 0.0697 - learning_rate: 3.0000e-05\n",
      "Epoch 1318/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 3.3072e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1319/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.2492e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1320/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 3.3608e-04 - val_loss: 0.0691 - learning_rate: 3.0000e-05\n",
      "Epoch 1321/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.2603e-04 - val_loss: 0.0702 - learning_rate: 3.0000e-05\n",
      "Epoch 1322/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 3.3567e-04 - val_loss: 0.0695 - learning_rate: 3.0000e-05\n",
      "Epoch 1323/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.4565e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1324/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 3.2158e-04 - val_loss: 0.0682 - learning_rate: 3.0000e-05\n",
      "Epoch 1325/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.3488e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1326/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 3.2244e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 1327/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.1564e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 1328/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 3.2581e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 1329/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.2220e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1330/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 3.3586e-04 - val_loss: 0.0676 - learning_rate: 3.0000e-05\n",
      "Epoch 1331/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.2398e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1332/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 3.2524e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 1333/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.2292e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 1334/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 3.3734e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 1335/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.3453e-04 - val_loss: 0.0707 - learning_rate: 3.0000e-05\n",
      "Epoch 1336/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 3.4589e-04 - val_loss: 0.0678 - learning_rate: 3.0000e-05\n",
      "Epoch 1337/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.3980e-04 - val_loss: 0.0675 - learning_rate: 3.0000e-05\n",
      "Epoch 1338/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 3.2949e-04 - val_loss: 0.0699 - learning_rate: 3.0000e-05\n",
      "Epoch 1339/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.2433e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 1340/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 3.3497e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1341/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.2523e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1342/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 3.3061e-04 - val_loss: 0.0704 - learning_rate: 3.0000e-05\n",
      "Epoch 1343/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 3.2306e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 1344/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.2495e-04 - val_loss: 0.0663 - learning_rate: 3.0000e-05\n",
      "Epoch 1345/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 3.3318e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 1346/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.2913e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 1347/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 3.3013e-04 - val_loss: 0.0658 - learning_rate: 3.0000e-05\n",
      "Epoch 1348/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.3576e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1349/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 3.2790e-04 - val_loss: 0.0694 - learning_rate: 3.0000e-05\n",
      "Epoch 1350/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.2770e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 1351/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 3.3445e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 1352/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.3682e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 1353/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 3.2989e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 1354/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.4441e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 1355/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 3.3175e-04 - val_loss: 0.0702 - learning_rate: 3.0000e-05\n",
      "Epoch 1356/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 3.3240e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1357/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.2124e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 1358/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 3.2663e-04 - val_loss: 0.0674 - learning_rate: 3.0000e-05\n",
      "Epoch 1359/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.1882e-04 - val_loss: 0.0694 - learning_rate: 3.0000e-05\n",
      "Epoch 1360/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 3.1618e-04 - val_loss: 0.0684 - learning_rate: 3.0000e-05\n",
      "Epoch 1361/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.2780e-04 - val_loss: 0.0700 - learning_rate: 3.0000e-05\n",
      "Epoch 1362/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 3.2711e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 1363/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 3.2687e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n",
      "Epoch 1364/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 3.2195e-04 - val_loss: 0.0697 - learning_rate: 3.0000e-05\n",
      "Epoch 1365/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.2111e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1366/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 3.2693e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 1367/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 3.3264e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 18:11:34.382113: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.3409e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 1368/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 3.1886e-04 - val_loss: 0.0668 - learning_rate: 3.0000e-05\n",
      "Epoch 1369/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.1171e-04 - val_loss: 0.0681 - learning_rate: 3.0000e-05\n",
      "Epoch 1370/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 3.3188e-04 - val_loss: 0.0695 - learning_rate: 3.0000e-05\n",
      "Epoch 1371/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.2590e-04 - val_loss: 0.0693 - learning_rate: 3.0000e-05\n",
      "Epoch 1372/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 3.2258e-04 - val_loss: 0.0693 - learning_rate: 3.0000e-05\n",
      "Epoch 1373/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.1916e-04 - val_loss: 0.0664 - learning_rate: 3.0000e-05\n",
      "Epoch 1374/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 3.1447e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 1375/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 3.0835e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 1376/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.1840e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1377/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 3.0419e-04 - val_loss: 0.0697 - learning_rate: 3.0000e-05\n",
      "Epoch 1378/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.2220e-04 - val_loss: 0.0671 - learning_rate: 3.0000e-05\n",
      "Epoch 1379/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - loss: 3.2735e-04 - val_loss: 0.0688 - learning_rate: 3.0000e-05\n",
      "Epoch 1380/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.1957e-04 - val_loss: 0.0694 - learning_rate: 3.0000e-05\n",
      "Epoch 1381/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 3.1244e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 1382/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.2194e-04 - val_loss: 0.0673 - learning_rate: 3.0000e-05\n",
      "Epoch 1383/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 3.1043e-04 - val_loss: 0.0685 - learning_rate: 3.0000e-05\n",
      "Epoch 1384/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.1116e-04 - val_loss: 0.0690 - learning_rate: 3.0000e-05\n",
      "Epoch 1385/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 3.1464e-04 - val_loss: 0.0680 - learning_rate: 3.0000e-05\n",
      "Epoch 1386/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.2045e-04 - val_loss: 0.0689 - learning_rate: 3.0000e-05\n",
      "Epoch 1387/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 3.1433e-04 - val_loss: 0.0696 - learning_rate: 3.0000e-05\n",
      "Epoch 1388/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 3.1330e-04 - val_loss: 0.0672 - learning_rate: 3.0000e-05\n",
      "Epoch 1389/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 3.1507e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 1390/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 3.1731e-04 - val_loss: 0.0699 - learning_rate: 3.0000e-05\n",
      "Epoch 1391/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 3.1813e-04 - val_loss: 0.0698 - learning_rate: 3.0000e-05\n",
      "Epoch 1392/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 3.1387e-04 - val_loss: 0.0687 - learning_rate: 3.0000e-05\n",
      "Epoch 1393/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.2249e-04 - val_loss: 0.0706 - learning_rate: 3.0000e-05\n",
      "Epoch 1394/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - loss: 3.1366e-04 - val_loss: 0.0679 - learning_rate: 3.0000e-05\n",
      "Epoch 1395/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 3.1857e-04 - val_loss: 0.0692 - learning_rate: 3.0000e-05\n",
      "Epoch 1396/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - loss: 3.2416e-04 - val_loss: 0.0706 - learning_rate: 3.0000e-05\n",
      "Epoch 1397/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 3.2139e-04 - val_loss: 0.0670 - learning_rate: 3.0000e-05\n",
      "Epoch 1398/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 3.2961e-04 - val_loss: 0.0683 - learning_rate: 3.0000e-05\n",
      "Epoch 1399/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 3.1483e-04 - val_loss: 0.0695 - learning_rate: 3.0000e-05\n",
      "Epoch 1400/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 3.1258e-04 - val_loss: 0.0677 - learning_rate: 3.0000e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with the custom callback\n",
    "history = model_builder.train_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    epochs=1400,\n",
    "    callbacks_list=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the losses from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "train_loss_x_midpoints = history.history.get('x_midpoints_reshape_loss', train_loss)\n",
    "val_loss_x_midpoints = history.history.get('val_x_midpoints_reshape_loss', val_loss)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2,1)\n",
    "plt.plot(train_loss_x_midpoints, label='Train Loss x_midpoints_reshape')\n",
    "plt.plot(val_loss_x_midpoints, label='Validation Loss x_midpoints_reshape')\n",
    "plt.xlabel('Epochs')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_builder.model.save(\"/home/da886/Analysis/12KFixed_13_SparsespotsrandomSPOTSoverfit.keras\")\n",
    "# loaded_model = tf.keras.models.load_model(\n",
    "# \"/home/da886/Analysis/30KFixed_13_SparsespotsrandomSPOTS.keras\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, batch shape: (800, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728670619.016412  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.017347  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.017696  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.018022  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.018308  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.018574  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.018615  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.019080  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.019102  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.019405  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.019795  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.019905  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.020076  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.020598  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.020606  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.020743  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.021170  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.021319  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.021473  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.021653  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.021892  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.022085  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.022280  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.022514  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.022740  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.022864  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.023267  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.023482  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.023501  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.023883  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.024233  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.024289  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.024442  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.024854  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.025089  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.025329  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.025625  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.025814  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.025955  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.026371  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.026397  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.027038  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.027121  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.027145  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.027706  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.027882  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.027901  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.028616  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.028656  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.028744  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.029494  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.029537  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.030182  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.030198  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.031182  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.031199  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.031811  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.031935  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.032745  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.032843  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.045803  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.046196  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.046492  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.046786  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.047075  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.047364  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.047662  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.047987  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.048287  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.048595  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.048900  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.049227  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.049494  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.049540  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.049956  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.049975  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.050307  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.050404  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.050583  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.051062  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.051114  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.051233  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.051712  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.051764  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.051850  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.052408  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.052465  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.052547  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.053119  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.053175  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.053253  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.053731  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.053783  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.053853  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.054354  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.054409  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.054501  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.054892  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.055020  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.055152  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.055544  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.055574  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.056215  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.056288  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.056306  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.056883  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.056986  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.057334  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.057579  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.057702  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.058192  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.058194  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.058318  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.058779  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.058910  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.058968  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.059234  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.059540  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.059687  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.060053  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.060173  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.060572  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.060697  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.061080  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.061200  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.061594  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.061724  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.062192  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.062458  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.062635  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.063085  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.063284  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.063860  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.063943  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.064408  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.064604  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.065018  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.065434  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.074112  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.074412  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.074690  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.074957  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.075221  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.075503  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.075764  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.076014  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.076263  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.076533  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.076795  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.077055  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.077534  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.078001  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.078393  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.078795  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.079282  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.079749  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.080253  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.080618  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.081006  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.081335  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.081647  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.081891  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.081957  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.082485  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.082488  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.082962  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.083085  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.083322  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.083569  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.083798  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.084017  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.084250  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.084456  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.084689  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.084896  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.085123  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.085306  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.085771  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.085940  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.085994  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.086279  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.086360  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.086879  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.086909  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.086968  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.087467  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.087654  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.087677  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.087962  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.088191  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.088487  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.088689  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.088910  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.088988  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.089484  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.089589  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.089692  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.089896  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.090111  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.090239  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.090464  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.090767  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.090787  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.091251  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.091255  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.091542  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.091995  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.092000  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.092313  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.092587  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.092689  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.092990  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.093294  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.093648  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.093975  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.094369  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.094741  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.095309  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.096966  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.097224  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.097486  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.097737  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.098002  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.098271  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.098544  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.099042  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.099050  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.099538  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.099547  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.099952  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.100052  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.100343  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.100542  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.100672  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.100895  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.101184  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.101303  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.101599  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.101765  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.101824  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.101973  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.102295  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.102465  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.102498  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.102779  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.103067  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.103081  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.103319  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.103564  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.103565  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.103687  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.104200  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.104233  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.104312  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.104610  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.104745  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.104859  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.105133  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.105387  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.105399  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.105557  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.105856  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.106085  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.106104  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.106229  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.106664  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.106672  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.106685  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.107094  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.107187  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.107305  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.107587  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.107667  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.107955  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.108416  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.108521  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.108963  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.109035  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.109483  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.109556  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.109833  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.110244  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.110322  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.110690  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.111153  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.111600  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.112383  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.113658  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.113705  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.113981  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.114350  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.114433  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.114741  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.114981  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.115080  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.115385  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.115782  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.115856  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.116066  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.116383  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.116604  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.116689  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.117184  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.117186  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.117596  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.117693  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.118000  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.118411  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.118509  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.118731  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.119184  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.119268  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.119484  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.119804  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.120109  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.120493  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.120609  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.120804  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.121201  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.121647  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.121891  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.122234  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.122612  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.123405  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.123509  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.124086  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.124772  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.125489  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.126188  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.131187  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.131533  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.131844  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.132168  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.132472  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.132808  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.133116  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.133442  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.133746  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.134074  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.134384  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.134728  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.135557  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.135633  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.135919  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.136230  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.136420  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.136589  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.136880  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.137279  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.137358  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.137574  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.137871  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.138208  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.138496  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.138591  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.138982  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.139074  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.139094  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.139404  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.139502  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.139827  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.139925  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.140238  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.140469  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.140754  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.140841  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.140957  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.141274  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.141388  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.141769  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.141863  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.141960  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.142310  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.142418  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.142715  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.142893  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.142992  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.143227  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.143769  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.143782  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.144090  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.144535  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.144640  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.144889  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.145456  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.145465  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.145832  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.146203  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.146728  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.147288  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.148069  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.148675  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.152135  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.152498  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.152823  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.153134  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.153451  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.153789  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.154102  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.154423  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.154743  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.155053  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.155302  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.155383  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.155906  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.155910  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.156250  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.156667  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.156771  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.156991  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.157329  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.157790  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.157873  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.158124  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.158445  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.158861  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.158966  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.159211  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.159562  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.159892  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.160357  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.161380  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.161489  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.162526  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.162620  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.163536  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.163654  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.163968  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.164403  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.164484  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.164707  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.165145  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.165224  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.165474  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.165799  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.166236  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.166260  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.166618  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.166967  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.167308  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.167667  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.168063  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.168173  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.168588  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.168999  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.169436  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.169865  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.170588  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.171340  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.172575  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.173368  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.180569  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.180993  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.181374  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.181767  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.182123  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.182525  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.182906  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.183281  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.183670  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.184073  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.184491  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.184920  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.185341  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.185820  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.186346  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.186884  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.187461  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.187815  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.188120  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.188307  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.188785  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.188878  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.189129  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.189457  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.189795  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.190165  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.190377  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.190553  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.190916  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.191455  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.191454  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.192051  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.192058  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.192595  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.192705  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.192817  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.193013  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.193301  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.193404  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.193973  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.194006  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.194214  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.194599  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.194610  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.195189  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.195196  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.195790  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.195799  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.196400  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.196410  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.196770  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.197294  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.197385  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.197746  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.198392  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.198429  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.198879  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.199286  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.199809  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.199892  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.200281  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.200893  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.201072  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.201922  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.203251  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.203301  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.203739  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.204322  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.204407  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.204769  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.205294  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.205784  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.206317  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.206955  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.207439  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.207918  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.208455  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.208954  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.209601  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.210031  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.210422  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.210925  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.210939  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.211304  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.211735  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.212110  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.212144  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.212596  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.212690  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.213115  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.213292  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.213310  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.213642  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.213744  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.214300  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.214312  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.214963  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.214969  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.215414  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.215587  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.215799  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.216405  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.216419  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.216817  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.217235  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.217649  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.218012  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.218128  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.218930  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.219711  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.220220  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.220584  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.221312  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.222181  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.222460  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.222801  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.223784  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.225393  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.225491  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.227002  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.227113  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.228058  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.229574  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.273446  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.273849  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.274241  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.274627  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.275020  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.275430  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.275895  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.276107  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.276320  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.276535  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.276877  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.276981  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.277575  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.277585  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.278226  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.278237  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.278782  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.278864  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.279312  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.279415  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.279728  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.280091  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.280193  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.280795  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.280805  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.281373  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.281473  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.281828  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.282099  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.282317  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.282797  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.282982  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.283545  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.284149  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.284334  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.284776  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.285440  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.286474  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.286905  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.288140  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.289063  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.290729  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.297676  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.298228  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.298721  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.299203  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.299798  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.300284  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.300336  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.300958  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.301078  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.301754  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.301766  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.302390  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.302485  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.303054  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.303159  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.303858  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.303867  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.304649  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.304657  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.305203  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.305689  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.306228  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.306790  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.307082  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.307342  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.309036  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.309649  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.309988  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.310018  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.310206  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.310675  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.311166  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.311669  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.312166  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.312697  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.312890  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.312971  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.313514  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.314121  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.314701  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.314976  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.315353  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.315513  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.315959  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.316743  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.317407  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.317573  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.317809  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.318401  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.319289  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.319844  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.320354  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.320436  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.322813  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.324799  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.327821  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.328508  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.330724  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.340617  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.341035  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.341435  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.341871  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.342298  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.342771  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.343256  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.344546  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.345860  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.347174  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.349458  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.351127  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.353399  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.355296  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.394939  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.395322  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.395705  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.396097  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.396486  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.396874  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.397270  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.397674  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.398070  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.398447  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.398836  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.399255  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.399663  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.400078  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.400550  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.401039  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.401591  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.402094  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.402631  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.403296  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.403905  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.405606  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.407256  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.415498  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.415886  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.416090  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.416270  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.416676  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.416696  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.416988  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.417396  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.417576  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.418111  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.418122  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.418828  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.418852  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 2s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728670619.419639  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.419701  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.419722  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.420098  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.420368  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.420498  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.420667  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.421019  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.421136  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.421377  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.421685  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.421791  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.422139  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.422435  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.422535  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.422858  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.423149  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.423255  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.423608  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.423899  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.424002  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.424486  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.424797  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.424930  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.425126  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.425873  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.425969  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.426294  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.426523  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.426833  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.427233  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.427818  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.428086  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.429127  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.429140  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.429985  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.430958  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.431553  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.432025  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.434447  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.435451  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.435619  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.435930  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.436225  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.436540  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.436860  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.437167  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.437483  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.437780  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.438081  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.438377  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.438543  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.438919  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.439320  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.439645  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.440024  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.440351  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.440681  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.441104  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.441509  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.441988  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.442480  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.443107  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.444255  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.449421  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.449857  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.450245  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.450670  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.450774  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.451243  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.451356  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.451844  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.451854  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.452293  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.452394  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.452449  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.452634  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.452963  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.453076  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.453499  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.453601  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.453864  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.454082  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.454159  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.454639  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.454723  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.455123  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.455406  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.455616  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.455836  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.457034  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.457101  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.457215  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.458260  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.458864  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.458876  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.460592  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.460759  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.461461  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.462078  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.463341  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.464229  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.464678  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.464999  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.465759  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.466555  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.468209  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.468915  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.472176  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.472532  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.472891  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.473281  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.473591  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.473932  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.474276  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.474628  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.474989  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.475629  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.476008  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.476431  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.476864  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.477424  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.477995  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.478585  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.479314  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.479983  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.480699  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.481592  207309 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.510704  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.511093  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.511472  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.511871  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.512260  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.512641  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.513053  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.513453  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.513880  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.514139  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.514330  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.514576  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.514786  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.514982  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.515336  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.515440  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.516043  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.516055  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.516598  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.516681  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.517125  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.517228  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.517544  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.517873  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.517980  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.518628  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.518636  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.519174  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.519277  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.519616  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.519846  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.520076  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.520766  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.520779  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.521261  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.521491  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.521797  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.522365  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.522906  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.523226  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.523470  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.524130  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.525082  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.525098  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.526795  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.528454  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.533853  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.534201  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.534528  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.534871  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.535312  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.535681  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.536147  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.536548  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.537016  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.537271  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.537774  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.537867  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.538117  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.538572  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.538733  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.539050  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.539532  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.539688  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.540022  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.540536  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.540632  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.541027  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.541860  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.541942  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.542563  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.543543  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.543644  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.544398  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.545529  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.547012  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.555809  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.556130  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.556429  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.556741  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.557066  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.557373  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.557684  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.557980  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.558276  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.558639  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.559035  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.559234  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.559562  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.559673  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.560146  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.560157  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.560708  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.560718  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.561284  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.561290  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.561827  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.561837  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.562258  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.562363  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.562575  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.563027  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.563038  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.563516  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.563616  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.563908  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.564245  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.564351  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.564710  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.564904  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.565110  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.565432  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.565767  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.566176  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.566276  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.566683  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.567185  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.567684  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.568313  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.569444  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.572676  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.573027  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.573345  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.573657  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.573981  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.574319  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.574655  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.574990  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.575442  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.575944  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.576611  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.576782  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.577127  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.577634  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.578391  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.578414  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.578948  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.579491  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.579855  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.580029  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.580591  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.581863  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.582523  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.583171  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.584442  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.586234  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.587107  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.587998  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.590777  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.591320  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.592510  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.594611  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.594962  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.595331  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.595945  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.595952  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.596270  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.596610  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.596956  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.597312  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.597680  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.598311  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.598690  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.599221  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.599328  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.599883  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.599898  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.600271  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.600457  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.600682  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.601144  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.601227  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.601496  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.602057  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.602065  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.602417  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.602906  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.603001  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.603675  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.603773  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.604068  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.604724  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.604736  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.605165  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.605669  207298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.605838  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.606405  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.607002  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.607744  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.608422  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.609130  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728670619.610026  207292 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Processing batch 2, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 3, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step \n",
      "Processing batch 4, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "Processing batch 5, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 6, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 7, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 8, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 9, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 10, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 11, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 12, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the function for visualizing midpoints\n",
    "def visualize_midpoints(image, midpoints, title=\"Predicted Midpoint Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualizes midpoints on an image without using a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "    - title: The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    midpoints_np = midpoints\n",
    "\n",
    "    # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot midpoints directly, only if they are not (0, 0)\n",
    "    for i, (x, y) in enumerate(midpoints_np):\n",
    "        if x >= 0 and y >= 0:  # Only plot if the point is not (0, 0)\n",
    "            plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create the validation dataset\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n",
    "# val_dataset = val_dataset.batch(800)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)\n",
    "# # Initialize lists to collect the data\n",
    "all_images = []\n",
    "all_true_midpoints = []\n",
    "all_pred_midpoints = []\n",
    "\n",
    "# # Loop through each batch in the validation dataset, predict, and collect results\n",
    "# for i, (data_batch, midpoints_batch) in enumerate(val_dataset):\n",
    "\n",
    "for i, (data_batch, midpoints_batch) in enumerate(train_dataset):\n",
    "    print(f\"Processing batch {i + 1}, batch shape: {data_batch.shape}\")\n",
    "    \n",
    "    # Get the model predictions\n",
    "    predictions =model_builder.model.predict(data_batch)\n",
    "\n",
    "    # Extend the lists to store data from each batch\n",
    "    all_images.extend(data_batch.numpy())  # Store all images\n",
    "    all_true_midpoints.extend(midpoints_batch.numpy())  # Store all true midpoints\n",
    "    all_pred_midpoints.extend(predictions)  # Store all predicted midpoints\n",
    "\n",
    "# Convert lists to arrays for easier indexing\n",
    "all_images = np.array(all_images)\n",
    "all_true_midpoints = np.array(all_true_midpoints)\n",
    "all_pred_midpoints = np.array(all_pred_midpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9600, 64, 64), (9600, 1, 13, 2), (9600, 1, 13, 2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape,all_pred_midpoints.shape,all_true_midpoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select an index to visualize from the entire dataset\n",
    "index_to_visualize = np.random.randint(0, len(all_images))\n",
    "\n",
    "# index_to_visualize = 11548\n",
    "# Visualize the selected image with predicted and true midpoints\n",
    "visualize_midpoints(all_images[index_to_visualize], all_pred_midpoints[index_to_visualize, 0, :, :] * np.max(centers), title=\"Predicted Midpoints\")\n",
    "visualize_midpoints(all_images[index_to_visualize], all_true_midpoints[index_to_visualize, 0, :, :] * np.max(centers), title=\"Ground Truth Midpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.009317, 67.174446)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_pred_midpoints)*np.max(centers),np.max(all_pred_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 63.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_true_midpoints)*np.max(centers),np.max(all_true_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 63.0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_images), np.max(train_images), np.min(train_midpoints)*np.max(centers), np.max(train_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[17.562103 ,  1.2478412],\n",
       "         [ 3.2080665,  4.5532303],\n",
       "         [26.095625 , 25.599243 ],\n",
       "         [29.099148 , 30.337223 ],\n",
       "         [35.85275  , 34.472622 ],\n",
       "         [12.965058 , 38.609756 ],\n",
       "         [57.1551   , 41.10317  ],\n",
       "         [44.44326  , 44.55042  ],\n",
       "         [20.582745 , 50.31373  ],\n",
       "         [47.863594 , 55.27526  ],\n",
       "         [56.22484  , 58.052418 ],\n",
       "         [ 8.230308 , 60.271122 ],\n",
       "         [ 4.082509 , 61.400772 ]]], dtype=float32),\n",
       " array([[[16.,  1.],\n",
       "         [ 3.,  5.],\n",
       "         [25., 27.],\n",
       "         [30., 28.],\n",
       "         [35., 35.],\n",
       "         [12., 36.],\n",
       "         [56., 42.],\n",
       "         [44., 45.],\n",
       "         [21., 56.],\n",
       "         [48., 56.],\n",
       "         [56., 59.],\n",
       "         [ 8., 60.],\n",
       "         [ 5., 62.]]], dtype=float32))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred_midpoints[2]*64,all_true_midpoints[2]*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1., 29., 34.],\n",
       "        [ 1.,  6., 20.],\n",
       "        [ 1., 12., 25.],\n",
       "        ...,\n",
       "        [ 1., 48., 63.],\n",
       "        [ 1., 56., 58.],\n",
       "        [ 1., 44.,  9.]],\n",
       "\n",
       "       [[ 1., 46., 53.],\n",
       "        [ 1., 32.,  3.],\n",
       "        [ 1., 31., 15.],\n",
       "        ...,\n",
       "        [ 1., 27.,  8.],\n",
       "        [ 1., 32., 28.],\n",
       "        [ 1.,  3., 33.]],\n",
       "\n",
       "       [[ 1., 18., 14.],\n",
       "        [ 1., 37., 20.],\n",
       "        [ 1., 29., 12.],\n",
       "        ...,\n",
       "        [ 1.,  2., 33.],\n",
       "        [ 1., 38., 36.],\n",
       "        [ 1., 51., 44.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1., 38.,  8.],\n",
       "        [ 1., 26., 51.],\n",
       "        [ 1., 19., 29.],\n",
       "        ...,\n",
       "        [ 1.,  2., 40.],\n",
       "        [ 1., 34., 30.],\n",
       "        [ 1., 27., 21.]],\n",
       "\n",
       "       [[ 1., 60., 34.],\n",
       "        [ 1., 16.,  4.],\n",
       "        [ 1., 25., 54.],\n",
       "        ...,\n",
       "        [ 1., 46., 15.],\n",
       "        [ 1., 36., 50.],\n",
       "        [ 1., 24., 12.]],\n",
       "\n",
       "       [[ 1., 36., 21.],\n",
       "        [ 1., 42.,  1.],\n",
       "        [ 1., 42., 52.],\n",
       "        ...,\n",
       "        [ 1., 25., 33.],\n",
       "        [ 1., 52.,  7.],\n",
       "        [ 1., 28., 25.]]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[2],)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables to track the min and max MSE\n",
    "min_mse = float('inf')\n",
    "max_mse = float('-inf')\n",
    "min_mse_index = -1\n",
    "max_mse_index = -1\n",
    "\n",
    "# Loop through each prediction to calculate the MSE\n",
    "for i in range(len(all_pred_midpoints)):\n",
    "    mse = np.mean((all_pred_midpoints[i] - all_true_midpoints[i]) **2)\n",
    "    \n",
    "    if mse < min_mse:\n",
    "        min_mse = mse\n",
    "        min_mse_index = i\n",
    "    \n",
    "    if mse > max_mse:\n",
    "        max_mse = mse\n",
    "        max_mse_index = i\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot an image with its centers\n",
    "def plot_image_with_centers(image, true_center, predicted_center, title):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  # Display the image\n",
    "\n",
    "    # Plot the actual center (Groundtruth)\n",
    "    plt.scatter(true_center[:, 0], true_center[:, 1], color='green', label='Groundtruth', s=10)\n",
    "\n",
    "    # Plot the predicted center\n",
    "    plt.scatter(predicted_center[:, 0], predicted_center[:, 1], color='red', label='Predictions', s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the image with the least MSE\n",
    "plot_image_with_centers(all_images[min_mse_index],\n",
    "                        all_true_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Least MSE. MSE: {min_mse:.4f}')\n",
    "\n",
    "# Plotting the image with the largest MSE\n",
    "plot_image_with_centers(all_images[max_mse_index],\n",
    "                        all_true_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Largest MSE. MSE: {max_mse:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5266"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mse_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
