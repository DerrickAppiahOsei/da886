{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Set CUDA device order and visible devices\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7,8,9\"\n",
    "\n",
    "# # Set the device\n",
    "# device = '/cpu:0'\n",
    "# if tf.config.experimental.list_physical_devices('GPU'):\n",
    "#     try:\n",
    "#         # Restrict TensorFlow to only use the second GPU\n",
    "#         gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#         if gpus:\n",
    "#             tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "#             device = '/gpu:0'\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "\n",
    "# print(\"device\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 21:40:59.526431: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-08 21:40:59.541909: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-08 21:40:59.555530: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-08 21:40:59.559636: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-08 21:40:59.572650: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-08 21:41:00.210539: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 21:41:01.937386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79196 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:45:00.0, compute capability: 8.0\n",
      "2024-10-08 21:41:01.939537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79196 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:46:00.0, compute capability: 8.0\n",
      "2024-10-08 21:41:01.941430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79194 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:49:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # Only GPUs 0 and 1 will be visible to TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\",\"/gpu:2\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# DataLoader Class Definition\n",
    "# -----------------------------\n",
    "class DataLoader:\n",
    "    def __init__(self, h5_filename):\n",
    "        self.h5_filename = h5_filename\n",
    "        self.images, self.centers = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with h5py.File(self.h5_filename, 'r') as f:\n",
    "            images = np.array(f['images'])\n",
    "            centers = np.array(f['centers_training'])\n",
    "        return images, centers\n",
    "\n",
    "    def plot_image_with_centers(self, image_index=None):\n",
    "        if image_index is None:\n",
    "            image_index = np.random.randint(0, len(self.images))\n",
    "\n",
    "        image = self.images[image_index]\n",
    "        centers = self.centers[image_index]\n",
    "\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        valid_centers = centers[centers[:, 0] == 1]\n",
    "        for center in valid_centers:\n",
    "            plt.scatter(center[1], center[2], c='red', marker='x')  # center[1] is x and center[2] is y\n",
    "        plt.title('Image with Valid Centers Marked')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_centers(centers):\n",
    "        return centers[np.lexsort((centers[:, 0], centers[:, 1]))]\n",
    "\n",
    "    def normalize_data(self):\n",
    "        normalized_images = self.images / np.max(self.images)\n",
    "        sorted_centers = np.array([self.sort_centers(image_centers[:, 1:]) for image_centers in self.centers])\n",
    "        normalized_centers = sorted_centers / 64\n",
    "\n",
    "        normalized_midpoints = tf.expand_dims(normalized_centers, axis=1)\n",
    "        return normalized_images, normalized_midpoints.numpy()\n",
    "\n",
    "    def split_data(self, train_size=0.8, random_state=42):\n",
    "        normalized_images, normalized_midpoints_np = self.normalize_data()\n",
    "        return train_test_split(normalized_images, normalized_midpoints_np, train_size=train_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Utility Function Definition\n",
    "# -----------------------------\n",
    "def plot_transposed_images_with_midpoints(dataset, image_indices=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Extracts multiple images and their midpoints from the given dataset, transposes the images, \n",
    "    corrects the midpoints, and plots the transposed images with the corrected midpoints.\n",
    "\n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The dataset from which to extract the images and midpoints.\n",
    "    - image_indices (list): The indices of the images in the batch to visualize. Default is [0, 1, 2, 3].\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract a sample image batch and its corresponding midpoints from the dataset\n",
    "    sample_image_batch, sample_midpoints_batch = next(iter(dataset))\n",
    "\n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(image_indices):\n",
    "            # Select the specified image and corresponding midpoints from the batch\n",
    "            sample_image = np.array(sample_image_batch[image_indices[i]])\n",
    "            sample_midpoints = np.array(sample_midpoints_batch[image_indices[i]])\n",
    "\n",
    "            # Transpose the image\n",
    "            transposed_image = sample_image.T\n",
    "\n",
    "            # Correct the midpoints by swapping the x and y coordinates\n",
    "            transposed_midpoints_corrected = sample_midpoints[:, :, [1, 0]]\n",
    "\n",
    "            # Plot the transposed image with corrected midpoints\n",
    "            ax.imshow(transposed_image, cmap='gray')\n",
    "            ax.scatter(\n",
    "                transposed_midpoints_corrected[:, :, 0] * 64, \n",
    "                transposed_midpoints_corrected[:, :, 1] * 64, \n",
    "                c='red', marker='o', s=5\n",
    "            )\n",
    "            ax.set_title(f'Image {image_indices[i]} for this batch')\n",
    "        else:\n",
    "            ax.axis('off')  # If fewer than 4 images are requested, hide the unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Loss and Callback Definitions\n",
    "# -----------------------------\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(exponent):\n",
    "    def loss(y_true, y_pred):\n",
    "        diff = tf.abs(y_true - y_pred)\n",
    "        powered_diff = tf.pow(diff, exponent)\n",
    "        return tf.reduce_mean(powered_diff)\n",
    "    return loss\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DynamicExponentCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_exponent, increment, update_frequency):\n",
    "        super().__init__()\n",
    "        self.exponent = initial_exponent\n",
    "        self.increment = increment\n",
    "        self.update_frequency = update_frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.update_frequency == 0:\n",
    "            self.exponent += self.increment\n",
    "            print(f\"\\nEpoch {epoch + 1}: Increasing exponent to {self.exponent}\")\n",
    "            self.model.loss = self.custom_loss(self.exponent)\n",
    "\n",
    "    def custom_loss(self, exponent):\n",
    "        def loss(y_true, y_pred):\n",
    "            diff = tf.abs(y_true - y_pred)\n",
    "            powered_diff = tf.pow(diff, exponent)\n",
    "            return tf.reduce_mean(powered_diff)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'initial_exponent': self.exponent,\n",
    "            'increment': self.increment,\n",
    "            'update_frequency': self.update_frequency,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my NEW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# class ModelBuilder:\n",
    "#     def __init__(self, input_shape=(64, 64, 1), num_classes=3, num_coordinates=2, learning_rate=3e-5, weights_path=None, l2_reg=0.001):\n",
    "#         self.input_shape = input_shape\n",
    "#         self.num_classes = num_classes\n",
    "#         self.num_coordinates = num_coordinates\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.l2_reg = l2_reg\n",
    "#         self.model = self.build_model()\n",
    "\n",
    "#         # Load weights if a path is provided\n",
    "#         if weights_path is not None:\n",
    "#             self.model.load_weights(weights_path)\n",
    "\n",
    "#         self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "#         # self.optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "#     def build_model(self):\n",
    "#         l2 = regularizers.l2(self.l2_reg)\n",
    "        \n",
    "#         x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "#         # First branch\n",
    "#         x_1 = layers.Conv2D(64, kernel_size=6, strides=1, padding='same', activation='relu')(x_input)\n",
    "#         x_1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=3, padding='same', activation='relu', kernel_regularizer=l2)(x_1)\n",
    "#         # x_1 = layers.Dropout(0.1)(x_1)\n",
    "#         # x_1 = layers.BatchNormalization()(x_1)\n",
    "\n",
    "#         # Second branch\n",
    "#         x_2 = layers.Conv2D(32, kernel_size=8, strides=3, padding='same', activation='relu')(x_input)\n",
    "#         x_2 = layers.Conv2D(64, kernel_size=4, strides=1, padding='same', activation='relu')(x_2)\n",
    "#         x_2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_2)\n",
    "#         # x_2 = layers.Dropout(0.1)(x_2)\n",
    "#         # x_2 = layers.BatchNormalization()(x_2)\n",
    "\n",
    "#         # Concatenate branches\n",
    "#         x_3 = layers.concatenate([x_1, x_2])\n",
    "#         x_3 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_3)\n",
    "#         # x_3 = layers.Dropout(0.1)(x_3)\n",
    "#         # x_3 = layers.BatchNormalization()(x_3)\n",
    "\n",
    "#         # Third branch\n",
    "#         x_4 = layers.Conv2D(64, kernel_size=19, strides=5, padding='same', activation='relu', kernel_regularizer=l2)(x_input)\n",
    "        \n",
    "#         # Flatten and concatenate\n",
    "#         x_3 = layers.Flatten()(x_3)\n",
    "#         x_4 = layers.Flatten()(x_4)\n",
    "#         x = layers.Concatenate()([x_3, x_4])\n",
    "\n",
    "#         # Dense layers with L2 regularization\n",
    "#         x = layers.Dense(256, activation='relu', kernel_regularizer=l2)(x)\n",
    "#         # x = layers.Dropout(0.1)(x)\n",
    "\n",
    "#         # Output layer for midpoints\n",
    "#         x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "#         x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "#         return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "#     def compile_model(self, loss_function):\n",
    "#         self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "#     def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "#         history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "#         return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, input_shape=(64, 64, 1), num_classes=13, num_coordinates=2, learning_rate=1e-3, weights_path=None,l1_reg=0.001,l2_reg =0.01):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_coordinates = num_coordinates\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # Load weights if a path is provided\n",
    "        if weights_path is not None:\n",
    "            self.model.load_weights(weights_path)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        # self.optimizer =tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        l1 = regularizers.l1(self.l1_reg)\n",
    "        l2 = regularizers.l2(self.l2_reg)\n",
    "\n",
    "    \n",
    "        x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(128, kernel_size=5, padding='same', activation='relu')(x)\n",
    "        # x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='linear', name='x_midpoints')(x)\n",
    "        x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "        return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "    def compile_model(self, loss_function):\n",
    "        self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "    def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "        history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Main Script Execution\n",
    "# -----------------------------\n",
    "\n",
    "# Load data\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_Mixed_13.h5'             \n",
    "h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KNoFalsePositivesFixed-index84_13.h5'\n",
    "data_loader = DataLoader(h5_filename)\n",
    "images, centers = data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5fa074a2d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=np.random.randint(0,len(centers))\n",
    "data_loader.plot_image_with_centers(l)\n",
    "plt.imshow(images[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.765625, 0.140625],\n",
       "        [0.625   , 0.171875],\n",
       "        [0.65625 , 0.234375],\n",
       "        [0.65625 , 0.28125 ],\n",
       "        [0.171875, 0.296875],\n",
       "        [0.453125, 0.359375],\n",
       "        [0.78125 , 0.375   ],\n",
       "        [0.625   , 0.453125],\n",
       "        [0.546875, 0.578125],\n",
       "        [0.796875, 0.59375 ],\n",
       "        [0.46875 , 0.671875],\n",
       "        [0.625   , 0.71875 ],\n",
       "        [0.203125, 0.765625]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.random.randint(0, len(images))\n",
    "train_midpoints[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data and split it into training and validation sets\n",
    "train_images, val_images, train_midpoints, val_midpoints = data_loader.split_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: (24000, 64, 64), Train Midpoints: (24000, 1, 13, 2)\n",
      "Validation Images: (6000, 64, 64), Validation Midpoints: (6000, 1, 13, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 1000\n",
    "train_dataset = train_dataset.shuffle(buffer_size=8000, reshuffle_each_iteration=True).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=8000).batch(batch_size)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f'Train Images: {train_images.shape}, Train Midpoints: {train_midpoints.shape}')\n",
    "print(f'Validation Images: {val_images.shape}, Validation Midpoints: {val_midpoints.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_transposed_images_with_midpoints(train_dataset, image_indices=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=10, verbose=1, mode='min', min_lr=3e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">819,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,338</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m819,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │        \u001b[38;5;34m13,338\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m2\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,059,162</span> (34.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,059,162\u001b[0m (34.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,057,882</span> (34.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,057,882\u001b[0m (34.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# dynamic_exponent_callback = DynamicExponentCallback(2, 1, 50)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # Instantiate the model builder\n",
    "    # model_builder = ModelBuilder(weights_path= \"/home/da886/Weights from Josh's model/Josh's5fixedMSE45overfit-1.keras\")\n",
    "    model_builder = ModelBuilder()\n",
    "\n",
    "    # Build the model\n",
    "    model_builder.build_model()\n",
    "\n",
    "    # Display the model architecture\n",
    "    model_builder.model.summary()\n",
    "\n",
    "    # Compile the model using the custom loss function\n",
    "    # model_builder.compile_model(loss_function=dynamic_exponent_callback.custom_loss(2))\n",
    "    model_builder.compile_model(loss_function=tf.keras.losses.MeanSquaredError()) \n",
    "    \n",
    "    # model_builder.compile_model(loss_function=custom_loss(3))e\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 21:48:34.467242: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-08 21:48:34.476608: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-08 21:48:34.512417: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1728424114.579492  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.582471  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.582998  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.637506  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.637505  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.637721  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.638366  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.638381  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.638592  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.644564  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.644570  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.645320  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.665650  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.666195  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.666266  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.668424  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.668439  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.669229  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.670432  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.670611  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.670777  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.671724  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.672037  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.676201  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.676655  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.676672  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.678028  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.698913  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.698988  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.700354  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.700429  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.700763  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.701558  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.701631  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.702159  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.703090  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.703272  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.703529  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.704999  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.705125  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.705249  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.706805  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.706812  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.706899  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.708554  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.709715  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.709809  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.710615  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.711948  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.712043  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.712474  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.715566  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.715638  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.716017  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.719851  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.719924  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.720275  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.725927  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.725945  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.726018  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.728386  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.728390  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.729230  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.730873  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.736819  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.736841  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.736906  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.740357  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.740355  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.740449  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.840441  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.840484  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.841502  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.841516  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.842607  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.842622  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.843709  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.843724  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.844936  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.844950  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.846383  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.846398  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.848313  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.848328  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.850110  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.850211  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.851845  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.851945  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.853639  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.853808  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.856617  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.856816  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.859592  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.859813  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.878245  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.878540  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.878903  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.879209  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.879630  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.879932  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.880380  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.880692  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.881175  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.881491  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.881939  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.882267  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.882750  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.883074  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.883621  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.883944  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.885462  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.885852  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.886449  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.886843  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.887433  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.888358  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.889133  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.889410  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.896980  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.897086  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.898128  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.898307  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.899155  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.899319  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.903345  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.903443  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.905701  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.905780  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.908132  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.908233  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.909615  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.910080  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.911551  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.912294  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.913787  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.914712  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.916228  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.926123  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.927169  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.927708  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.928291  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.928766  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.929314  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.929909  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.930309  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.930930  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.931957  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.932061  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.933586  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.934987  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.936628  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.938016  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.939677  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.941010  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.942682  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.943952  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.945653  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.946897  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.948632  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.950126  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.951877  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.986960  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.987775  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.988819  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.988936  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.989873  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.989983  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.990781  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.991090  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.991844  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.992265  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.992955  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.993480  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.994129  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.994664  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.995335  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.996096  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.996525  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.997463  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.997961  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.998967  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424114.999329  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.000827  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.002855  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.004696  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.008042  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.009942  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.010044  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.011567  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.011837  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.013492  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.013661  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.015742  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.015757  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.017481  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.017719  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.019466  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.020967  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.021895  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.025159  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.025402  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.029648  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.037509  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.038991  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.040722  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.041946  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.042203  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.043605  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.043706  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.045369  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.046091  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.046870  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.048298  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.050715  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.051908  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.056619  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.057652  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.062396  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.063488  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.068268  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.069139  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.074001  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.074820  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.079722  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.081027  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.085948  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.086619  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.087514  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.088398  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.089286  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.090294  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.091644  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.093321  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.094976  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.096630  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.098391  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.101374  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.104367  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.123397  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.124087  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.124806  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.125558  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.126365  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.127132  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.127928  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.128791  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.129861  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.130835  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.131816  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.132853  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.135195  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.136323  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.137318  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.140950  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.142272  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.143607  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.145543  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.147769  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.150205  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.154101  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.155377  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.156753  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.158307  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.159737  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.159956  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.161071  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.161632  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.161662  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.162481  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.162722  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.163357  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.163868  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.164093  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.164914  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.165129  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.165811  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.165989  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.167209  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.167700  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.167787  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.169440  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.169550  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.170866  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.171332  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.171586  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.173434  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.173933  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.175573  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.176956  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.177730  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.178050  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.179937  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.182908  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.184225  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.186160  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.186396  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.189059  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.191799  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.192654  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.194779  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.195374  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.198303  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.198320  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.201550  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.201566  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.205038  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.208270  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.208369  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.212192  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.218885  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.223342  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.224152  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.225060  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.226114  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.226419  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.227211  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.228374  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.228883  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.229598  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.230907  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.231009  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.232350  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.233559  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.233753  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.235250  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.236574  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.237029  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.239055  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.239222  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.239537  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.241475  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.241657  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.244332  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.244372  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.244548  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.246334  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.247354  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.247784  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.247974  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.249852  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.250088  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.250267  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.252054  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.252251  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.252972  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.253806  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.255007  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.257274  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.257857  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.260293  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.261505  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.263041  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.264254  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.273474  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.274540  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.274969  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.275477  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.276713  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.278196  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.279611  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.282013  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.285887  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.286861  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.287899  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.293690  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.297422  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.297919  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.299602  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.305306  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.308660  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.308996  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.311041  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.317305  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.319890  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.321098  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.332030  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.333014  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.344039  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.391156  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.392426  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.393811  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.395370  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.397024  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.398699  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.400436  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.402194  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.404290  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.406420  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.408570  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.415089  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.423473  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.426158  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.428890  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.431827  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.435201  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.438228  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.444657  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.462244  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.464706  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.466714  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.469164  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.472132  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.474570  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.476935  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.478100  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.479652  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.480432  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.482496  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.483096  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.484920  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.485770  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.487642  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.488775  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.489264  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.491774  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.491797  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.494454  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.495112  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.497143  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.497892  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.499021  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.500161  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.500942  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.503026  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.505295  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.506354  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.509287  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.509384  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.510419  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.512452  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.513231  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.516069  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.517173  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.519769  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.521976  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.523541  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.524431  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.527334  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.529498  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.533152  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.534254  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.535067  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.539129  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.540147  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.544589  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.544598  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.544707  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.549627  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.553753  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.556778  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.559823  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.566186  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.568958  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.568972  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.572121  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.575404  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.581447  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.584786  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.588464  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.596846  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.601590  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.613861  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.623383  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.627568  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.631326  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.635598  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.639790  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.640518  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.644649  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.644979  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.648281  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.648987  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.652416  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.653689  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.656461  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.658402  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.661649  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.662461  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.665701  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.667209  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.670536  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.675341  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.679496  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.684296  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.690482  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.708199  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.713651  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.714851  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.717188  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.719848  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.722519  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.725525  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.728350  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.731665  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.731927  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.734482  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.736275  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.737551  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.741174  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.745008  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.748940  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.752895  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.754906  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.758158  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.760184  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.765278  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.770938  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.776031  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.776910  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.779970  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.780279  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.795538  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.798848  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.801975  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.803798  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.808015  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.820813  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.822742  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.827037  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.833165  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.845994  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.859936  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.864060  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.867706  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.871872  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.876002  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.881297  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.885320  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.890024  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.894768  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.898830  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.903431  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.927097  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.950758  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.973696  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424115.995640  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.017482  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.041433  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.064778  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.115741  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.119825  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.124271  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.128591  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.133492  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.135874  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.138338  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.140007  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.143474  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.144505  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.148313  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.148868  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.153927  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.154024  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.158890  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.159536  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.164091  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.166161  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.169010  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.172934  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.174571  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.180114  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.180293  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.186985  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.191017  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.193807  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.200115  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.201095  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.209648  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.212101  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.219099  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.221242  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.226531  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.230829  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.240397  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.247977  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.253417  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.265289  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.275227  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.276742  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.287213  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.298948  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.305907  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.311936  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.313312  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.320799  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.327269  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.337193  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.341485  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.344880  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.349129  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.354117  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.355909  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.356917  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.360016  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.362109  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.363752  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.364490  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.368822  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.369971  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.373869  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.374062  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.378755  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.379169  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.381871  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.383950  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.388767  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.388873  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.391187  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.394403  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.399285  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.400080  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.406750  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.407186  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.413584  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.416456  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.420831  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.425956  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.431839  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.435317  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.441094  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.450803  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.460421  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.467996  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.473798  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.479288  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.495277  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.507252  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.517585  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.519003  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.522141  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.548359  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.555843  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.561718  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.563430  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.566143  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.570020  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.580291  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.587898  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.597091  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.604892  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.605170  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.609729  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.613061  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.622234  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.631679  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.649217  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.654765  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.678271  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.695205  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.701446  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.722641  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.742462  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.765957  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.810377  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.854377  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.899714  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424116.946539  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.276646  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.284601  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.291954  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.300245  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.310327  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.318774  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.319716  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.326768  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.329627  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.334197  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.340284  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.342772  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.349838  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.353051  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.360268  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.362644  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.372729  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.373147  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.383615  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.386238  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.393419  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.399934  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.404098  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.414288  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.417126  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.430297  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.432187  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.444206  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.450727  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.458852  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.468370  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.476798  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.491427  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.495403  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.513110  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.514504  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.525313  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.533292  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.536268  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.540743  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.549064  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.557499  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.558824  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.561638  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.568638  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.578740  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.585029  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.589665  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.599425  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.610115  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.623137  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.628028  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.636391  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.650315  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.664725  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.689135  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.707661  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.725283  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.748251  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.771541  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.815106  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.886564  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.890211  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.893532  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.897271  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.905824  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.909468  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.914214  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.918430  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.922014  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.926151  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.930264  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.952839  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.963191  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.966912  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.970310  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.973939  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.975021  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.977656  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.982359  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.985887  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.990161  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.993818  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.997657  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424117.998028  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.002156  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.020037  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.026226  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.041804  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.049696  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.064862  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.072971  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.088660  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.100331  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.122355  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.145667  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.152825  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.156496  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.159844  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.163475  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.167141  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.169662  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.170654  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.175355  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.179581  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.183177  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.187457  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.191740  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.215315  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.238155  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.261217  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.283883  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.305853  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.329133  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.353146  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.405416  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.409393  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.413152  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.417108  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.421329  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.425513  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.429788  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.434596  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.439251  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.444161  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.450122  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.456315  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.463137  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.470285  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.478975  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.486610  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.487877  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.490638  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.494472  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.497385  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.498496  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.502742  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.506947  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.508847  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.511171  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.516030  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.520442  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.520811  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.525841  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.531953  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.538233  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.541842  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.545203  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.552534  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.561319  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.570346  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.570397  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.571562  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.572731  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.574250  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.575440  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.576581  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.577858  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.579323  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.579975  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.580683  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.581884  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.583138  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.589264  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.591602  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.595384  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.601643  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.603965  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.608039  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.614342  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.615743  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.621033  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.627505  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.637391  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.666009  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.667198  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.668392  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.669947  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.671174  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.672488  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.672576  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.673795  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.675283  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.676717  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.676792  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.678017  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.679301  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.680513  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.684492  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.685555  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.688790  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.691799  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.693232  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.697659  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.698153  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.702365  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.704596  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.706964  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.709448  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.710684  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.710983  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.712155  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.712166  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.713394  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.714637  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.715864  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.717210  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.717751  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.718261  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.718559  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.719788  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.721093  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.722639  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.724334  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.724539  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.724561  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.726147  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.728196  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.730311  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.731327  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.732242  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.734893  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.738423  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.740841  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.743706  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.747097  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.749379  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.755845  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.765401  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.776873  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.777025  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.777490  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.777989  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.778379  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.779499  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.780698  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.781906  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.783087  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.784448  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.786871  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.788657  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.788759  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.800137  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.800553  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.801005  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.801422  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.801847  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.802311  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.802713  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.803105  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.803502  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.804007  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.804483  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.804975  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.805370  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.805765  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.806413  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.806898  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.806955  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.807542  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.808161  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.809571  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.809588  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.810428  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.810831  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.811076  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.812093  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.812371  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.813338  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.814704  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.815463  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.816065  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.817327  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.818640  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.820209  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.821748  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.823562  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.825612  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.827778  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.829694  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.831967  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.832434  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.832531  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.832932  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.833679  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.834416  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.835358  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.836804  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.837814  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.838503  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.838820  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.838872  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.840008  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.840868  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.841251  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.841436  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.842369  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.842770  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.842876  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.843075  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.843362  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.843655  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.844097  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.844193  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.844434  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.844766  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.845076  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.845606  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.845618  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.845951  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.846345  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.846865  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.847000  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.847323  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.847336  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.847764  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.848167  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.848599  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.848707  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.849989  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.850420  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.851241  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.851801  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.852449  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.852563  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.853040  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.854160  564785 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.858755  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.864925  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.871262  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.877650  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.877884  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.878338  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.878842  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.879229  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.880366  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.881575  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.882804  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.884119  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.884190  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.885565  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.887087  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.888737  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.890873  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.897414  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.900288  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.900712  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.901163  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.901577  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.902008  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.902475  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.902891  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.903290  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.903691  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.904195  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.904672  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.905162  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.905561  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.905966  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.906619  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.907111  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.907696  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.909596  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.911077  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.912376  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.915478  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.931895  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.932226  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.932521  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.933279  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.934021  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.934961  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.936407  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.937416  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.938466  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.940459  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.941957  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.942234  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.942533  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.942822  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.943118  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.943433  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.943758  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.944085  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.944387  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.944697  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.945030  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.945438  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.945834  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.946153  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.946574  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.946979  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.947451  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.950532  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.951068  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.951653  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.952776  564769 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.979918  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.981166  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.982373  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.983615  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.984871  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.986112  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.987468  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.988810  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.990073  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.991387  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.992957  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.994504  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.996312  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424118.998398  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.000518  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.002428  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.005056  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.010911  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.013729  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.019346  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.046677  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.047135  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.047637  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.048025  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.049157  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.050348  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.051558  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.052732  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.054085  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.055583  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.057215  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.068655  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.069078  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.069523  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.069940  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.070366  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.070831  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.071238  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.071636  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.072036  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.072544  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.073026  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.073523  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.073920  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.074318  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.074981  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.075547  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.076475  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.078392  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.079861  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.081158  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.084267  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.100720  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.101086  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.101386  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.102136  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.102953  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.103678  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.103928  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.105567  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.105671  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.107795  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.107902  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.108196  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.108864  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.110350  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.110665  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.110970  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.111070  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.111383  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.111700  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.112022  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.112629  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.112644  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.113154  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.113163  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.113586  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.113685  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.113890  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.114190  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.114302  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.114824  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.114840  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.115174  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.115617  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.115631  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.115933  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.116355  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.116442  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.116776  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.117114  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.117219  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.117647  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.117804  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.117991  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.118415  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.118885  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.118978  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.119371  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.122453  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.122989  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.123572  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.124687  564794 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.137697  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.138029  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.138362  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.138647  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.140858  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.141168  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.141510  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.141816  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.142107  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.144149  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.145775  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.146110  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.146463  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.147831  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.149318  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.149737  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.150168  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.156108  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.159804  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.162988  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.167744  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.168376  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.168965  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.169255  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.169772  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.170075  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.170366  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.170687  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.171008  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.171537  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.171934  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.172266  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.172593  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.172986  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.173386  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.174029  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.174605  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.175241  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.175853  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.176942  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.182529  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.182835  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.183219  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.183577  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.184338  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.184708  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.185275  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.185723  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.186078  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.186897  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.187697  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.188027  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.188389  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.188442  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.189058  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.190378  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.190564  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.190867  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.190974  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.191473  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.191489  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.193372  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.193680  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.194070  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.194359  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.194749  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.194759  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.195128  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.195408  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.195742  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.196035  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.196318  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.196712  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.197051  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.197403  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.197789  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.198147  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.198250  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.198595  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.200492  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.201265  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.203085  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.203621  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.204192  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.204687  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.205216  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.208081  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.210315  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.214120  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.214829  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.216581  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.216674  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.217652  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.217845  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.218008  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.218600  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.218622  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.219083  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.219098  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.219559  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.219575  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.219912  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.220189  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.220481  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.221096  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.221120  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.221386  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.221714  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.222002  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.222490  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.222666  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.222963  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.223083  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.223416  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.223537  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.223785  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.224169  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.224489  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.224828  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.226029  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.226721  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.227238  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.227787  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.228279  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.228803  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.231106  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.233308  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.236083  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.236686  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.236709  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.237137  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.237776  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.238593  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.238876  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.239045  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.239440  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.239539  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.240010  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.240027  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.240612  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.240719  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.241323  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.241426  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.241856  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.241960  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.242401  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.242503  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.242829  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.243220  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.243627  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.244006  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.244403  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.244878  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.246865  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.247327  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.247798  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.248384  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.248928  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.249545  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.250113  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.251323  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.252543  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.253689  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.254057  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.254501  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.254997  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.255169  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.255559  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.255960  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.256346  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.256757  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.257159  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.257566  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.257982  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.258371  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.258781  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.259160  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.259559  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.260000  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.260686  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.261134  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.261614  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.262197  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.262742  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.263349  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.263913  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.264620  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.265078  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.265234  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.265554  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.265968  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.266508  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.266607  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.266933  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.267380  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.267994  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.268009  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.268440  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.268897  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.269287  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.269404  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.269805  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.270303  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.270763  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.271240  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.271761  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.272338  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.274146  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.277694  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.278999  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.279417  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.279869  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.280273  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.280778  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.280910  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.281676  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.282117  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.282517  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.282934  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.283390  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.283800  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.284198  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.284698  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.285173  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.285650  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.286168  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.286743  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.288565  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.292151  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.295100  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.296184  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.296670  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.297085  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.297508  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.297944  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.298398  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.298872  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.299315  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.299741  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.300198  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.300626  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.301075  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.301541  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.302003  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.302519  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.303004  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.303469  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.303929  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.304872  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.305326  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.305878  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.306473  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.307149  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.309309  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.310237  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.310708  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.311130  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.311467  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.311650  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.312088  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.312550  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.313015  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.313463  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.313884  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.314343  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.314672  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.314848  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.315300  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.315766  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.316228  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.316746  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.317244  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.317913  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.317932  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.318394  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.319339  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.319798  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.320337  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.321064  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.321175  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.321752  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.323944  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.324303  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.326107  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.329254  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.332478  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.335574  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.338721  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.339571  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.340232  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.340669  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.341185  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.341866  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.342162  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.342457  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.342741  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.343190  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.343369  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.343691  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.343770  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.344335  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.344421  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.344742  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.344921  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.345092  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.345429  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.345614  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.345770  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.346215  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.346602  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.346937  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.347276  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.347358  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.347767  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.347940  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.348169  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.348817  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.349393  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.350028  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.350643  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.351073  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.351731  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.354889  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.354976  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.355551  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.355989  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.356466  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.357094  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.357190  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.357721  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.357743  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.358065  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.358297  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.358457  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.359153  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.359231  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.359568  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.359790  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.359957  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.360390  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.360464  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.360702  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.361459  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.361658  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.362365  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.362828  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.362847  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.363213  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.363790  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.363900  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.364441  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.364852  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.364978  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.365284  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.366727  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.366929  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.367887  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.367987  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.369022  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.370156  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.370264  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.371231  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.371530  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.372706  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.373989  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.374333  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.375196  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.376505  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.377789  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.378933  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.379641  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.380207  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.380848  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.381612  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.381990  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.383004  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.383178  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.384313  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.384599  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.385596  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.386467  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.386871  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.388145  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.388367  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.389300  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.389567  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.389831  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.390138  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.390462  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.390904  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.390975  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.391217  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.391893  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.392314  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.392395  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.392619  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.392903  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.393181  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.393643  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.393723  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.393947  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.394245  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.394418  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.394641  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.395089  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.395168  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.395451  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.395838  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.396158  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.396542  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.396766  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.397749  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.398203  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.398442  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.398964  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.399508  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.399815  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.400012  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.400417  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.400560  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.401654  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.402873  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.403575  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.405101  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.406855  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.408155  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.408553  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.409145  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.409600  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.410126  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.410219  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.410474  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.410768  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.411296  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.411844  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.412160  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.412478  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.416286  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.418863  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.422348  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.423130  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.423578  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.424225  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.424611  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.425016  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.425408  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.425820  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.426212  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.426616  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.427030  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.427414  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.427822  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.428200  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.428599  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.429038  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.429732  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.430180  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.430658  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.431237  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.431784  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.432392  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.432958  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.434183  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.434412  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.435442  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.436597  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.437753  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.441406  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.447658  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.448134  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.448595  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.449005  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.449426  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.449845  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.450291  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.450701  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.451118  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.451574  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.451987  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.452385  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.452883  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.453348  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.453828  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.454353  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.454935  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.456775  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.457059  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.460375  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.463337  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.479328  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.479794  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.480218  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.480654  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.481101  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.481568  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.482039  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.482485  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.482908  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.483374  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.483814  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.484273  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.484753  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.485217  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.485737  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.486231  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.486693  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.487163  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.488133  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.488596  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.489141  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.489752  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.490430  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.492622  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.494770  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.497927  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.501032  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.504141  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.507244  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.515453  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.516601  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.517902  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.519102  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.520282  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.521486  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.522601  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.522780  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.523185  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.523630  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.524284  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.524295  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.524811  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.525234  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.525580  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.525777  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.526188  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.526712  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.526985  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.527279  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.527880  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.528394  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.529144  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.529779  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.529999  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.531588  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.531849  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.532969  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.533088  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.533303  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.534406  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.534977  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.535628  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.536094  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.536912  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.537011  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.538232  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.539179  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.539527  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.540789  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.541538  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.542052  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.543508  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.544906  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.545653  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.546504  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.546856  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.547585  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.548090  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.548203  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.549254  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.549930  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.550407  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.551754  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.551835  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.553058  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.553213  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.553573  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.554348  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.555599  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.555788  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.556856  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.558278  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.558353  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.559447  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.559978  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.560739  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.562143  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.563504  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.564597  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.565116  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.566938  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.568847  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.570308  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.574917  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.577278  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.580986  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.584530  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.585943  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.587282  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.587503  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.588663  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.589992  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.591368  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.592787  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.594149  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.595607  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.597080  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.598497  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.599634  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.599967  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.601774  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.602011  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.603156  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.603448  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.604935  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.605041  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.606335  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.606766  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.607697  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.608561  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.609096  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.610257  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.610547  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.611931  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.612220  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.613418  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.614017  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.614929  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.616351  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.617584  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.617848  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.619428  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.619684  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.621087  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.621375  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.622444  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.622906  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.624644  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.626448  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.628358  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.628380  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.630350  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.632163  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.635209  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.635734  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.637700  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.639567  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.643951  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.646515  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.652690  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.653471  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.661435  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.662376  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.670101  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.671210  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.680114  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.689188  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.697248  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.698407  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.699710  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.700928  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.702113  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.703323  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.704600  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.705874  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.707134  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.708534  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.709937  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.711535  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.713125  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.714856  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.716538  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.718355  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.720546  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.722951  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.729126  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.734780  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.741683  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.766515  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.767946  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.769312  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.770703  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.772065  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.773474  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.774923  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.776308  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.777795  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.779292  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.780725  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.782216  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.784055  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.785473  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.787263  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.789010  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.789871  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.790838  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.791059  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.792312  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.792569  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.793650  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.794565  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.795000  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.796391  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.796701  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.798584  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.799969  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.800559  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.801847  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.802732  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.803817  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.805003  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.807626  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.809466  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.809690  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.810771  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.810937  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.812201  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.813533  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.814877  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.816518  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.816681  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.817678  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.818582  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.820545  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.822716  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.824987  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.826547  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.827609  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.828011  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.829379  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.831509  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.834957  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.835417  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.836379  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.838394  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.842038  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.844290  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.845702  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.847583  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.849271  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.851120  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.853146  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.853238  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.854611  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.856976  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.858072  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.860533  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.861726  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.864629  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.865431  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.868296  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.869014  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.872876  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.872980  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.876826  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.877745  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.880431  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.882959  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.884572  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.887926  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.888322  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.892845  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.893801  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.897799  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.900620  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.903061  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.908076  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.914032  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.921062  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.922045  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.942609  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.944810  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.965654  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.967124  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.974587  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.975782  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.977059  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.978408  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.979755  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.981470  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.983371  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.985352  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.987513  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.988201  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.989807  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.992428  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.992517  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424119.994299  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.001331  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.012641  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.013663  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.015905  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.016169  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.019629  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.023079  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.026721  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.030358  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.033920  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.037553  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.037724  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.040234  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.041674  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.045397  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.049540  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.053221  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.057677  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.062026  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.062558  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.067819  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.072787  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.078675  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.085548  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.107166  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.130045  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.152668  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.178069  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.201867  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.226280  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.335584  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.339181  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.342915  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.346634  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.350578  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.354435  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.357948  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.358674  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.361589  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.362797  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.365353  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.367039  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.369099  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.372014  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.373080  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.377087  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.377204  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.381358  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.382414  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.385497  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.388354  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.390149  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.394884  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.395285  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.400565  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.401393  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.405937  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.407851  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.412030  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.416231  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.418734  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.425479  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.425555  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.432128  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.436806  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.440710  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.449983  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.460084  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.461567  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.485374  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.491559  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.496162  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.500732  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.505274  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.509660  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.514007  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.517171  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.518876  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.521846  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.523473  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.523608  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.526486  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.527244  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.528685  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.531170  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.531254  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.533963  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.534937  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.535676  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.538915  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.539323  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.540037  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.542808  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.544264  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.544934  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.547231  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.549563  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.550641  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.551576  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.554933  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.556048  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.557030  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.560279  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.560975  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.561897  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.565729  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.566122  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.568176  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.570757  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.571450  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.574964  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.577223  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.577546  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.582469  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.583689  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.584195  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.588600  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.588876  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.590762  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.595009  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.597313  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.601896  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.605851  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.606358  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.609519  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.612914  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.615127  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.615845  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.620054  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.626900  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.626995  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.629842  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.636410  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.643565  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.650485  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.650567  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.654348  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.676595  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.681648  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.682131  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.686789  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.691404  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.695988  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.700388  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.702715  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.704744  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.708943  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.709800  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.714480  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.719756  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.725015  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.729950  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.730375  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.734898  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.735318  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.741606  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.747847  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.752689  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.757146  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.758928  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.760861  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.765706  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.773223  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.779624  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.784332  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.788159  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.795514  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.802137  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.809313  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.811521  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.816109  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.843608  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.870949  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.898291  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.924293  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.950298  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424120.977543  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.259989  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.263645  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.267838  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.272203  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.276744  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.282661  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.285602  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.289219  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.289391  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.293608  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.296550  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.298003  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.302524  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.304634  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.308406  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.313318  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.314885  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.322424  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.323498  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.330116  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.330712  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.339609  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.350008  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.356770  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.358936  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.386453  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.391502  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.398634  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.405887  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.413182  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.418371  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.424283  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.425718  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.431767  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.432943  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.439408  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.440575  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.447554  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.448636  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.453517  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.455199  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.456185  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.457241  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.461484  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.463745  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.464065  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.465916  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.470470  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.471243  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.472460  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.476518  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.478845  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.480408  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.483326  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.489132  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.489325  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.490740  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.497124  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.499017  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.499228  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.504942  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.507901  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.508399  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.515455  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.518181  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.518914  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.524877  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.525897  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.530497  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.535420  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.544504  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.546277  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.554122  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.558176  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.572425  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.586960  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.587432  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.594641  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.601744  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.609057  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.615111  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.617104  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.624838  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.631077  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.632752  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.641198  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.649097  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.657861  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.659708  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.665563  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.673374  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.674645  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.683855  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.694201  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.703722  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.703722  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.714394  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.725057  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.726099  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.740276  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.752321  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.774171  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.782945  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.802805  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.821755  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.826879  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.851896  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.870659  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.920938  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424121.970437  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.020326  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.410932  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.418232  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.425663  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.433280  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.441368  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.442150  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.449531  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.449874  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.456968  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.459052  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.464586  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.468362  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.472978  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.478017  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.481401  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.488418  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.490813  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.499254  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.500266  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.510152  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.510172  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.520756  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.522804  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.531705  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.536438  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.542572  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.549580  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.555092  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.562918  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.568755  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.579875  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.582011  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.595412  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.598249  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.612101  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.612494  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.619459  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.620433  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.626951  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.630988  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.634647  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.642757  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.651394  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.653488  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.660806  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.665889  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.670295  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.680094  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.690759  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.699437  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.701879  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.712809  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.725505  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.726721  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.738078  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.739270  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.747336  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.752562  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.756758  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.759728  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.766005  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.766421  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.771768  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.775871  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.781313  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.783160  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.785199  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.790906  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.794671  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.800711  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.801754  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.804791  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.810233  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.815467  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.819557  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.824041  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.825227  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.829103  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.835829  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.839286  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.844482  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.849987  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.855074  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.859791  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.865115  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.869496  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.870459  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.874008  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.879203  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.884611  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.889867  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.896789  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.899968  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.908890  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.910207  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.919475  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.924340  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.928837  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.931657  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.937675  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.941511  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.945092  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.951010  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.951027  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.959433  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.960525  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.968054  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.970212  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.972965  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.979743  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.984975  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.986279  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.989085  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.998621  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424122.998941  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.003322  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.008769  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.013646  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.019472  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.020255  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.029267  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.034192  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.039784  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.048421  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.048909  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.061668  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.063406  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.071642  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.080391  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.090816  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.098624  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.103088  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.116510  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.116617  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.130721  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.144237  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.151703  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.157530  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.169746  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.174617  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.191568  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.204678  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.205622  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.220413  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.223878  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.259370  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.270339  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.278662  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.314868  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.323683  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.347568  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.376935  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.384173  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.431954  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.487893  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424123.556832  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.290119  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.297528  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.306109  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.314885  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.324377  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.328975  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.336394  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.336908  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.345100  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.351424  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.354080  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.363371  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.365006  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.375544  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.379712  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.389418  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.395464  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.402587  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.412813  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.417204  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.432643  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.434339  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.450291  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.458601  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.472190  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.496625  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.507112  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.514587  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.523347  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.528134  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.532371  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.534441  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.538432  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.541959  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.542655  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.546964  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.551008  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.554713  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.555163  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.559661  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.563982  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.565603  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.568841  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.569562  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.572597  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.573093  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.576619  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.578388  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.580856  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.582671  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.583531  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.585212  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.588301  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.589385  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.593466  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.593683  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.598306  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.598665  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.599345  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.602619  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.605731  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.607597  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.611947  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.614714  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.617395  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.621764  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.627496  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.629345  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.632232  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.632794  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.636899  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.638829  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.645552  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.654044  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.660020  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.669426  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.677117  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.678529  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.682439  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.700470  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.708708  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.723163  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.734639  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.745721  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.749645  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.752890  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.756899  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.759920  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.761150  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.765586  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.769729  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.773993  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.776236  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.778619  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.783013  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.788020  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.792369  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.797815  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.801987  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.802230  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.807960  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.813214  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.819179  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.825684  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.849617  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.857299  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.880545  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.903144  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.929520  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.955781  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424124.981182  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.056065  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.060309  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.064504  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.068869  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.073435  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.077861  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.082768  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.087693  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.093074  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.098781  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.099496  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.103769  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.104661  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.107982  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.110538  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.112377  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.116982  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.117967  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.121473  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.126654  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.126670  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.131591  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.133977  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.136950  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.141594  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.142727  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.148650  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.151287  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.154541  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.161736  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.163231  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.170292  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.174819  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.177746  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.185474  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.195263  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.197965  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.207485  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.219282  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.232776  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.238506  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.242891  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.243494  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.248200  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.253891  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.260237  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.267328  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.274434  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.277933  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.278908  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.282008  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.283230  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.283427  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.287462  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.288436  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.290502  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.291834  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.293193  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.296422  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.298618  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.298880  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.300869  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.305110  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.305280  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.305798  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.310684  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.312365  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.314109  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.315969  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.319395  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.321616  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.323153  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.326893  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.327428  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.332165  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.333306  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.335308  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.340393  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.342278  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.343395  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.348818  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.349753  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.349918  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.356215  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.356322  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.358865  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.363604  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.363952  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.367945  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.369913  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.373627  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.376976  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.379768  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.385687  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.386961  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.391131  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.394367  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.397399  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.400702  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.402498  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.408077  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.414435  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.414803  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.420898  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.424440  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.424956  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.435922  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.447323  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.449922  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.455681  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.459683  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.461072  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.466057  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.469816  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.470783  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.474644  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.476395  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.482639  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.489630  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.494758  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.496641  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.501339  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.504102  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.512488  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.519695  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.520621  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.527111  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.528025  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.536093  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.545180  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.546546  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.554222  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.562695  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.564334  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.572030  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.573399  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.578432  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.585838  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.592195  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.597386  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.602180  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.607963  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.613633  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.625002  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.637292  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.642539  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.647465  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.672515  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.697485  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.724202  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.750927  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.785318  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424125.819784  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.070499  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.074770  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.079419  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.084156  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.089262  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.095641  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.102722  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.110333  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.117296  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.118585  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.121619  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.126288  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.130561  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.131076  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.136234  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.141946  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.142614  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.149761  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.155600  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.157405  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.165745  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.177896  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.179525  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.189428  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.203144  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.227187  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.232785  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.266267  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.279113  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.295703  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.300007  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.304664  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.309444  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.313354  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.314257  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.314593  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.316924  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.319278  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.321095  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.321755  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.324220  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.326801  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.328223  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.329416  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.331837  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.334144  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.335801  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.336557  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.339617  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.343493  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.344142  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.346590  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.349570  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.353478  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.356016  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.356685  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.360230  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.361501  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.364396  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.364574  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.366788  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.367430  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.369294  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.371782  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.374380  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.377068  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.377248  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.379509  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.381130  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.381861  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.384289  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.387347  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.389084  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.391309  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.394452  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.397344  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.400823  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.401344  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.404610  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.405305  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.410897  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.414366  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.415273  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.427655  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.427851  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.439669  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.440583  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.451352  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.457534  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.464845  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.478035  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.490924  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.491893  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.540185  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.543033  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.545384  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.547867  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.550346  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.552935  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.555563  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.558006  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.560421  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.562952  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.566028  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.569923  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.573030  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.575897  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.579813  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.583030  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.586575  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.589905  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.590883  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.592428  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.594923  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.597490  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.600123  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.602856  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.603391  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.605658  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.608486  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.611446  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.614490  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.615229  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.617537  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.621265  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.624831  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.626891  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.628922  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.633404  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.638584  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.640365  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.640517  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.642905  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.644591  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.645423  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.648006  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.650649  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.653408  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.653671  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.656226  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.656696  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.659058  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.662005  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.665069  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.666522  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.668210  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.672355  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.676206  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.677382  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.680543  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.680567  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.683929  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.685075  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.687305  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.690189  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.690385  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.693067  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.696057  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.696533  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.699055  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.702278  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.706198  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.708948  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.710631  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.715027  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.719248  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.724097  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.728944  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.729777  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.732359  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.732743  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.736157  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.737476  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.739580  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.741860  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.742503  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.745405  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.747221  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.748443  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.751454  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.752592  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.754710  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.758883  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.758908  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.763360  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.767460  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.767816  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.772083  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.776923  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.780226  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.781767  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.785190  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.790297  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.793906  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.794687  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.800065  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.805451  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.807525  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.811596  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.816731  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.819249  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.820172  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.821160  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.821771  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.824353  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.826994  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.829729  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.832532  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.833000  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.834781  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.835368  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.838341  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.841412  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.844644  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.846586  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.848626  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.852147  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.852460  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.856564  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.860161  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.861084  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.866312  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.869440  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.872405  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.873739  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.884700  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.887307  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.905019  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.905590  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.908586  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.911992  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.915395  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.918288  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.921190  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.922663  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.924225  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.927219  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.930443  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.934384  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.938804  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.943234  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.947519  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.952423  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.957311  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.960775  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.965891  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.970301  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.975689  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.981082  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.987211  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424126.995783  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.008577  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.022319  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.035993  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.049656  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.063306  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.080825  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.098343  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.106034  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.108767  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.111564  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.114812  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.118286  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.121998  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.125963  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.130263  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.135741  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.141757  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.149221  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.159919  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.162266  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.162684  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.165478  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.168729  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.172217  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.175990  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.177012  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.180002  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.184317  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.189794  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.195793  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.197880  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.203250  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.216304  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.224901  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.231143  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.251975  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.255797  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.257312  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.258759  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.260273  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.261836  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.263503  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.265017  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.266438  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.268037  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.269535  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.271229  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.273377  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.275018  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.276779  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.278924  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.279268  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.280782  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.283170  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.285171  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.291761  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.297572  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.303361  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.309957  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.310516  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.311483  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.312940  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.314451  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.316021  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.317881  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.317898  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.319391  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.320815  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.322452  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.323954  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.325653  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.327802  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.329454  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.331210  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.333349  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.335211  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.336955  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.337629  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.339867  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.339888  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.342718  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.345990  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.346489  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.349521  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.352371  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.353275  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.357259  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.358242  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.361546  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.365477  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.367079  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.372739  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.373293  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.381030  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.392975  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.394553  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.394644  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.396219  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.397782  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.399410  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.401092  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.402809  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.404579  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.406392  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.408210  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.409783  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.410060  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.412306  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.414527  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.416905  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.419449  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.422396  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.425419  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.430875  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.431307  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.438477  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.448799  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.450411  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.451993  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.452419  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.453565  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.454194  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.455204  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.455833  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.456903  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.457816  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.458539  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.458711  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.459661  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.460508  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.461689  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.462329  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.463804  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.464161  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.466045  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.466147  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.467963  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.468395  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.469990  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.470640  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.472401  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.473032  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.474560  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.475592  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.476719  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.478657  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.479346  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.481600  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.481836  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.483873  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.486787  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.487970  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.488730  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.488905  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.490252  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.491894  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.491899  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.493412  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.494612  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.494986  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.495298  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.496640  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.497733  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.498148  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.499569  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.501178  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.501504  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.502693  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.504393  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.505646  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.506553  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.508200  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.509391  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.509967  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.510589  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.511192  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.512135  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.512852  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.514010  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.514852  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.516409  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.516705  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.517559  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.518422  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.518728  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.520823  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.522915  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.524524  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.524866  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.525068  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.526920  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.529115  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.530915  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.531616  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.531714  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.533906  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.536550  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.536846  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.538581  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.538841  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.541119  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.544067  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.544281  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.546211  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.547462  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.548983  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.551812  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.551898  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.555024  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.556245  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.558801  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.562909  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.566697  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.567877  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.574806  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.581749  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.588656  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.595562  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.604388  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.613212  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.623725  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.628134  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.629750  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.631342  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.632916  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.634550  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.636245  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.637972  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.639753  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.641575  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.643406  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.645262  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.647505  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.649761  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.652188  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.654781  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.657822  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.660935  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.666929  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.674146  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.685478  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.687404  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.688200  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.689290  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.689974  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.691383  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.691612  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.693801  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.693812  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.695659  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.696169  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.697678  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.698554  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.699787  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.701144  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.701898  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.703806  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.705837  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.708267  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.710442  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.712621  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.715270  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.716669  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.717545  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.719800  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.720571  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.722714  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.724825  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.725518  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.727599  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.730309  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.731221  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.733431  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.737199  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.738605  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.741345  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.743306  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.745239  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.746286  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.747143  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.749131  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.749300  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.751554  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.753261  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.753908  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.756298  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.758890  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.760222  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.761838  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.767190  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.774142  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.774501  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.778461  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.783037  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.783677  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.789670  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.791100  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.791919  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.792220  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.793504  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.794789  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.796129  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.797549  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.797660  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.798693  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.800054  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.801409  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.802525  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.802633  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.804023  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.805469  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.806981  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.808621  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.808790  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.810644  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.812805  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.814812  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.818555  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.820569  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.821704  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.823553  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.826522  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.830169  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.833843  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.851597  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.852718  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.854013  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.855309  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.856665  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.857965  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.859113  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.860491  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.861861  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.862996  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.864388  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.865853  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.867378  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.869112  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.871114  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.871196  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.872236  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.873495  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.873596  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.874596  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.875686  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.875804  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.877169  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.878556  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.879456  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.879940  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.881416  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.881594  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.882905  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.884343  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.884634  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.885915  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.887334  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.887666  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.889062  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.890828  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.891376  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.892564  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.895016  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.895173  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.896674  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.899739  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.903465  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.912921  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.914549  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.916140  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.917715  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.919323  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.920905  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.922305  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.922489  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.923867  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.924247  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.925260  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.926161  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.926957  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.928393  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.928487  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.930231  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.930670  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.931937  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.933041  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.933474  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.933705  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.934627  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.935230  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.935455  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.935789  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.936896  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.937124  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.938192  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.938267  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.939430  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.939617  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.941023  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.941700  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.942452  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.943907  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.944719  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.945404  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.946852  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.947211  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.948429  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.949742  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.949913  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.951646  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.952403  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.953439  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.953922  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.955193  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.956019  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.957606  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.958023  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.959277  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.959634  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.962375  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.963341  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.963427  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.966126  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.967046  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.969332  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.972844  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.975523  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.977100  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.977375  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.977465  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.978980  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.980551  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.981998  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.982191  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.983781  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.985362  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.986754  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.987351  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.987881  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.988154  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.989852  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.991288  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.993032  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.994737  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.996499  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.998023  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424127.999896  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.000892  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.002183  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.004456  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.007440  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.009934  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.012425  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.015070  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.018693  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.022312  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.025943  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.029563  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.030778  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.031910  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.033212  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.034144  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.034521  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.035883  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.037184  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.038319  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.038739  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.039714  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.041085  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.042215  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.043615  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.044591  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.045100  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.046634  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.047506  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.048382  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.048651  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.049855  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.050009  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.050275  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.051271  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.052719  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.052732  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.054148  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.054764  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.055746  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.057153  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.058584  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.060631  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.063660  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.066029  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.066692  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.069817  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.070422  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.074169  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.074604  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.080249  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.084772  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.096372  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.097177  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.098016  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.098871  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.099613  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.100497  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.101349  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.102241  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.102998  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.103973  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.104802  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.105920  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.107161  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.108400  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.110298  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.110655  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.111461  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.111708  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.112302  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.112702  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.112874  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.114262  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.114293  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.114372  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.115407  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.115695  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.115935  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.116557  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.117132  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.117677  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.117915  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.118748  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.119483  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.119563  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.120168  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.120853  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.122297  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.122569  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.123790  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.125241  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.125801  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.126818  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.128243  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.128904  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.129976  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.131747  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.132920  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.132937  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.133479  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.135879  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.137544  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.137750  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.140611  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.143364  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.144338  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.147941  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.151881  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.152676  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.153580  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.153789  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.154381  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.155176  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.155433  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.156114  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.157277  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.157287  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.158272  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.158871  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.159228  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.159575  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.160245  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.160572  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.160642  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.161282  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.161465  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.162593  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.162667  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.162681  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.163434  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.163741  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.164226  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.164401  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.164869  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.165267  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.165629  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.165866  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.166172  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.167051  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.167272  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.167348  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.168038  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.168905  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.169077  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.169950  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.170124  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.170523  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.171378  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.172280  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.172714  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.172794  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.173999  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.175042  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.175770  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.176697  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.177307  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.178339  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.179194  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.180008  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.180607  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.181474  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.181737  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.181964  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.183150  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.183435  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.183756  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.184359  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.185634  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.186430  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.186861  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.186963  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.188184  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.189491  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.189593  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.189777  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.190876  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.192006  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.192188  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.193110  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.194041  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.194664  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.194983  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.196291  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.196388  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.197495  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.198275  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.198695  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.201527  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.201881  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.203913  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.205489  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.206708  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.209209  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.209302  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.210752  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.214243  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.215263  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.215324  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.216091  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.216860  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.217687  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.217846  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.218497  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.219426  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.219896  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.220413  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.221483  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.221580  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.222527  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.223517  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.224591  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.224671  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.225037  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.225687  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.226743  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.227860  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.228844  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.230042  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.230212  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.232778  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.235409  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.243233  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.244594  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.245797  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.247003  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.248269  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.249526  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.250753  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.251987  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.253247  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.254519  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.255525  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.255646  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.256493  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.256656  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.257476  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.257635  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.258702  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.258870  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.259696  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.259991  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.260733  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.261197  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.261805  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.263066  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.264046  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.264351  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.266544  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.266852  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.269237  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.271657  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.271821  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.273201  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.275187  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.276724  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.278690  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.280253  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.282415  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.283781  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.286966  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.287342  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.290802  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.291965  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.293153  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.294557  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.295870  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.297418  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.298188  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.299174  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.299187  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.300385  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.300615  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.302286  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.303689  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.305277  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.306469  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.307705  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.309088  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.309419  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.310717  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.312899  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.313259  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.314523  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.320201  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.320212  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.321231  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.321331  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.322206  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.323245  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.324064  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.324247  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.325276  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.325916  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.326350  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.327602  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.328881  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.330559  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.331087  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.331657  564790 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.336428  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.339793  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.342189  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.343003  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.343328  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.343873  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.344731  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.345490  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.346378  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.347025  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.347257  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.348152  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.348905  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.349882  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.350719  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.351616  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.351872  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.353124  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.354366  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.356624  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.358311  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.361463  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.362115  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.362884  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.363154  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.364093  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.364906  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.365988  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.366601  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.367404  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.368965  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.369613  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.370172  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.371419  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.372938  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.373010  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.374552  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.376732  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.378351  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.383871  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.384890  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.387657  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.395262  564786 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.402960  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.403754  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.404527  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.405315  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.406108  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.407040  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.408019  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.408998  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.409954  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.410929  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.411920  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.412921  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.413980  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.415102  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.416088  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.417315  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.419877  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.422508  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.430367  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.431738  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.432944  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.434148  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.435422  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.436692  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.437925  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.439153  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.440420  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.441695  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.442620  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.443541  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.444474  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.445795  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.446902  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.448094  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.450928  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.453313  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.456109  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.458491  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.460020  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.463514  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.467011  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.470509  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.474065  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.504656  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.505568  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.506443  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.507490  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.508487  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.509521  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.510578  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.511832  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.513112  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.515307  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.520562  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - loss: 1.0822"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728424128.523927  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.527421  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.531128  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.535693  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.546165  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.546919  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.548113  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.550000  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.551405  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.552975  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.554170  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.555408  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.556783  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.558395  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.560577  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.562198  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.568720  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.571447  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424128.579048  564795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.4927"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 21:48:51.026672: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-08 21:48:51.026783: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-08 21:48:51.026919: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "W0000 00:00:1728424131.807636  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.808417  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.809407  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.810349  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.811323  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.812261  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.813228  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.813745  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.814305  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.814605  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.815273  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.815557  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.815939  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.816489  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.816619  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.816867  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.817672  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.817873  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.818852  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.819013  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.819164  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.819888  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.820320  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.820320  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.821140  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.821270  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.821463  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.822189  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.822343  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.822563  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.823527  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.823731  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.824207  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.824911  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.825242  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.825373  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.826302  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.826504  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.826645  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.827333  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.828022  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.828223  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.828344  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.829169  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.829662  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.829789  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.830011  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.830851  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.831277  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.831381  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.832040  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.833063  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.833071  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.833467  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.834653  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.834784  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.835032  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.836155  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.836512  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.837707  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.838068  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.838173  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.838692  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.839691  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.839691  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.839888  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.840700  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.841344  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.841623  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.842106  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.843290  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.844156  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.844708  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.845443  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.845538  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.846307  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.846651  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.846901  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.847297  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.847478  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.848087  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.848390  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.848968  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.849162  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.849694  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.850621  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.851078  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.851414  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.852273  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.852729  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.853812  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.854012  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.855263  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.855605  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.855715  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.856876  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.857247  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.858622  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.858732  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.858908  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.860925  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.862191  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.862505  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.863532  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.863900  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.865982  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.867640  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.867998  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.870588  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.871120  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.873139  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.875773  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.882654  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.883470  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.884154  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.885595  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.886391  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.887073  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.887763  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.887872  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.888518  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.889176  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.889928  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.890336  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.890725  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.891417  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.892159  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.892942  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.893697  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.894365  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.894614  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.894918  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.895145  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.895939  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.896625  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.897368  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.899139  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.899528  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.899824  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.902887  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.903681  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.904373  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.906535  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.907026  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.908940  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.910626  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.910862  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.912281  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.915035  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.915132  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.915895  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.919215  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.920193  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424131.924380  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.000653  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.001318  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.002035  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.002797  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.003670  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.003797  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.004680  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.004693  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.005415  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.005605  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.006189  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.006507  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.006973  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.007367  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.007823  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.008265  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.008714  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.009128  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.009250  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.009635  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.009835  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.010286  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.010650  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.010762  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.011516  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.011678  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.011691  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.012497  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.012688  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.012863  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.013368  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.013714  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.013994  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.014272  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.014773  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.015309  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.015383  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.016075  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.016250  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.016599  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.017356  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.017370  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.018279  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.018847  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.018858  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.019307  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.020053  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.020383  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.020716  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.021669  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.022137  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.022812  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.024278  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.024300  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.024320  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.025516  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.026784  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.027810  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.027827  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.029599  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.030250  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.031443  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.034780  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.035761  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.036631  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.037221  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.037470  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.038414  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.039032  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.039353  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.040088  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.040192  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.041017  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.041126  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.042076  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.042178  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.043245  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.043255  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.044043  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.044597  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.044876  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.045902  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.046004  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.046268  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.046907  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.047267  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.047345  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.048125  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.048299  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.049078  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.049467  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.050021  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.050898  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.051009  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.051574  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.051845  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.052784  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.053691  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.055224  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.055244  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.056028  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.056408  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.057711  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.059647  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.060312  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.061881  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.063889  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.066303  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.069201  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.070568  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.072668  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.078000  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.079380  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.081352  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.083427  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.086729  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.088099  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.088949  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.092181  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.093479  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.098927  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.259488  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.260402  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.260714  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.261362  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.261628  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.262351  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.262575  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.263493  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.263592  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.264573  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.264675  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.265837  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.265846  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.266963  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.267064  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.267746  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.268216  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.268314  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.268670  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.269514  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.269738  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.269812  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.270893  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.271035  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.271146  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.272100  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.272274  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.272486  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.273116  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.273584  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.273954  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.274144  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.275024  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.275274  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.275620  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.276453  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.276668  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.277396  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.277727  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.278412  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.279121  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.279298  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.280287  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.280461  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.281316  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.281918  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.282295  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.283393  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.283605  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.284331  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.285369  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.286665  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.287207  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.287568  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.289212  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.291365  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.291445  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.292027  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.294135  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.296170  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.296774  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.297387  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.301939  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.306719  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.307581  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.308145  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.308902  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.309458  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.310201  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.310754  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.311767  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.312432  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.313335  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.313983  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.314743  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.315376  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.316059  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.316670  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.317309  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.317912  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.318456  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.318795  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.319380  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.319793  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.321224  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.321305  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.321641  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.322868  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.323212  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.323598  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.324428  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.325471  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.325979  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.326085  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.327383  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.328624  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.330095  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.332507  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.332592  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.332876  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.334478  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.336721  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.341134  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.341333  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.343586  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.349427  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.349603  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.352063  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.360256  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.366996  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.367008  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.377522  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.384013  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.384226  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.394202  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.394660  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.394747  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.404539  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.405004  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.405194  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.415363  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.740272  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.741696  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.743096  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.744557  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.745277  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.746063  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.746726  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.747645  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.748147  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.749216  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.749643  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.750842  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.751157  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.752918  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.752962  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.753245  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.754584  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.754833  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.755044  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.756365  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.756438  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.756991  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.757940  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.758225  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.758962  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.759453  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.760199  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.761268  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.761283  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.762141  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.762852  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.763830  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.764151  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.764489  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.766461  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.766539  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.766651  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.768508  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.769038  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.770439  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.771829  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.772444  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.774597  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.775424  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.777161  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.778346  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.779923  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.780646  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.781532  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.783593  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.784952  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.786793  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.788717  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.790240  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.791163  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.791668  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.794876  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.796529  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.798344  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.802505  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.806174  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.808225  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.808890  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.810295  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.811783  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.812612  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.813890  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.815128  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.815991  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.817182  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.818501  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.819157  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.821073  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.821741  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.823164  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.823986  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.824655  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.825176  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.826004  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.826767  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.827820  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.828309  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.828868  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.830094  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.830711  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.831258  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.832147  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.833850  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.834502  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.835949  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.836952  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.837975  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.840626  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.842883  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.843434  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.844952  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.847305  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.849920  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.849993  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.856630  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.862668  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.863180  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.873472  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.875865  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.880125  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.889679  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.892824  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.896402  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.907079  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.909199  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.913972  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.925067  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.926656  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.932500  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.945150  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.960558  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.969803  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424132.982624  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.633153  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.635451  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.637890  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.640150  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.642652  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.645351  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.648129  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.650991  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.651019  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.653333  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.654139  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.655799  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.657922  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.658253  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.658405  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.660839  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.660919  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.661219  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.663307  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.663582  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.664674  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.665608  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.666342  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.668281  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.668296  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.669058  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.670912  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.672222  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.672913  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.673652  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.675992  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.676342  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.677940  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.679386  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.679561  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.682832  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.683544  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.683565  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.686318  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.686874  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.690292  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.690977  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.693730  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.696143  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.698366  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.699286  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.701597  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.703520  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.705215  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.708943  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.711713  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.717425  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.723394  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.723845  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.724704  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.730011  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.730640  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.738170  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.742403  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.744811  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.747403  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.751066  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.755324  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.757236  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.759154  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.762871  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.766328  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.767507  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.770044  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.771190  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.774355  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.776001  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.778239  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.779574  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.781435  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.781996  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.783207  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.785186  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.786754  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.787588  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.789537  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.790542  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.792176  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.793433  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.795504  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.797204  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.799176  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.801896  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.802901  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.805615  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.807407  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.810470  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.812092  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.814095  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.815631  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.817890  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.822302  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.826921  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.835727  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.841746  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.850579  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.862132  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.874690  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.877294  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.895451  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.906518  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.910975  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.927494  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.940854  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.943038  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.962400  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.977273  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424133.978018  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424134.000333  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424134.015021  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424134.055460  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424134.078552  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424134.094861  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.403395  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.407380  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.411393  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.415414  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.419771  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.424243  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.429128  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.433635  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.437325  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.439529  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.439573  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.441360  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.443615  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.444501  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.445429  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.447695  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.449520  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.450597  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.451803  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.453932  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.456186  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.456826  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.458497  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.460730  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.463657  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.463669  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.465656  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.468246  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.470458  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.472760  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.473830  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.476309  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.478884  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.481428  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.481890  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.485095  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.487720  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.491281  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.491455  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.494196  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.498156  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.501088  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.507332  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.510469  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.516637  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.518776  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.519880  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.526040  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.529457  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.530113  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.547610  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.554075  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.554245  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.557541  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.561057  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.565600  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.569091  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.569858  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.576671  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.582476  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.583211  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.583703  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.589983  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.591688  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.596779  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.598329  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.600459  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.605525  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.607290  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.607907  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.612638  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.614215  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.614962  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.619952  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.623405  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.623406  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.628317  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.630652  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.632150  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.635194  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.637774  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.644833  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.646074  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.651917  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.653198  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.660255  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.663111  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.668931  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.670345  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.677887  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.678851  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.687730  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.714307  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.728494  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.734007  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.765168  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.785387  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.793665  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.830779  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.850601  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.856352  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.893822  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.913989  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.921456  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.959249  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424135.979328  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424136.000671  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424136.039338  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424136.059596  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424136.148795  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424136.188260  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424136.208948  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.844703  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.851855  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.859135  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.866498  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.874430  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.883182  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.892854  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.895785  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.897455  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.902006  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.903017  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.904660  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.910381  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.911993  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.913232  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.917849  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.919416  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.922859  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.925818  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.927970  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.934910  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.934918  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.936710  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.944833  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.946626  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.947040  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.954126  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.955922  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.959767  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.965502  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.967258  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.975396  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.976995  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.977887  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.987629  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.989084  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.995072  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424138.999959  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.001425  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.012985  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.013289  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.014330  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.031388  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.032378  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.048920  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.049682  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.064226  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.067377  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.067979  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.086165  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.115947  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.119021  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.119284  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.123907  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.127454  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.131008  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.135665  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.139208  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.141228  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.141612  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.143564  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.147069  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.151941  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.155575  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.159795  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.164295  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.167577  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.171619  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.179907  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.183484  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.187137  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.191671  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.192056  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.195695  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.197951  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.199989  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.203458  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.205875  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.208384  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.209479  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.212077  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.213407  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.213439  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.216354  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.218281  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.220862  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.221950  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.226291  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.229791  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.234767  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.238492  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.242807  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.246553  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.247383  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.248872  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.270925  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.275698  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.278457  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.297694  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.304549  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.310972  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.331264  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.336865  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.346166  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.363392  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.369179  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.395729  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.405705  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.425008  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.432468  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.486660  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424139.511777  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.712925  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.716737  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.720283  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.724037  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.728060  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.732077  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.736368  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.740419  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.744931  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.749411  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.755280  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.761189  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.767692  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.776339  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.785214  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.785985  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.789212  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.792888  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.794914  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.796865  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.800936  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.801430  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.804971  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.805330  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.808961  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.809267  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.812829  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.813324  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.816900  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.817455  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.818169  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.821039  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.822971  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.825452  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.828541  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.828797  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.829851  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.834784  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.834790  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.839342  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.841474  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.845222  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.846150  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.847353  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.848470  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.849736  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.850320  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.850872  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.851141  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.852043  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.853488  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.854997  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.856566  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.857770  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.857957  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.859300  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.859884  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.860649  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.866411  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.868238  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.868716  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.875980  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.877025  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.884804  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.885556  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.891327  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.893848  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.902400  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.902511  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.907580  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.918851  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.918978  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.919915  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.921120  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.922238  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.923492  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.924626  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.925785  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.927229  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.928735  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.930307  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.931633  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.931757  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.932979  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.934316  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.935102  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.941815  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.949734  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.950656  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.950957  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.952090  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.953378  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.954513  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.955695  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.957171  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.958702  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.959212  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.960328  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.961580  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.962917  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.964277  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.967540  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.971904  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.976005  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.980871  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.989447  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.992638  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424140.997809  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.006279  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.009112  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.022754  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.039036  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.231601  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.232771  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.233904  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.235024  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.236210  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.237486  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.238750  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.239916  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.241213  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.242474  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.243972  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.245457  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.247196  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.249262  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.251805  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.253930  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.274087  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.279948  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.282692  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.294010  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.294436  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.294828  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.295246  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.295663  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.296138  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.296606  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.297891  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.299350  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.300939  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.302632  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.304687  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.307183  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.307328  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.308511  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.309084  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.309670  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.310793  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.312000  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.313285  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.314559  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.315739  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.317051  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.318331  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.319842  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.321357  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.323110  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.325201  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.327329  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.327959  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.327971  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.328357  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.328748  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.329163  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.329573  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.330009  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.330196  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.330439  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.330881  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.331247  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.331724  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.332104  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.332588  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.332970  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.333478  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.333874  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.334339  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.334961  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.335528  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.335944  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.337128  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.337374  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.338296  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.338825  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.339443  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.340645  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.342021  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.342032  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.343296  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.344475  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.345781  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.347069  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.348582  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.350091  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.350523  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.351859  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.353952  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.356616  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.356683  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.357521  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.357869  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.358151  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.358428  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.358955  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.359052  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.359398  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.359836  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.360600  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.361327  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.362046  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.363494  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.365492  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.367134  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.368766  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.369075  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.369412  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.369709  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.370140  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.370423  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.370711  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.370715  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.371111  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.371219  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.371539  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.371671  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.371843  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.372326  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.372337  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.372754  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.372856  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.373143  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.373355  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.373561  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.373939  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.374041  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.375184  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.375289  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.375644  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.376049  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.376559  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.376785  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.378396  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.379162  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.379623  564761 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.380188  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.382277  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.384718  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.385087  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.386625  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.387848  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.390978  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.402490  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.402924  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.403322  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.403737  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.404153  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.404634  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.405205  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.405216  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.405621  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.406005  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.406440  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.406601  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.406862  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.407272  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.407685  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.408212  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.408292  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.408739  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.409107  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.409590  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.409914  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.410127  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.410632  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.411020  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.411654  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.411724  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.412068  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.412542  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.413184  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.413890  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.413968  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.415749  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.416406  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.417230  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.418310  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.420372  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.435902  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.436245  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.436626  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.436744  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.436928  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.437166  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.437616  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.437693  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.438093  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.438493  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.438600  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.439016  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.439322  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.439490  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.439927  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.440096  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.440383  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.440793  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.440933  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.441289  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.441672  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.442156  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.442448  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.442622  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.443127  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.443528  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.444000  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.444500  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.444664  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.445233  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.446167  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.447084  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.447830  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.448147  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.448610  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.448687  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.448924  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.449362  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.449645  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.449940  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.450262  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.450580  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.450855  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.451145  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.451443  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.451925  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.451995  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.452396  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.452793  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.453840  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.454304  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.454719  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.455240  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.458304  564789 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.467622  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.467964  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.468255  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.468538  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.469074  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.469846  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.470607  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.471342  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.472070  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.473525  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.475493  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.477153  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.478794  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.479112  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.479449  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.479750  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.480180  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.480461  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.480749  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.481071  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.481386  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.481665  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.481955  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.482252  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.482628  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.483022  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.483414  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.484452  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.484908  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.485332  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.485846  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728424141.488887  564745 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 573ms/step - loss: 0.4809 - val_loss: 0.2128 - learning_rate: 0.0010\n",
      "Epoch 2/1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 21:49:01.694099: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 21:49:04.691308: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0254 - val_loss: 0.2004 - learning_rate: 0.0010\n",
      "Epoch 3/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0233 - val_loss: 0.1956 - learning_rate: 0.0010\n",
      "Epoch 4/1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 21:49:08.477886: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.0211 - val_loss: 0.2042 - learning_rate: 0.0010\n",
      "Epoch 5/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0189 - val_loss: 0.2175 - learning_rate: 0.0010\n",
      "Epoch 6/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0179"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 21:49:18.022200: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0179 - val_loss: 0.2292 - learning_rate: 0.0010\n",
      "Epoch 7/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0173 - val_loss: 0.2397 - learning_rate: 0.0010\n",
      "Epoch 8/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0170 - val_loss: 0.2466 - learning_rate: 0.0010\n",
      "Epoch 9/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0166 - val_loss: 0.2531 - learning_rate: 0.0010\n",
      "Epoch 10/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0164 - val_loss: 0.2517 - learning_rate: 0.0010\n",
      "Epoch 11/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0162 - val_loss: 0.2495 - learning_rate: 0.0010\n",
      "Epoch 12/1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 21:49:35.342229: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0159 - val_loss: 0.2489 - learning_rate: 0.0010\n",
      "Epoch 13/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0157\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0157 - val_loss: 0.2367 - learning_rate: 0.0010\n",
      "Epoch 14/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0154 - val_loss: 0.2204 - learning_rate: 9.0000e-04\n",
      "Epoch 15/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0152 - val_loss: 0.2110 - learning_rate: 9.0000e-04\n",
      "Epoch 16/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0151 - val_loss: 0.1963 - learning_rate: 9.0000e-04\n",
      "Epoch 17/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0149 - val_loss: 0.1920 - learning_rate: 9.0000e-04\n",
      "Epoch 18/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0147 - val_loss: 0.1726 - learning_rate: 9.0000e-04\n",
      "Epoch 19/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 0.0145 - val_loss: 0.1574 - learning_rate: 9.0000e-04\n",
      "Epoch 20/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0144 - val_loss: 0.1513 - learning_rate: 9.0000e-04\n",
      "Epoch 21/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0142 - val_loss: 0.1508 - learning_rate: 9.0000e-04\n",
      "Epoch 22/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0140"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 21:50:12.252903: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0140 - val_loss: 0.1273 - learning_rate: 9.0000e-04\n",
      "Epoch 23/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0139 - val_loss: 0.1075 - learning_rate: 9.0000e-04\n",
      "Epoch 24/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0138 - val_loss: 0.0885 - learning_rate: 9.0000e-04\n",
      "Epoch 25/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0138 - val_loss: 0.0782 - learning_rate: 9.0000e-04\n",
      "Epoch 26/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0136 - val_loss: 0.0743 - learning_rate: 9.0000e-04\n",
      "Epoch 27/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 0.0135 - val_loss: 0.0519 - learning_rate: 9.0000e-04\n",
      "Epoch 28/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0133 - val_loss: 0.0477 - learning_rate: 9.0000e-04\n",
      "Epoch 29/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0131 - val_loss: 0.0360 - learning_rate: 9.0000e-04\n",
      "Epoch 30/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0130 - val_loss: 0.0247 - learning_rate: 9.0000e-04\n",
      "Epoch 31/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0129 - val_loss: 0.0171 - learning_rate: 9.0000e-04\n",
      "Epoch 32/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 0.0127 - val_loss: 0.0149 - learning_rate: 9.0000e-04\n",
      "Epoch 33/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0126 - val_loss: 0.0170 - learning_rate: 9.0000e-04\n",
      "Epoch 34/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0125 - val_loss: 0.0183 - learning_rate: 9.0000e-04\n",
      "Epoch 35/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0124 - val_loss: 0.0400 - learning_rate: 9.0000e-04\n",
      "Epoch 36/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 132ms/step - loss: 0.0123 - val_loss: 0.0504 - learning_rate: 9.0000e-04\n",
      "Epoch 37/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0122 - val_loss: 0.0195 - learning_rate: 9.0000e-04\n",
      "Epoch 38/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0120 - val_loss: 0.0168 - learning_rate: 9.0000e-04\n",
      "Epoch 39/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0119 - val_loss: 0.0179 - learning_rate: 9.0000e-04\n",
      "Epoch 40/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0118 - val_loss: 0.0217 - learning_rate: 9.0000e-04\n",
      "Epoch 41/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0117 - val_loss: 0.0147 - learning_rate: 9.0000e-04\n",
      "Epoch 42/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0117 - val_loss: 0.0170 - learning_rate: 9.0000e-04\n",
      "Epoch 43/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0115 - val_loss: 0.0168 - learning_rate: 9.0000e-04\n",
      "Epoch 44/1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 21:51:24.675262: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0114 - val_loss: 0.0180 - learning_rate: 9.0000e-04\n",
      "Epoch 45/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 0.0113 - val_loss: 0.0171 - learning_rate: 9.0000e-04\n",
      "Epoch 46/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0111 - val_loss: 0.0247 - learning_rate: 9.0000e-04\n",
      "Epoch 47/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0111 - val_loss: 0.0205 - learning_rate: 9.0000e-04\n",
      "Epoch 48/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 0.0111 - val_loss: 0.0241 - learning_rate: 9.0000e-04\n",
      "Epoch 49/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0108 - val_loss: 0.0151 - learning_rate: 9.0000e-04\n",
      "Epoch 50/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0107 - val_loss: 0.0125 - learning_rate: 9.0000e-04\n",
      "Epoch 51/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0106 - val_loss: 0.0168 - learning_rate: 9.0000e-04\n",
      "Epoch 52/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 0.0105 - val_loss: 0.0130 - learning_rate: 9.0000e-04\n",
      "Epoch 53/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0105 - val_loss: 0.0123 - learning_rate: 9.0000e-04\n",
      "Epoch 54/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0103 - val_loss: 0.0125 - learning_rate: 9.0000e-04\n",
      "Epoch 55/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0102 - val_loss: 0.0129 - learning_rate: 9.0000e-04\n",
      "Epoch 56/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0102 - val_loss: 0.0142 - learning_rate: 9.0000e-04\n",
      "Epoch 57/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 0.0100 - val_loss: 0.0162 - learning_rate: 9.0000e-04\n",
      "Epoch 58/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0100 - val_loss: 0.0164 - learning_rate: 9.0000e-04\n",
      "Epoch 59/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0098 - val_loss: 0.0165 - learning_rate: 9.0000e-04\n",
      "Epoch 60/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0097 - val_loss: 0.0124 - learning_rate: 9.0000e-04\n",
      "Epoch 61/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 0.0097 - val_loss: 0.0115 - learning_rate: 9.0000e-04\n",
      "Epoch 62/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0096 - val_loss: 0.0134 - learning_rate: 9.0000e-04\n",
      "Epoch 63/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0095 - val_loss: 0.0121 - learning_rate: 9.0000e-04\n",
      "Epoch 64/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0094 - val_loss: 0.0125 - learning_rate: 9.0000e-04\n",
      "Epoch 65/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0094 - val_loss: 0.0218 - learning_rate: 9.0000e-04\n",
      "Epoch 66/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 137ms/step - loss: 0.0093 - val_loss: 0.0153 - learning_rate: 9.0000e-04\n",
      "Epoch 67/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0092 - val_loss: 0.0130 - learning_rate: 9.0000e-04\n",
      "Epoch 68/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0091 - val_loss: 0.0143 - learning_rate: 9.0000e-04\n",
      "Epoch 69/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0090 - val_loss: 0.0118 - learning_rate: 9.0000e-04\n",
      "Epoch 70/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0089 - val_loss: 0.0124 - learning_rate: 9.0000e-04\n",
      "Epoch 71/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0089\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0089 - val_loss: 0.0152 - learning_rate: 9.0000e-04\n",
      "Epoch 72/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0087 - val_loss: 0.0120 - learning_rate: 8.1000e-04\n",
      "Epoch 73/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0085 - val_loss: 0.0124 - learning_rate: 8.1000e-04\n",
      "Epoch 74/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0085 - val_loss: 0.0110 - learning_rate: 8.1000e-04\n",
      "Epoch 75/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0084 - val_loss: 0.0122 - learning_rate: 8.1000e-04\n",
      "Epoch 76/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0082 - val_loss: 0.0122 - learning_rate: 8.1000e-04\n",
      "Epoch 77/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0082 - val_loss: 0.0187 - learning_rate: 8.1000e-04\n",
      "Epoch 78/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 0.0081 - val_loss: 0.0159 - learning_rate: 8.1000e-04\n",
      "Epoch 79/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0080 - val_loss: 0.0130 - learning_rate: 8.1000e-04\n",
      "Epoch 80/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0079 - val_loss: 0.0136 - learning_rate: 8.1000e-04\n",
      "Epoch 81/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0079 - val_loss: 0.0123 - learning_rate: 8.1000e-04\n",
      "Epoch 82/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0078 - val_loss: 0.0152 - learning_rate: 8.1000e-04\n",
      "Epoch 83/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0077 - val_loss: 0.0167 - learning_rate: 8.1000e-04\n",
      "Epoch 84/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0075\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 0.0075 - val_loss: 0.0120 - learning_rate: 8.1000e-04\n",
      "Epoch 85/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0074 - val_loss: 0.0114 - learning_rate: 7.2900e-04\n",
      "Epoch 86/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0073"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 21:53:51.563423: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0073 - val_loss: 0.0118 - learning_rate: 7.2900e-04\n",
      "Epoch 87/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0072 - val_loss: 0.0166 - learning_rate: 7.2900e-04\n",
      "Epoch 88/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0071 - val_loss: 0.0155 - learning_rate: 7.2900e-04\n",
      "Epoch 89/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0070 - val_loss: 0.0132 - learning_rate: 7.2900e-04\n",
      "Epoch 90/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0069 - val_loss: 0.0145 - learning_rate: 7.2900e-04\n",
      "Epoch 91/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 0.0068 - val_loss: 0.0116 - learning_rate: 7.2900e-04\n",
      "Epoch 92/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0066 - val_loss: 0.0124 - learning_rate: 7.2900e-04\n",
      "Epoch 93/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0065 - val_loss: 0.0120 - learning_rate: 7.2900e-04\n",
      "Epoch 94/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0064\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0064 - val_loss: 0.0111 - learning_rate: 7.2900e-04\n",
      "Epoch 95/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0063 - val_loss: 0.0113 - learning_rate: 6.5610e-04\n",
      "Epoch 96/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0060 - val_loss: 0.0135 - learning_rate: 6.5610e-04\n",
      "Epoch 97/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0060 - val_loss: 0.0187 - learning_rate: 6.5610e-04\n",
      "Epoch 98/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0058 - val_loss: 0.0122 - learning_rate: 6.5610e-04\n",
      "Epoch 99/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0057 - val_loss: 0.0136 - learning_rate: 6.5610e-04\n",
      "Epoch 100/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0056 - val_loss: 0.0126 - learning_rate: 6.5610e-04\n",
      "Epoch 101/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0056 - val_loss: 0.0145 - learning_rate: 6.5610e-04\n",
      "Epoch 102/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 0.0054 - val_loss: 0.0119 - learning_rate: 6.5610e-04\n",
      "Epoch 103/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0053 - val_loss: 0.0148 - learning_rate: 6.5610e-04\n",
      "Epoch 104/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0051\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0051 - val_loss: 0.0156 - learning_rate: 6.5610e-04\n",
      "Epoch 105/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0049 - val_loss: 0.0152 - learning_rate: 5.9049e-04\n",
      "Epoch 106/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0047 - val_loss: 0.0131 - learning_rate: 5.9049e-04\n",
      "Epoch 107/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0046 - val_loss: 0.0123 - learning_rate: 5.9049e-04\n",
      "Epoch 108/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0044 - val_loss: 0.0138 - learning_rate: 5.9049e-04\n",
      "Epoch 109/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0043 - val_loss: 0.0131 - learning_rate: 5.9049e-04\n",
      "Epoch 110/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0041 - val_loss: 0.0126 - learning_rate: 5.9049e-04\n",
      "Epoch 111/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0040 - val_loss: 0.0129 - learning_rate: 5.9049e-04\n",
      "Epoch 112/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0039 - val_loss: 0.0164 - learning_rate: 5.9049e-04\n",
      "Epoch 113/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 0.0039 - val_loss: 0.0284 - learning_rate: 5.9049e-04\n",
      "Epoch 114/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0037\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0037 - val_loss: 0.0155 - learning_rate: 5.9049e-04\n",
      "Epoch 115/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0035 - val_loss: 0.0128 - learning_rate: 5.3144e-04\n",
      "Epoch 116/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0033 - val_loss: 0.0137 - learning_rate: 5.3144e-04\n",
      "Epoch 117/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0031 - val_loss: 0.0175 - learning_rate: 5.3144e-04\n",
      "Epoch 118/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0031 - val_loss: 0.0186 - learning_rate: 5.3144e-04\n",
      "Epoch 119/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0030 - val_loss: 0.0156 - learning_rate: 5.3144e-04\n",
      "Epoch 120/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0028 - val_loss: 0.0143 - learning_rate: 5.3144e-04\n",
      "Epoch 121/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0027 - val_loss: 0.0133 - learning_rate: 5.3144e-04\n",
      "Epoch 122/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0026 - val_loss: 0.0147 - learning_rate: 5.3144e-04\n",
      "Epoch 123/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 0.0026 - val_loss: 0.0131 - learning_rate: 5.3144e-04\n",
      "Epoch 124/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0025\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 0.0025 - val_loss: 0.0124 - learning_rate: 5.3144e-04\n",
      "Epoch 125/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0023 - val_loss: 0.0126 - learning_rate: 4.7830e-04\n",
      "Epoch 126/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0022 - val_loss: 0.0131 - learning_rate: 4.7830e-04\n",
      "Epoch 127/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0021 - val_loss: 0.0131 - learning_rate: 4.7830e-04\n",
      "Epoch 128/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0020 - val_loss: 0.0125 - learning_rate: 4.7830e-04\n",
      "Epoch 129/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0019 - val_loss: 0.0131 - learning_rate: 4.7830e-04\n",
      "Epoch 130/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0019 - val_loss: 0.0154 - learning_rate: 4.7830e-04\n",
      "Epoch 131/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0018 - val_loss: 0.0137 - learning_rate: 4.7830e-04\n",
      "Epoch 132/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0017 - val_loss: 0.0134 - learning_rate: 4.7830e-04\n",
      "Epoch 133/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0017 - val_loss: 0.0171 - learning_rate: 4.7830e-04\n",
      "Epoch 134/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0017\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0017 - val_loss: 0.0126 - learning_rate: 4.7830e-04\n",
      "Epoch 135/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0016 - val_loss: 0.0124 - learning_rate: 4.3047e-04\n",
      "Epoch 136/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0015 - val_loss: 0.0129 - learning_rate: 4.3047e-04\n",
      "Epoch 137/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0014 - val_loss: 0.0121 - learning_rate: 4.3047e-04\n",
      "Epoch 138/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0014 - val_loss: 0.0129 - learning_rate: 4.3047e-04\n",
      "Epoch 139/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0013 - val_loss: 0.0125 - learning_rate: 4.3047e-04\n",
      "Epoch 140/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0013 - val_loss: 0.0131 - learning_rate: 4.3047e-04\n",
      "Epoch 141/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0013 - val_loss: 0.0135 - learning_rate: 4.3047e-04\n",
      "Epoch 142/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0012 - val_loss: 0.0124 - learning_rate: 4.3047e-04\n",
      "Epoch 143/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0012 - val_loss: 0.0127 - learning_rate: 4.3047e-04\n",
      "Epoch 144/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0012\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0012 - val_loss: 0.0132 - learning_rate: 4.3047e-04\n",
      "Epoch 145/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0012 - val_loss: 0.0119 - learning_rate: 3.8742e-04\n",
      "Epoch 146/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0011 - val_loss: 0.0131 - learning_rate: 3.8742e-04\n",
      "Epoch 147/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0011 - val_loss: 0.0126 - learning_rate: 3.8742e-04\n",
      "Epoch 148/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0011 - val_loss: 0.0128 - learning_rate: 3.8742e-04\n",
      "Epoch 149/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0010 - val_loss: 0.0133 - learning_rate: 3.8742e-04\n",
      "Epoch 150/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 137ms/step - loss: 9.9802e-04 - val_loss: 0.0129 - learning_rate: 3.8742e-04\n",
      "Epoch 151/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 9.9580e-04 - val_loss: 0.0131 - learning_rate: 3.8742e-04\n",
      "Epoch 152/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.6749e-04 - val_loss: 0.0132 - learning_rate: 3.8742e-04\n",
      "Epoch 153/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.4812e-04 - val_loss: 0.0126 - learning_rate: 3.8742e-04\n",
      "Epoch 154/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 9.5917e-04\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.6067e-04 - val_loss: 0.0127 - learning_rate: 3.8742e-04\n",
      "Epoch 155/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.4088e-04 - val_loss: 0.0137 - learning_rate: 3.4868e-04\n",
      "Epoch 156/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.7417e-04 - val_loss: 0.0128 - learning_rate: 3.4868e-04\n",
      "Epoch 157/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.7438e-04 - val_loss: 0.0125 - learning_rate: 3.4868e-04\n",
      "Epoch 158/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.5560e-04 - val_loss: 0.0127 - learning_rate: 3.4868e-04\n",
      "Epoch 159/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.4063e-04 - val_loss: 0.0125 - learning_rate: 3.4868e-04\n",
      "Epoch 160/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 8.2736e-04 - val_loss: 0.0126 - learning_rate: 3.4868e-04\n",
      "Epoch 161/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 8.2409e-04 - val_loss: 0.0129 - learning_rate: 3.4868e-04\n",
      "Epoch 162/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.0541e-04 - val_loss: 0.0125 - learning_rate: 3.4868e-04\n",
      "Epoch 163/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 7.7931e-04 - val_loss: 0.0137 - learning_rate: 3.4868e-04\n",
      "Epoch 164/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 7.7523e-04\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 7.7645e-04 - val_loss: 0.0127 - learning_rate: 3.4868e-04\n",
      "Epoch 165/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 7.6937e-04 - val_loss: 0.0123 - learning_rate: 3.1381e-04\n",
      "Epoch 166/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 7.3881e-04 - val_loss: 0.0128 - learning_rate: 3.1381e-04\n",
      "Epoch 167/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 7.4777e-04 - val_loss: 0.0125 - learning_rate: 3.1381e-04\n",
      "Epoch 168/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 7.3525e-04 - val_loss: 0.0127 - learning_rate: 3.1381e-04\n",
      "Epoch 169/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 7.4196e-04 - val_loss: 0.0126 - learning_rate: 3.1381e-04\n",
      "Epoch 170/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 7.2323e-04 - val_loss: 0.0138 - learning_rate: 3.1381e-04\n",
      "Epoch 171/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 6.9109e-04 - val_loss: 0.0130 - learning_rate: 3.1381e-04\n",
      "Epoch 172/1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 21:58:42.756239: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 6.9944e-04 - val_loss: 0.0126 - learning_rate: 3.1381e-04\n",
      "Epoch 173/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 6.9482e-04 - val_loss: 0.0129 - learning_rate: 3.1381e-04\n",
      "Epoch 174/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 7.1064e-04\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 7.0923e-04 - val_loss: 0.0128 - learning_rate: 3.1381e-04\n",
      "Epoch 175/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 6.6105e-04 - val_loss: 0.0122 - learning_rate: 2.8243e-04\n",
      "Epoch 176/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 6.4519e-04 - val_loss: 0.0128 - learning_rate: 2.8243e-04\n",
      "Epoch 177/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 6.2160e-04 - val_loss: 0.0124 - learning_rate: 2.8243e-04\n",
      "Epoch 178/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 6.1609e-04 - val_loss: 0.0124 - learning_rate: 2.8243e-04\n",
      "Epoch 179/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 6.2768e-04 - val_loss: 0.0127 - learning_rate: 2.8243e-04\n",
      "Epoch 180/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 6.0451e-04 - val_loss: 0.0123 - learning_rate: 2.8243e-04\n",
      "Epoch 181/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 6.1292e-04 - val_loss: 0.0125 - learning_rate: 2.8243e-04\n",
      "Epoch 182/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 5.9543e-04 - val_loss: 0.0125 - learning_rate: 2.8243e-04\n",
      "Epoch 183/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 6.0546e-04 - val_loss: 0.0126 - learning_rate: 2.8243e-04\n",
      "Epoch 184/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 5.8756e-04\n",
      "Epoch 184: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 5.8817e-04 - val_loss: 0.0128 - learning_rate: 2.8243e-04\n",
      "Epoch 185/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 6.0588e-04 - val_loss: 0.0128 - learning_rate: 2.5419e-04\n",
      "Epoch 186/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 5.8424e-04 - val_loss: 0.0126 - learning_rate: 2.5419e-04\n",
      "Epoch 187/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 5.8038e-04 - val_loss: 0.0126 - learning_rate: 2.5419e-04\n",
      "Epoch 188/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 5.8167e-04 - val_loss: 0.0125 - learning_rate: 2.5419e-04\n",
      "Epoch 189/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 5.6060e-04 - val_loss: 0.0126 - learning_rate: 2.5419e-04\n",
      "Epoch 190/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 5.4784e-04 - val_loss: 0.0125 - learning_rate: 2.5419e-04\n",
      "Epoch 191/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 5.6653e-04 - val_loss: 0.0125 - learning_rate: 2.5419e-04\n",
      "Epoch 192/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 5.5088e-04 - val_loss: 0.0123 - learning_rate: 2.5419e-04\n",
      "Epoch 193/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 5.4605e-04 - val_loss: 0.0131 - learning_rate: 2.5419e-04\n",
      "Epoch 194/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 5.4754e-04\n",
      "Epoch 194: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 5.4768e-04 - val_loss: 0.0127 - learning_rate: 2.5419e-04\n",
      "Epoch 195/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 5.4396e-04 - val_loss: 0.0126 - learning_rate: 2.2877e-04\n",
      "Epoch 196/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 5.4795e-04 - val_loss: 0.0129 - learning_rate: 2.2877e-04\n",
      "Epoch 197/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 5.2009e-04 - val_loss: 0.0124 - learning_rate: 2.2877e-04\n",
      "Epoch 198/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 5.1421e-04 - val_loss: 0.0124 - learning_rate: 2.2877e-04\n",
      "Epoch 199/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.9569e-04 - val_loss: 0.0124 - learning_rate: 2.2877e-04\n",
      "Epoch 200/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 5.0113e-04 - val_loss: 0.0126 - learning_rate: 2.2877e-04\n",
      "Epoch 201/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 5.1589e-04 - val_loss: 0.0132 - learning_rate: 2.2877e-04\n",
      "Epoch 202/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 4.9899e-04 - val_loss: 0.0125 - learning_rate: 2.2877e-04\n",
      "Epoch 203/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.8366e-04 - val_loss: 0.0125 - learning_rate: 2.2877e-04\n",
      "Epoch 204/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 4.8845e-04\n",
      "Epoch 204: ReduceLROnPlateau reducing learning rate to 0.00020589114428730683.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.8806e-04 - val_loss: 0.0124 - learning_rate: 2.2877e-04\n",
      "Epoch 205/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.8709e-04 - val_loss: 0.0127 - learning_rate: 2.0589e-04\n",
      "Epoch 206/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.8854e-04 - val_loss: 0.0122 - learning_rate: 2.0589e-04\n",
      "Epoch 207/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.8341e-04 - val_loss: 0.0126 - learning_rate: 2.0589e-04\n",
      "Epoch 208/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.7096e-04 - val_loss: 0.0125 - learning_rate: 2.0589e-04\n",
      "Epoch 209/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 4.6713e-04 - val_loss: 0.0126 - learning_rate: 2.0589e-04\n",
      "Epoch 210/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 4.6704e-04 - val_loss: 0.0125 - learning_rate: 2.0589e-04\n",
      "Epoch 211/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.6639e-04 - val_loss: 0.0127 - learning_rate: 2.0589e-04\n",
      "Epoch 212/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 4.7384e-04 - val_loss: 0.0125 - learning_rate: 2.0589e-04\n",
      "Epoch 213/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 4.6844e-04 - val_loss: 0.0125 - learning_rate: 2.0589e-04\n",
      "Epoch 214/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 4.7287e-04\n",
      "Epoch 214: ReduceLROnPlateau reducing learning rate to 0.00018530203378759326.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.7263e-04 - val_loss: 0.0128 - learning_rate: 2.0589e-04\n",
      "Epoch 215/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 4.6107e-04 - val_loss: 0.0127 - learning_rate: 1.8530e-04\n",
      "Epoch 216/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.5548e-04 - val_loss: 0.0126 - learning_rate: 1.8530e-04\n",
      "Epoch 217/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 4.4807e-04 - val_loss: 0.0127 - learning_rate: 1.8530e-04\n",
      "Epoch 218/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 4.4147e-04 - val_loss: 0.0128 - learning_rate: 1.8530e-04\n",
      "Epoch 219/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 4.5882e-04 - val_loss: 0.0123 - learning_rate: 1.8530e-04\n",
      "Epoch 220/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.2642e-04 - val_loss: 0.0128 - learning_rate: 1.8530e-04\n",
      "Epoch 221/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 4.5286e-04 - val_loss: 0.0126 - learning_rate: 1.8530e-04\n",
      "Epoch 222/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 137ms/step - loss: 4.3604e-04 - val_loss: 0.0126 - learning_rate: 1.8530e-04\n",
      "Epoch 223/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 4.4796e-04 - val_loss: 0.0126 - learning_rate: 1.8530e-04\n",
      "Epoch 224/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 4.2085e-04\n",
      "Epoch 224: ReduceLROnPlateau reducing learning rate to 0.00016677183302817866.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.2097e-04 - val_loss: 0.0125 - learning_rate: 1.8530e-04\n",
      "Epoch 225/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.3378e-04 - val_loss: 0.0127 - learning_rate: 1.6677e-04\n",
      "Epoch 226/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.2935e-04 - val_loss: 0.0122 - learning_rate: 1.6677e-04\n",
      "Epoch 227/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 4.1137e-04 - val_loss: 0.0129 - learning_rate: 1.6677e-04\n",
      "Epoch 228/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 4.1888e-04 - val_loss: 0.0126 - learning_rate: 1.6677e-04\n",
      "Epoch 229/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.1715e-04 - val_loss: 0.0127 - learning_rate: 1.6677e-04\n",
      "Epoch 230/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.0837e-04 - val_loss: 0.0128 - learning_rate: 1.6677e-04\n",
      "Epoch 231/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 4.1164e-04 - val_loss: 0.0125 - learning_rate: 1.6677e-04\n",
      "Epoch 232/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 4.0373e-04 - val_loss: 0.0124 - learning_rate: 1.6677e-04\n",
      "Epoch 233/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.0647e-04 - val_loss: 0.0127 - learning_rate: 1.6677e-04\n",
      "Epoch 234/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.9616e-04\n",
      "Epoch 234: ReduceLROnPlateau reducing learning rate to 0.00015009464841568844.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 3.9618e-04 - val_loss: 0.0125 - learning_rate: 1.6677e-04\n",
      "Epoch 235/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.9285e-04 - val_loss: 0.0126 - learning_rate: 1.5009e-04\n",
      "Epoch 236/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 3.8724e-04 - val_loss: 0.0126 - learning_rate: 1.5009e-04\n",
      "Epoch 237/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.8490e-04 - val_loss: 0.0127 - learning_rate: 1.5009e-04\n",
      "Epoch 238/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 3.7702e-04 - val_loss: 0.0127 - learning_rate: 1.5009e-04\n",
      "Epoch 239/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.7906e-04 - val_loss: 0.0128 - learning_rate: 1.5009e-04\n",
      "Epoch 240/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 3.8318e-04 - val_loss: 0.0124 - learning_rate: 1.5009e-04\n",
      "Epoch 241/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.7541e-04 - val_loss: 0.0127 - learning_rate: 1.5009e-04\n",
      "Epoch 242/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.7659e-04 - val_loss: 0.0127 - learning_rate: 1.5009e-04\n",
      "Epoch 243/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.8271e-04 - val_loss: 0.0128 - learning_rate: 1.5009e-04\n",
      "Epoch 244/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 3.9222e-04\n",
      "Epoch 244: ReduceLROnPlateau reducing learning rate to 0.0001350851875031367.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.9219e-04 - val_loss: 0.0127 - learning_rate: 1.5009e-04\n",
      "Epoch 245/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.7713e-04 - val_loss: 0.0123 - learning_rate: 1.3509e-04\n",
      "Epoch 246/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.7282e-04 - val_loss: 0.0127 - learning_rate: 1.3509e-04\n",
      "Epoch 247/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.7614e-04 - val_loss: 0.0126 - learning_rate: 1.3509e-04\n",
      "Epoch 248/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.7127e-04 - val_loss: 0.0128 - learning_rate: 1.3509e-04\n",
      "Epoch 249/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.6365e-04 - val_loss: 0.0124 - learning_rate: 1.3509e-04\n",
      "Epoch 250/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.6099e-04 - val_loss: 0.0125 - learning_rate: 1.3509e-04\n",
      "Epoch 251/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.7078e-04 - val_loss: 0.0124 - learning_rate: 1.3509e-04\n",
      "Epoch 252/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 3.5499e-04 - val_loss: 0.0127 - learning_rate: 1.3509e-04\n",
      "Epoch 253/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 3.5098e-04 - val_loss: 0.0127 - learning_rate: 1.3509e-04\n",
      "Epoch 254/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.6258e-04\n",
      "Epoch 254: ReduceLROnPlateau reducing learning rate to 0.00012157666351413355.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 3.6297e-04 - val_loss: 0.0127 - learning_rate: 1.3509e-04\n",
      "Epoch 255/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.5361e-04 - val_loss: 0.0128 - learning_rate: 1.2158e-04\n",
      "Epoch 256/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.5735e-04 - val_loss: 0.0126 - learning_rate: 1.2158e-04\n",
      "Epoch 257/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.4487e-04 - val_loss: 0.0125 - learning_rate: 1.2158e-04\n",
      "Epoch 258/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.4917e-04 - val_loss: 0.0127 - learning_rate: 1.2158e-04\n",
      "Epoch 259/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.4570e-04 - val_loss: 0.0125 - learning_rate: 1.2158e-04\n",
      "Epoch 260/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.3676e-04 - val_loss: 0.0123 - learning_rate: 1.2158e-04\n",
      "Epoch 261/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.3616e-04 - val_loss: 0.0129 - learning_rate: 1.2158e-04\n",
      "Epoch 262/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 3.3644e-04 - val_loss: 0.0124 - learning_rate: 1.2158e-04\n",
      "Epoch 263/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.4310e-04 - val_loss: 0.0128 - learning_rate: 1.2158e-04\n",
      "Epoch 264/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.3708e-04\n",
      "Epoch 264: ReduceLROnPlateau reducing learning rate to 0.00010941899454337544.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.3698e-04 - val_loss: 0.0126 - learning_rate: 1.2158e-04\n",
      "Epoch 265/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.3659e-04 - val_loss: 0.0126 - learning_rate: 1.0942e-04\n",
      "Epoch 266/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.2981e-04 - val_loss: 0.0126 - learning_rate: 1.0942e-04\n",
      "Epoch 267/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.3261e-04 - val_loss: 0.0121 - learning_rate: 1.0942e-04\n",
      "Epoch 268/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.3372e-04 - val_loss: 0.0125 - learning_rate: 1.0942e-04\n",
      "Epoch 269/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 3.2361e-04 - val_loss: 0.0125 - learning_rate: 1.0942e-04\n",
      "Epoch 270/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.2894e-04 - val_loss: 0.0129 - learning_rate: 1.0942e-04\n",
      "Epoch 271/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 3.2913e-04 - val_loss: 0.0129 - learning_rate: 1.0942e-04\n",
      "Epoch 272/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 3.3205e-04 - val_loss: 0.0125 - learning_rate: 1.0942e-04\n",
      "Epoch 273/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 3.3496e-04 - val_loss: 0.0124 - learning_rate: 1.0942e-04\n",
      "Epoch 274/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 3.2732e-04\n",
      "Epoch 274: ReduceLROnPlateau reducing learning rate to 9.847709443420172e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.2823e-04 - val_loss: 0.0129 - learning_rate: 1.0942e-04\n",
      "Epoch 275/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.3815e-04 - val_loss: 0.0124 - learning_rate: 9.8477e-05\n",
      "Epoch 276/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.2390e-04 - val_loss: 0.0125 - learning_rate: 9.8477e-05\n",
      "Epoch 277/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.1452e-04 - val_loss: 0.0126 - learning_rate: 9.8477e-05\n",
      "Epoch 278/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.1848e-04 - val_loss: 0.0127 - learning_rate: 9.8477e-05\n",
      "Epoch 279/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 3.1336e-04 - val_loss: 0.0126 - learning_rate: 9.8477e-05\n",
      "Epoch 280/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.2639e-04 - val_loss: 0.0125 - learning_rate: 9.8477e-05\n",
      "Epoch 281/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 3.1587e-04 - val_loss: 0.0129 - learning_rate: 9.8477e-05\n",
      "Epoch 282/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.2141e-04 - val_loss: 0.0128 - learning_rate: 9.8477e-05\n",
      "Epoch 283/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 3.1174e-04 - val_loss: 0.0130 - learning_rate: 9.8477e-05\n",
      "Epoch 284/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.1478e-04\n",
      "Epoch 284: ReduceLROnPlateau reducing learning rate to 8.862938630045391e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.1465e-04 - val_loss: 0.0124 - learning_rate: 9.8477e-05\n",
      "Epoch 285/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 3.0741e-04 - val_loss: 0.0126 - learning_rate: 8.8629e-05\n",
      "Epoch 286/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 2.9692e-04 - val_loss: 0.0127 - learning_rate: 8.8629e-05\n",
      "Epoch 287/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 2.9838e-04 - val_loss: 0.0125 - learning_rate: 8.8629e-05\n",
      "Epoch 288/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.0416e-04 - val_loss: 0.0126 - learning_rate: 8.8629e-05\n",
      "Epoch 289/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.0685e-04 - val_loss: 0.0126 - learning_rate: 8.8629e-05\n",
      "Epoch 290/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.0107e-04 - val_loss: 0.0124 - learning_rate: 8.8629e-05\n",
      "Epoch 291/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.0736e-04 - val_loss: 0.0127 - learning_rate: 8.8629e-05\n",
      "Epoch 292/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 3.0194e-04 - val_loss: 0.0125 - learning_rate: 8.8629e-05\n",
      "Epoch 293/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.9659e-04 - val_loss: 0.0128 - learning_rate: 8.8629e-05\n",
      "Epoch 294/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.1233e-04\n",
      "Epoch 294: ReduceLROnPlateau reducing learning rate to 7.976644701557234e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.1207e-04 - val_loss: 0.0128 - learning_rate: 8.8629e-05\n",
      "Epoch 295/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.9990e-04 - val_loss: 0.0124 - learning_rate: 7.9766e-05\n",
      "Epoch 296/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 2.9590e-04 - val_loss: 0.0126 - learning_rate: 7.9766e-05\n",
      "Epoch 297/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.9946e-04 - val_loss: 0.0127 - learning_rate: 7.9766e-05\n",
      "Epoch 298/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.9275e-04 - val_loss: 0.0125 - learning_rate: 7.9766e-05\n",
      "Epoch 299/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.9428e-04 - val_loss: 0.0125 - learning_rate: 7.9766e-05\n",
      "Epoch 300/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.8096e-04 - val_loss: 0.0127 - learning_rate: 7.9766e-05\n",
      "Epoch 301/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.9220e-04 - val_loss: 0.0125 - learning_rate: 7.9766e-05\n",
      "Epoch 302/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 2.8321e-04 - val_loss: 0.0125 - learning_rate: 7.9766e-05\n",
      "Epoch 303/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.7914e-04 - val_loss: 0.0124 - learning_rate: 7.9766e-05\n",
      "Epoch 304/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 2.9601e-04\n",
      "Epoch 304: ReduceLROnPlateau reducing learning rate to 7.178980231401511e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.9578e-04 - val_loss: 0.0126 - learning_rate: 7.9766e-05\n",
      "Epoch 305/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 2.7588e-04 - val_loss: 0.0125 - learning_rate: 7.1790e-05\n",
      "Epoch 306/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 2.7433e-04 - val_loss: 0.0128 - learning_rate: 7.1790e-05\n",
      "Epoch 307/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.7964e-04 - val_loss: 0.0125 - learning_rate: 7.1790e-05\n",
      "Epoch 308/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.7997e-04 - val_loss: 0.0128 - learning_rate: 7.1790e-05\n",
      "Epoch 309/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.8694e-04 - val_loss: 0.0126 - learning_rate: 7.1790e-05\n",
      "Epoch 310/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.7580e-04 - val_loss: 0.0130 - learning_rate: 7.1790e-05\n",
      "Epoch 311/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.8163e-04 - val_loss: 0.0125 - learning_rate: 7.1790e-05\n",
      "Epoch 312/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.7730e-04 - val_loss: 0.0130 - learning_rate: 7.1790e-05\n",
      "Epoch 313/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 2.7894e-04 - val_loss: 0.0130 - learning_rate: 7.1790e-05\n",
      "Epoch 314/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 2.7851e-04\n",
      "Epoch 314: ReduceLROnPlateau reducing learning rate to 6.461082011810504e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.7853e-04 - val_loss: 0.0124 - learning_rate: 7.1790e-05\n",
      "Epoch 315/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.6815e-04 - val_loss: 0.0125 - learning_rate: 6.4611e-05\n",
      "Epoch 316/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.6697e-04 - val_loss: 0.0126 - learning_rate: 6.4611e-05\n",
      "Epoch 317/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.7672e-04 - val_loss: 0.0126 - learning_rate: 6.4611e-05\n",
      "Epoch 318/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.7269e-04 - val_loss: 0.0127 - learning_rate: 6.4611e-05\n",
      "Epoch 319/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.7012e-04 - val_loss: 0.0127 - learning_rate: 6.4611e-05\n",
      "Epoch 320/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 2.7115e-04 - val_loss: 0.0125 - learning_rate: 6.4611e-05\n",
      "Epoch 321/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.6309e-04 - val_loss: 0.0128 - learning_rate: 6.4611e-05\n",
      "Epoch 322/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.7171e-04 - val_loss: 0.0126 - learning_rate: 6.4611e-05\n",
      "Epoch 323/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.7171e-04 - val_loss: 0.0127 - learning_rate: 6.4611e-05\n",
      "Epoch 324/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 2.6742e-04\n",
      "Epoch 324: ReduceLROnPlateau reducing learning rate to 5.8149741380475466e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.6752e-04 - val_loss: 0.0126 - learning_rate: 6.4611e-05\n",
      "Epoch 325/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.7001e-04 - val_loss: 0.0127 - learning_rate: 5.8150e-05\n",
      "Epoch 326/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.6490e-04 - val_loss: 0.0129 - learning_rate: 5.8150e-05\n",
      "Epoch 327/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.6145e-04 - val_loss: 0.0127 - learning_rate: 5.8150e-05\n",
      "Epoch 328/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.6916e-04 - val_loss: 0.0126 - learning_rate: 5.8150e-05\n",
      "Epoch 329/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.6284e-04 - val_loss: 0.0128 - learning_rate: 5.8150e-05\n",
      "Epoch 330/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.5818e-04 - val_loss: 0.0127 - learning_rate: 5.8150e-05\n",
      "Epoch 331/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.6207e-04 - val_loss: 0.0128 - learning_rate: 5.8150e-05\n",
      "Epoch 332/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.6160e-04 - val_loss: 0.0126 - learning_rate: 5.8150e-05\n",
      "Epoch 333/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.6121e-04 - val_loss: 0.0130 - learning_rate: 5.8150e-05\n",
      "Epoch 334/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 2.5475e-04\n",
      "Epoch 334: ReduceLROnPlateau reducing learning rate to 5.233476658759173e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 2.5475e-04 - val_loss: 0.0126 - learning_rate: 5.8150e-05\n",
      "Epoch 335/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 2.5365e-04 - val_loss: 0.0127 - learning_rate: 5.2335e-05\n",
      "Epoch 336/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 2.5854e-04 - val_loss: 0.0126 - learning_rate: 5.2335e-05\n",
      "Epoch 337/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.5434e-04 - val_loss: 0.0126 - learning_rate: 5.2335e-05\n",
      "Epoch 338/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.5075e-04 - val_loss: 0.0127 - learning_rate: 5.2335e-05\n",
      "Epoch 339/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.5551e-04 - val_loss: 0.0128 - learning_rate: 5.2335e-05\n",
      "Epoch 340/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.5103e-04 - val_loss: 0.0128 - learning_rate: 5.2335e-05\n",
      "Epoch 341/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.5310e-04 - val_loss: 0.0127 - learning_rate: 5.2335e-05\n",
      "Epoch 342/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 2.4832e-04 - val_loss: 0.0127 - learning_rate: 5.2335e-05\n",
      "Epoch 343/1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 22:08:29.282923: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.5623e-04 - val_loss: 0.0129 - learning_rate: 5.2335e-05\n",
      "Epoch 344/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 2.5534e-04\n",
      "Epoch 344: ReduceLROnPlateau reducing learning rate to 4.7101289601414466e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.5580e-04 - val_loss: 0.0127 - learning_rate: 5.2335e-05\n",
      "Epoch 345/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.4925e-04 - val_loss: 0.0128 - learning_rate: 4.7101e-05\n",
      "Epoch 346/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.4759e-04 - val_loss: 0.0124 - learning_rate: 4.7101e-05\n",
      "Epoch 347/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.4656e-04 - val_loss: 0.0126 - learning_rate: 4.7101e-05\n",
      "Epoch 348/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.4900e-04 - val_loss: 0.0129 - learning_rate: 4.7101e-05\n",
      "Epoch 349/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.4984e-04 - val_loss: 0.0127 - learning_rate: 4.7101e-05\n",
      "Epoch 350/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.4431e-04 - val_loss: 0.0125 - learning_rate: 4.7101e-05\n",
      "Epoch 351/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.5055e-04 - val_loss: 0.0128 - learning_rate: 4.7101e-05\n",
      "Epoch 352/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.4502e-04 - val_loss: 0.0125 - learning_rate: 4.7101e-05\n",
      "Epoch 353/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.3827e-04 - val_loss: 0.0128 - learning_rate: 4.7101e-05\n",
      "Epoch 354/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 2.4533e-04\n",
      "Epoch 354: ReduceLROnPlateau reducing learning rate to 4.239116096869111e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.4527e-04 - val_loss: 0.0128 - learning_rate: 4.7101e-05\n",
      "Epoch 355/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.4308e-04 - val_loss: 0.0128 - learning_rate: 4.2391e-05\n",
      "Epoch 356/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.3782e-04 - val_loss: 0.0128 - learning_rate: 4.2391e-05\n",
      "Epoch 357/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 2.4075e-04 - val_loss: 0.0127 - learning_rate: 4.2391e-05\n",
      "Epoch 358/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.4486e-04 - val_loss: 0.0128 - learning_rate: 4.2391e-05\n",
      "Epoch 359/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.3695e-04 - val_loss: 0.0127 - learning_rate: 4.2391e-05\n",
      "Epoch 360/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 2.3677e-04 - val_loss: 0.0125 - learning_rate: 4.2391e-05\n",
      "Epoch 361/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 137ms/step - loss: 2.3515e-04 - val_loss: 0.0124 - learning_rate: 4.2391e-05\n",
      "Epoch 362/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.3671e-04 - val_loss: 0.0126 - learning_rate: 4.2391e-05\n",
      "Epoch 363/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.3529e-04 - val_loss: 0.0125 - learning_rate: 4.2391e-05\n",
      "Epoch 364/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 2.3917e-04\n",
      "Epoch 364: ReduceLROnPlateau reducing learning rate to 3.815204618149437e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.3933e-04 - val_loss: 0.0127 - learning_rate: 4.2391e-05\n",
      "Epoch 365/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.3832e-04 - val_loss: 0.0126 - learning_rate: 3.8152e-05\n",
      "Epoch 366/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.3859e-04 - val_loss: 0.0124 - learning_rate: 3.8152e-05\n",
      "Epoch 367/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.3814e-04 - val_loss: 0.0127 - learning_rate: 3.8152e-05\n",
      "Epoch 368/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.3340e-04 - val_loss: 0.0125 - learning_rate: 3.8152e-05\n",
      "Epoch 369/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.3844e-04 - val_loss: 0.0128 - learning_rate: 3.8152e-05\n",
      "Epoch 370/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.3560e-04 - val_loss: 0.0125 - learning_rate: 3.8152e-05\n",
      "Epoch 371/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.3350e-04 - val_loss: 0.0125 - learning_rate: 3.8152e-05\n",
      "Epoch 372/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.3542e-04 - val_loss: 0.0126 - learning_rate: 3.8152e-05\n",
      "Epoch 373/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.3055e-04 - val_loss: 0.0130 - learning_rate: 3.8152e-05\n",
      "Epoch 374/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 2.3205e-04\n",
      "Epoch 374: ReduceLROnPlateau reducing learning rate to 3.4336842873017304e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.3202e-04 - val_loss: 0.0127 - learning_rate: 3.8152e-05\n",
      "Epoch 375/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.3032e-04 - val_loss: 0.0128 - learning_rate: 3.4337e-05\n",
      "Epoch 376/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.2691e-04 - val_loss: 0.0128 - learning_rate: 3.4337e-05\n",
      "Epoch 377/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.2843e-04 - val_loss: 0.0128 - learning_rate: 3.4337e-05\n",
      "Epoch 378/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 2.2987e-04 - val_loss: 0.0126 - learning_rate: 3.4337e-05\n",
      "Epoch 379/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.2417e-04 - val_loss: 0.0127 - learning_rate: 3.4337e-05\n",
      "Epoch 380/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.2943e-04 - val_loss: 0.0126 - learning_rate: 3.4337e-05\n",
      "Epoch 381/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.2380e-04 - val_loss: 0.0125 - learning_rate: 3.4337e-05\n",
      "Epoch 382/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.2669e-04 - val_loss: 0.0129 - learning_rate: 3.4337e-05\n",
      "Epoch 383/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.2408e-04 - val_loss: 0.0126 - learning_rate: 3.4337e-05\n",
      "Epoch 384/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 2.2402e-04\n",
      "Epoch 384: ReduceLROnPlateau reducing learning rate to 3.0903160222806036e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.2390e-04 - val_loss: 0.0129 - learning_rate: 3.4337e-05\n",
      "Epoch 385/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.3224e-04 - val_loss: 0.0126 - learning_rate: 3.0903e-05\n",
      "Epoch 386/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.2416e-04 - val_loss: 0.0130 - learning_rate: 3.0903e-05\n",
      "Epoch 387/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 2.2730e-04 - val_loss: 0.0128 - learning_rate: 3.0903e-05\n",
      "Epoch 388/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.2116e-04 - val_loss: 0.0128 - learning_rate: 3.0903e-05\n",
      "Epoch 389/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1901e-04 - val_loss: 0.0129 - learning_rate: 3.0903e-05\n",
      "Epoch 390/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.3110e-04 - val_loss: 0.0126 - learning_rate: 3.0903e-05\n",
      "Epoch 391/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 2.2316e-04 - val_loss: 0.0128 - learning_rate: 3.0903e-05\n",
      "Epoch 392/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 2.2343e-04 - val_loss: 0.0128 - learning_rate: 3.0903e-05\n",
      "Epoch 393/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 2.2219e-04 - val_loss: 0.0127 - learning_rate: 3.0903e-05\n",
      "Epoch 394/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 2.2198e-04\n",
      "Epoch 394: ReduceLROnPlateau reducing learning rate to 3e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 2.2199e-04 - val_loss: 0.0126 - learning_rate: 3.0903e-05\n",
      "Epoch 395/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.2705e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 396/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.2016e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 397/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1657e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 398/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.2164e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 399/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.2360e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 400/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.1978e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 401/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.2340e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 402/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1951e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 403/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.1694e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 404/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.2062e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 405/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1454e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 406/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.2127e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 407/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.1986e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 408/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.1866e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 409/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 2.1831e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 410/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.2141e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 411/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.2039e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 412/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.2033e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 413/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 2.2095e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 414/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 2.2484e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 415/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 2.1871e-04 - val_loss: 0.0124 - learning_rate: 3.0000e-05\n",
      "Epoch 416/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.1574e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 417/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1319e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 418/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1676e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 419/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1770e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 420/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.2279e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 421/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1861e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 422/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1484e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 423/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.1570e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 424/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.1710e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 425/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1395e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 426/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1229e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 427/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1381e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 428/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1337e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 429/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1506e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 430/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.1428e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 431/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1345e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 432/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1157e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 433/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1598e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 434/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.0898e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 435/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.1216e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 436/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1011e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 437/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1525e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 438/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0853e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 439/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.0875e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 440/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 2.1317e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 441/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 2.0844e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 442/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0651e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 443/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1536e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 444/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.0712e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 445/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1506e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 446/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1033e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 447/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0822e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 448/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1653e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 449/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.1042e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 450/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 2.1150e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 451/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1218e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 452/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0916e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 453/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.0875e-04 - val_loss: 0.0124 - learning_rate: 3.0000e-05\n",
      "Epoch 454/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0869e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 455/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.0703e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 456/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.0629e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 457/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.0889e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 458/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1050e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 459/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.0910e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 460/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.0908e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 461/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.1082e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 462/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1220e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 463/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.0587e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 464/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.0920e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 465/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 2.0263e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 466/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.0609e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 467/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.0475e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 468/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.0695e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 469/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0463e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 470/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.0559e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 471/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.0811e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 472/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0413e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 473/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.0840e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 474/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 2.0409e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 475/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0584e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 476/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.0530e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 477/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0828e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 478/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1038e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 479/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0533e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 480/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.9837e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 481/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.0105e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 482/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.0331e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 483/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.0387e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 484/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.0333e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 485/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.0249e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 486/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0160e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 487/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.0197e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 488/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.0444e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 489/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.0443e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 490/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9737e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 491/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.9932e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 492/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.0160e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 493/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.9695e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 494/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 2.0122e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 495/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.9785e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 496/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.9948e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 497/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 1.9783e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 498/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.9491e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 499/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 1.9871e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 500/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.9498e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 501/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.9973e-04 - val_loss: 0.0124 - learning_rate: 3.0000e-05\n",
      "Epoch 502/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.9561e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 503/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9721e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 504/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.9446e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 505/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.9298e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 506/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.9823e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 507/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9617e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 508/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9552e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 509/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.9614e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 510/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.9458e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 511/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.9394e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 512/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.9174e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 513/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.9047e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 514/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.9053e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 515/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.9512e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 516/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.9201e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 517/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.8878e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 518/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9908e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 519/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9449e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 520/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9369e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 521/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.9498e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 522/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.9201e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 523/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.9020e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 524/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9522e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 525/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8961e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 526/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8780e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 527/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8942e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 528/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.8954e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 529/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8868e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 530/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.9192e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 531/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8794e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 532/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 1.8832e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 533/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.8837e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 534/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8560e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 535/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.8686e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 536/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8958e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 537/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.8871e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 538/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.8887e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 539/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.9274e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 540/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9027e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 541/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.8783e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 542/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.8474e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 543/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.8484e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 544/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.9160e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 545/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 1.8667e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 546/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.8355e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 547/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8815e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 548/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.8609e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 549/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8558e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 550/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8640e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 551/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8955e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 552/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.8399e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 553/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.8620e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 554/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.8979e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 555/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.8546e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 556/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.8199e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 557/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.8531e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 558/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 1.8770e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 559/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8261e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 560/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8086e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 561/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.8204e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 562/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8282e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 563/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.8490e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 564/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.8104e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 565/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.8409e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 566/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.8187e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 567/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.8387e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 568/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.8129e-04 - val_loss: 0.0124 - learning_rate: 3.0000e-05\n",
      "Epoch 569/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7165e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 570/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8141e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 571/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.8194e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 572/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.8689e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 573/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7780e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 574/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8181e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 575/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8282e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 576/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.8287e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 577/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.8377e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 578/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7830e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 579/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7643e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 580/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7980e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 581/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7234e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 582/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8100e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 583/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7558e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 584/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8252e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 585/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 1.8098e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 586/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7680e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 587/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7812e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 588/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.8088e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 589/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7581e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 590/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.7204e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 591/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 1.7635e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 592/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7463e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 593/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7534e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 594/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7657e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 595/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7267e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 596/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7446e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 597/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8227e-04 - val_loss: 0.0124 - learning_rate: 3.0000e-05\n",
      "Epoch 598/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7752e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 599/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 1.7915e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 600/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7652e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 601/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7785e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 602/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7268e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 603/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7523e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 604/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7088e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 605/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.6731e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 606/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7490e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 607/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7417e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 608/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7832e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 609/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7758e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 610/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.7549e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 611/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7600e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 612/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7618e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 613/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7054e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 614/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7215e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 615/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6991e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 616/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6725e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 617/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.6939e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 618/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.6861e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 619/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6946e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 620/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7473e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 621/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7237e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 622/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7002e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 623/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6707e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 624/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 1.6902e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 625/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7296e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 626/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6843e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 627/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6891e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 628/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6701e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 629/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7381e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 630/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6807e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 631/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7008e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 632/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.6669e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 633/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6911e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 634/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.6806e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 635/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6737e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 636/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.6791e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 637/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.6420e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 638/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.6618e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 639/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.6595e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 640/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.6814e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 641/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6723e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 642/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6800e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 643/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.7292e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 644/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.6671e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 645/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.6668e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 646/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.6863e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 647/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6486e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 648/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6367e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 649/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.6635e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 650/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6952e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 651/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6520e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 652/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.6305e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 653/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6453e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 654/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6260e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 655/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.6047e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 656/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6166e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 657/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6292e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 658/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6209e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 659/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 1.6410e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 660/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.6318e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 661/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6103e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 662/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6518e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 663/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5928e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 664/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6580e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 665/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5777e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 666/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6148e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 667/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6594e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 668/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6170e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 669/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6703e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 670/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6187e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 671/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6028e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 672/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5920e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 673/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5793e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 674/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5900e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 675/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6269e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 676/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5817e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 677/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5880e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 678/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5803e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 679/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5861e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 680/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.5700e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 681/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5625e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 682/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6457e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 683/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5649e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 684/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5584e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 685/1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 22:27:58.978897: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6066e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 686/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.5717e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 687/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5560e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 688/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6342e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 689/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6484e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 690/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.5729e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 691/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5977e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 692/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.5675e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 693/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5610e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 694/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.5859e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 695/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.5457e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 696/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5213e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 697/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5438e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 698/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.5525e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 699/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5476e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 700/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.5017e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 701/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.5219e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 702/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5728e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 703/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5741e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 704/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5476e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 705/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5355e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 706/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5432e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 707/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.5304e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 708/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.5053e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 709/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.5075e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 710/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5154e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 711/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5085e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 712/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.5109e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 713/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5192e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 714/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5134e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 715/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5136e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 716/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5329e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 717/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5022e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 718/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.5408e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 719/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.5157e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 720/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5038e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 721/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4992e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 722/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4912e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 723/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 1.4842e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 724/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4547e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 725/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5267e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 726/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5042e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 727/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.5137e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 728/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.5235e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 729/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4804e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 730/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4783e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 731/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5239e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 732/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4830e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 733/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4922e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 734/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5087e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 735/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4929e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 736/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4795e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 737/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4699e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 738/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4818e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 739/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.4884e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 740/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5533e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 741/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4868e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 742/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4726e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 743/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4998e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 744/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4939e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 745/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4702e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 746/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.4365e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 747/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 1.4529e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 748/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4630e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 749/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4726e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 750/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.4612e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 751/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4784e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 752/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4489e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 753/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4638e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 754/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.4444e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 755/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4513e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 756/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4546e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 757/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5078e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 758/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.4740e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 759/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4424e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 760/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4841e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 761/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4679e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 762/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.4329e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 763/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4323e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 764/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4094e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 765/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4239e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 766/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4052e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 767/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3875e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 768/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3965e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 769/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.3555e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 770/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4373e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 771/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4045e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 772/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4290e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 773/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4086e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 774/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3992e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 775/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.4137e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 776/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4011e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 777/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4696e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 778/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4315e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 779/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.3867e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 780/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3906e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 781/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.4344e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 782/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 1.3687e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 783/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4047e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 784/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3573e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 785/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3656e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 786/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4051e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 787/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4211e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 788/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.4004e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 789/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3737e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 790/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3641e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 791/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 1.3683e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 792/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3837e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 793/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4588e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 794/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.4056e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 795/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4132e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 796/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4485e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 797/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3811e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 798/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3105e-04 - val_loss: 0.0125 - learning_rate: 3.0000e-05\n",
      "Epoch 799/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3364e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 800/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3476e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 801/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3536e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 802/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.3945e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 803/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.4094e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 804/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4314e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 805/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3903e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 806/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4000e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 807/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3859e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 808/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3476e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 809/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3823e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 810/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3632e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 811/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3567e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 812/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3958e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 813/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3559e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 814/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3519e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 815/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3429e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 816/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3356e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 817/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3150e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 818/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3420e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 819/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.3449e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 820/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3090e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 821/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3159e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 822/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3090e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 823/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3809e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 824/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3373e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 825/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3393e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 826/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3144e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 827/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3443e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 828/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3711e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 829/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2968e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 830/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2992e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 831/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3279e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 832/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3110e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 833/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3410e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 834/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3281e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 835/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3361e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 836/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3141e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 837/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3162e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 838/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2836e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 839/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2778e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 840/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2837e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 841/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3136e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 842/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2709e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 843/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2997e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 844/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2742e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 845/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 1.2677e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 846/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2881e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 847/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2864e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 848/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3033e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 849/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2785e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 850/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2787e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 851/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2821e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 852/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 1.3560e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 853/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 1.2740e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 854/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2589e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 855/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3318e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 856/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2503e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 857/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2531e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 858/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3117e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 859/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2856e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 860/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3383e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 861/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3002e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 862/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2687e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 863/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2951e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 864/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2560e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 865/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.3227e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 866/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3126e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 867/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2451e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 868/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2081e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 869/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2586e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 870/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2771e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 871/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2540e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 872/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3091e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 873/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2866e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 874/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2613e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 875/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2497e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 876/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2340e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 877/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2475e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 878/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2789e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 879/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2493e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 880/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2741e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 881/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2539e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 882/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2344e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 883/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2250e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 884/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2848e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 885/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2616e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 886/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2741e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 887/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2943e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 888/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2538e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 889/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2685e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 890/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1928e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 891/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2416e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 892/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2552e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 893/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2156e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 894/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2322e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 895/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2238e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 896/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2414e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 897/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2565e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 898/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2432e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 899/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.2159e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 900/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 1.2002e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 901/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2201e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 902/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1953e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 903/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 1.2230e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 904/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2038e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 905/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1968e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 906/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1873e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 907/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1973e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 908/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1804e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 909/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1826e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 910/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2006e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 911/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1882e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 912/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1942e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 913/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2044e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 914/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2375e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 915/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2238e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 916/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2048e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 917/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2333e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 918/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2088e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 919/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1561e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 920/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1665e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 921/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1697e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 922/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.1834e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 923/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2295e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 924/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2255e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 925/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2102e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 926/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1884e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 927/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1644e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 928/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1692e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 929/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1862e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 930/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 1.1755e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 931/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1852e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 932/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 1.1566e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 933/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1580e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 934/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1584e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 935/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1511e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 936/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1699e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 937/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1922e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 938/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1680e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 939/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1560e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 940/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1897e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 941/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1678e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 942/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1439e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 943/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2099e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 944/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1475e-04 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 945/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1251e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 946/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1200e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 947/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1234e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 948/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1212e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 949/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1850e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 950/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2040e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 951/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1801e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 952/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1550e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 953/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1238e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 954/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1246e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 955/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1177e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 956/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0924e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 957/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0987e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 958/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1118e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 959/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1133e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 960/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1423e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 961/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1632e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 962/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1573e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 963/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1605e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 964/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1324e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 965/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1553e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 966/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 1.1219e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 967/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1025e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 968/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 1.0872e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 969/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.1351e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 970/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1045e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 971/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1376e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 972/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1314e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 973/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0719e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 974/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1411e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 975/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2027e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 976/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1498e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 977/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1401e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 978/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.1225e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 979/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1313e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 980/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0634e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 981/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0894e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 982/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0811e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 983/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1095e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 984/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0987e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 985/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1010e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 986/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0951e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 987/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1310e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 988/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1636e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 989/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1589e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 990/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1138e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 991/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0792e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 992/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1202e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 993/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0787e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 994/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1390e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 995/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0419e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 996/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0862e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 997/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0806e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 998/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1355e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 999/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0981e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1000/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1301e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1001/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1043e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1002/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1218e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1003/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0715e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1004/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0751e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1005/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0459e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1006/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0955e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1007/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0575e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1008/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0845e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1009/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0863e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1010/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0656e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1011/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0784e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 1012/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0595e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1013/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0812e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1014/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0590e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1015/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0829e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1016/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0793e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1017/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0614e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1018/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0517e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1019/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0562e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1020/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0333e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1021/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.0496e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1022/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0911e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1023/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0896e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1024/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 1.0713e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1025/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0618e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1026/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0485e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1027/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 1.0317e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1028/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0861e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1029/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0733e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1030/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0230e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 1031/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0298e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1032/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0196e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1033/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.0993e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1034/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0663e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1035/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0365e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1036/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.9136e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1037/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0327e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1038/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0429e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1039/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0454e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1040/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0193e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1041/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0447e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1042/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0056e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1043/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0181e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1044/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0450e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1045/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0174e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1046/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0388e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1047/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0324e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1048/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.9924e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1049/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0424e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1050/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0209e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1051/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0048e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1052/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0392e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1053/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0596e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1054/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0378e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1055/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0307e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1056/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0094e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1057/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.0209e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1058/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.0214e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1059/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 1.0246e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1060/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0360e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 1061/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0309e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1062/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0251e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1063/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0309e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1064/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0474e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1065/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0322e-04 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 1066/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0658e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1067/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0077e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1068/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0121e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1069/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0214e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1070/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0018e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1071/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.9618e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1072/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.8376e-05 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 1073/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0211e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1074/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0436e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1075/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0167e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1076/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.8179e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1077/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0110e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1078/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.9922e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1079/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.7510e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1080/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.7750e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1081/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0208e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1082/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 9.8074e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1083/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.8878e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1084/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.7049e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1085/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.5734e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1086/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.9410e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1087/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 9.8171e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1088/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.9330e-05 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 1089/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0179e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1090/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 9.7954e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1091/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.9109e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1092/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0163e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1093/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.9778e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 1094/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.3293e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1095/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.4576e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1096/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0040e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1097/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0013e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1098/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.6293e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1099/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.5321e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1100/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.4585e-05 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 1101/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.7090e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1102/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.8677e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1103/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.1114e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1104/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.7611e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1105/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.6080e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1106/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.8336e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1107/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0017e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1108/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 9.4333e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1109/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.9765e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1110/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.8389e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1111/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0008e-04 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1112/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.4497e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1113/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.6782e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1114/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.4667e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1115/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.4670e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1116/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.4046e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1117/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.6143e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1118/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.5330e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1119/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0029e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1120/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.8633e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1121/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.7496e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1122/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.3790e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1123/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 9.4414e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1124/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.4622e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1125/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 9.3135e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1126/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.4559e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1127/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 9.3889e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1128/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.9912e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1129/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.1815e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1130/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.5750e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1131/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 9.3793e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1132/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.3359e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1133/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.5488e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1134/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.3938e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1135/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.4389e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1136/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.4232e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1137/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.2138e-05 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 1138/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.2890e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1139/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.6664e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1140/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.5795e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1141/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.4277e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1142/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.3712e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1143/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.8307e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1144/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.3545e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1145/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.8509e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1146/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.5236e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1147/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.3442e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 1148/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.4455e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1149/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.4754e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1150/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0030e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1151/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.2475e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1152/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 9.5636e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1153/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.1277e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1154/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.0950e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1155/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 9.6081e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1156/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.5342e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1157/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.0617e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1158/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.1950e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1159/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.3948e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1160/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 9.1639e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1161/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.1425e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1162/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.5650e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1163/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.9857e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1164/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 9.0303e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1165/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 9.0395e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1166/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.9143e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1167/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.1436e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1168/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.0670e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1169/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 8.9732e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1170/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.0933e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1171/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.6374e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1172/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.0282e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1173/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.9226e-05 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 1174/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.0892e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1175/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.8962e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1176/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.0657e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1177/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 8.8174e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1178/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.2758e-05 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 1179/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.9258e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1180/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.9882e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1181/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.9537e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1182/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.9301e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1183/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.8725e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1184/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.8002e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1185/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.9740e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1186/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.9822e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1187/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.9926e-05 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 1188/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.0141e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1189/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.5693e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1190/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.1746e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1191/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.7549e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1192/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.5706e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1193/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.4692e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1194/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.2027e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1195/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.8317e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1196/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.8723e-05 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 1197/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.0369e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1198/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.8416e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1199/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.0786e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1200/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.9850e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1201/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.7136e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1202/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 8.4744e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1203/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.9863e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1204/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.5918e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1205/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.5497e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1206/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.9130e-05 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 1207/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.6681e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1208/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.7728e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1209/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.0740e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1210/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.6043e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1211/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.7608e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1212/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.5900e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1213/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 8.8580e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1214/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.5767e-05 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 1215/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.3754e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1216/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.4045e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1217/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 8.5904e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1218/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.7290e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1219/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.6015e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1220/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.3347e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1221/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.5797e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1222/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 8.7235e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1223/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 8.6154e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1224/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.8457e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1225/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.7690e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1226/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.4016e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1227/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.4109e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1228/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.5181e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1229/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.3655e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1230/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.3542e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1231/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.4292e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1232/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 8.6434e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1233/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.7186e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1234/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.5762e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1235/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.6878e-05 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 1236/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 8.4883e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1237/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.4897e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1238/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.9428e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1239/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.5741e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1240/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.5855e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1241/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.4518e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1242/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.2488e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1243/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.1291e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1244/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.1477e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1245/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.2173e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1246/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.8307e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1247/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.4986e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1248/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.6369e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1249/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.5604e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1250/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.6751e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1251/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.7905e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1252/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.6452e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1253/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.4775e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 1254/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 7.9780e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1255/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.1055e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1256/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 8.1858e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1257/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.1157e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1258/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.1514e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1259/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.9255e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1260/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 7.8921e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1261/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.5070e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 1262/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.3444e-05 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 1263/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.4169e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1264/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.1894e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1265/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.5207e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1266/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.2159e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1267/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 7.9930e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1268/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.0355e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1269/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.1516e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1270/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.1057e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1271/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.2526e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1272/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.2839e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1273/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.4230e-05 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 1274/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.5038e-05 - val_loss: 0.0126 - learning_rate: 3.0000e-05\n",
      "Epoch 1275/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.5886e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1276/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.1456e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1277/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.8325e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1278/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 7.7928e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1279/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 8.3915e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1280/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 7.8402e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1281/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 7.9083e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1282/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.2482e-05 - val_loss: 0.0127 - learning_rate: 3.0000e-05\n",
      "Epoch 1283/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.7393e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1284/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.5324e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1285/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.3495e-05 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 1286/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.0206e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1287/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 7.8908e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1288/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.1950e-05 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 1289/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.0388e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 1290/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 7.7291e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1291/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 7.9735e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1292/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.1291e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1293/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.0211e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1294/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 7.8119e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1295/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 8.2682e-05 - val_loss: 0.0128 - learning_rate: 3.0000e-05\n",
      "Epoch 1296/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.2649e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1297/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.2253e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1298/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 7.9715e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1299/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 7.7432e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1300/1300\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 7.9213e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with the custom callback\n",
    "history = model_builder.train_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    epochs=1300,\n",
    "    callbacks_list=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the losses from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "train_loss_x_midpoints = history.history.get('x_midpoints_reshape_loss', train_loss)\n",
    "val_loss_x_midpoints = history.history.get('val_x_midpoints_reshape_loss', val_loss)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2,1)\n",
    "plt.plot(train_loss_x_midpoints, label='Train Loss x_midpoints_reshape')\n",
    "plt.plot(val_loss_x_midpoints, label='Validation Loss x_midpoints_reshape')\n",
    "plt.xlabel('Epochs')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder.model.save(\"/home/da886/Analysis/30KNoFalsePositivesFixed-index84_13__overfit.keras\")\n",
    "# loaded_model = tf.keras.models.load_model(\n",
    "# \"/home/da886/Analysis/30KNoFalsePositivesFixed-index6_13__overfitNo.keras\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, batch shape: (800, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728435261.147523  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.147859  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.148533  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.148680  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.148889  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.149485  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.149502  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.149622  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.150203  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.150218  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.150355  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.150754  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.150940  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.151036  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.151292  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.151654  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.151675  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.151828  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.152276  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.152387  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.152423  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.152870  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.153140  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.153257  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.153432  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.153928  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.153937  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.154061  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.154600  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.154799  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.154820  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.155192  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.155402  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.155405  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.155869  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.156075  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.156145  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.156690  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.156735  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.156824  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.157298  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.157504  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.157565  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.158165  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.158201  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.158293  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.158766  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.158995  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.159012  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.159667  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.159781  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.159822  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.160589  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.160649  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.160775  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.161226  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.161502  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.161524  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.162283  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.162398  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.177409  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.177813  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.178093  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.178376  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.178653  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.178930  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.179213  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.179376  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.179523  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.179742  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.180106  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.180289  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.180381  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.180727  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.180774  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.180990  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.181345  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.181405  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.181660  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.182007  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.182028  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.182275  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.182521  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.182590  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.182759  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.183111  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.183188  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.183412  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.183771  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.183793  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.184024  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.184374  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.184394  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.184549  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.184911  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.184982  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.185231  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.185509  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.185578  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.185818  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.186183  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.186377  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.186398  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.186759  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.187011  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.187072  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.187269  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.187643  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.187726  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.187905  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.188479  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.188567  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.188604  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.188915  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.189261  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.189562  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.189697  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.189771  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.190281  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.190523  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.190558  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.190784  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.191290  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.191300  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.191414  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.192013  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.192016  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.192139  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.192475  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.192598  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.193794  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.193997  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.194567  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.194758  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.195085  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.195537  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.195672  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.195982  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.209515  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.209928  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.210246  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.210542  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.210841  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.211136  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.211429  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.211586  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.211706  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.212218  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.212226  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.212647  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.212676  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.213170  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.213196  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.213621  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.213632  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.213954  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.214349  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.214460  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.214751  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.214950  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.214985  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.215297  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.215406  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.215673  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.215821  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.215849  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.216150  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.216383  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.216642  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.216657  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.216804  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.216952  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.217502  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.217519  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.217622  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.217789  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.218288  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.218304  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.218402  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.218580  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.219125  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.219143  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.219144  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.219411  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.219614  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.219963  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.220180  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.220361  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.220783  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.220873  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.221337  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.221506  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.222012  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.222497  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.222973  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.225321  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.225573  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.225828  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.226080  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.226339  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.226640  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.226907  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.227039  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.227316  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.227454  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.227717  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.227853  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.228123  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.228260  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.228522  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.228658  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.228934  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.229136  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.229404  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.229406  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.229632  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.229899  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.229900  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.230116  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.230271  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.230384  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.230606  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.230731  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.230889  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.231181  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.231310  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.231484  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.231796  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.231906  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.232088  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.232386  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.232504  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.232680  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.233006  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.233127  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.233301  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.233592  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.233706  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.233786  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.234288  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.234302  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.234312  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.234751  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.234754  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.234883  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.235142  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.235148  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.235749  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.235754  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.235862  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.236078  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.236253  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.236453  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.236929  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.237008  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.237373  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.237382  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.237703  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.237973  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.238158  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.238508  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.238927  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.239321  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.239863  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.242354  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.242684  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.242976  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.243280  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.243580  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.243878  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.244191  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.244462  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.244521  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.244926  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.245031  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.245379  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.245490  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.245752  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.245863  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.246008  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.246122  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.246251  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.246462  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.246643  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.246929  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.247101  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.247199  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.247344  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.247439  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.247839  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.248049  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.248143  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.248281  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.248377  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.248712  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.248803  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.249014  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.249304  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.249595  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.249610  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.249722  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.249937  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.250275  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.250461  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.250483  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.250672  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.250860  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.251065  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.251261  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.251436  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.251813  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.251906  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.252084  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.252295  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.252450  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.252778  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.252882  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.253135  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.253588  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.253751  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.254440  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.254526  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.255120  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.255915  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.255927  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.256481  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.256637  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.257003  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.257738  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.265043  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.265336  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.265623  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.265908  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.266192  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.266481  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.266768  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.267060  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.267374  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.267688  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.267989  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.268438  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.268856  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.268958  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.269423  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.269439  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.269959  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.269972  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.270395  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.270493  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.270805  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.270917  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.271226  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.271324  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.271537  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.272058  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.272075  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.272391  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.272721  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.272831  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.273142  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.273337  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.273596  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.273736  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.273863  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.273961  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.274315  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.274623  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.274638  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.274824  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.275015  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.275207  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.275393  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.275569  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.275780  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.276107  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.276336  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.276503  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.276916  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.276992  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.277246  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.277648  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.277729  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.278062  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.278429  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.278795  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.279039  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.279554  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.280462  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.281757  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.281934  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.282152  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.282482  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.282786  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.283146  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.283438  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.283558  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.283862  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.284307  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.284408  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.284643  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.284954  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.285375  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.285395  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.285743  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.285778  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.286143  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.286704  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.286715  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.287032  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.287353  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.287857  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.287865  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.288175  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.288497  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.289041  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.289057  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.289370  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.289700  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.290214  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.290229  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.290999  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.291847  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.291958  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.292761  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.292970  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.293894  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.294499  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.295427  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.296345  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.298089  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.306199  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.306516  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.306840  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.307140  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.307453  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.307760  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.308080  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.308428  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.308780  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.309128  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.309469  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.309831  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.310231  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.310638  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.311048  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.311466  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.311895  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.312612  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.313369  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.314605  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.315393  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.317903  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.318354  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.318803  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.319273  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.319727  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.320133  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.320509  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.320920  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.321486  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.321564  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.322030  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.322122  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.322630  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.322642  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.322929  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.323194  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.323234  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.323450  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.323836  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.323851  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.324045  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.324466  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.324481  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.324678  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.325123  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.325132  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.325231  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.325808  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.325815  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.325915  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.326517  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.326520  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.326618  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.327078  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.327253  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.327272  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.327487  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.327662  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.327955  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.328267  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.328387  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.328456  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.328922  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.329017  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.329222  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.329507  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.329583  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.330049  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.330126  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.330776  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.330921  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.331080  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.331384  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.331820  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.331838  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.332120  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.332352  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.333035  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.333113  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.333657  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.334454  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.334461  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.335427  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.335892  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.338032  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.339363  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.339713  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.340141  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.340527  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.340922  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.341285  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.341709  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.342109  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.342477  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.342833  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.342845  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.343505  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.343525  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.344138  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.344145  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.344777  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.344786  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.345167  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.345599  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.346120  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.346217  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.346510  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.346879  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.347282  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.347725  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.347899  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.348159  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.348265  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.348742  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.349209  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.349683  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.349693  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.349863  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.350390  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.350877  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.351540  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.351565  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.351640  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.352128  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.352616  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.353236  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.353359  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.353434  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.353898  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.354404  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.355035  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.355880  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.356209  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.356522  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.357395  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.358378  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.359176  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.360636  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.360732  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.362911  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.365103  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.367330  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.371765  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.403571  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.403984  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.404371  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.404752  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.405158  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.405560  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.405967  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.406369  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.406794  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.407455  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.407489  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.408038  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.408131  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.408560  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.408658  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.408971  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.409175  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.409386  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.409971  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.409983  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.410518  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.410619  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.410940  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.411324  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.411433  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.412106  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.412118  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.412562  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.412786  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.413018  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.413500  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.414159  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.414265  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.414733  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.415321  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.415942  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.416420  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.416614  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.418304  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.418314  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.420462  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.422135  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.428111  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.428661  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.429161  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.429644  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.430235  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.430724  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.431257  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.431803  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.431853  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.432434  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.432541  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.433223  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.433231  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.433953  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.433963  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.434737  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.434750  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.435246  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.435782  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.436333  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.436818  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.437162  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.437384  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.437952  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.438496  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.439755  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.440941  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.442278  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.443555  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.444546  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.446109  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.446937  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.448412  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.449374  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.450831  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.453277  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.454429  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.454567  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.455099  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.455573  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.456043  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.456532  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.457038  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.457536  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.458040  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.458276  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.458596  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.459193  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.459776  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.460370  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.460968  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.461761  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.462509  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.463317  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.464200  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.465162  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.473238  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.475455  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.485463  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.485880  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.486264  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.486692  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.487111  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.487586  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.488065  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.489352  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.490650  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.491969  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.494252  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.495921  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.498200  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.500090  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.539754  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.540146  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.540526  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.540920  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.541310  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.541691  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.542090  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.542488  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.542877  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.543257  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.543642  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.544051  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.544557  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.544788  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.544980  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.545368  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.545538  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.545905  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.546069  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.546464  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.546640  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.547043  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.547226  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.547600  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.547791  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.548142  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.548455  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.548714  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.549077  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.549511  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.549535  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 1s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728435261.550213  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.550299  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.550998  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.551134  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.551147  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.551553  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.551795  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.552108  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.552585  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.552753  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.552875  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.553430  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.553528  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.554006  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.554532  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.554643  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.555290  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.555462  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.555954  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.556572  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.556667  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.557348  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.557636  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.558206  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.559076  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.559948  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.560127  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.560945  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.561707  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.562151  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.562236  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.562561  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.562861  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.563307  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.563666  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.563986  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.564597  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.564835  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.565236  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.565712  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.566383  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.567087  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.567764  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.568621  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.568631  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.569758  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.571226  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.578245  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.578840  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.579424  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.580056  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.580903  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.580909  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.581555  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.581718  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.582066  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.582372  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.582624  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.582904  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.583136  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.583557  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.584122  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.584183  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.584363  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.584691  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.585073  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.585325  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.585983  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.586101  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.586235  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.586734  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.586857  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.587535  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.587664  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.587943  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.588272  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.588847  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.589127  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.589443  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.589715  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.589978  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.590490  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.590872  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.591114  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.591526  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.592009  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.592384  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.592679  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.592752  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.593321  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.594532  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.594582  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.594694  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.596192  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.597194  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.599078  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.600743  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.601727  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.602044  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.602311  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.602582  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.602849  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.603115  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.603394  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.603670  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.604126  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.604636  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.605155  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.605719  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.606272  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.607250  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.608498  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.610109  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.610387  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.610671  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.610950  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.611247  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.611508  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.611772  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.612046  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.612318  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.612693  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.612977  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.613272  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.613566  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.613931  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.614268  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.614626  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.614974  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.615688  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.616059  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.616467  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.616908  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.618048  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.618543  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.624818  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.625114  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.625382  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.625652  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.626169  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.626714  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.627260  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.627971  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.628660  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.629255  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.630450  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.632015  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.632977  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.633225  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.633492  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.633767  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.634020  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.634292  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.634549  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.634828  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.635133  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.635453  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.635725  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.636091  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.636476  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.636861  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.637255  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.637697  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.638117  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.638613  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.639163  564710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.641911  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.642303  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.642683  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.643069  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.643454  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.643836  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.644229  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.644624  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.645018  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.645429  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.645846  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.646268  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.646942  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.646954  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.647592  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.647600  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.648215  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.648226  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.648741  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.648831  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.649160  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.649520  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.649625  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.650262  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.650276  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.650800  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.650899  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.651210  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.651803  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.651813  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.652238  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.652633  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.652745  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.653198  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.653649  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.654122  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.654343  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.654660  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.655230  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.655775  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.655988  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.656356  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.657041  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.657767  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.659500  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.661140  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.664948  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.665325  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.665654  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.665988  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.666444  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.666810  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.667277  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.667677  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.668146  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.668826  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.669512  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.669982  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.670465  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.670562  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.670902  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.671457  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.671462  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.671866  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.672234  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.672639  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.672832  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.673239  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.673715  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.674134  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.674410  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.675101  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.675953  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.676798  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.677926  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.679415  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.686294  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.686604  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.686892  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.687201  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.687509  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.687810  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.688118  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.688407  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.688697  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.689057  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.689425  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.689812  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.690152  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.690519  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.690833  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.691153  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.691710  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.691822  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.692355  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.692372  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.692777  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.692881  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.693110  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.693618  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.693634  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.693943  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.694486  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.694497  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.694801  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.695099  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.695570  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.695679  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.695968  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.696369  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.696822  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.697210  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.697529  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.697861  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.698285  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.698689  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.699167  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.699664  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.700285  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.701421  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.702765  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.703078  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.703341  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.703645  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.703905  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.704175  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.704450  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.704713  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.705164  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.705665  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.706169  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.706724  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.707264  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.708242  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.708388  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.708704  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.708965  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.709244  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.709748  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.709753  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.710033  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.710313  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.710583  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.711039  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.711369  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.711604  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.711771  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.712207  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.712284  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.712495  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.712990  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.712995  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.713255  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.713715  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.713726  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.713984  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.714249  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.714662  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.714932  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.715030  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.715316  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.715608  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.715970  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.716315  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.716407  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.716756  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.717105  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.717838  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.718001  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.718434  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.718449  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.718838  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.718932  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.719147  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.719607  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.719622  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.719883  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.720150  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.720418  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.720802  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.720904  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.721185  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.721531  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.721611  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.721907  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.722208  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.722574  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.722969  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.723331  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.723686  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.724398  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.724775  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.725174  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.725622  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.726759  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.727252  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.728053  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.728347  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.728727  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.729012  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.729532  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.730076  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.730619  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.731307  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.731992  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.732564  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.733655  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.733863  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.733988  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.734265  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.734533  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.735061  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.735543  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.735648  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.736199  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.736520  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.736845  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.736950  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.737129  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.737393  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.737759  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.737861  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.738047  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.738406  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.738513  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.738711  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.739007  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.739317  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.739683  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.739784  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.740055  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.740431  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.740807  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.741209  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.741395  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.741668  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.742077  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.742368  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.742799  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.742811  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.743075  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.743559  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.743566  564781 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.743948  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.744236  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.744492  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.744801  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.745106  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.745424  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.745701  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.746076  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.746453  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.746837  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.747244  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.747690  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.748111  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.748619  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728435261.749176  564735 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Processing batch 2, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 3, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 4, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 5, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 6, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 7, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 8, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 9, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 10, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 11, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 12, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 13, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 14, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 15, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 16, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 17, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 18, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 19, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 20, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 21, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 22, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 23, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 24, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 25, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 26, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 27, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 28, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 29, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 30, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the function for visualizing midpoints\n",
    "def visualize_midpoints(image, midpoints, title=\"Predicted Midpoint Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualizes midpoints on an image without using a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "    - title: The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    midpoints_np = midpoints\n",
    "\n",
    "    # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot midpoints directly, only if they are not (0, 0)\n",
    "    for i, (x, y) in enumerate(midpoints_np):\n",
    "        if x >= 3 and y >= 3:  # Only plot if the point is not (0, 0)\n",
    "            plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create the validation dataset\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n",
    "# val_dataset = val_dataset.batch(800)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)\n",
    "# # Initialize lists to collect the data\n",
    "all_images = []\n",
    "all_true_midpoints = []\n",
    "all_pred_midpoints = []\n",
    "\n",
    "# # Loop through each batch in the validation dataset, predict, and collect results\n",
    "# for i, (data_batch, midpoints_batch) in enumerate(val_dataset):\n",
    "\n",
    "for i, (data_batch, midpoints_batch) in enumerate(train_dataset):\n",
    "    print(f\"Processing batch {i + 1}, batch shape: {data_batch.shape}\")\n",
    "    \n",
    "    # Get the model predictions\n",
    "    predictions = model_builder.model.predict(data_batch)\n",
    "\n",
    "    # Extend the lists to store data from each batch\n",
    "    all_images.extend(data_batch.numpy())  # Store all images\n",
    "    all_true_midpoints.extend(midpoints_batch.numpy())  # Store all true midpoints\n",
    "    all_pred_midpoints.extend(predictions)  # Store all predicted midpoints\n",
    "\n",
    "# Convert lists to arrays for easier indexing\n",
    "all_images = np.array(all_images)\n",
    "all_true_midpoints = np.array(all_true_midpoints)\n",
    "all_pred_midpoints = np.array(all_pred_midpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24000, 64, 64), (24000, 1, 13, 2), (24000, 1, 13, 2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape,all_pred_midpoints.shape,all_true_midpoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWMAAAF2CAYAAAC72fnJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9WklEQVR4nO3de3RU1b0H8O9MHpOQxwQQ8lCIWEFABDUUTINPIhEolYpVW7WRq1flBuSht4KWh4hEsS344FFtF7haEYv3ovUBCClgSQEFcVW0RsQoqZiAXpmEKCHM7PtHyMhMdsiec/bJ7Anfz1qzdM6cs88+Z878ONm/s/d2CSEEiIgoqtzRrgARETEYExEZgcGYiMgADMZERAZgMCYiMgCDMRGRARiMiYgMwGBMRGQABmMiIgMwGJNlZ599Nm677bbg+82bN8PlcmHz5s1Rq1O48Drqdtttt+Hss89uc73PPvsMLpcLK1ascKwugPPHS85hMI5RK1asgMvlCr6SkpLQp08fTJw4ETU1NdGuXkTeeOMNzJkzJ6p1aD6Pd9xxh/TzBx98MLjOV1991c61ax9Llixx/B8Lal18tCtA9sydOxe9evXC0aNHsXXrVixduhRvvPEG9uzZg06dOrVrXS677DJ89913SExMjGi7N954A4sXL456QE5KSsL//M//YMmSJS2O4YUXXkBSUhKOHj0asvzZZ59FIBBoz2qeUkVFBdxua/dYS5YswRlnnME76yjhnXGMGzlyJG655RbccccdWLFiBaZMmYLKykq88sorrW5TX1/vSF3cbjeSkpIsB4Nou+aaa1BbW4u1a9eGLP/HP/6ByspKjB49usU2CQkJ8Hg87VXFNnk8HiQkJES7GmRBbP5qqFVXXXUVAKCyshJAU5tmamoq9u3bh1GjRiEtLQ0333wzACAQCGDRokU4//zzkZSUhMzMTNx111345ptvQsoUQmDevHk466yz0KlTJ1x55ZX44IMPWuy7tTbjHTt2YNSoUejcuTNSUlIwcOBAPPHEE8H6LV68GABCml2a6a7jqZx55pm47LLLsHLlypDlzz//PC644AIMGDCgxTayNuPDhw/jtttug9frRUZGBoqLi3H48GHptqmpqfj0009RVFSElJQU5OTkYO7cuQgfTLG+vh733nsvevToAY/Hg/POOw+/+c1vWqwX3mbc3JxVXl6OadOmoVu3bkhJScFPf/pTHDp0KGS7Dz74AFu2bAl+B1dccQUAoLGxEQ899BB69+6NpKQkdO3aFcOGDcOGDRsUziqpYjNFB7Nv3z4AQNeuXYPLjh8/jqKiIgwbNgy/+c1vgs0Xd911F1asWIHx48fjnnvuQWVlJZ5++mns3r0b5eXlwTusWbNmYd68eRg1ahRGjRqFd999FyNGjMCxY8farM+GDRvw4x//GNnZ2Zg8eTKysrLwr3/9C6+99homT56Mu+66CwcOHMCGDRvwpz/9qcX27VHHk/3iF7/A5MmTceTIEaSmpuL48eNYvXo1pk2b1qKJQkYIgWuvvRZbt27F3XffjX79+mHNmjUoLi6Wru/3+3HNNdfgkksuwYIFC7Bu3TrMnj0bx48fx9y5c4Nl/uQnP8GmTZtw++2348ILL8T69evx3//93/jiiy+wcOHCNus1adIkdO7cGbNnz8Znn32GRYsWYeLEiXjxxRcBAIsWLcKkSZOQmpqKBx98EACQmZkJAJgzZw5KS0txxx13YMiQIaitrcXOnTvx7rvv4uqrr1Y6r6RAUExavny5ACA2btwoDh06JKqqqsSqVatE165dRXJysvj3v/8thBCiuLhYABDTp08P2f7vf/+7ACCef/75kOXr1q0LWX7w4EGRmJgoRo8eLQKBQHC9Bx54QAAQxcXFwWWbNm0SAMSmTZuEEEIcP35c9OrVS+Tm5opvvvkmZD8nl1VSUiJkl6ITdWwNAFFSUiL+7//+TyQmJoo//elPQgghXn/9deFyucRnn30mZs+eLQCIQ4cOBbcrLi4Wubm5wfcvv/yyACAWLFgQXHb8+HFx6aWXCgBi+fLlIdsCEJMmTQo5L6NHjxaJiYnB/TSXOW/evJA6X3/99cLlcolPPvkkuCw3NzfkeJuvk8LCwpBzM3XqVBEXFycOHz4cXHb++eeLyy+/vMW5GTRokBg9enQbZ5DsYjNFjCssLES3bt3Qo0cP3HTTTUhNTcWaNWtw5plnhqw3YcKEkPerV6+G1+vF1Vdfja+++ir4ysvLQ2pqKjZt2gQA2LhxI44dO4ZJkyaFNB9MmTKlzbrt3r0blZWVmDJlCjIyMkI+O7ms1rRHHcN17twZ11xzDV544QUAwMqVK/GjH/0Iubm5Stu/8cYbiI+PDznfcXFxmDRpUqvbTJw4Mfj/LpcLEydOxLFjx7Bx48ZgmXFxcbjnnntCtrv33nshhGjRxi1z5513hpybSy+9FH6/H59//nmb22ZkZOCDDz7A3r1721yXrGMzRYxbvHgx+vTpg/j4eGRmZuK8885rkUCLj4/HWWedFbJs79698Pl86N69u7TcgwcPAkDwx9q7d++Qz7t164bOnTufsm7NTSaytlYV7VFHmV/84he49dZbsX//frz88stYsGCB8raff/45srOzkZqaGrL8vPPOk67vdrtxzjnnhCzr06cPgKZnk5vLzMnJQVpaWsh6/fr1C37elp49e4a8bz4v4W3vMnPnzsW1116LPn36YMCAAbjmmmtw6623YuDAgW1uS+oYjGPckCFDMHjw4FOu4/F4WgToQCCA7t274/nnn5du061bN211tCpadfzJT34Cj8eD4uJiNDQ04IYbbnBkP+0pLi5OulwozLp22WWXYd++fXjllVfw5ptv4g9/+AMWLlyIZcuWtfpcNkWOwfg09YMf/AAbN25EQUEBkpOTW12v+c/zvXv3htzBHTp0qM27qh/84AcAgD179qCwsLDV9VprsmiPOsokJydj7Nix+POf/4yRI0fijDPOUN42NzcXZWVlwQRgs4qKCun6gUAAn376afBuGAA+/vhjAAg+pZGbm4uNGzeirq4u5O74o48+Cn6uw6majrp06YLx48dj/PjxOHLkCC677DLMmTOHwVgjthmfpm644Qb4/X48/PDDLT47fvx48FGswsJCJCQk4Kmnngq5i1q0aFGb+7j44ovRq1cvLFq0qMWjXSeXlZKSAgAt1mmPOrbmvvvuw+zZszFz5syIths1ahSOHz+OpUuXBpf5/X489dRTrW7z9NNPB/9fCIGnn34aCQkJGD58eLBMv98fsh4ALFy4EC6XCyNHjoyojq1JSUmRPoL39ddfh7xPTU3Fueeei4aGBi37pSa8Mz5NXX755bjrrrtQWlqK9957DyNGjEBCQgL27t2L1atX44knnsD111+Pbt264b777kNpaSl+/OMfY9SoUdi9ezfWrl3b5h2j2+3G0qVLMWbMGFx44YUYP348srOz8dFHH+GDDz7A+vXrAQB5eXkAgHvuuQdFRUWIi4vDTTfd1C51bM2gQYMwaNCgiLcbM2YMCgoKMH36dHz22Wfo378//vd//xc+n0+6flJSEtatW4fi4mIMHToUa9euxeuvv44HHngg2AwzZswYXHnllXjwwQfx2WefYdCgQXjzzTfxyiuvYMqUKcG/QOzKy8vD0qVLMW/ePJx77rno3r07rrrqKvTv3x9XXHEF8vLy0KVLF+zcuRMvvfRSSOKRNIjmoxxkXfMjS++8884p1ysuLhYpKSmtfv7MM8+IvLw8kZycLNLS0sQFF1wgfvWrX4kDBw4E1/H7/eKhhx4S2dnZIjk5WVxxxRViz549LR6jCn+0rdnWrVvF1VdfLdLS0kRKSooYOHCgeOqpp4KfHz9+XEyaNEl069ZNuFyuFo+56axja3Di0bZTUXm0TQghvv76a3HrrbeK9PR04fV6xa233ip2794tfbQtJSVF7Nu3T4wYMUJ06tRJZGZmitmzZwu/3x9SZl1dnZg6darIyckRCQkJonfv3uLxxx8PeVxNiNYfbQu/TmTfVXV1tRg9erRIS0sTAIKPuc2bN08MGTJEZGRkiOTkZNG3b1/xyCOPiGPHjp3yfFFkXEIotOATkXa33XYbXnrpJRw5ciTaVSEDsM2YiMgADMZERAZgMCYiMgDbjImIDMA7YyIiAzgWjBcvXoyzzz4bSUlJGDp0KN5++22ndkVEFPMcaaZ48cUX8ctf/hLLli3D0KFDsWjRIqxevRoVFRWtDvrSLBAI4MCBA0hLS1Ma2YuIyFRCCNTV1SEnJ6ftGXCceHh5yJAhIQ/Q+/1+kZOTI0pLS9vctqqqSgDgiy+++Oowr6qqqjZjn/bu0MeOHcOuXbswY8aM4DK3243CwkJs27atze3Dhwm0SzYfWGNjo9K24SNd+f1+y/WQzZOm0rdfVv/jx4+3WCY0/oEj+4tEtXyd50zGTt1UqHxPsu9ENimp7Nhl9Y+PD/0Zyu6gZDOWyNbTfb7Dqf61qvM7scrpayUSKnFNezD+6quv4Pf7g1O2NMvMzAyOMnWyhoaGkIu9rq5Oa33sNHXobCaxWpZsO6cvMjvlO920FI1jV1lH9bhVtlUtPxrNeAzG1qict6g/TVFaWgqv1xt89ejRI9pVIiJqd9qD8RlnnIG4uDjU1NSELK+pqUFWVlaL9WfMmAGfzxd8VVVV6a4SEZHxtDdTJCYmIi8vD2VlZRg7diyApva0srIy6ZB7Ho9H2k5nRXjbGyBvV5OtJ2uHlS1TIdunbGZh2Xqytker26kep86ydJ4zWT1U6iZbR1a+rK4qbbOy8mVltZk9b2Wfds5FNOish9O/CZnExMQWyyKdVVwHR8YznjZtGoqLizF48GAMGTIEixYtQn19PcaPH+/E7oiIYp4jwfjGG2/EoUOHMGvWLFRXV+PCCy/EunXrWiT1iIioiXFjU9TW1sLr9VraVvantNN/Xsuo/smksp7sTyjVP5OtNlPI6CxLxs6fmTqbKVSaFnSWBbSsr51z4TSn69ZRmyl8Ph/S09NPuU7Un6YgIqIONgee6t2J6jKVf1k7derUYtm3337b5natlR9+l6f7X2iVZFRSUlKLZbIEpEz4tqrb2bm7Cv/eVe/irSZCVf8KUU26hddDdqemMwFsRzTKVzlOO/Wy+hvTff55Z0xEZAAGYyIiAzAYExEZIGbajFUy07L2GtUBVlTbqsKptg/LqGblVbaTtVlabQtTbefVua3VJw9kVJ/yUL0OVMqz8zRFONVzqPoUgNXrzM4TNCq5CVVWn6awetyqdLef886YiMgADMZERAZgMCYiMgCDMRGRAWImgSdLJqiQjQinOoC9yj5Vk2ROdydWHWktPKnh9OhU7TECmUp3aKuJOTtUk8Lhy1QTTzo7gui+Ptu7i7Sda0rWyUnlYQBZAjWcEEJ5ZiHeGRMRGYDBmIjIAAzGREQGYDAmIjJAzCTwZMkElQZ61UZ8lenRrfaoam1blWWqx21nDF8VsiSH1SmKdCeLVL4X1ZHQVKgmk1WPyelErsr5sTOqncp6Onu9Ai2/TzuJaKvXgfYRFbWWRkREljAYExEZgMGYiMgADMZERAaImQSe1elw7CRHVMpXpTpVT3hSwM50Pjp7QcmSHO0xkaMKlX2qnn+VRJPuITqdLkslUWZnklWriXQ703upfOe6r0+dw4JKy9daGhERWcJgTERkAAZjIiIDMBgTERnA2AReXFwcXC5X8L3V5JxqksDqPFt2kihWE08ysmSFSu891R5PKj0UZfWQrWO1F5cqO8N2qib6wlntoSij2kNR5/VodbjPSPYZTucQoDKqyTqd+wz/7oQQ8Pv9avWwtEciItKKwZiIyAAMxkREBjC2zVi1naUtVkdkiharD5bL2sdU2svtjKqm2o6sQvcD9CpU2wpV2u11Xmd2Oiaofnfh68m2s3NMVq/jaFwHOusWvo4QQrkevDMmIjIAgzERkQEYjImIDMBgTERkAGMTeOF0Tu2ik50peOxM46RSD50jqKWlpbVYVldXp618O51Pws+t08kiOyPpqbBzHat2EgovT3VUPlndrHaiMpnK79rqVHCt4Z0xEZEBGIyJiAwQcTB+6623MGbMGOTk5MDlcuHll18O+VwIgVmzZiE7OxvJyckoLCzE3r17ddWXOpg4ADMBrAsE8GshEBfBc5lEHUnEwbi+vh6DBg3C4sWLpZ8vWLAATz75JJYtW4YdO3YgJSUFRUVFMdf5gtrHAwDmALgawGwhMCO61SGKGpeIpItI+MYuF9asWYOxY8cCaLorzsnJwb333ov77rsPAODz+ZCZmYkVK1bgpptuarPM2tpaeL1eq1UylmqCyurocaoJPJ1TSakksmTH09DQ8H0Zo0bBXVYWfP8mgKII92n1GGQJKllS0uPxtFlWNJLHMrJjUqmH7lHhwp38nTdLSUlRKl9notVOIj28vEgS5D6fD+np6adcR2ubcWVlJaqrq1FYWBhc5vV6MXToUGzbtk3nrqiDCBQUQJwYKjUAYGt0q0MUNVofbauurgYAZGZmhizPzMwMfhauoaEh5F/N2tpanVUiwwXuvx8A8Le5c7EVwPzoVocoaqL+NEVpaSm8Xm/w1aNHj2hXidpTfDwCDz6IIgAPA9AzPBRR7NEajLOysgAANTU1IctramqCn4WbMWMGfD5f8FVVVaWzSkSRO34c7kceaWrPfuQRxEW7PnRa0NpM0atXL2RlZaGsrAwXXnghgKZmhx07dmDChAnSbTwej1KCREZlmD7VhIbOxIGMKWVZTXbpTJypft9OJ+tkiRuPx4OZaHrCww0AZWV4AE137Tr2qZL0sZM4szPVkNV9yoR/d7LvXLUno1U6k+ZAy2tPpZdeJNMuRRyMjxw5gk8++ST4vrKyEu+99x66dOmCnj17YsqUKZg3bx569+6NXr16YebMmcjJyQk+cUFkumH4/k9G94n3RE6LOBjv3LkTV155ZfD9tGnTAADFxcVYsWIFfvWrX6G+vh533nknDh8+jGHDhmHdunXSgc6JTLQVQCGaAjGf8KD2Yus5YydE8pxxLDVTOM3qn8SqdDYZRGOfkQx6E4emzijDgOATHm39oWnn2W+VsnRfi1Zn4lAle549/LwuiIuD/6QZ4JvX00X3byL8nKk0gzQ3U6g8Zxwzo7YRtRc/rLUR6xR3ojfiMCGw1eXCI4j9J02ae1u6ceIvDyHwSFgwPp0ZG4xdLhdcJ31RVu9c7fxLGN60IitLZUhHO1TmsWttnzrvLGXbqfzVYedc6DyPTg9hKrsWrV57DQ0NcM2bB/fcuXChKXAJtPwHIhp/raiSnY/wtvgfBQI4rvAbVrnDVZ2PUXXIW5V4o/2vFa2lEZEWrvJyuE60ILqE6BBJxK1oaoMH2BYvY+ydMdHpTBQUQJSVwSUEhMuFrWaldixp7l15cls8fY/BmMhAYvp0BNB0hywKCjD/oYeiXSXbTGiLNxmDMZGJ4uMhfv1rNN8P+ztAMKZTMzYYCyHQ1lN34Y3xqkk+1UeHVB7/0dlLCWiZgFFNyKg+xmP1cUBZWTofnbPD6rCgTj9GZXWONNUeiqr1j8bwnjrL1/k4oM4hY3UnS5nAIyIyAIMxEZEBGIyJiAxgbJuxCpWHsO08GO/0CFI6Ox3IOoJYbStU7dyicr51T+tktTzV3IHqtuGcbj+30+6r8j3ZyYdYrZusQ5PP52uxLC0trcWy8PPdHp1dVEZtC18mhJBOOSXDO2MiMtOJcaVfb2zEA35/h585PKbvjImo43I/9hjiHn4YhULgqhNjAs+P67hD/fPOmIiM5D6pS7gbQEEMjaJoBYMxERkpfObwco05FhPFdDOFyqhqqqN1qYy6pTqCmiqVutkZjU0liaKzLN10Toej85jsJNNUErntkYxSqa+dMZpVErmyZSd3eGkxrrTfrzyFkRNURnyzEw9iOhgTUcd1uo1l0bHv+4mIYgSDMRGRARiMiYgMYGybcfi0SzLffvttm+XY6cWlkoRQLV91eiaVXmE6R+vSnZgzIWnodALMzjlT6ekWjemUVHuvqvY0DK+vrBea6uh0Ktdxe4xM5/R3wDtjImo/J3rVxY8ahZloemKCmhh7Z0xEHU9zrzqXEJhzYtnp9MTEqfDOmIjaTXivuo4w0aouDMZE1G7Ce9VxhujvxUwzhc5kjuoUOVane1Fdz2rSQWcCTPcwiSrl2UmEmsDpuuo+P1YTYDqPqTlZ16JXXdh6Vnu5RmNqKd3XQcwEYyKKfadbr7pIsJmCiMgADMZERAZgMCYiMoCxbcaJiYkhPfBUGvFlc2XV1dW1WBaNISJVkzJWEytWewLKkpmycx2N8+M0q8kiO0lPq+XJzo+s/rKks6z88O9d9/kPP3bVc2Z1CMr2uH5Uvs/wdYQQEIrTRfHOmIjIAAzGREQGYDAmIjKAsW3GslGewnXq1Cnkvax9OHwdQG20N6Bl+4+dB+NVO0iEl2ens4XKtnamiXGarD1b1iaq0j4pOxeyY3d6pDurnRNU66+ShwBaXmd2jkklX+F0RxnVTlV29qlyHYQfpxBCeaoo3hkTERmAwZiIyAARBePS0lL88Ic/RFpaGrp3746xY8eioqIiZJ2jR4+ipKQEXbt2RWpqKsaNG4eamhqtlSYi6mgiCsZbtmxBSUkJtm/fjg0bNqCxsREjRoxAfX19cJ2pU6fi1VdfxerVq7FlyxYcOHAA1113nfaKExF1JC6h+kSyxKFDh9C9e3ds2bIFl112GXw+H7p164aVK1fi+uuvBwB89NFH6NevH7Zt24ZLLrmkzTJra2vh9XqtVsmyWBo1TMbpUatkyTSZ8H2qTi3ldKcS1WSg6nomsDPll9PnWyedoxvKWP2dR1Ivn8+H9PT0U5dnqRYn7QAAunTpAgDYtWsXGhsbUVhYGFynb9++6NmzJ7Zt22ZnV0REHZrlR9sCgQCmTJmCgoICDBgwAABQXV2NxMREZGRkhKybmZmJ6upqaTkNDQ0hj7HV1tZarRIRUcyyfGdcUlKCPXv2YNWqVbYqUFpaCq/XG3z16NHDVnlERLHIUjCeOHEiXnvtNWzatAlnnXVWcHlWVhaOHTuGw4cPh6xfU1ODrKwsaVkzZsyAz+cLvqqqqqxUiYgopkXUTCGEwKRJk7BmzRps3rwZvXr1Cvk8Ly8PCQkJKCsrw7hx4wAAFRUV2L9/P/Lz86Vlejye4JQsJ3O5XCGjtulMOKg2vKskraKR3HE62Wh1NDNVuqd6UqH6PZnwfaom4VSp9Ei001tN5Xuyc81a/c5Ve2KqsrOtioiCcUlJCVauXIlXXnkFaWlpwXZgr9eL5ORkeL1e3H777Zg2bRq6dOmC9PR0TJo0Cfn5+UpPUhARna4iCsZLly4FAFxxxRUhy5cvX47bbrsNALBw4UK43W6MGzcODQ0NKCoqwpIlS7RUloioo7L1nLETmp8zbu9mChmV5xRN+LMWiK1mClWx/nysKqvNFDqbFkxuprDK6XMmE7XnjImISA9jh9AMn65E5S5Vd0Ig/K5XtUePHeFJQ9mdt867DNm/9id3b2+WkJDQYpnTd6mxdBds5y5e5btzethOO+VbnTZKJztDzcoS9dGYmo13xkREBmAwJiIyAIMxEZEBGIyppePHgYcfhquoCHj44ab3ROQoYx9t62h0Pi4mS+DJlqk8didLSsx2uzErEIAbQADAXLcbj0mSHLL6h885qDrfoB3h51b1vEZjaEaryVc7CUKriWfVBJjKPmXHaHVYVploDB1q1BCa1DEVnAjEQNMFUhBDTzUQxSoGY2qh3O1Gc/gNnHhPRM4y9jljip5HXS7A7UZBIIBytxuPulxwtb0ZEdkQM23GVtt/TJ5Gx2o7suq50NlmplpWeFuhbLtonH9ZPay2s9u5pnSO/OV4JwTNI8U5SbWu7X3Omjuvsc2YiChGMBgTERmAwZiIyAAMxkREBujwT1OoJJlaWxaeTLOTuNGZSJTVVXU0qvBOGHZGu5JxenQuq2T1Vz3/VjtNmDKGr+zYw5PkspH6TOm0oqI9plgKX6b7u+SdMRGRARiMiYgMwGBMRGQABmMiIgPETALPamO/aiO7ynp2eo7pnBbJTj1UpnWSiUYySic7I62FL1Od6DIaI4TJlsl6evp8vjb3qfqdW012RSOpZ2dblfJsTY9leUsiItKGwZiIyAAMxkREBmAwJiIyQMwk8HSympiQ9WhTSfgA1nsI2UkIqCZNrJalwukkjZ19qtYjvDyr27VGZYoiO73JrA7Lqvqdq5zbaFwHqlTjQfh6KkOwNg+hqYJ3xkREBmAwJiIyAIMxEZEBGIyJiAxwWibwrPYGUkmEAPIeT7Lyw4ezVKWaSFRJrMjKqquray4U7sceg7u8HHM3bcKjLhf8ru+nJpXtMzxZ4XK1nMpU53x0rZUXTnacsu9TVlb496n6vakmba0OQamzB6SdZJpKAkx3ss5q0lNWD6u9dHX3QD0tgzGpcT/2GOIefhguITALANxuPCIJrkRkH5spqFXu8nK4TtzpugEUGPIoElFHxGBMrQoUFECcuBMOACg/RXNAHICZADBiBDB3LhBDgwgRmYDNFNSqwP33A0BIm3FrHgAwBwA2bAA2bmxaOGuW01Uk6jBcQrV7SDupra1tMT9Xa3Q24ltlJ5mmUp4siaU6hKNKLyJdSYj1AEac9H4DgGvc7qj0srIz9KNKfTt16qRUvp2hTsPZmUNRZc5EOwlCWcLa6WSXzt6rsu9TJUmr8jsUQsDv98Pn8yE9Pf3U5bW5RyIFW9HUlIET/93KRB9RRNhMQVrMP/HfS9EUiEujWRmiGBTRnfHSpUsxcOBApKenIz09Hfn5+Vi7dm3w86NHj6KkpARdu3ZFamoqxo0bh5qaGu2VJvP4ATyMpqaJeWHPIxNR2yJqM3711VcRFxeH3r17QwiB5557Do8//jh2796N888/HxMmTMDrr7+OFStWwOv1YuLEiXC73SgvL1euUHObcUJCQkiHAZW2U1kbkdURmWTrtcfIU0616dql2mbp9Eh0MuHnTLV81WsjvDw7Uzip1EN1qi3V70SlzVh1uibVjk8q17HTU3mZNFWYSpux7QRely5d8Pjjj+P6669Ht27dsHLlSlx//fUAgI8++gj9+vXDtm3bcMkllyiVx2DMYBwpBuNTr8dg7Ez5kXA0gef3+7Fq1SrU19cjPz8fu3btQmNjIwoLC4Pr9O3bFz179sS2bdtaLaehoQG1tbUhLyKi003Ewfj9999HamoqPB4P7r77bqxZswb9+/dHdXU1EhMTkZGREbJ+ZmYmqqurWy2vtLQUXq83+OrRo0fEB0FEFOsiDsbnnXce3nvvPezYsQMTJkxAcXExPvzwQ8sVmDFjBnw+X/BVVVVluSwiolgV8aNtiYmJOPfccwEAeXl5eOedd/DEE0/gxhtvxLFjx3D48OGQu+OamhpkZWW1Wp7H44HH42mxvLGxMdKq2WojUukU4PTIVrJ9qLZTW+0UoNKeCFhva1MduczOVEZW66baaUKlI47Kdq3RWX/V86PSti9rH1a9jlWOyen2W92dwHTGA2n5dgsIBAJoaGhAXl4eEhISUFZWFvysoqIC+/fvR35+vt3dEBF1aBHdGc+YMQMjR45Ez549UVdXh5UrV2Lz5s1Yv349vF4vbr/9dkybNg1dunRBeno6Jk2ahPz8fOUnKYiITlcRBeODBw/il7/8Jb788kt4vV4MHDgQ69evx9VXXw0AWLhwIdxuN8aNG4eGhgYUFRVhyZIljlSciKgjiemBgsLbcHTPhhCNNmOrz+k63WasWg+Vc6a7zdjpwYjau83YznWsen6sXtsmPbtrRbTajFWeM46ZsSlUgobui0Lnj9xqAk+1LNVkjtPnTIWd+suWhQc92Tm0M8JZ+Laq//Cp7jMtLS3kfXDaKwt0/uNndSTA1tZrb507d26xrL6+vsUy1e/J6X/0OWobEZEBGIyJiAzAYExEZAAGYyIiAxibwHO5XCGjtsnofJrC6SSE1QSS1d5NgPWEg52Mc3j9VRNbqvtU6R0oS7Cplq9yblVHRlP9nsITdjpHGgTUntCx89sxIVknq/8333yjdR/h15Wd6dVkeGdMRGQABmMiIgMwGBMRGYDBmIjIAMYm8IQQOLmntkpvLDuJIZUkhyrVsqwmymTT4ciOXVZWp06dQt5/++23luoAqE8PpEK1i7dK0s1qHVTZGabSag9Lq4m51rZVqZedpKTObvEq6zndO661emgt39HSiYhICYMxEZEBGIyJiAxgbJtxXFxcSKcPlTazaAyvKOP0PlWnS5cJbyOWnTOnp2JSZXWfTl8HsjZ7Wdu7jErdZN9vNK5tO22kKnWzM1RrOJ3tz62tF/692Bl+VoZ3xkREBmAwJiIyAIMxEZEBGIyJiAxgbALP7/e3uY7VB+hVRwNTKcvOw/jtXX9A7WF81U4TKsk/Ox0wZOdWZcojp+cqVE3WyVitm53vXIXqVFg6yfYpo3LsdubwU+0wFU53Apt3xkREBmAwJiIyAIMxEZEBGIyJiAxgbAIvnNURpOxMV6OyjtOjwpkwpQ2gfs50Jn1UknW6qVwvqqPVmdIjVIX2ZJRCotjpa9vO9aPye9X9XfLOmIjIAAzGREQGYDAmIjIAgzERkQFiJoFnlWojvkqyxc40NKYkbqzWw2qyRTWJpdobS+c+VVk9dlO+81iiMr0aoNYDz06yNxrfHe+MiYgMwGBMRGQABmMiIgMwGBMRGaBDJfDsDAOo0uNGd48hqz2E7CSoVHpG2RE+P5zqfH12hiK1yup5jMawpk6LxvCwMrLyne6pZ0pPSd4ZExEZgMGYiMgAtoLxo48+CpfLhSlTpgSXHT16FCUlJejatStSU1Mxbtw41NTU2K0nEVGHZrnN+J133sHvf/97DBw4MGT51KlT8frrr2P16tXwer2YOHEirrvuOpSXl0dUvsvlgsvlCr63Oqqaqmi0WZoyIptOqm3E4XSea1l7n6x9vr6+vsWyhISENss3+Xuz2snJTucl1Tb0tuoQST1U2tlV24JVj8nxtmsrGx05cgQ333wznn32WXTu3Dm43Ofz4Y9//CN+97vf4aqrrkJeXh6WL1+Of/zjH9i+fbu2ShMRdTSWgnFJSQlGjx6NwsLCkOW7du1CY2NjyPK+ffuiZ8+e2LZtm7SshoYG1NbWhryIiE43ETdTrFq1Cu+++y7eeeedFp9VV1cjMTERGRkZIcszMzNRXV0tLa+0tBQPPfRQpNUgIupQIrozrqqqwuTJk/H888+3eJ7UqhkzZsDn8wVfVVVVWsolIoolEd0Z79q1CwcPHsTFF18cXOb3+/HWW2/h6aefxvr163Hs2DEcPnw45O64pqYGWVlZ0jI9Hg88Ho+1yoc1sqsm4VQ7h+hMEuhMCKgmqGTHpJJYsTPSnZX9RbKe1Qf0ZfVXSdYBah1ZdI5OZ+dcqHZystqpQed1bKezhcp6ukfqc7pzTkTBePjw4Xj//fdDlo0fPx59+/bF/fffjx49eiAhIQFlZWUYN24cAKCiogL79+9Hfn6+vloTaRQH4AEAwwBsBTAfgD+qNaLTUUTBOC0tDQMGDAhZlpKSgq5duwaX33777Zg2bRq6dOmC9PR0TJo0Cfn5+bjkkkv01ZpIowcAzEFTm11z6vnhqNWGTlfax6ZYuHAh3G43xo0bh4aGBhQVFWHJkiW6d0OkzTB8nzxxn3hP1N5sB+PNmzeHvE9KSsLixYuxePFiu0UTtYutaLojdgMInHhP1N6MHbVNCAEhxCnXUUkc2ElyqJSvmqSR1cPqqG0yVhNsdsrSOTKXneSo3e3mn/jvyW3GJwu/DnQnnsKX2ek5JqPzu5P9Jqwm9VQT7lbrKvt9ycrSOXVaeP1V4lgzY4MxUXvxg23EFH0ctY2IyAAMxkREBmAwJiIyQIdvM5Y1zsu6csvWU2nYVx0+0Onh91SThuH10N1DTmdZVvepmgxUHcJR53fndM8xq+U5nVS1w2qi22oyvDVWevwKIeD3q3Uh4p0xEZEBGIyJiAzAYExEZAAGYyIiA3T4BJ6M1XnaZOz0jJKxOmyn072ZZGSJ0PCkier+VBOhOnv9qSZ3Va6XaCS2VKkM26mzF5rqPlV7r+pOxFmlcux2kr28MyYiMgCDMRGRARiMiQwUB2AmgPUn/hsX3epQOzgt24yJTMcB708/MROMrSYhnE6s6B7GMHxZp06dWqzz7bffKu3T6WSISgLGzv5Uk5cq29lJ1qn0vNKZtP3uu+8QP2oU3GVlTZ/D3oD3KteZrJebKpW5FlXPj9Xrxc7v3Oq2OucDBNhMQWSkQEEBhMsFABAuFwe8Pw3EzJ0x0ekkcP/9AAB3eTkCBQWYP3dulGtETmMwJjJRfDwCDz6I5j+W/QzGHV7MBGOVthiVTgiRUOmAocpq+5Vq+7CMKQ/Lh7M6HRSgt71fdn6sdvpQpdI+6fF4tJXV2jIVutv7rbKaJ1Ad7U21ruHl6f59sc2YiMgADMZERAZgMCYiMgCDMRGRAYxN4MXFxcF14jlLQN6IH96ALku0qCaLrI4ypZvKPqxOQ2OHzsSW7pHuVOhO5jhZvp0poqyy0ynGaqcJnQlIO52jVOlM5MrwzpiIyAAMxkREBmAwJiIyAIMxEZEBjE3g+f1+LeWo9syRJTDC15Otozpyk+p64UkTWdJANVmnczQq1eRFQ0NDyHvV3mQyOkfcU/1OrI5053QCUjVZp3ptq/QuVb3OZPtUuV50jnRnJ1kXjYSptB6Olk5EREoYjImIDMBgTERkAGPbjClGHT8O92OPBcfhjQOgp/WfqGNzCSFEtCtxstraWni93hbLZQ3qKlP8qPSsA9SSCaoJB9k+dfY6s5PYCk8Q2kkGyhIas91uzAoE4AYQQNM8buFzt+merkaFziSNaq9O1WmjojLFj8bhYVU43WvU6aFPAXtDaPp8PqSnp59yHTZTkFYFJwIxYH/uNqLTCYMxaVXudgdnpwgAnLuNSFFEwXjOnDlwuVwhr759+wY/P3r0KEpKStC1a1ekpqZi3LhxqKmp0V5pMtejLhfmut3YAGCu24350a4QUYyIOIF3/vnnY+PGjd8XcFJb1tSpU/H6669j9erV8Hq9mDhxIq677jqUl5frqS0Zz+9y4RGXCzjRJulvh5HuiDqCiINxfHw8srKyWiz3+Xz44x//iJUrV+Kqq64CACxfvhz9+vXD9u3bcckll9iqqNUeQtEYrlE1saKS6NNdV5Wkhp1kS/gxyc6FSo8wwJzvKVx7zIUYzukEpx0q14vs+tE57KWdZJ1qctTpYWojbjPeu3cvcnJycM455+Dmm2/G/v37AQC7du1CY2MjCgsLg+v27dsXPXv2xLZt21otr6GhAbW1tSEvIqLTTUTBeOjQoVixYgXWrVuHpUuXorKyEpdeeinq6upQXV2NxMREZGRkhGyTmZmJ6urqVsssLS2F1+sNvnr06GHpQIiIYllEzRQjR44M/v/AgQMxdOhQ5Obm4i9/+QuSk5MtVWDGjBmYNm1a8H1tbS0DMhGddmz1wMvIyECfPn3wySef4Oqrr8axY8dw+PDhkLvjmpoaaRtzM4/HozSyl0q7juqD/TKqD+irrKPavme1g4HVusroblNXabuLRqcPnSOEycpSPSaV70lnXVsrT2d7vEpbqqxdWdY+rNqOrLPTiint8baeMz5y5Aj27duH7Oxs5OXlISEhAWVlZcHPKyoqsH//fuTn59uuKBFRRxbRnfF9992HMWPGIDc3FwcOHMDs2bMRFxeHn//85/B6vbj99tsxbdo0dOnSBenp6Zg0aRLy8/NtP0lBRNTRRRSM//3vf+PnP/85vv76a3Tr1g3Dhg3D9u3b0a1bNwDAwoUL4Xa7MW7cODQ0NKCoqAhLlixxpOJERB1JzAwUpLPNWLUNzek2YxXRaDN2uk03Gm3GdpjYZhwH4AE0jf2xFcB8NI2OF43ntVWoPrsejTbj9qAyUFDMBONosDNKUzirP1ang32sBUan62tqMAs3E8BDLhdcQkC4XAjMmgXx618jISGhxbo6j8lOQlyn8OtAVi/Z7zVa3y9HbSPqoIYBcJ24j3IJAReHHIh5DMZEMWgrAOFyASf+KwoKolshso0zfRDFoPkAZs+aBVd5OURBAcT06dGuEtnEYEwUg/wAxK9/DaMSPmRLhw/GdhrsdY7SFI3RulSmqnI6WaeacJNl22XnTCXpqXquVZ++CV/m9KhzqudMlqyT0ZmgikYy0+rohrGWnGabMRGRARiMiYgMwGBMRGQABmMiIgPETALPatdkE3tPNUtKSmqxLDxpqPuYnJ7WKZwsYaKSkGltW5nwbe0kbnROxWRn+iqrrF4vdq4zpxNlVocAVR02wJQYwTtjIiIDMBgTERmAwZiIyAAMxkREBoiZBJ6MzmSU1fGSVXv+yNaTzRdntYec04kJWTJKtk+VOfBUj0l2HlXKs5r4A+THGV4P2fi6MlaHcNSZoNW9ndVxs3VeP3aoJlVVfte6e/PxzpiIyAAMxkREBmAwJiIyQEy3GatQHZlLpf3HzshQOjs62GkfDl9P1vFE1m6ns7OCav1VR0fTOT2WbFunOzCEs5ObcHpUMqsdMGTnVTUnoDP3YadN2ulzyztjIiIDMBgTERmAwZiIyAAMxkREBoiZBJ7Oh9mtPuBuZ2Sx9k4CtSY8Yef0KGJ2qHYwiEZy0QQ6rynVZKDq+VH57UTjvNr5fsN/O7o7qPDOmIjIAAzGREQGYDAmIjIAgzERkQFiJoGnQrWXm84Enmo97Iy+Fs5O4kMl6aD7PFrdLhoJHqvJKBmrySLVHpwyqt+T0yOQqbAzVZXV70Tnb0d3D0jeGRMRGYDBmIjIAAzGREQGYDAmIjJAh0rg2Wo819jzyk6iT2Vbp4dOtFOWynCWqj3r7CR4VFhNVOrupadyzqKRYJPRmSiTnX/V79Lq+db53XHaJSKiDojBmIjIABEH4y+++AK33HILunbtiuTkZFxwwQXYuXNn8HMhBGbNmoXs7GwkJyejsLAQe/fu1VppIqKOJqJg/M0336CgoAAJCQlYu3YtPvzwQ/z2t79F586dg+ssWLAATz75JJYtW4YdO3YgJSUFRUVFjk/BTUQUy1xCCKG68vTp01FeXo6///3v0s+FEMjJycG9996L++67DwDg8/mQmZmJFStW4KabbmpzH7W1tfB6vS2Wq/RAsjPkXzRYrZudY1JJnqkm2GTC66H7XKvMaej0cI0651XUXY9ozJUXjbn4nKa7J6zP50N6evqp96lcGoC//vWvGDx4MH72s5+he/fuuOiii/Dss88GP6+srER1dTUKCwuDy7xeL4YOHYpt27ZJy2xoaEBtbW3Ii4jodBNRMP7000+xdOlS9O7dG+vXr8eECRNwzz334LnnngMAVFdXAwAyMzNDtsvMzAx+Fq60tBRerzf46tGjh5XjICKKaREF40AggIsvvhjz58/HRRddhDvvvBP/+Z//iWXLllmuwIwZM+Dz+YKvqqoqy2UREcWqiIJxdnY2+vfvH7KsX79+2L9/PwAgKysLAFBTUxOyTk1NTfCzcB6PB+np6SEvIqLTTUQ98AoKClBRURGy7OOPP0Zubi4AoFevXsjKykJZWRkuvPBCAE0JuR07dmDChAm2Kmo1KeN04sbpBJXuZJTTPaOcpnI+wucqA9R7AlpNPKlup5LskvUylJWveh04nUyzmnS2Whbg/BCg0UjyRxSMp06dih/96EeYP38+brjhBrz99tt45pln8MwzzwAAXC4XpkyZgnnz5qF3797o1asXZs6ciZycHIwdO9aJ+hMRdQwiQq+++qoYMGCA8Hg8om/fvuKZZ54J+TwQCIiZM2eKzMxM4fF4xPDhw0VFRYVy+T6fTwBo8XK73S1esvWcfOmug6y8aB8jAJGYmNjiFY16WH0lJSW1eMnObXx8fIuX09eByj5l59+Ua8Pq+VC51u2cx2ifg7ZePp+vzdgX0XPG7aG154xNeF5Ydx2cntXDKp2D8USD080Udq6DaDRTOE3lfMRaM4VuKs8Zx8yobVbbMWU/TNULW6UDg6x82XqyuqpM8WOH1YfxTb+w26La21Pn9Fs6/6G2M9Kd1Q4pdjpuWM3dqI6aZ/UfTZOnP5PuU2tpRERkCYMxEZEBGIyJiAzAYExEZICYSeCpJDVkDeqyZI7TyRaZTp06tVgmq5vOpIDKKHaqnUpkGX7ZeuH7NOEpGLtUngxQPU6nE0+qCbDwfdgZ9c9qpw87yTSnp8JyevREaXmWtyQiIm0YjImIDMBgTERkAOPajCPpEGi186DOToeqZcnWi0bnR53nTKUswzp4auH0d6n7nOn8nqLxmzP1OtMdq4wLxnV1dcrrxlIw/u6777Tt0w6rx97Y2Niu+zOZ7Jj8fr+28nWWpbu8aPzmVOpvejCuq6uTDvNwMuPGpggEAjhw4ADS0tJQV1eHHj16oKqqKibHOa6trWX9o4j1j65Yrz9g/xiEEKirq0NOTk6bXayNuzN2u90466yzADQNyQkg5gedZ/2ji/WPrlivP2DvGNq6I27GBB4RkQEYjImIDGB0MPZ4PJg9ezY8Hk+0q2IJ6x9drH90xXr9gfY9BuMSeEREpyOj74yJiE4XDMZERAZgMCYiMgCDMRGRAYwNxosXL8bZZ5+NpKQkDB06FG+//Xa0q9Sqt956C2PGjEFOTg5cLhdefvnlkM+FEJg1axays7ORnJyMwsJC7N27NzqVDVNaWoof/vCHSEtLQ/fu3TF27FhUVFSErHP06FGUlJSga9euSE1Nxbhx41BTUxOlGodaunQpBg4cGHwoPz8/H2vXrg1+bnLdZR599FG4XC5MmTIluMz0Y5gzZw5cLlfIq2/fvsHPTa8/AHzxxRe45ZZb0LVrVyQnJ+OCCy7Azp07g5+3x2/YyGD84osvYtq0aZg9ezbeffddDBo0CEVFRTh48GC0qyZVX1+PQYMGYfHixdLPFyxYgCeffBLLli3Djh07kJKSgqKiIuVZjJ20ZcsWlJSUYPv27diwYQMaGxsxYsQI1NfXB9eZOnUqXn31VaxevRpbtmzBgQMHcN1110Wx1t8766yz8Oijj2LXrl3YuXMnrrrqKlx77bX44IMPAJhd93DvvPMOfv/732PgwIEhy2PhGM4//3x8+eWXwdfWrVuDn5le/2+++QYFBQVISEjA2rVr8eGHH+K3v/0tOnfuHFynXX7DwkBDhgwRJSUlwfd+v1/k5OSI0tLSKNZKDQCxZs2a4PtAICCysrLE448/Hlx2+PBh4fF4xAsvvBCFGp7awYMHBQCxZcsWIURTXRMSEsTq1auD6/zrX/8SAMS2bduiVc1T6ty5s/jDH/4QU3Wvq6sTvXv3Fhs2bBCXX365mDx5shAiNs7/7NmzxaBBg6SfxUL977//fjFs2LBWP2+v37Bxd8bHjh3Drl27UFhYGFzmdrtRWFiIbdu2RbFm1lRWVqK6ujrkeLxeL4YOHWrk8fh8PgBAly5dAAC7du1CY2NjSP379u2Lnj17Gld/v9+PVatWob6+Hvn5+TFV95KSEowePTqkrkDsnP+9e/ciJycH55xzDm6++Wbs378fQGzU/69//SsGDx6Mn/3sZ+jevTsuuugiPPvss8HP2+s3bFww/uqrr+D3+5GZmRmyPDMzE9XV1VGqlXXNdY6F4wkEApgyZQoKCgowYMAAAE31T0xMREZGRsi6JtX//fffR2pqKjweD+6++26sWbMG/fv3j4m6A8CqVavw7rvvorS0tMVnsXAMQ4cOxYoVK7Bu3TosXboUlZWVuPTSS1FXVxcT9f/000+xdOlS9O7dG+vXr8eECRNwzz334LnnngPQfr9h40Zto+gpKSnBnj17Qtr7YsF5552H9957Dz6fDy+99BKKi4uxZcuWaFdLSVVVFSZPnowNGzYgKSkp2tWxZOTIkcH/HzhwIIYOHYrc3Fz85S9/QXJychRrpiYQCGDw4MGYP38+AOCiiy7Cnj17sGzZMhQXF7dbPYy7Mz7jjDMQFxfXIttaU1ODrKysKNXKuuY6m348EydOxGuvvYZNmzYFhzAFmup/7NgxHD58OGR9k+qfmJiIc889F3l5eSgtLcWgQYPwxBNPxETdd+3ahYMHD+Liiy9GfHw84uPjsWXLFjz55JOIj49HZmam8ccQLiMjA3369MEnn3wSE99BdnY2+vfvH7KsX79+waaW9voNGxeMExMTkZeXh7KysuCyQCCAsrIy5OfnR7Fm1vTq1QtZWVkhx1NbW4sdO3YYcTxCCEycOBFr1qzB3/72N/Tq1Svk87y8PCQkJITUv6KiAvv37zei/jKBQAANDQ0xUffhw4fj/fffx3vvvRd8DR48GDfffHPw/00/hnBHjhzBvn37kJ2dHRPfQUFBQYvHOT/++GPk5uYCaMffsLZUoEarVq0SHo9HrFixQnz44YfizjvvFBkZGaK6ujraVZOqq6sTu3fvFrt37xYAxO9+9zuxe/du8fnnnwshhHj00UdFRkaGeOWVV8Q///lPce2114pevXqJ7777Lso1F2LChAnC6/WKzZs3iy+//DL4+vbbb4Pr3H333aJnz57ib3/7m9i5c6fIz88X+fn5Uaz196ZPny62bNkiKisrxT//+U8xffp04XK5xJtvvimEMLvurTn5aQohzD+Ge++9V2zevFlUVlaK8vJyUVhYKM444wxx8OBBIYT59X/77bdFfHy8eOSRR8TevXvF888/Lzp16iT+/Oc/B9dpj9+wkcFYCCGeeuop0bNnT5GYmCiGDBkitm/fHu0qtWrTpk0CQItXcXGxEKLp0ZiZM2eKzMxM4fF4xPDhw0VFRUV0K32CrN4AxPLly4PrfPfdd+K//uu/ROfOnUWnTp3ET3/6U/Hll19Gr9In+Y//+A+Rm5srEhMTRbdu3cTw4cODgVgIs+vemvBgbPox3HjjjSI7O1skJiaKM888U9x4443ik08+CX5uev2FEOLVV18VAwYMEB6PR/Tt21c888wzIZ+3x2+YQ2gSERnAuDZjIqLTEYMxEZEBGIyJiAzAYExEZAAGYyIiAzAYExEZgMGYiMgADMZERAZgMCYiMgCDMRGRARiMiYgMwGBMRGSA/wcZcktw8w+oCQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select an index to visualize from the entire dataset\n",
    "index_to_visualize = np.random.randint(0, len(all_images))\n",
    "\n",
    "# index_to_visualize = 11548\n",
    "# Visualize the selected image with predicted and true midpoints\n",
    "visualize_midpoints(all_images[index_to_visualize], all_pred_midpoints[index_to_visualize, 0, :, :] * 64, title=\"Predicted Midpoints\")\n",
    "visualize_midpoints(all_images[index_to_visualize], all_true_midpoints[index_to_visualize, 0, :, :] * 64, title=\"Ground Truth Midpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07237816, 0.91962624)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_pred_midpoints),np.max(all_pred_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.140625, 0.84375)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_true_midpoints),np.max(all_true_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.6588065 , 0.13951787],\n",
       "         [0.78171575, 0.15159717],\n",
       "         [0.19733031, 0.19591215],\n",
       "         [0.65489393, 0.27009186],\n",
       "         [0.25095755, 0.30472112],\n",
       "         [0.52209944, 0.31213707],\n",
       "         [0.19568872, 0.3521382 ],\n",
       "         [0.22697227, 0.38265854],\n",
       "         [0.81788504, 0.4486158 ],\n",
       "         [0.36481556, 0.5178408 ],\n",
       "         [0.2634527 , 0.54608494],\n",
       "         [0.3190305 , 0.8388679 ],\n",
       "         [0.34085596, 0.8453953 ]]], dtype=float32),\n",
       " array([[[0.65625 , 0.140625],\n",
       "         [0.78125 , 0.15625 ],\n",
       "         [0.1875  , 0.1875  ],\n",
       "         [0.65625 , 0.28125 ],\n",
       "         [0.234375, 0.296875],\n",
       "         [0.546875, 0.296875],\n",
       "         [0.1875  , 0.359375],\n",
       "         [0.234375, 0.375   ],\n",
       "         [0.828125, 0.453125],\n",
       "         [0.359375, 0.515625],\n",
       "         [0.265625, 0.546875],\n",
       "         [0.328125, 0.84375 ],\n",
       "         [0.359375, 0.84375 ]]], dtype=float32))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred_midpoints[2],all_true_midpoints[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables to track the min and max MSE\n",
    "min_mse = float('inf')\n",
    "max_mse = float('-inf')\n",
    "min_mse_index = -1\n",
    "max_mse_index = -1\n",
    "\n",
    "# Loop through each prediction to calculate the MSE\n",
    "for i in range(len(all_pred_midpoints)):\n",
    "    mse = np.mean((all_pred_midpoints[i] - all_true_midpoints[i]) **2)\n",
    "    \n",
    "    if mse < min_mse:\n",
    "        min_mse = mse\n",
    "        min_mse_index = i\n",
    "    \n",
    "    if mse > max_mse:\n",
    "        max_mse = mse\n",
    "        max_mse_index = i\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot an image with its centers\n",
    "def plot_image_with_centers(image, true_center, predicted_center, title):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  # Display the image\n",
    "\n",
    "    # Plot the actual center (Groundtruth)\n",
    "    plt.scatter(true_center[:, 0], true_center[:, 1], color='green', label='Groundtruth', s=10)\n",
    "\n",
    "    # Plot the predicted center\n",
    "    plt.scatter(predicted_center[:, 0], predicted_center[:, 1], color='red', label='Predictions', s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the image with the least MSE\n",
    "plot_image_with_centers(all_images[min_mse_index],\n",
    "                        all_true_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Least MSE. MSE: {min_mse:.4f}')\n",
    "\n",
    "# Plotting the image with the largest MSE\n",
    "plot_image_with_centers(all_images[max_mse_index],\n",
    "                        all_true_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Largest MSE. MSE: {max_mse:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5266"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mse_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
