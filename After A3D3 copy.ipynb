{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:37:12.254944: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-23 15:37:12.268618: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-23 15:37:12.281793: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-23 15:37:12.285755: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-23 15:37:12.297529: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-23 15:37:12.889979: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:37:17.435583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79196 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:4e:00.0, compute capability: 8.0\n",
      "2024-10-23 15:37:17.437102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79196 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:4f:00.0, compute capability: 8.0\n",
      "2024-10-23 15:37:17.438520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79196 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:c5:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3,4,5\"  # Only GPUs 0 and 1 will be visible to TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:3\", \"/gpu:4\",\"/gpu:5\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# DataLoader Class Definition\n",
    "# -----------------------------\n",
    "class DataLoader:\n",
    "    def __init__(self, h5_filename):\n",
    "        self.h5_filename = h5_filename\n",
    "        self.images, self.centers = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with h5py.File(self.h5_filename, 'r') as f:\n",
    "            images = np.array(f['images'])\n",
    "            centers = np.array(f['centers_training'])\n",
    "        return images, centers\n",
    "\n",
    "    def plot_image_with_centers(self, image_index=None):\n",
    "        if image_index is None:\n",
    "            image_index = np.random.randint(0, len(self.images))\n",
    "\n",
    "        image = self.images[image_index]\n",
    "        centers = self.centers[image_index]\n",
    "\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        valid_centers = centers[centers[:, 0] == 1]\n",
    "        for center in valid_centers:\n",
    "            plt.scatter(center[1], center[2], c='red', marker='o',s=5)  # center[1] is x and center[2] is y\n",
    "        plt.title('Image with Valid Centers Marked')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_centers(centers):\n",
    "        return centers[np.lexsort((centers[:, 0], centers[:, 1]))]\n",
    "\n",
    "    def normalize_data(self):\n",
    "        normalized_images = self.images / np.max(self.images)\n",
    "        sorted_centers = np.array([self.sort_centers(image_centers[:, 1:]) for image_centers in self.centers])\n",
    "        normalized_centers = sorted_centers / np.max(centers)\n",
    "\n",
    "        normalized_midpoints = tf.expand_dims(normalized_centers, axis=1)\n",
    "        return normalized_images, normalized_midpoints.numpy()\n",
    "\n",
    "    def split_data(self, train_size=0.8, random_state=42):\n",
    "        normalized_images, normalized_midpoints_np = self.normalize_data()\n",
    "        return train_test_split(normalized_images, normalized_midpoints_np, train_size=train_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Utility Function Definition\n",
    "# -----------------------------\n",
    "def plot_transposed_images_with_midpoints(dataset, image_indices=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Extracts multiple images and their midpoints from the given dataset, transposes the images, \n",
    "    corrects the midpoints, and plots the transposed images with the corrected midpoints.\n",
    "\n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The dataset from which to extract the images and midpoints.\n",
    "    - image_indices (list): The indices of the images in the batch to visualize. Default is [0, 1, 2, 3].\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract a sample image batch and its corresponding midpoints from the dataset\n",
    "    sample_image_batch, sample_midpoints_batch = next(iter(dataset))\n",
    "\n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(image_indices):\n",
    "            # Select the specified image and corresponding midpoints from the batch\n",
    "            sample_image = np.array(sample_image_batch[image_indices[i]])\n",
    "            sample_midpoints = np.array(sample_midpoints_batch[image_indices[i]])\n",
    "\n",
    "            # Transpose the image\n",
    "            transposed_image = sample_image.T\n",
    "\n",
    "            # Correct the midpoints by swapping the x and y coordinates\n",
    "            transposed_midpoints_corrected = sample_midpoints[:, :, [1, 0]]\n",
    "\n",
    "            # Plot the transposed image with corrected midpoints\n",
    "            ax.imshow(transposed_image, cmap='gray')\n",
    "            ax.scatter(\n",
    "                transposed_midpoints_corrected[:, :, 0] * 31, \n",
    "                transposed_midpoints_corrected[:, :, 1] * 31, \n",
    "                c='red', marker='o', s=5\n",
    "            )\n",
    "            ax.set_title(f'Image {image_indices[i]} for this batch')\n",
    "        else:\n",
    "            ax.axis('off')  # If fewer than 4 images are requested, hide the unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Loss and Callback Definitions\n",
    "# -----------------------------\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(exponent):\n",
    "    def loss(y_true, y_pred):\n",
    "        diff = tf.abs(y_true - y_pred)\n",
    "        powered_diff = tf.pow(diff, exponent)\n",
    "        return tf.reduce_mean(powered_diff)\n",
    "    return loss\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DynamicExponentCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_exponent, increment, update_frequency):\n",
    "        super().__init__()\n",
    "        self.exponent = initial_exponent\n",
    "        self.increment = increment\n",
    "        self.update_frequency = update_frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.update_frequency == 0:\n",
    "            self.exponent += self.increment\n",
    "            print(f\"\\nEpoch {epoch + 1}: Increasing exponent to {self.exponent}\")\n",
    "            self.model.loss = self.custom_loss(self.exponent)\n",
    "\n",
    "    def custom_loss(self, exponent):\n",
    "        def loss(y_true, y_pred):\n",
    "            diff = tf.abs(y_true - y_pred)\n",
    "            powered_diff = tf.pow(diff, exponent)\n",
    "            return tf.reduce_mean(powered_diff)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'initial_exponent': self.exponent,\n",
    "            'increment': self.increment,\n",
    "            'update_frequency': self.update_frequency,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my NEW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, input_shape=(32, 32, 1), num_classes=5, num_coordinates=2, learning_rate=1e-3, weights_path=None, l1_reg=0.001, l2_reg=0.007):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_coordinates = num_coordinates\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # Load weights if a path is provided\n",
    "        if weights_path is not None:\n",
    "            self.model.load_weights(weights_path)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        l1 = regularizers.l1(self.l1_reg)\n",
    "        l2 = regularizers.l2(self.l2_reg)\n",
    "        \n",
    "        # # CBAM Attention Block\n",
    "        # def cbam_block(input_tensor, reduction_ratio=16):\n",
    "        #     \"\"\"CBAM block, which includes channel and spatial attention\"\"\"\n",
    "        #     # Channel Attention\n",
    "        #     channel_attention = layers.GlobalAveragePooling2D()(input_tensor)\n",
    "        #     channel_attention = layers.Reshape((1, 1, input_tensor.shape[-1]))(channel_attention)\n",
    "        #     channel_attention = layers.Dense(input_tensor.shape[-1] // reduction_ratio, activation='relu')(channel_attention)\n",
    "        #     channel_attention = layers.Dense(input_tensor.shape[-1], activation='sigmoid')(channel_attention)\n",
    "        #     x = layers.Multiply()([input_tensor, channel_attention])\n",
    "\n",
    "        #     # Spatial Attention\n",
    "        #     avg_pool = layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(x)\n",
    "        #     max_pool = layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(x)\n",
    "        #     concat = layers.Concatenate(axis=-1)([avg_pool, max_pool])\n",
    "        #     spatial_attention = layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')(concat)\n",
    "        #     x = layers.Multiply()([x, spatial_attention])\n",
    "\n",
    "        #     return x\n",
    "    \n",
    "        x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=19, padding='same', activation='relu',kernel_regularizer=l2)(x_input)\n",
    "       \n",
    "        \n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "        x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "        return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "    def compile_model(self, loss_function):\n",
    "        self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "    def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "        history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Main Script Execution\n",
    "# -----------------------------\n",
    "\n",
    "# Load data\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_Mixed_13.h5'             \n",
    "h5_filename = '/home/da886/Final Electron counting project/Images and Labels/33KFixed_Mixed_5_32by32_95indexFor19kernel.h5'\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_13_SparsespotsRandomIndex.h5'\n",
    "# h5_filename ='/home/da886/Final Electron counting project/Images and Labels/30KFixed-index6_13.h5'\n",
    "data_loader = DataLoader(h5_filename)\n",
    "images, centers = data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f35f42d72c0>, 12504)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=np.random.randint(0,len(centers))\n",
    "data_loader.plot_image_with_centers(l)\n",
    "plt.imshow(images[l]),l\n",
    "# plt.grid(True),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f17b8157d90>, 5501)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[l]),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., 27.,  2.],\n",
       "       [ 1.,  9., 15.],\n",
       "       [ 1., 29., 25.],\n",
       "       [ 1., 15.,  3.],\n",
       "       [ 1., 22.,  8.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.random.randint(0,len(centers))\n",
    "centers[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data and split it into training and validation sets\n",
    "train_images, val_images, train_midpoints, val_midpoints = data_loader.split_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_images), np.max(train_images), np.min(train_midpoints), np.max(train_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: (26400, 32, 32), Train Midpoints: (26400, 1, 5, 2)\n",
      "Validation Images: (6600, 32, 32), Validation Midpoints: (6600, 1, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 1000\n",
    "train_dataset = train_dataset.shuffle(buffer_size=8000, reshuffle_each_iteration=True).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=8000).batch(batch_size)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f'Train Images: {train_images.shape}, Train Midpoints: {train_midpoints.shape}')\n",
    "print(f'Validation Images: {val_images.shape}, Validation Midpoints: {val_midpoints.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_transposed_images_with_midpoints(train_dataset, image_indices=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=10, verbose=1, mode='min', min_lr=7e-6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">185,344</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">524288</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,242,890</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │       \u001b[38;5;34m185,344\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m524288\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │     \u001b[38;5;34m5,242,890\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,428,234</span> (20.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,428,234\u001b[0m (20.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,428,234</span> (20.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,428,234\u001b[0m (20.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# dynamic_exponent_callback = DynamicExponentCallback(2, 1, 400)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    model_builder = ModelBuilder()\n",
    "\n",
    "    model_builder.build_model()\n",
    "\n",
    "    model_builder.model.summary()\n",
    "\n",
    "    model_builder.compile_model(loss_function=tf.keras.losses.MeanSquaredError()) \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:38:40.019657: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2024-10-23 15:38:42.111723: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1729697922.160110 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.182917 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.190509 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.206710 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.221480 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.248491 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.286553 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.301408 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.317715 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.377389 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.445500 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.454460 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.461967 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.478115 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.493077 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.520715 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.558026 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.568345 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.576253 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697922.636587 1976710 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.279798 1976701 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.286120 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.292588 1976715 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.299026 1976701 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.305523 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.311893 1976715 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.318221 1976701 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.323937 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.329295 1976715 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.334774 1976701 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.342721 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.349776 1976715 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.356660 1976701 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.365185 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.373460 1976715 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.381760 1976701 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.391383 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.400699 1976715 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.410074 1976701 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.420835 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.430179 1976715 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.439387 1976701 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.588803 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697923.734794 1976715 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0738"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:38:45.606354: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-23 15:38:45.606503: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "W0000 00:00:1729697925.615476 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.617788 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.621084 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.628001 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.641011 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.647308 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.658321 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.673404 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.677827 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.681156 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.704591 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.727265 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.729405 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.732612 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.739399 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.743484 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.749658 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.760783 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.775900 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.780322 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.783700 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.807471 1976720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.851341 1976709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.854722 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.858288 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.862022 1976709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.865139 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.868065 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.871138 1976709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.873741 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.876398 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.879082 1976709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.882077 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.885270 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.888384 1976709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.892083 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.895925 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.899754 1976709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.903819 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.907922 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.912072 1976709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.915979 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.919827 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.923769 1976709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697925.981694 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0734"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729697926.040386 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.496708 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.506617 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.515882 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.537341 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.546582 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.555040 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.563645 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.574536 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.583434 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.592821 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.602999 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.613327 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.622872 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.634786 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.645327 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.656036 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.667357 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.679335 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.690200 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.701922 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.713189 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.725526 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.741481 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.753030 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.764156 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.782173 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.797631 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.809241 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.824031 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.841737 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.857009 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.877605 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.892130 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.909625 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.924297 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.944488 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.958817 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.975656 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697926.990492 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.011307 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.027466 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.044521 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.059084 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.081666 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.097832 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.115134 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.146130 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.162545 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.184833 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.206964 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.268333 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.298281 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.328125 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.388317 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.392461 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.452911 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.457013 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.463907 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.468143 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.474867 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.501150 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.507995 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.534024 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.571695 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.597778 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.635401 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.695609 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.735440 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.793683 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.802750 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.860519 1976704 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697927.873505 1976713 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-10-23 15:38:48.248958: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "W0000 00:00:1729697928.279482 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.285033 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.290817 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.296633 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.301889 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.307210 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.312329 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.318009 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.323899 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.329428 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.335786 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.342105 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.348438 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.354765 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.361151 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.367565 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.374786 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.382057 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.389543 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.396468 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.403274 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.410101 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.417437 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.424863 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.432219 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.441767 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.451458 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.460999 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.471919 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.482546 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.493200 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.502054 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.510851 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.519713 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.532164 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.544412 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.556917 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.565736 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.574566 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.583489 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.593975 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.604464 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.614400 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.624976 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.634635 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.648266 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.658296 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.671949 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.690483 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.704205 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.722521 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.759193 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.777594 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.813886 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.816574 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.852930 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.855484 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.859777 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.862399 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.866679 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.882747 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.886989 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.903158 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.926008 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.942134 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.965049 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697928.999624 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697929.022897 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697929.058790 1976714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 204ms/step - loss: 0.0731 - val_loss: 0.0498 - learning_rate: 0.0010\n",
      "Epoch 2/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729697929.064510 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697929.101265 1976719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697929.112027 1976712 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:38:51.168808: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0462 - val_loss: 0.0386 - learning_rate: 0.0010\n",
      "Epoch 3/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0390 - val_loss: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 4/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:38:53.843336: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0358 - val_loss: 0.0329 - learning_rate: 0.0010\n",
      "Epoch 5/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0337 - val_loss: 0.0326 - learning_rate: 0.0010\n",
      "Epoch 6/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:39:00.823857: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0330 - val_loss: 0.0345 - learning_rate: 0.0010\n",
      "Epoch 7/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0321 - val_loss: 0.0313 - learning_rate: 0.0010\n",
      "Epoch 8/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0315 - val_loss: 0.0323 - learning_rate: 0.0010\n",
      "Epoch 9/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0318 - val_loss: 0.0307 - learning_rate: 0.0010\n",
      "Epoch 10/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0308"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:39:10.342999: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0308 - val_loss: 0.0304 - learning_rate: 0.0010\n",
      "Epoch 11/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0313 - val_loss: 0.0309 - learning_rate: 0.0010\n",
      "Epoch 12/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:39:12.929808: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0303 - val_loss: 0.0313 - learning_rate: 0.0010\n",
      "Epoch 13/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0309 - val_loss: 0.0301 - learning_rate: 0.0010\n",
      "Epoch 14/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0322 - val_loss: 0.0336 - learning_rate: 0.0010\n",
      "Epoch 15/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0304 - val_loss: 0.0292 - learning_rate: 0.0010\n",
      "Epoch 16/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0298 - val_loss: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 17/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0298 - val_loss: 0.0303 - learning_rate: 0.0010\n",
      "Epoch 18/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0297 - val_loss: 0.0297 - learning_rate: 0.0010\n",
      "Epoch 19/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0298 - val_loss: 0.0298 - learning_rate: 0.0010\n",
      "Epoch 20/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0295 - val_loss: 0.0315 - learning_rate: 0.0010\n",
      "Epoch 21/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0302 - val_loss: 0.0285 - learning_rate: 0.0010\n",
      "Epoch 22/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:39:38.807926: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0290 - val_loss: 0.0298 - learning_rate: 0.0010\n",
      "Epoch 23/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0291"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:39:41.274402: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0291 - val_loss: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 24/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0299 - val_loss: 0.0287 - learning_rate: 0.0010\n",
      "Epoch 25/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0291 - val_loss: 0.0286 - learning_rate: 0.0010\n",
      "Epoch 26/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0290 - val_loss: 0.0317 - learning_rate: 0.0010\n",
      "Epoch 27/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0296 - val_loss: 0.0294 - learning_rate: 0.0010\n",
      "Epoch 28/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0288 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 29/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0288 - val_loss: 0.0285 - learning_rate: 0.0010\n",
      "Epoch 30/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0286 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 31/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0291 - val_loss: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 32/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0288 - val_loss: 0.0285 - learning_rate: 0.0010\n",
      "Epoch 33/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0291 - val_loss: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 34/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0285 - val_loss: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 35/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0286 - val_loss: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 36/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0294"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:40:12.608036: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0294 - val_loss: 0.0286 - learning_rate: 0.0010\n",
      "Epoch 37/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0284 - val_loss: 0.0284 - learning_rate: 0.0010\n",
      "Epoch 38/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0281 - val_loss: 0.0290 - learning_rate: 0.0010\n",
      "Epoch 39/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0281 - val_loss: 0.0278 - learning_rate: 0.0010\n",
      "Epoch 40/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0297 - val_loss: 0.0289 - learning_rate: 0.0010\n",
      "Epoch 41/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0282 - val_loss: 0.0301 - learning_rate: 0.0010\n",
      "Epoch 42/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0283 - val_loss: 0.0293 - learning_rate: 0.0010\n",
      "Epoch 43/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0279 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 44/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:40:29.500787: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0288 - val_loss: 0.0285 - learning_rate: 0.0010\n",
      "Epoch 45/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0279 - val_loss: 0.0282 - learning_rate: 0.0010\n",
      "Epoch 46/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0281 - val_loss: 0.0277 - learning_rate: 0.0010\n",
      "Epoch 47/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0285 - val_loss: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 48/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0287 - val_loss: 0.0277 - learning_rate: 0.0010\n",
      "Epoch 49/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0276"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:40:43.605871: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0276 - val_loss: 0.0276 - learning_rate: 0.0010\n",
      "Epoch 50/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0294 - val_loss: 0.0288 - learning_rate: 0.0010\n",
      "Epoch 51/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0283 - val_loss: 0.0273 - learning_rate: 0.0010\n",
      "Epoch 52/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0282 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 53/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0277 - val_loss: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 54/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0276 - val_loss: 0.0273 - learning_rate: 0.0010\n",
      "Epoch 55/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0278 - val_loss: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 56/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0274 - val_loss: 0.0275 - learning_rate: 0.0010\n",
      "Epoch 57/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0276 - val_loss: 0.0312 - learning_rate: 0.0010\n",
      "Epoch 58/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0294 - val_loss: 0.0294 - learning_rate: 0.0010\n",
      "Epoch 59/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0275 - val_loss: 0.0273 - learning_rate: 0.0010\n",
      "Epoch 60/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0281 - val_loss: 0.0293 - learning_rate: 0.0010\n",
      "Epoch 61/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0272\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0272 - val_loss: 0.0273 - learning_rate: 0.0010\n",
      "Epoch 62/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:41:14.947150: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0271 - val_loss: 0.0272 - learning_rate: 9.0000e-04\n",
      "Epoch 63/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0272 - val_loss: 0.0280 - learning_rate: 9.0000e-04\n",
      "Epoch 64/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0269 - val_loss: 0.0273 - learning_rate: 9.0000e-04\n",
      "Epoch 65/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0272 - val_loss: 0.0283 - learning_rate: 9.0000e-04\n",
      "Epoch 66/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0269 - val_loss: 0.0300 - learning_rate: 9.0000e-04\n",
      "Epoch 67/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0270 - val_loss: 0.0270 - learning_rate: 9.0000e-04\n",
      "Epoch 68/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0268 - val_loss: 0.0268 - learning_rate: 9.0000e-04\n",
      "Epoch 69/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0270 - val_loss: 0.0272 - learning_rate: 9.0000e-04\n",
      "Epoch 70/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0265 - val_loss: 0.0287 - learning_rate: 9.0000e-04\n",
      "Epoch 71/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0272 - val_loss: 0.0275 - learning_rate: 9.0000e-04\n",
      "Epoch 72/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0268 - val_loss: 0.0264 - learning_rate: 9.0000e-04\n",
      "Epoch 73/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0266 - val_loss: 0.0353 - learning_rate: 9.0000e-04\n",
      "Epoch 74/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0277 - val_loss: 0.0279 - learning_rate: 9.0000e-04\n",
      "Epoch 75/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0265"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:41:46.150684: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0265 - val_loss: 0.0267 - learning_rate: 9.0000e-04\n",
      "Epoch 76/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0265 - val_loss: 0.0279 - learning_rate: 9.0000e-04\n",
      "Epoch 77/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0262 - val_loss: 0.0265 - learning_rate: 9.0000e-04\n",
      "Epoch 78/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0268 - val_loss: 0.0261 - learning_rate: 9.0000e-04\n",
      "Epoch 79/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0266 - val_loss: 0.0264 - learning_rate: 9.0000e-04\n",
      "Epoch 80/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0263 - val_loss: 0.0270 - learning_rate: 9.0000e-04\n",
      "Epoch 81/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0263 - val_loss: 0.0280 - learning_rate: 9.0000e-04\n",
      "Epoch 82/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0265 - val_loss: 0.0266 - learning_rate: 9.0000e-04\n",
      "Epoch 83/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0259 - val_loss: 0.0266 - learning_rate: 9.0000e-04\n",
      "Epoch 84/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0260 - val_loss: 0.0262 - learning_rate: 9.0000e-04\n",
      "Epoch 85/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0258 - val_loss: 0.0263 - learning_rate: 9.0000e-04\n",
      "Epoch 86/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0259 - val_loss: 0.0276 - learning_rate: 9.0000e-04\n",
      "Epoch 87/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:42:12.736314: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0259 - val_loss: 0.0263 - learning_rate: 9.0000e-04\n",
      "Epoch 88/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0257"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:42:17.322286: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0257 - val_loss: 0.0256 - learning_rate: 9.0000e-04\n",
      "Epoch 89/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0272 - val_loss: 0.0269 - learning_rate: 9.0000e-04\n",
      "Epoch 90/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0261 - val_loss: 0.0255 - learning_rate: 9.0000e-04\n",
      "Epoch 91/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0254 - val_loss: 0.0262 - learning_rate: 9.0000e-04\n",
      "Epoch 92/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0255 - val_loss: 0.0257 - learning_rate: 9.0000e-04\n",
      "Epoch 93/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0262 - val_loss: 0.0264 - learning_rate: 9.0000e-04\n",
      "Epoch 94/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0251 - val_loss: 0.0254 - learning_rate: 9.0000e-04\n",
      "Epoch 95/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0252 - val_loss: 0.0264 - learning_rate: 9.0000e-04\n",
      "Epoch 96/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0252 - val_loss: 0.0260 - learning_rate: 9.0000e-04\n",
      "Epoch 97/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0253 - val_loss: 0.0255 - learning_rate: 9.0000e-04\n",
      "Epoch 98/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0253 - val_loss: 0.0262 - learning_rate: 9.0000e-04\n",
      "Epoch 99/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0251 - val_loss: 0.0267 - learning_rate: 9.0000e-04\n",
      "Epoch 100/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0251 - val_loss: 0.0256 - learning_rate: 9.0000e-04\n",
      "Epoch 101/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0248"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:42:48.823700: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0248 - val_loss: 0.0265 - learning_rate: 9.0000e-04\n",
      "Epoch 102/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0248 - val_loss: 0.0256 - learning_rate: 9.0000e-04\n",
      "Epoch 103/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0250 - val_loss: 0.0257 - learning_rate: 9.0000e-04\n",
      "Epoch 104/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0245\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0245 - val_loss: 0.0258 - learning_rate: 9.0000e-04\n",
      "Epoch 105/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0249 - val_loss: 0.0253 - learning_rate: 8.1000e-04\n",
      "Epoch 106/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0243 - val_loss: 0.0263 - learning_rate: 8.1000e-04\n",
      "Epoch 107/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0247 - val_loss: 0.0251 - learning_rate: 8.1000e-04\n",
      "Epoch 108/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0244 - val_loss: 0.0247 - learning_rate: 8.1000e-04\n",
      "Epoch 109/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0246 - val_loss: 0.0267 - learning_rate: 8.1000e-04\n",
      "Epoch 110/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0247 - val_loss: 0.0256 - learning_rate: 8.1000e-04\n",
      "Epoch 111/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0244 - val_loss: 0.0257 - learning_rate: 8.1000e-04\n",
      "Epoch 112/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0242 - val_loss: 0.0256 - learning_rate: 8.1000e-04\n",
      "Epoch 113/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0241 - val_loss: 0.0253 - learning_rate: 8.1000e-04\n",
      "Epoch 114/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0243"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:43:19.986477: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0243 - val_loss: 0.0251 - learning_rate: 8.1000e-04\n",
      "Epoch 115/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0247 - val_loss: 0.0247 - learning_rate: 8.1000e-04\n",
      "Epoch 116/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0242 - val_loss: 0.0251 - learning_rate: 8.1000e-04\n",
      "Epoch 117/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0247 - val_loss: 0.0258 - learning_rate: 8.1000e-04\n",
      "Epoch 118/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0242\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0242 - val_loss: 0.0253 - learning_rate: 8.1000e-04\n",
      "Epoch 119/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0238 - val_loss: 0.0249 - learning_rate: 7.2900e-04\n",
      "Epoch 120/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0237 - val_loss: 0.0244 - learning_rate: 7.2900e-04\n",
      "Epoch 121/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0238 - val_loss: 0.0250 - learning_rate: 7.2900e-04\n",
      "Epoch 122/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0238 - val_loss: 0.0255 - learning_rate: 7.2900e-04\n",
      "Epoch 123/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0240 - val_loss: 0.0251 - learning_rate: 7.2900e-04\n",
      "Epoch 124/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0240 - val_loss: 0.0247 - learning_rate: 7.2900e-04\n",
      "Epoch 125/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0237 - val_loss: 0.0248 - learning_rate: 7.2900e-04\n",
      "Epoch 126/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0237 - val_loss: 0.0244 - learning_rate: 7.2900e-04\n",
      "Epoch 127/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0239"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:43:51.214736: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0239 - val_loss: 0.0249 - learning_rate: 7.2900e-04\n",
      "Epoch 128/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0237 - val_loss: 0.0246 - learning_rate: 7.2900e-04\n",
      "Epoch 129/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0236 - val_loss: 0.0251 - learning_rate: 7.2900e-04\n",
      "Epoch 130/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0236\n",
      "Epoch 130: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0236 - val_loss: 0.0253 - learning_rate: 7.2900e-04\n",
      "Epoch 131/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0234 - val_loss: 0.0241 - learning_rate: 6.5610e-04\n",
      "Epoch 132/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0232 - val_loss: 0.0247 - learning_rate: 6.5610e-04\n",
      "Epoch 133/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0233 - val_loss: 0.0245 - learning_rate: 6.5610e-04\n",
      "Epoch 134/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0236 - val_loss: 0.0248 - learning_rate: 6.5610e-04\n",
      "Epoch 135/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0233 - val_loss: 0.0244 - learning_rate: 6.5610e-04\n",
      "Epoch 136/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0233 - val_loss: 0.0249 - learning_rate: 6.5610e-04\n",
      "Epoch 137/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0235 - val_loss: 0.0254 - learning_rate: 6.5610e-04\n",
      "Epoch 138/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0234 - val_loss: 0.0262 - learning_rate: 6.5610e-04\n",
      "Epoch 139/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0238 - val_loss: 0.0252 - learning_rate: 6.5610e-04\n",
      "Epoch 140/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:44:22.778059: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0235 - val_loss: 0.0242 - learning_rate: 6.5610e-04\n",
      "Epoch 141/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0230\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0230 - val_loss: 0.0252 - learning_rate: 6.5610e-04\n",
      "Epoch 142/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0231 - val_loss: 0.0243 - learning_rate: 5.9049e-04\n",
      "Epoch 143/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0230 - val_loss: 0.0243 - learning_rate: 5.9049e-04\n",
      "Epoch 144/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0230 - val_loss: 0.0242 - learning_rate: 5.9049e-04\n",
      "Epoch 145/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0232 - val_loss: 0.0250 - learning_rate: 5.9049e-04\n",
      "Epoch 146/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0230 - val_loss: 0.0244 - learning_rate: 5.9049e-04\n",
      "Epoch 147/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0230 - val_loss: 0.0244 - learning_rate: 5.9049e-04\n",
      "Epoch 148/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0229 - val_loss: 0.0254 - learning_rate: 5.9049e-04\n",
      "Epoch 149/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0230 - val_loss: 0.0242 - learning_rate: 5.9049e-04\n",
      "Epoch 150/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0230 - val_loss: 0.0239 - learning_rate: 5.9049e-04\n",
      "Epoch 151/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0230 - val_loss: 0.0240 - learning_rate: 5.9049e-04\n",
      "Epoch 152/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0230 - val_loss: 0.0238 - learning_rate: 5.9049e-04\n",
      "Epoch 153/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0230"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:44:54.286277: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0230 - val_loss: 0.0247 - learning_rate: 5.9049e-04\n",
      "Epoch 154/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0230 - val_loss: 0.0244 - learning_rate: 5.9049e-04\n",
      "Epoch 155/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0229 - val_loss: 0.0245 - learning_rate: 5.9049e-04\n",
      "Epoch 156/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0229 - val_loss: 0.0244 - learning_rate: 5.9049e-04\n",
      "Epoch 157/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0230 - val_loss: 0.0240 - learning_rate: 5.9049e-04\n",
      "Epoch 158/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0229 - val_loss: 0.0237 - learning_rate: 5.9049e-04\n",
      "Epoch 159/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0228 - val_loss: 0.0241 - learning_rate: 5.9049e-04\n",
      "Epoch 160/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0229 - val_loss: 0.0241 - learning_rate: 5.9049e-04\n",
      "Epoch 161/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0229 - val_loss: 0.0243 - learning_rate: 5.9049e-04\n",
      "Epoch 162/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0228 - val_loss: 0.0236 - learning_rate: 5.9049e-04\n",
      "Epoch 163/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0226 - val_loss: 0.0244 - learning_rate: 5.9049e-04\n",
      "Epoch 164/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0229 - val_loss: 0.0245 - learning_rate: 5.9049e-04\n",
      "Epoch 165/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0228 - val_loss: 0.0250 - learning_rate: 5.9049e-04\n",
      "Epoch 166/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0227"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:45:25.811541: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0227 - val_loss: 0.0240 - learning_rate: 5.9049e-04\n",
      "Epoch 167/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0229 - val_loss: 0.0240 - learning_rate: 5.9049e-04\n",
      "Epoch 168/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0226 - val_loss: 0.0246 - learning_rate: 5.9049e-04\n",
      "Epoch 169/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0229 - val_loss: 0.0234 - learning_rate: 5.9049e-04\n",
      "Epoch 170/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0227 - val_loss: 0.0239 - learning_rate: 5.9049e-04\n",
      "Epoch 171/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0225 - val_loss: 0.0240 - learning_rate: 5.9049e-04\n",
      "Epoch 172/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0226 - val_loss: 0.0240 - learning_rate: 5.9049e-04\n",
      "Epoch 173/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:45:40.490100: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0230 - val_loss: 0.0240 - learning_rate: 5.9049e-04\n",
      "Epoch 174/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0233 - val_loss: 0.0238 - learning_rate: 5.9049e-04\n",
      "Epoch 175/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0225 - val_loss: 0.0238 - learning_rate: 5.9049e-04\n",
      "Epoch 176/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0225 - val_loss: 0.0241 - learning_rate: 5.9049e-04\n",
      "Epoch 177/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0224 - val_loss: 0.0252 - learning_rate: 5.9049e-04\n",
      "Epoch 178/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0227 - val_loss: 0.0235 - learning_rate: 5.9049e-04\n",
      "Epoch 179/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:45:57.405244: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 179: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0225 - val_loss: 0.0241 - learning_rate: 5.9049e-04\n",
      "Epoch 180/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0224 - val_loss: 0.0232 - learning_rate: 5.3144e-04\n",
      "Epoch 181/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0223 - val_loss: 0.0239 - learning_rate: 5.3144e-04\n",
      "Epoch 182/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0223 - val_loss: 0.0242 - learning_rate: 5.3144e-04\n",
      "Epoch 183/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0224 - val_loss: 0.0243 - learning_rate: 5.3144e-04\n",
      "Epoch 184/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0226 - val_loss: 0.0234 - learning_rate: 5.3144e-04\n",
      "Epoch 185/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0224 - val_loss: 0.0237 - learning_rate: 5.3144e-04\n",
      "Epoch 186/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0222 - val_loss: 0.0240 - learning_rate: 5.3144e-04\n",
      "Epoch 187/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0224 - val_loss: 0.0236 - learning_rate: 5.3144e-04\n",
      "Epoch 188/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0223 - val_loss: 0.0243 - learning_rate: 5.3144e-04\n",
      "Epoch 189/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0225 - val_loss: 0.0236 - learning_rate: 5.3144e-04\n",
      "Epoch 190/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0224\n",
      "Epoch 190: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0224 - val_loss: 0.0235 - learning_rate: 5.3144e-04\n",
      "Epoch 191/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0223 - val_loss: 0.0234 - learning_rate: 4.7830e-04\n",
      "Epoch 192/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:46:28.744998: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0221 - val_loss: 0.0237 - learning_rate: 4.7830e-04\n",
      "Epoch 193/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0221 - val_loss: 0.0235 - learning_rate: 4.7830e-04\n",
      "Epoch 194/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0222 - val_loss: 0.0241 - learning_rate: 4.7830e-04\n",
      "Epoch 195/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0221 - val_loss: 0.0234 - learning_rate: 4.7830e-04\n",
      "Epoch 196/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0222 - val_loss: 0.0237 - learning_rate: 4.7830e-04\n",
      "Epoch 197/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0221 - val_loss: 0.0237 - learning_rate: 4.7830e-04\n",
      "Epoch 198/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0222 - val_loss: 0.0235 - learning_rate: 4.7830e-04\n",
      "Epoch 199/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0221 - val_loss: 0.0243 - learning_rate: 4.7830e-04\n",
      "Epoch 200/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0222\n",
      "Epoch 200: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0222 - val_loss: 0.0234 - learning_rate: 4.7830e-04\n",
      "Epoch 201/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0219 - val_loss: 0.0235 - learning_rate: 4.3047e-04\n",
      "Epoch 202/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0219 - val_loss: 0.0230 - learning_rate: 4.3047e-04\n",
      "Epoch 203/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0219 - val_loss: 0.0235 - learning_rate: 4.3047e-04\n",
      "Epoch 204/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0219 - val_loss: 0.0239 - learning_rate: 4.3047e-04\n",
      "Epoch 205/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:47:00.294637: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0219 - val_loss: 0.0232 - learning_rate: 4.3047e-04\n",
      "Epoch 206/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0220 - val_loss: 0.0237 - learning_rate: 4.3047e-04\n",
      "Epoch 207/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0218 - val_loss: 0.0241 - learning_rate: 4.3047e-04\n",
      "Epoch 208/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0220 - val_loss: 0.0232 - learning_rate: 4.3047e-04\n",
      "Epoch 209/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0220 - val_loss: 0.0233 - learning_rate: 4.3047e-04\n",
      "Epoch 210/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0219 - val_loss: 0.0232 - learning_rate: 4.3047e-04\n",
      "Epoch 211/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0219 - val_loss: 0.0234 - learning_rate: 4.3047e-04\n",
      "Epoch 212/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0217\n",
      "Epoch 212: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0218 - val_loss: 0.0232 - learning_rate: 4.3047e-04\n",
      "Epoch 213/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0219 - val_loss: 0.0235 - learning_rate: 3.8742e-04\n",
      "Epoch 214/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0220 - val_loss: 0.0229 - learning_rate: 3.8742e-04\n",
      "Epoch 215/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0218 - val_loss: 0.0231 - learning_rate: 3.8742e-04\n",
      "Epoch 216/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0217 - val_loss: 0.0245 - learning_rate: 3.8742e-04\n",
      "Epoch 217/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0218 - val_loss: 0.0231 - learning_rate: 3.8742e-04\n",
      "Epoch 218/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0218"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:47:31.850589: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0218 - val_loss: 0.0234 - learning_rate: 3.8742e-04\n",
      "Epoch 219/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0217 - val_loss: 0.0234 - learning_rate: 3.8742e-04\n",
      "Epoch 220/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0217 - val_loss: 0.0231 - learning_rate: 3.8742e-04\n",
      "Epoch 221/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0219 - val_loss: 0.0235 - learning_rate: 3.8742e-04\n",
      "Epoch 222/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0217 - val_loss: 0.0236 - learning_rate: 3.8742e-04\n",
      "Epoch 223/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0217 - val_loss: 0.0237 - learning_rate: 3.8742e-04\n",
      "Epoch 224/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0216\n",
      "Epoch 224: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0216 - val_loss: 0.0237 - learning_rate: 3.8742e-04\n",
      "Epoch 225/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0217 - val_loss: 0.0234 - learning_rate: 3.4868e-04\n",
      "Epoch 226/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0217 - val_loss: 0.0231 - learning_rate: 3.4868e-04\n",
      "Epoch 227/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0216 - val_loss: 0.0233 - learning_rate: 3.4868e-04\n",
      "Epoch 228/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0216 - val_loss: 0.0232 - learning_rate: 3.4868e-04\n",
      "Epoch 229/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0216 - val_loss: 0.0238 - learning_rate: 3.4868e-04\n",
      "Epoch 230/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0216 - val_loss: 0.0227 - learning_rate: 3.4868e-04\n",
      "Epoch 231/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:48:03.316991: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0216 - val_loss: 0.0231 - learning_rate: 3.4868e-04\n",
      "Epoch 232/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0217 - val_loss: 0.0235 - learning_rate: 3.4868e-04\n",
      "Epoch 233/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0214 - val_loss: 0.0233 - learning_rate: 3.4868e-04\n",
      "Epoch 234/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0218 - val_loss: 0.0235 - learning_rate: 3.4868e-04\n",
      "Epoch 235/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0216 - val_loss: 0.0230 - learning_rate: 3.4868e-04\n",
      "Epoch 236/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0216 - val_loss: 0.0229 - learning_rate: 3.4868e-04\n",
      "Epoch 237/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0216 - val_loss: 0.0231 - learning_rate: 3.4868e-04\n",
      "Epoch 238/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0217 - val_loss: 0.0234 - learning_rate: 3.4868e-04\n",
      "Epoch 239/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0215 - val_loss: 0.0230 - learning_rate: 3.4868e-04\n",
      "Epoch 240/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0215\n",
      "Epoch 240: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0215 - val_loss: 0.0232 - learning_rate: 3.4868e-04\n",
      "Epoch 241/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0214 - val_loss: 0.0229 - learning_rate: 3.1381e-04\n",
      "Epoch 242/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0215 - val_loss: 0.0228 - learning_rate: 3.1381e-04\n",
      "Epoch 243/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0215 - val_loss: 0.0236 - learning_rate: 3.1381e-04\n",
      "Epoch 244/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:48:34.566283: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0216 - val_loss: 0.0230 - learning_rate: 3.1381e-04\n",
      "Epoch 245/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0214 - val_loss: 0.0233 - learning_rate: 3.1381e-04\n",
      "Epoch 246/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0215 - val_loss: 0.0236 - learning_rate: 3.1381e-04\n",
      "Epoch 247/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0215 - val_loss: 0.0235 - learning_rate: 3.1381e-04\n",
      "Epoch 248/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0216 - val_loss: 0.0230 - learning_rate: 3.1381e-04\n",
      "Epoch 249/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0214 - val_loss: 0.0231 - learning_rate: 3.1381e-04\n",
      "Epoch 250/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0213\n",
      "Epoch 250: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0213 - val_loss: 0.0228 - learning_rate: 3.1381e-04\n",
      "Epoch 251/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0213 - val_loss: 0.0230 - learning_rate: 2.8243e-04\n",
      "Epoch 252/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0213 - val_loss: 0.0230 - learning_rate: 2.8243e-04\n",
      "Epoch 253/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0214 - val_loss: 0.0226 - learning_rate: 2.8243e-04\n",
      "Epoch 254/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0213 - val_loss: 0.0235 - learning_rate: 2.8243e-04\n",
      "Epoch 255/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0213 - val_loss: 0.0231 - learning_rate: 2.8243e-04\n",
      "Epoch 256/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0213 - val_loss: 0.0233 - learning_rate: 2.8243e-04\n",
      "Epoch 257/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0213"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:49:06.159054: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0213 - val_loss: 0.0227 - learning_rate: 2.8243e-04\n",
      "Epoch 258/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0213 - val_loss: 0.0228 - learning_rate: 2.8243e-04\n",
      "Epoch 259/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0213 - val_loss: 0.0233 - learning_rate: 2.8243e-04\n",
      "Epoch 260/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0213 - val_loss: 0.0224 - learning_rate: 2.8243e-04\n",
      "Epoch 261/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0214 - val_loss: 0.0230 - learning_rate: 2.8243e-04\n",
      "Epoch 262/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0214 - val_loss: 0.0234 - learning_rate: 2.8243e-04\n",
      "Epoch 263/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0214 - val_loss: 0.0232 - learning_rate: 2.8243e-04\n",
      "Epoch 264/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0214 - val_loss: 0.0234 - learning_rate: 2.8243e-04\n",
      "Epoch 265/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0213 - val_loss: 0.0230 - learning_rate: 2.8243e-04\n",
      "Epoch 266/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0213 - val_loss: 0.0233 - learning_rate: 2.8243e-04\n",
      "Epoch 267/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0213 - val_loss: 0.0232 - learning_rate: 2.8243e-04\n",
      "Epoch 268/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0212 - val_loss: 0.0230 - learning_rate: 2.8243e-04\n",
      "Epoch 269/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0213 - val_loss: 0.0230 - learning_rate: 2.8243e-04\n",
      "Epoch 270/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0213"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:49:37.405268: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 270: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0213 - val_loss: 0.0229 - learning_rate: 2.8243e-04\n",
      "Epoch 271/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0212 - val_loss: 0.0231 - learning_rate: 2.5419e-04\n",
      "Epoch 272/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0213 - val_loss: 0.0229 - learning_rate: 2.5419e-04\n",
      "Epoch 273/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0211 - val_loss: 0.0227 - learning_rate: 2.5419e-04\n",
      "Epoch 274/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0213 - val_loss: 0.0223 - learning_rate: 2.5419e-04\n",
      "Epoch 275/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0212 - val_loss: 0.0230 - learning_rate: 2.5419e-04\n",
      "Epoch 276/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0213 - val_loss: 0.0225 - learning_rate: 2.5419e-04\n",
      "Epoch 277/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0211 - val_loss: 0.0225 - learning_rate: 2.5419e-04\n",
      "Epoch 278/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0212 - val_loss: 0.0234 - learning_rate: 2.5419e-04\n",
      "Epoch 279/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0213 - val_loss: 0.0229 - learning_rate: 2.5419e-04\n",
      "Epoch 280/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0212\n",
      "Epoch 280: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0212 - val_loss: 0.0232 - learning_rate: 2.5419e-04\n",
      "Epoch 281/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0212 - val_loss: 0.0221 - learning_rate: 2.2877e-04\n",
      "Epoch 282/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0211 - val_loss: 0.0227 - learning_rate: 2.2877e-04\n",
      "Epoch 283/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0212"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:50:08.801257: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0212 - val_loss: 0.0227 - learning_rate: 2.2877e-04\n",
      "Epoch 284/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0211 - val_loss: 0.0227 - learning_rate: 2.2877e-04\n",
      "Epoch 285/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0212 - val_loss: 0.0225 - learning_rate: 2.2877e-04\n",
      "Epoch 286/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0212 - val_loss: 0.0227 - learning_rate: 2.2877e-04\n",
      "Epoch 287/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0211 - val_loss: 0.0230 - learning_rate: 2.2877e-04\n",
      "Epoch 288/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0211 - val_loss: 0.0227 - learning_rate: 2.2877e-04\n",
      "Epoch 289/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0211 - val_loss: 0.0226 - learning_rate: 2.2877e-04\n",
      "Epoch 290/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0211 - val_loss: 0.0232 - learning_rate: 2.2877e-04\n",
      "Epoch 291/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0210\n",
      "Epoch 291: ReduceLROnPlateau reducing learning rate to 0.00020589114428730683.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0210 - val_loss: 0.0228 - learning_rate: 2.2877e-04\n",
      "Epoch 292/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0211 - val_loss: 0.0231 - learning_rate: 2.0589e-04\n",
      "Epoch 293/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0211 - val_loss: 0.0226 - learning_rate: 2.0589e-04\n",
      "Epoch 294/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0210 - val_loss: 0.0233 - learning_rate: 2.0589e-04\n",
      "Epoch 295/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0210 - val_loss: 0.0225 - learning_rate: 2.0589e-04\n",
      "Epoch 296/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0212"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:50:40.387912: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0211 - val_loss: 0.0230 - learning_rate: 2.0589e-04\n",
      "Epoch 297/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0210 - val_loss: 0.0226 - learning_rate: 2.0589e-04\n",
      "Epoch 298/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0211 - val_loss: 0.0234 - learning_rate: 2.0589e-04\n",
      "Epoch 299/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0212 - val_loss: 0.0228 - learning_rate: 2.0589e-04\n",
      "Epoch 300/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0211 - val_loss: 0.0231 - learning_rate: 2.0589e-04\n",
      "Epoch 301/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0210\n",
      "Epoch 301: ReduceLROnPlateau reducing learning rate to 0.00018530203378759326.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0210 - val_loss: 0.0223 - learning_rate: 2.0589e-04\n",
      "Epoch 302/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0210 - val_loss: 0.0231 - learning_rate: 1.8530e-04\n",
      "Epoch 303/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0209 - val_loss: 0.0227 - learning_rate: 1.8530e-04\n",
      "Epoch 304/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0210 - val_loss: 0.0220 - learning_rate: 1.8530e-04\n",
      "Epoch 305/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0209 - val_loss: 0.0234 - learning_rate: 1.8530e-04\n",
      "Epoch 306/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0210 - val_loss: 0.0226 - learning_rate: 1.8530e-04\n",
      "Epoch 307/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0209 - val_loss: 0.0225 - learning_rate: 1.8530e-04\n",
      "Epoch 308/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0210 - val_loss: 0.0228 - learning_rate: 1.8530e-04\n",
      "Epoch 309/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0210"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:51:11.817231: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0210 - val_loss: 0.0227 - learning_rate: 1.8530e-04\n",
      "Epoch 310/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0210 - val_loss: 0.0224 - learning_rate: 1.8530e-04\n",
      "Epoch 311/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0209\n",
      "Epoch 311: ReduceLROnPlateau reducing learning rate to 0.00016677183302817866.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0209 - val_loss: 0.0228 - learning_rate: 1.8530e-04\n",
      "Epoch 312/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0210 - val_loss: 0.0226 - learning_rate: 1.6677e-04\n",
      "Epoch 313/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0209 - val_loss: 0.0223 - learning_rate: 1.6677e-04\n",
      "Epoch 314/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0209 - val_loss: 0.0223 - learning_rate: 1.6677e-04\n",
      "Epoch 315/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0208 - val_loss: 0.0228 - learning_rate: 1.6677e-04\n",
      "Epoch 316/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0209 - val_loss: 0.0231 - learning_rate: 1.6677e-04\n",
      "Epoch 317/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0208 - val_loss: 0.0226 - learning_rate: 1.6677e-04\n",
      "Epoch 318/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0208 - val_loss: 0.0224 - learning_rate: 1.6677e-04\n",
      "Epoch 319/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0210 - val_loss: 0.0221 - learning_rate: 1.6677e-04\n",
      "Epoch 320/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0209 - val_loss: 0.0227 - learning_rate: 1.6677e-04\n",
      "Epoch 321/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0210\n",
      "Epoch 321: ReduceLROnPlateau reducing learning rate to 0.00015009464841568844.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0210 - val_loss: 0.0231 - learning_rate: 1.6677e-04\n",
      "Epoch 322/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0209"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:51:43.248473: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0209 - val_loss: 0.0225 - learning_rate: 1.5009e-04\n",
      "Epoch 323/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0208 - val_loss: 0.0225 - learning_rate: 1.5009e-04\n",
      "Epoch 324/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0208 - val_loss: 0.0224 - learning_rate: 1.5009e-04\n",
      "Epoch 325/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0210 - val_loss: 0.0224 - learning_rate: 1.5009e-04\n",
      "Epoch 326/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0209 - val_loss: 0.0230 - learning_rate: 1.5009e-04\n",
      "Epoch 327/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0209 - val_loss: 0.0226 - learning_rate: 1.5009e-04\n",
      "Epoch 328/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0208 - val_loss: 0.0225 - learning_rate: 1.5009e-04\n",
      "Epoch 329/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0209 - val_loss: 0.0229 - learning_rate: 1.5009e-04\n",
      "Epoch 330/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0210 - val_loss: 0.0226 - learning_rate: 1.5009e-04\n",
      "Epoch 331/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0208\n",
      "Epoch 331: ReduceLROnPlateau reducing learning rate to 0.0001350851875031367.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0208 - val_loss: 0.0225 - learning_rate: 1.5009e-04\n",
      "Epoch 332/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0209 - val_loss: 0.0227 - learning_rate: 1.3509e-04\n",
      "Epoch 333/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0208 - val_loss: 0.0227 - learning_rate: 1.3509e-04\n",
      "Epoch 334/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0208 - val_loss: 0.0226 - learning_rate: 1.3509e-04\n",
      "Epoch 335/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0209"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:52:14.886442: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0209 - val_loss: 0.0223 - learning_rate: 1.3509e-04\n",
      "Epoch 336/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0208 - val_loss: 0.0224 - learning_rate: 1.3509e-04\n",
      "Epoch 337/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0208 - val_loss: 0.0226 - learning_rate: 1.3509e-04\n",
      "Epoch 338/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0208 - val_loss: 0.0223 - learning_rate: 1.3509e-04\n",
      "Epoch 339/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0209 - val_loss: 0.0223 - learning_rate: 1.3509e-04\n",
      "Epoch 340/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0207 - val_loss: 0.0232 - learning_rate: 1.3509e-04\n",
      "Epoch 341/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0209\n",
      "Epoch 341: ReduceLROnPlateau reducing learning rate to 0.00012157666351413355.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0209 - val_loss: 0.0223 - learning_rate: 1.3509e-04\n",
      "Epoch 342/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0208 - val_loss: 0.0225 - learning_rate: 1.2158e-04\n",
      "Epoch 343/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0207 - val_loss: 0.0227 - learning_rate: 1.2158e-04\n",
      "Epoch 344/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0208 - val_loss: 0.0222 - learning_rate: 1.2158e-04\n",
      "Epoch 345/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:52:36.790277: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0208 - val_loss: 0.0228 - learning_rate: 1.2158e-04\n",
      "Epoch 346/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0208 - val_loss: 0.0225 - learning_rate: 1.2158e-04\n",
      "Epoch 347/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0208 - val_loss: 0.0225 - learning_rate: 1.2158e-04\n",
      "Epoch 348/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0208"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:52:46.267807: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0208 - val_loss: 0.0228 - learning_rate: 1.2158e-04\n",
      "Epoch 349/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0208 - val_loss: 0.0230 - learning_rate: 1.2158e-04\n",
      "Epoch 350/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0208 - val_loss: 0.0223 - learning_rate: 1.2158e-04\n",
      "Epoch 351/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0206\n",
      "Epoch 351: ReduceLROnPlateau reducing learning rate to 0.00010941899454337544.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0225 - learning_rate: 1.2158e-04\n",
      "Epoch 352/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0207 - val_loss: 0.0224 - learning_rate: 1.0942e-04\n",
      "Epoch 353/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0207 - val_loss: 0.0232 - learning_rate: 1.0942e-04\n",
      "Epoch 354/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0208 - val_loss: 0.0228 - learning_rate: 1.0942e-04\n",
      "Epoch 355/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0207 - val_loss: 0.0224 - learning_rate: 1.0942e-04\n",
      "Epoch 356/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0206 - val_loss: 0.0228 - learning_rate: 1.0942e-04\n",
      "Epoch 357/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0207 - val_loss: 0.0222 - learning_rate: 1.0942e-04\n",
      "Epoch 358/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0207 - val_loss: 0.0223 - learning_rate: 1.0942e-04\n",
      "Epoch 359/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0208 - val_loss: 0.0226 - learning_rate: 1.0942e-04\n",
      "Epoch 360/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0208 - val_loss: 0.0223 - learning_rate: 1.0942e-04\n",
      "Epoch 361/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0208"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:53:17.675569: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 361: ReduceLROnPlateau reducing learning rate to 9.847709443420172e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0208 - val_loss: 0.0225 - learning_rate: 1.0942e-04\n",
      "Epoch 362/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0207 - val_loss: 0.0224 - learning_rate: 9.8477e-05\n",
      "Epoch 363/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0220 - learning_rate: 9.8477e-05\n",
      "Epoch 364/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0226 - learning_rate: 9.8477e-05\n",
      "Epoch 365/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0206 - val_loss: 0.0223 - learning_rate: 9.8477e-05\n",
      "Epoch 366/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0207 - val_loss: 0.0222 - learning_rate: 9.8477e-05\n",
      "Epoch 367/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0227 - learning_rate: 9.8477e-05\n",
      "Epoch 368/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0207 - val_loss: 0.0224 - learning_rate: 9.8477e-05\n",
      "Epoch 369/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0208 - val_loss: 0.0219 - learning_rate: 9.8477e-05\n",
      "Epoch 370/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0227 - learning_rate: 9.8477e-05\n",
      "Epoch 371/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0207 - val_loss: 0.0226 - learning_rate: 9.8477e-05\n",
      "Epoch 372/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0224 - learning_rate: 9.8477e-05\n",
      "Epoch 373/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0206\n",
      "Epoch 373: ReduceLROnPlateau reducing learning rate to 8.862938630045391e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0224 - learning_rate: 9.8477e-05\n",
      "Epoch 374/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:53:49.300752: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0223 - learning_rate: 8.8629e-05\n",
      "Epoch 375/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0226 - learning_rate: 8.8629e-05\n",
      "Epoch 376/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0206 - val_loss: 0.0229 - learning_rate: 8.8629e-05\n",
      "Epoch 377/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0208 - val_loss: 0.0219 - learning_rate: 8.8629e-05\n",
      "Epoch 378/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0223 - learning_rate: 8.8629e-05\n",
      "Epoch 379/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0207 - val_loss: 0.0224 - learning_rate: 8.8629e-05\n",
      "Epoch 380/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0207 - val_loss: 0.0223 - learning_rate: 8.8629e-05\n",
      "Epoch 381/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0223 - learning_rate: 8.8629e-05\n",
      "Epoch 382/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0207 - val_loss: 0.0223 - learning_rate: 8.8629e-05\n",
      "Epoch 383/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0206\n",
      "Epoch 383: ReduceLROnPlateau reducing learning rate to 7.976644701557234e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0224 - learning_rate: 8.8629e-05\n",
      "Epoch 384/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0207 - val_loss: 0.0220 - learning_rate: 7.9766e-05\n",
      "Epoch 385/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0207 - val_loss: 0.0223 - learning_rate: 7.9766e-05\n",
      "Epoch 386/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0206 - val_loss: 0.0222 - learning_rate: 7.9766e-05\n",
      "Epoch 387/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0207"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:54:20.725290: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0207 - val_loss: 0.0223 - learning_rate: 7.9766e-05\n",
      "Epoch 388/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0207 - val_loss: 0.0222 - learning_rate: 7.9766e-05\n",
      "Epoch 389/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0226 - learning_rate: 7.9766e-05\n",
      "Epoch 390/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0221 - learning_rate: 7.9766e-05\n",
      "Epoch 391/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0222 - learning_rate: 7.9766e-05\n",
      "Epoch 392/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0207 - val_loss: 0.0227 - learning_rate: 7.9766e-05\n",
      "Epoch 393/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0205\n",
      "Epoch 393: ReduceLROnPlateau reducing learning rate to 7.178980231401511e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0223 - learning_rate: 7.9766e-05\n",
      "Epoch 394/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0206 - val_loss: 0.0220 - learning_rate: 7.1790e-05\n",
      "Epoch 395/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0206 - val_loss: 0.0230 - learning_rate: 7.1790e-05\n",
      "Epoch 396/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0206 - val_loss: 0.0224 - learning_rate: 7.1790e-05\n",
      "Epoch 397/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0207 - val_loss: 0.0232 - learning_rate: 7.1790e-05\n",
      "Epoch 398/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0221 - learning_rate: 7.1790e-05\n",
      "Epoch 399/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0207 - val_loss: 0.0224 - learning_rate: 7.1790e-05\n",
      "Epoch 400/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0207"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:54:52.338920: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0207 - val_loss: 0.0229 - learning_rate: 7.1790e-05\n",
      "Epoch 401/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0227 - learning_rate: 7.1790e-05\n",
      "Epoch 402/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0222 - learning_rate: 7.1790e-05\n",
      "Epoch 403/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0206\n",
      "Epoch 403: ReduceLROnPlateau reducing learning rate to 6.461082011810504e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0221 - learning_rate: 7.1790e-05\n",
      "Epoch 404/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0207 - val_loss: 0.0222 - learning_rate: 6.4611e-05\n",
      "Epoch 405/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0223 - learning_rate: 6.4611e-05\n",
      "Epoch 406/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0225 - learning_rate: 6.4611e-05\n",
      "Epoch 407/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0228 - learning_rate: 6.4611e-05\n",
      "Epoch 408/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0228 - learning_rate: 6.4611e-05\n",
      "Epoch 409/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0223 - learning_rate: 6.4611e-05\n",
      "Epoch 410/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0206 - val_loss: 0.0224 - learning_rate: 6.4611e-05\n",
      "Epoch 411/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0205 - val_loss: 0.0222 - learning_rate: 6.4611e-05\n",
      "Epoch 412/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0230 - learning_rate: 6.4611e-05\n",
      "Epoch 413/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0206"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:55:23.711902: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 413: ReduceLROnPlateau reducing learning rate to 5.8149741380475466e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0206 - val_loss: 0.0219 - learning_rate: 6.4611e-05\n",
      "Epoch 414/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 5.8150e-05\n",
      "Epoch 415/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0226 - learning_rate: 5.8150e-05\n",
      "Epoch 416/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0226 - learning_rate: 5.8150e-05\n",
      "Epoch 417/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0225 - learning_rate: 5.8150e-05\n",
      "Epoch 418/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0225 - learning_rate: 5.8150e-05\n",
      "Epoch 419/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0205 - val_loss: 0.0224 - learning_rate: 5.8150e-05\n",
      "Epoch 420/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0222 - learning_rate: 5.8150e-05\n",
      "Epoch 421/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0206 - val_loss: 0.0220 - learning_rate: 5.8150e-05\n",
      "Epoch 422/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0225 - learning_rate: 5.8150e-05\n",
      "Epoch 423/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0206\n",
      "Epoch 423: ReduceLROnPlateau reducing learning rate to 5.233476658759173e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0226 - learning_rate: 5.8150e-05\n",
      "Epoch 424/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0223 - learning_rate: 5.2335e-05\n",
      "Epoch 425/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0223 - learning_rate: 5.2335e-05\n",
      "Epoch 426/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0206"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:55:55.326886: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0225 - learning_rate: 5.2335e-05\n",
      "Epoch 427/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0222 - learning_rate: 5.2335e-05\n",
      "Epoch 428/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0205 - val_loss: 0.0224 - learning_rate: 5.2335e-05\n",
      "Epoch 429/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 5.2335e-05\n",
      "Epoch 430/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0206 - val_loss: 0.0221 - learning_rate: 5.2335e-05\n",
      "Epoch 431/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0227 - learning_rate: 5.2335e-05\n",
      "Epoch 432/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0227 - learning_rate: 5.2335e-05\n",
      "Epoch 433/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0205\n",
      "Epoch 433: ReduceLROnPlateau reducing learning rate to 4.7101289601414466e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0225 - learning_rate: 5.2335e-05\n",
      "Epoch 434/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0225 - learning_rate: 4.7101e-05\n",
      "Epoch 435/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 4.7101e-05\n",
      "Epoch 436/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0206 - val_loss: 0.0225 - learning_rate: 4.7101e-05\n",
      "Epoch 437/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0224 - learning_rate: 4.7101e-05\n",
      "Epoch 438/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0206 - val_loss: 0.0222 - learning_rate: 4.7101e-05\n",
      "Epoch 439/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:56:26.927650: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0223 - learning_rate: 4.7101e-05\n",
      "Epoch 440/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0220 - learning_rate: 4.7101e-05\n",
      "Epoch 441/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0224 - learning_rate: 4.7101e-05\n",
      "Epoch 442/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0222 - learning_rate: 4.7101e-05\n",
      "Epoch 443/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0205\n",
      "Epoch 443: ReduceLROnPlateau reducing learning rate to 4.239116096869111e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0226 - learning_rate: 4.7101e-05\n",
      "Epoch 444/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0223 - learning_rate: 4.2391e-05\n",
      "Epoch 445/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 4.2391e-05\n",
      "Epoch 446/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0230 - learning_rate: 4.2391e-05\n",
      "Epoch 447/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 4.2391e-05\n",
      "Epoch 448/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0220 - learning_rate: 4.2391e-05\n",
      "Epoch 449/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0205 - val_loss: 0.0220 - learning_rate: 4.2391e-05\n",
      "Epoch 450/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0224 - learning_rate: 4.2391e-05\n",
      "Epoch 451/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0223 - learning_rate: 4.2391e-05\n",
      "Epoch 452/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:56:58.583566: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0221 - learning_rate: 4.2391e-05\n",
      "Epoch 453/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0204\n",
      "Epoch 453: ReduceLROnPlateau reducing learning rate to 3.815204618149437e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 4.2391e-05\n",
      "Epoch 454/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0224 - learning_rate: 3.8152e-05\n",
      "Epoch 455/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 3.8152e-05\n",
      "Epoch 456/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0206 - val_loss: 0.0227 - learning_rate: 3.8152e-05\n",
      "Epoch 457/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0222 - learning_rate: 3.8152e-05\n",
      "Epoch 458/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0225 - learning_rate: 3.8152e-05\n",
      "Epoch 459/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0228 - learning_rate: 3.8152e-05\n",
      "Epoch 460/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 3.8152e-05\n",
      "Epoch 461/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0223 - learning_rate: 3.8152e-05\n",
      "Epoch 462/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0220 - learning_rate: 3.8152e-05\n",
      "Epoch 463/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0205\n",
      "Epoch 463: ReduceLROnPlateau reducing learning rate to 3.4336842873017304e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0222 - learning_rate: 3.8152e-05\n",
      "Epoch 464/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0222 - learning_rate: 3.4337e-05\n",
      "Epoch 465/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:57:30.012901: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 3.4337e-05\n",
      "Epoch 466/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0226 - learning_rate: 3.4337e-05\n",
      "Epoch 467/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0225 - learning_rate: 3.4337e-05\n",
      "Epoch 468/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0216 - learning_rate: 3.4337e-05\n",
      "Epoch 469/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0222 - learning_rate: 3.4337e-05\n",
      "Epoch 470/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0226 - learning_rate: 3.4337e-05\n",
      "Epoch 471/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 3.4337e-05\n",
      "Epoch 472/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 3.4337e-05\n",
      "Epoch 473/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 3.4337e-05\n",
      "Epoch 474/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 3.4337e-05\n",
      "Epoch 475/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 3.4337e-05\n",
      "Epoch 476/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 3.4337e-05\n",
      "Epoch 477/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0206 - val_loss: 0.0223 - learning_rate: 3.4337e-05\n",
      "Epoch 478/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0206"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:58:01.660518: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 478: ReduceLROnPlateau reducing learning rate to 3.0903160222806036e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0206 - val_loss: 0.0227 - learning_rate: 3.4337e-05\n",
      "Epoch 479/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0206 - val_loss: 0.0222 - learning_rate: 3.0903e-05\n",
      "Epoch 480/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 3.0903e-05\n",
      "Epoch 481/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0206 - val_loss: 0.0223 - learning_rate: 3.0903e-05\n",
      "Epoch 482/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0217 - learning_rate: 3.0903e-05\n",
      "Epoch 483/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 3.0903e-05\n",
      "Epoch 484/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0218 - learning_rate: 3.0903e-05\n",
      "Epoch 485/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 3.0903e-05\n",
      "Epoch 486/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 3.0903e-05\n",
      "Epoch 487/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 3.0903e-05\n",
      "Epoch 488/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0204\n",
      "Epoch 488: ReduceLROnPlateau reducing learning rate to 2.7812844200525434e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0218 - learning_rate: 3.0903e-05\n",
      "Epoch 489/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0226 - learning_rate: 2.7813e-05\n",
      "Epoch 490/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 2.7813e-05\n",
      "Epoch 491/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:58:33.084487: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 2.7813e-05\n",
      "Epoch 492/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 2.7813e-05\n",
      "Epoch 493/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 2.7813e-05\n",
      "Epoch 494/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 2.7813e-05\n",
      "Epoch 495/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 2.7813e-05\n",
      "Epoch 496/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 2.7813e-05\n",
      "Epoch 497/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0204 - val_loss: 0.0227 - learning_rate: 2.7813e-05\n",
      "Epoch 498/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0205\n",
      "Epoch 498: ReduceLROnPlateau reducing learning rate to 2.5031560107890984e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0226 - learning_rate: 2.7813e-05\n",
      "Epoch 499/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0224 - learning_rate: 2.5032e-05\n",
      "Epoch 500/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 2.5032e-05\n",
      "Epoch 501/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0206 - val_loss: 0.0223 - learning_rate: 2.5032e-05\n",
      "Epoch 502/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0220 - learning_rate: 2.5032e-05\n",
      "Epoch 503/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 2.5032e-05\n",
      "Epoch 504/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:59:04.352131: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0222 - learning_rate: 2.5032e-05\n",
      "Epoch 505/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 2.5032e-05\n",
      "Epoch 506/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0223 - learning_rate: 2.5032e-05\n",
      "Epoch 507/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0219 - learning_rate: 2.5032e-05\n",
      "Epoch 508/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0204\n",
      "Epoch 508: ReduceLROnPlateau reducing learning rate to 2.2528404588229024e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 2.5032e-05\n",
      "Epoch 509/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0221 - learning_rate: 2.2528e-05\n",
      "Epoch 510/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 2.2528e-05\n",
      "Epoch 511/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 2.2528e-05\n",
      "Epoch 512/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 2.2528e-05\n",
      "Epoch 513/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0223 - learning_rate: 2.2528e-05\n",
      "Epoch 514/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 2.2528e-05\n",
      "Epoch 515/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 2.2528e-05\n",
      "Epoch 516/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 2.2528e-05\n",
      "Epoch 517/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:59:35.947196: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 2.2528e-05\n",
      "Epoch 518/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203\n",
      "Epoch 518: ReduceLROnPlateau reducing learning rate to 2.0275563474569936e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 2.2528e-05\n",
      "Epoch 519/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 2.0276e-05\n",
      "Epoch 520/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 2.0276e-05\n",
      "Epoch 521/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 2.0276e-05\n",
      "Epoch 522/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 2.0276e-05\n",
      "Epoch 523/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 2.0276e-05\n",
      "Epoch 524/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0221 - learning_rate: 2.0276e-05\n",
      "Epoch 525/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 2.0276e-05\n",
      "Epoch 526/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 2.0276e-05\n",
      "Epoch 527/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0223 - learning_rate: 2.0276e-05\n",
      "Epoch 528/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0203\n",
      "Epoch 528: ReduceLROnPlateau reducing learning rate to 1.8248007290821987e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 2.0276e-05\n",
      "Epoch 529/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0227 - learning_rate: 1.8248e-05\n",
      "Epoch 530/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:00:07.487992: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 1.8248e-05\n",
      "Epoch 531/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0221 - learning_rate: 1.8248e-05\n",
      "Epoch 532/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 1.8248e-05\n",
      "Epoch 533/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 1.8248e-05\n",
      "Epoch 534/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 1.8248e-05\n",
      "Epoch 535/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 1.8248e-05\n",
      "Epoch 536/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 1.8248e-05\n",
      "Epoch 537/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 1.8248e-05\n",
      "Epoch 538/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0204\n",
      "Epoch 538: ReduceLROnPlateau reducing learning rate to 1.6423206398030745e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 1.8248e-05\n",
      "Epoch 539/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0223 - learning_rate: 1.6423e-05\n",
      "Epoch 540/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0227 - learning_rate: 1.6423e-05\n",
      "Epoch 541/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 1.6423e-05\n",
      "Epoch 542/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 1.6423e-05\n",
      "Epoch 543/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:00:38.872117: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 1.6423e-05\n",
      "Epoch 544/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0205 - val_loss: 0.0220 - learning_rate: 1.6423e-05\n",
      "Epoch 545/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 1.6423e-05\n",
      "Epoch 546/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 1.6423e-05\n",
      "Epoch 547/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 1.6423e-05\n",
      "Epoch 548/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203\n",
      "Epoch 548: ReduceLROnPlateau reducing learning rate to 1.4780885430809576e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 1.6423e-05\n",
      "Epoch 549/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 1.4781e-05\n",
      "Epoch 550/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0227 - learning_rate: 1.4781e-05\n",
      "Epoch 551/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 1.4781e-05\n",
      "Epoch 552/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 1.4781e-05\n",
      "Epoch 553/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0221 - learning_rate: 1.4781e-05\n",
      "Epoch 554/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 1.4781e-05\n",
      "Epoch 555/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0223 - learning_rate: 1.4781e-05\n",
      "Epoch 556/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:01:10.561953: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 1.4781e-05\n",
      "Epoch 557/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 1.4781e-05\n",
      "Epoch 558/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0204\n",
      "Epoch 558: ReduceLROnPlateau reducing learning rate to 1.3302796560310526e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 1.4781e-05\n",
      "Epoch 559/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 1.3303e-05\n",
      "Epoch 560/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 1.3303e-05\n",
      "Epoch 561/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 1.3303e-05\n",
      "Epoch 562/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0227 - learning_rate: 1.3303e-05\n",
      "Epoch 563/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 1.3303e-05\n",
      "Epoch 564/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 1.3303e-05\n",
      "Epoch 565/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 1.3303e-05\n",
      "Epoch 566/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 1.3303e-05\n",
      "Epoch 567/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 1.3303e-05\n",
      "Epoch 568/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0204\n",
      "Epoch 568: ReduceLROnPlateau reducing learning rate to 1.1972517313552089e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 1.3303e-05\n",
      "Epoch 569/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:01:41.956759: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 1.1973e-05\n",
      "Epoch 570/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 1.1973e-05\n",
      "Epoch 571/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 1.1973e-05\n",
      "Epoch 572/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 1.1973e-05\n",
      "Epoch 573/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 1.1973e-05\n",
      "Epoch 574/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0218 - learning_rate: 1.1973e-05\n",
      "Epoch 575/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 1.1973e-05\n",
      "Epoch 576/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0226 - learning_rate: 1.1973e-05\n",
      "Epoch 577/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0224 - learning_rate: 1.1973e-05\n",
      "Epoch 578/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0205\n",
      "Epoch 578: ReduceLROnPlateau reducing learning rate to 1.077526558219688e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0205 - val_loss: 0.0223 - learning_rate: 1.1973e-05\n",
      "Epoch 579/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 1.0775e-05\n",
      "Epoch 580/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 1.0775e-05\n",
      "Epoch 581/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0223 - learning_rate: 1.0775e-05\n",
      "Epoch 582/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:02:13.360289: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 1.0775e-05\n",
      "Epoch 583/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 1.0775e-05\n",
      "Epoch 584/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 1.0775e-05\n",
      "Epoch 585/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 1.0775e-05\n",
      "Epoch 586/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0227 - learning_rate: 1.0775e-05\n",
      "Epoch 587/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 1.0775e-05\n",
      "Epoch 588/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0203\n",
      "Epoch 588: ReduceLROnPlateau reducing learning rate to 9.697739187686238e-06.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 1.0775e-05\n",
      "Epoch 589/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 9.6977e-06\n",
      "Epoch 590/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 9.6977e-06\n",
      "Epoch 591/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0216 - learning_rate: 9.6977e-06\n",
      "Epoch 592/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0218 - learning_rate: 9.6977e-06\n",
      "Epoch 593/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 9.6977e-06\n",
      "Epoch 594/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 9.6977e-06\n",
      "Epoch 595/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:02:44.979895: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 9.6977e-06\n",
      "Epoch 596/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 9.6977e-06\n",
      "Epoch 597/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 9.6977e-06\n",
      "Epoch 598/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203\n",
      "Epoch 598: ReduceLROnPlateau reducing learning rate to 8.727965268917615e-06.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 9.6977e-06\n",
      "Epoch 599/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0230 - learning_rate: 8.7280e-06\n",
      "Epoch 600/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 8.7280e-06\n",
      "Epoch 601/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 8.7280e-06\n",
      "Epoch 602/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 8.7280e-06\n",
      "Epoch 603/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 8.7280e-06\n",
      "Epoch 604/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0219 - learning_rate: 8.7280e-06\n",
      "Epoch 605/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 8.7280e-06\n",
      "Epoch 606/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 8.7280e-06\n",
      "Epoch 607/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 8.7280e-06\n",
      "Epoch 608/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:03:16.339902: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 608: ReduceLROnPlateau reducing learning rate to 7.855168496462283e-06.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0222 - learning_rate: 8.7280e-06\n",
      "Epoch 609/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.8552e-06\n",
      "Epoch 610/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.8552e-06\n",
      "Epoch 611/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.8552e-06\n",
      "Epoch 612/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.8552e-06\n",
      "Epoch 613/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 7.8552e-06\n",
      "Epoch 614/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.8552e-06\n",
      "Epoch 615/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.8552e-06\n",
      "Epoch 616/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0227 - learning_rate: 7.8552e-06\n",
      "Epoch 617/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.8552e-06\n",
      "Epoch 618/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0202\n",
      "Epoch 618: ReduceLROnPlateau reducing learning rate to 7.069651564961533e-06.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.8552e-06\n",
      "Epoch 619/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0217 - learning_rate: 7.0697e-06\n",
      "Epoch 620/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0697e-06\n",
      "Epoch 621/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:03:47.575707: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0218 - learning_rate: 7.0697e-06\n",
      "Epoch 622/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0697e-06\n",
      "Epoch 623/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0697e-06\n",
      "Epoch 624/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0697e-06\n",
      "Epoch 625/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 7.0697e-06\n",
      "Epoch 626/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0218 - learning_rate: 7.0697e-06\n",
      "Epoch 627/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 7.0697e-06\n",
      "Epoch 628/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0204\n",
      "Epoch 628: ReduceLROnPlateau reducing learning rate to 7e-06.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0697e-06\n",
      "Epoch 629/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 630/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 631/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 632/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 633/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 634/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:04:19.129261: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 635/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 636/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 637/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 638/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 639/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 640/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 641/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 642/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 643/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 644/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 645/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 646/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 647/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:04:50.538715: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 648/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 649/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 650/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 651/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 652/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 653/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 654/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 655/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 656/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 657/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 658/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 659/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 660/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:05:21.870929: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 661/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 662/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 663/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 664/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 665/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 666/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 667/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 668/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 669/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 670/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 671/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 672/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 673/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:05:53.362934: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 674/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 675/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 676/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 677/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 678/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 679/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 680/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 681/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 682/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 683/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 684/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 685/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 686/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:06:24.772047: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 687/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 688/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:06:29.515301: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 689/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 690/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 691/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 692/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 693/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 694/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 695/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 696/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 697/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 698/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 699/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:06:56.198345: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 700/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0228 - learning_rate: 7.0000e-06\n",
      "Epoch 701/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 702/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 703/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 704/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 705/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 706/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 707/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 708/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 709/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 710/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 711/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 712/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:07:27.900262: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 713/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 714/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 715/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 716/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 717/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 718/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 719/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 720/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 721/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 722/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 723/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 724/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 725/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:07:59.323575: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 726/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 727/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 728/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 729/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 730/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 731/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 732/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 733/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 734/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 735/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 736/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 737/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 738/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:08:30.960811: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 739/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 740/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 741/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 742/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 743/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 744/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 745/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 746/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 747/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 748/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 749/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0203 - val_loss: 0.0228 - learning_rate: 7.0000e-06\n",
      "Epoch 750/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 751/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:09:02.778349: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 752/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 753/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 754/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 755/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 756/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 757/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 758/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 759/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 760/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 761/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 762/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 763/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 764/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:09:34.200949: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 765/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 766/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 767/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 768/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 769/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 770/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 771/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 772/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 773/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 774/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 775/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 776/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 777/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:10:05.665918: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0204 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 778/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 779/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 780/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 781/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 782/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 783/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 784/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 785/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 786/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 787/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 788/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 789/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 790/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:10:37.280548: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 791/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 792/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 793/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 794/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 795/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 796/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 797/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 798/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0229 - learning_rate: 7.0000e-06\n",
      "Epoch 799/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 800/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 801/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 802/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 803/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:11:08.551881: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 804/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 805/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 806/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 807/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 808/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 809/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 810/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 811/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 812/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0215 - learning_rate: 7.0000e-06\n",
      "Epoch 813/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 814/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 815/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 816/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:11:40.175816: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 817/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 818/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 819/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 820/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 821/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 822/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 823/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 824/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 825/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 826/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 827/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 828/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 829/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:12:11.480358: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 830/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 831/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 832/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 833/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 834/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 835/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 836/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 837/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 838/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 839/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 840/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 841/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 842/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:12:43.080902: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 843/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 844/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 845/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 846/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 847/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 848/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 849/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 850/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 851/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0228 - learning_rate: 7.0000e-06\n",
      "Epoch 852/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 853/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 854/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 855/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:13:14.367018: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 856/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 857/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 858/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 859/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 860/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 861/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 862/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 863/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 864/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 865/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 866/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 867/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 868/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:13:45.912864: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 869/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 870/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 871/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 872/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 873/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 874/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 875/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 876/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 877/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 878/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 879/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 880/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 881/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:14:17.156645: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0232 - learning_rate: 7.0000e-06\n",
      "Epoch 882/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 883/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 884/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 885/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0229 - learning_rate: 7.0000e-06\n",
      "Epoch 886/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 887/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 888/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 889/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 890/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 891/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 892/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 893/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 894/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:14:48.667912: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 895/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 896/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 897/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0228 - learning_rate: 7.0000e-06\n",
      "Epoch 898/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 899/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 900/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 901/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 902/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 903/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 904/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 905/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 906/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 907/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:15:19.963335: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 908/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 909/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 910/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 911/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 912/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 913/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 914/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 915/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 916/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 917/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 918/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 919/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 920/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:15:51.182148: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 921/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 922/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 923/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 924/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 925/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 926/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 927/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 928/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 929/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 930/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 931/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 932/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 933/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:16:22.742015: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 934/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 935/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 936/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 937/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 938/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0228 - learning_rate: 7.0000e-06\n",
      "Epoch 939/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 940/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 941/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 942/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 943/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 944/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 945/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 946/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:16:54.152902: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 947/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 948/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 949/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 950/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 951/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 952/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 953/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 954/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 955/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 956/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 957/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 958/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 959/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:17:25.307063: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 960/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 961/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 962/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0205 - val_loss: 0.0215 - learning_rate: 7.0000e-06\n",
      "Epoch 963/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 964/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 965/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 966/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 967/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 968/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 969/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 970/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 971/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 972/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:17:56.774035: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 973/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 974/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 975/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 976/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 977/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 978/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 979/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 980/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 981/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 982/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 983/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 984/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 985/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:18:28.084953: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 986/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 987/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 988/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 989/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 990/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 991/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 992/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 993/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0214 - learning_rate: 7.0000e-06\n",
      "Epoch 994/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 995/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 996/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 997/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 998/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:18:59.375154: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 999/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1000/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1001/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1002/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1003/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1004/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1005/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1006/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1007/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1008/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1009/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1010/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1011/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:19:30.861994: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1012/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1013/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1014/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1015/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1016/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1017/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1018/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1019/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1020/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1021/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1022/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1023/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1024/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:20:02.272663: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1025/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1026/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 1027/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1028/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1029/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1030/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1031/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1032/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1033/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1034/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1035/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1036/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1037/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:20:33.702656: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1038/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1039/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1040/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1041/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1042/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1043/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1044/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1045/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1046/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1047/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1048/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1049/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1050/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:21:05.289296: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1051/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1052/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1053/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1054/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1055/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1056/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1057/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1058/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1059/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1060/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1061/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1062/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1063/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:21:36.686916: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1064/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1065/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1066/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1067/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1068/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1069/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1070/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1071/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1072/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1073/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 1074/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1075/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1076/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:22:07.940646: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1077/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1078/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1079/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1080/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1081/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1082/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1083/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1084/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1085/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1086/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1087/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1088/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1089/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:22:39.601490: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1090/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1091/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1092/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1093/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1094/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1095/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1096/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1097/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1098/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1099/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1100/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1101/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1102/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:23:10.962696: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1103/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1104/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1105/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1106/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1107/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1108/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1109/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1110/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1111/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1112/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1113/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1114/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1115/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:23:42.195795: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1116/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1117/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1118/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1119/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1120/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1121/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1122/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1123/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1124/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1125/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1126/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1127/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1128/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:24:13.933489: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1129/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1130/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1131/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1132/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1133/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1134/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1135/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1136/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1137/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1138/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1139/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1140/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1141/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:24:45.347028: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1142/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1143/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1144/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1145/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1146/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1147/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1148/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0215 - learning_rate: 7.0000e-06\n",
      "Epoch 1149/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1150/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1151/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1152/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1153/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1154/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:25:16.628013: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1155/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1156/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 1157/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1158/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1159/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1160/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1161/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0214 - learning_rate: 7.0000e-06\n",
      "Epoch 1162/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1163/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1164/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1165/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1166/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1167/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:25:48.233189: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1168/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1169/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1170/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1171/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1172/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1173/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1174/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1175/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1176/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1177/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1178/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1179/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1180/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:26:19.556850: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1181/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1182/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1183/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1184/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1185/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0228 - learning_rate: 7.0000e-06\n",
      "Epoch 1186/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1187/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1188/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1189/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1190/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1191/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1192/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1193/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:26:50.958877: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1194/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1195/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1196/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1197/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1198/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1199/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1200/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1201/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1202/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1203/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1204/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1205/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1206/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:27:22.560736: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1207/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1208/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1209/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1210/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1211/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1212/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1213/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1214/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1215/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1216/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1217/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1218/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1219/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:27:53.821934: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1220/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1221/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1222/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1223/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1224/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0228 - learning_rate: 7.0000e-06\n",
      "Epoch 1225/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1226/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1227/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1228/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1229/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1230/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1231/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1232/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:28:25.503302: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1233/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1234/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1235/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1236/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1237/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1238/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1239/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1240/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1241/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1242/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1243/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1244/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1245/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:28:56.713468: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1246/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1247/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1248/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1249/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1250/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1251/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1252/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1253/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1254/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1255/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1256/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1257/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1258/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:29:28.234683: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1259/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1260/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1261/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1262/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1263/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1264/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1265/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1266/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1267/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1268/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1269/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1270/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1271/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:29:59.490638: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1272/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1273/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1274/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1275/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1276/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1277/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1278/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1279/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1280/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1281/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0228 - learning_rate: 7.0000e-06\n",
      "Epoch 1282/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1283/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1284/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:30:31.081837: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1285/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1286/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1287/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1288/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1289/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1290/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1291/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1292/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1293/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1294/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1295/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1296/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1297/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:31:02.360059: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1298/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1299/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1300/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1301/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1302/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1303/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1304/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1305/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1306/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1307/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0214 - learning_rate: 7.0000e-06\n",
      "Epoch 1308/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1309/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1310/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:31:33.912103: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1311/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1312/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1313/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1314/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1315/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1316/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1317/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1318/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1319/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1320/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1321/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1322/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1323/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:32:05.279805: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1324/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1325/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1326/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1327/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1328/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1329/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1330/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1331/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1332/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1333/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1334/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1335/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1336/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:32:36.498395: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1337/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1338/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1339/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1340/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1341/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1342/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1343/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1344/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1345/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1346/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1347/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1348/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1349/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:33:08.086365: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1350/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1351/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1352/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1353/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1354/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1355/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 1356/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1357/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1358/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1359/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1360/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1361/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1362/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:33:39.354647: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1363/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1364/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1365/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1366/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1367/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1368/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1369/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1370/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1371/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1372/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1373/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1374/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1375/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:34:08.483441: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:34:10.679337: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1376/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1377/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1378/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1379/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1380/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0228 - learning_rate: 7.0000e-06\n",
      "Epoch 1381/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1382/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1383/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1384/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1385/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1386/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1387/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1388/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:34:42.539797: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1389/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1390/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1391/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1392/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1393/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1394/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1395/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1396/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1397/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1398/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1399/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1400/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1401/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:35:13.932789: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0204 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1402/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1403/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1404/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1405/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1406/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1407/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1408/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1409/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0215 - learning_rate: 7.0000e-06\n",
      "Epoch 1410/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1411/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1412/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1413/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1414/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:35:45.172506: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0214 - learning_rate: 7.0000e-06\n",
      "Epoch 1415/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1416/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1417/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1418/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1419/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1420/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1421/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1422/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1423/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1424/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1425/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1426/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1427/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:36:16.830331: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1428/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1429/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1430/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1431/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1432/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1433/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1434/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1435/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1436/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1437/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1438/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1439/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1440/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:36:48.103091: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1441/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1442/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1443/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1444/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1445/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1446/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1447/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1448/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1449/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1450/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1451/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1452/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1453/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:37:19.522157: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1454/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1455/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1456/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1457/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1458/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1459/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1460/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1461/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1462/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1463/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1464/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1465/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1466/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:37:51.158880: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1467/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1468/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0215 - learning_rate: 7.0000e-06\n",
      "Epoch 1469/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1470/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 1471/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1472/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1473/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1474/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1475/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1476/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1477/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1478/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0229 - learning_rate: 7.0000e-06\n",
      "Epoch 1479/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:38:22.594794: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1480/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1481/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1482/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1483/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1484/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1485/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1486/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1487/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1488/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1489/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1490/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1491/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1492/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:38:53.964035: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1493/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1494/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1495/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0228 - learning_rate: 7.0000e-06\n",
      "Epoch 1496/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1497/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1498/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1499/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1500/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1501/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1502/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1503/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1504/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1505/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:39:25.475412: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1506/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1507/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1508/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1509/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1510/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1511/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1512/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1513/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1514/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1515/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1516/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1517/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1518/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:39:56.825683: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1519/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1520/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1521/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1522/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1523/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1524/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1525/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1526/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1527/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1528/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1529/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1530/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1531/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:40:28.176526: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1532/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1533/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1534/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1535/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1536/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1537/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1538/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1539/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 1540/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1541/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1542/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1543/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1544/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:40:59.778097: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1545/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 1546/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1547/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1548/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1549/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1550/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1551/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1552/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1553/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1554/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1555/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1556/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1557/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:41:31.250615: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1558/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1559/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1560/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1561/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1562/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1563/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1564/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1565/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1566/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 1567/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1568/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1569/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1570/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:42:02.481028: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1571/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1572/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1573/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1574/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1575/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1576/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1577/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1578/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1579/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1580/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1581/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1582/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0214 - learning_rate: 7.0000e-06\n",
      "Epoch 1583/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:42:34.259348: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1584/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1585/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1586/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1587/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1588/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1589/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1590/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1591/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1592/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1593/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1594/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1595/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1596/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:43:05.658630: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0228 - learning_rate: 7.0000e-06\n",
      "Epoch 1597/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1598/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1599/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1600/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1601/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1602/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1603/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1604/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1605/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1606/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1607/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1608/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1609/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:43:36.927694: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1610/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1611/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1612/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1613/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1614/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1615/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1616/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1617/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1618/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1619/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1620/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1621/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1622/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:44:08.542057: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1623/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1624/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1625/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1626/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1627/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1628/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1629/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1630/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1631/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1632/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1633/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1634/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1635/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:44:39.860148: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 1636/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1637/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1638/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1639/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1640/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1641/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1642/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1643/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1644/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1645/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1646/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1647/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1648/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:45:11.434135: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1649/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1650/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1651/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1652/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1653/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1654/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1655/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1656/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1657/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1658/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1659/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1660/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1661/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:45:42.760788: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1662/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1663/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1664/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1665/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1666/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0200 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1667/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1668/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1669/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1670/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1671/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1672/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1673/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1674/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:46:14.232244: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1675/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1676/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1677/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1678/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1679/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1680/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1681/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1682/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1683/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1684/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1685/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1686/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1687/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:46:45.638488: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1688/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1689/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1690/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1691/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1692/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1693/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1694/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1695/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1696/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1697/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1698/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1699/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1700/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:47:17.091866: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0215 - learning_rate: 7.0000e-06\n",
      "Epoch 1701/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1702/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1703/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1704/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1705/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1706/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1707/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1708/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1709/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1710/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1711/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1712/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0212 - learning_rate: 7.0000e-06\n",
      "Epoch 1713/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:47:48.467515: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1714/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1715/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1716/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1717/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1718/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1719/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0200 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1720/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1721/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1722/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1723/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1724/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1725/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1726/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:48:20.204816: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1727/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1728/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1729/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1730/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1731/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1732/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1733/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1734/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1735/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1736/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1737/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1738/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1739/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:48:51.525435: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1740/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1741/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0214 - learning_rate: 7.0000e-06\n",
      "Epoch 1742/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1743/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1744/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1745/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1746/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1747/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1748/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1749/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1750/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1751/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1752/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:49:22.930660: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1753/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1754/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1755/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1756/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1757/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0201 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1758/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 1759/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1760/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1761/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1762/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1763/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1764/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1765/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:49:54.446160: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1766/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1767/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1768/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1769/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0231 - learning_rate: 7.0000e-06\n",
      "Epoch 1770/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1771/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1772/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1773/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1774/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1775/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1776/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1777/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1778/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:50:25.968889: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1779/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1780/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1781/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1782/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1783/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1784/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1785/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1786/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1787/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1788/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1789/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1790/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1791/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:50:57.216980: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1792/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1793/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1794/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1795/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1796/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1797/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1798/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1799/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1800/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1801/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 1802/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1803/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1804/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:51:29.003300: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1805/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1806/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1807/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1808/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1809/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1810/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1811/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1812/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1813/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1814/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1815/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1816/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1817/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:52:00.291607: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1818/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1819/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1820/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0200 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1821/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1822/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0215 - learning_rate: 7.0000e-06\n",
      "Epoch 1823/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1824/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1825/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0214 - learning_rate: 7.0000e-06\n",
      "Epoch 1826/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1827/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1828/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1829/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1830/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:52:31.726315: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1831/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1832/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0200 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1833/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1834/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1835/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1836/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1837/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1838/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1839/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1840/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1841/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1842/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0200 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1843/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:53:03.369048: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1844/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1845/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1846/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1847/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1848/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1849/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1850/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1851/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1852/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1853/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1854/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1855/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1856/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:53:34.845242: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1857/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1858/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1859/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1860/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0200 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1861/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1862/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1863/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1864/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1865/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1866/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1867/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1868/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0200 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1869/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:54:06.196942: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1870/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1871/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1872/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1873/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0200 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1874/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1875/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1876/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1877/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1878/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1879/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1880/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1881/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1882/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:54:37.886137: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1883/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0200 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1884/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1885/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0228 - learning_rate: 7.0000e-06\n",
      "Epoch 1886/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1887/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1888/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1889/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1890/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1891/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1892/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1893/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1894/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1895/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:55:09.214025: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1896/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1897/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1898/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0200 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1899/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1900/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1901/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1902/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1903/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1904/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0228 - learning_rate: 7.0000e-06\n",
      "Epoch 1905/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0228 - learning_rate: 7.0000e-06\n",
      "Epoch 1906/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1907/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1908/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:55:40.747260: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1909/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1910/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1911/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1912/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1913/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1914/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1915/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1916/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1917/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0226 - learning_rate: 7.0000e-06\n",
      "Epoch 1918/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1919/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0203 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1920/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1921/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:56:12.608351: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1922/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0200 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1923/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1924/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1925/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1926/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1927/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1928/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1929/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0216 - learning_rate: 7.0000e-06\n",
      "Epoch 1930/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1931/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0203 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1932/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1933/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1934/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:56:44.222907: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1935/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1936/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1937/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1938/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1939/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1940/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 1941/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0224 - learning_rate: 7.0000e-06\n",
      "Epoch 1942/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1943/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0212 - learning_rate: 7.0000e-06\n",
      "Epoch 1944/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1945/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1946/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1947/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:57:15.975684: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1948/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1949/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1950/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0200 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1951/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0215 - learning_rate: 7.0000e-06\n",
      "Epoch 1952/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0215 - learning_rate: 7.0000e-06\n",
      "Epoch 1953/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0202 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1954/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0200 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1955/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1956/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1957/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1958/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1959/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1960/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:57:46.133041: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1961/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1962/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1963/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1964/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1965/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1966/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1967/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1968/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0200 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1969/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1970/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1971/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1972/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:58:17.392895: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1973/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1974/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1975/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1976/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1977/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1978/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1979/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1980/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1981/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0218 - learning_rate: 7.0000e-06\n",
      "Epoch 1982/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1983/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0200 - val_loss: 0.0227 - learning_rate: 7.0000e-06\n",
      "Epoch 1984/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1985/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:58:49.105674: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1986/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0202 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1987/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0200 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1988/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1989/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n",
      "Epoch 1990/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0220 - learning_rate: 7.0000e-06\n",
      "Epoch 1991/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0217 - learning_rate: 7.0000e-06\n",
      "Epoch 1992/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0202 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1993/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1994/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1995/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0202 - val_loss: 0.0225 - learning_rate: 7.0000e-06\n",
      "Epoch 1996/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0219 - learning_rate: 7.0000e-06\n",
      "Epoch 1997/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 1998/2000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:59:20.997139: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0203 - val_loss: 0.0223 - learning_rate: 7.0000e-06\n",
      "Epoch 1999/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0201 - val_loss: 0.0221 - learning_rate: 7.0000e-06\n",
      "Epoch 2000/2000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0201 - val_loss: 0.0222 - learning_rate: 7.0000e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with the custom callback\n",
    "history = model_builder.train_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    epochs=2000,\n",
    "    callbacks_list=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the losses from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "train_loss_x_midpoints = history.history.get('x_midpoints_reshape_loss', train_loss)\n",
    "val_loss_x_midpoints = history.history.get('val_x_midpoints_reshape_loss', val_loss)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2,1)\n",
    "plt.plot(train_loss_x_midpoints, label='Train Loss x_midpoints_reshape')\n",
    "plt.plot(val_loss_x_midpoints, label='Validation Loss x_midpoints_reshape')\n",
    "plt.xlabel('Epochs')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder.model.save(\"/home/da886/Analysis/33KFixed_Mixed_5_32by32_95indexFor19kernel-l2reg.keras\")\n",
    "# loaded_model = tf.keras.models.load_model(\n",
    "# \"/home/da886/Analysis/30KFixed_13_SparsespotsrandomSPOTS.keras\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729634555.874463 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.875507 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.875875 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.876224 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.876534 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.876836 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.876921 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.877005 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.877808 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.877965 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.877989 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.878337 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.878643 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.878696 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.878926 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.879419 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.879467 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.879636 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.880134 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.880170 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.880359 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.880955 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.881032 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.881061 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.881765 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.881850 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.881890 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.882416 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.882487 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.882812 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.883101 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.883215 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.883396 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.883804 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.884062 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.884139 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.884460 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.884897 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.884966 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.885245 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.885642 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.885696 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.885857 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.886409 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.886469 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.886594 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.887253 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.887396 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.887496 2936637 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.887859 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.888070 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.888603 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.888725 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.889053 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.889275 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.889625 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.889805 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.890110 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.890518 2936610 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729634555.890771 2936631 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 3, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 4, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 5, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 6, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 7, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 8, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 9, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step   \n",
      "Processing batch 10, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 11, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Processing batch 12, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 13, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Define the function for visualizing midpoints\n",
    "# def visualize_midpoints(image, midpoints, title=\"Predicted Midpoint Visualization\"):\n",
    "#     \"\"\"\n",
    "#     Visualizes midpoints on an image without using a probability vector.\n",
    "\n",
    "#     Parameters:\n",
    "#     - image: A 3D tensor representing the image.\n",
    "#     - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "#     - title: The title of the plot.\n",
    "\n",
    "#     Returns:\n",
    "#     None (displays the image with midpoints).\n",
    "#     \"\"\"\n",
    "#     # Convert to NumPy arrays for easier handling\n",
    "#     image_np = image\n",
    "#     midpoints_np = midpoints\n",
    "\n",
    "#     # Denormalize image if necessary (adjust based on your normalization method)\n",
    "#     denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "#     # Visualize the image\n",
    "#     plt.figure(figsize=(4, 4))\n",
    "#     plt.imshow(denormalized_image, cmap='gray')\n",
    "#     plt.title(title)\n",
    "\n",
    "#     # Plot midpoints directly, only if they are not (0, 0)\n",
    "#     for i, (x, y) in enumerate(midpoints_np):\n",
    "#         if x >= 0 and y >= 0:  # Only plot if the point is not (0, 0)\n",
    "#             plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# # Create the validation dataset\n",
    "# # val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n",
    "# # val_dataset = val_dataset.batch(800)\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# # inputs,targets = next(iter(train_dataset))\n",
    "# # outputs = model_builder.model.predict(inputs)\n",
    "# # # Initialize lists to collect the data\n",
    "# all_images = []\n",
    "# all_true_midpoints = []\n",
    "# all_pred_midpoints = []\n",
    "\n",
    "# # # Loop through each batch in the validation dataset, predict, and collect results\n",
    "# # for i, (data_batch, midpoints_batch) in enumerate(val_dataset):\n",
    "\n",
    "# for i, (data_batch, midpoints_batch) in enumerate(train_dataset):\n",
    "#     print(f\"Processing batch {i + 1}, batch shape: {data_batch.shape}\")\n",
    "    \n",
    "#     # Get the model predictions\n",
    "#     predictions =model_builder.model.predict(data_batch)\n",
    "\n",
    "#     # Extend the lists to store data from each batch\n",
    "#     all_images.extend(data_batch.numpy())  # Store all images\n",
    "#     all_true_midpoints.extend(midpoints_batch.numpy())  # Store all true midpoints\n",
    "#     all_pred_midpoints.extend(predictions)  # Store all predicted midpoints\n",
    "\n",
    "# # Convert lists to arrays for easier indexing\n",
    "# all_images = np.array(all_images)\n",
    "# all_true_midpoints = np.array(all_true_midpoints)\n",
    "# all_pred_midpoints = np.array(all_pred_midpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, batch shape: (800, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:14:56.909282: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "W0000 00:00:1729696497.069734 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.070713 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.071345 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.071982 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.072732 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.073380 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.074106 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.074780 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.075812 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.076974 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.077911 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.078797 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.079662 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.080649 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.081729 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.082697 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.083666 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.084519 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.085533 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.086896 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.088101 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.090399 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.090939 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.091376 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.092209 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.094522 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.095854 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.101800 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.103664 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.109832 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.110376 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.110863 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.111383 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729696497.111935 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.112497 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.113071 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.113650 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.114314 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.115083 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.115985 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.116678 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.117516 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.118305 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.119217 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.120143 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.120935 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.121744 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.122627 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.123795 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.124834 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.126883 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.127334 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.127699 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.128303 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.130313 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.131363 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.134769 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696497.136149 1761502 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 3, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 4, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 5, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 6, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 7, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 8, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 9, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 10, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 11, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 12, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Processing batch 13, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the function for visualizing midpoints\n",
    "def visualize_midpoints_with_gt(image, true_midpoints, pred_midpoints, title=\"Predicted vs GT Midpoints\"):\n",
    "    \"\"\"\n",
    "    Visualizes ground truth and predicted midpoints on an image and draws lines to connect them.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - true_midpoints: A 2D tensor representing the ground truth midpoint coordinates (x, y).\n",
    "    - pred_midpoints: A 2D tensor representing the predicted midpoint coordinates (x, y).\n",
    "    - title: The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints and lines).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "\n",
    "    # Ensure that midpoints are in the shape (num_points, 2) for both true and predicted midpoints\n",
    "    true_midpoints_np = np.reshape(true_midpoints, (-1, 2))\n",
    "    pred_midpoints_np = np.reshape(pred_midpoints, (-1, 2))\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(image_np, cmap='gray')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot both ground truth and predicted midpoints\n",
    "    for i, ((gt_x, gt_y), (pred_x, pred_y)) in enumerate(zip(true_midpoints_np, pred_midpoints_np)):\n",
    "        if gt_x >= 0 and gt_y >= 0:  # Only plot if the GT point is valid\n",
    "            plt.scatter(gt_x, gt_y, color='blue', label='Ground Truth' if i == 0 else \"\", s=30)\n",
    "            plt.scatter(pred_x, pred_y, color='red', label='Prediction' if i == 0 else \"\", s=30)\n",
    "\n",
    "            # Draw a line connecting the GT and predicted points\n",
    "            plt.plot([gt_x, pred_x], [gt_y, pred_y], color='green', linewidth=1)\n",
    "\n",
    "    # Add legend only once\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Create the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "train_dataset = train_dataset.batch(800)\n",
    "\n",
    "# Initialize lists to collect the data\n",
    "all_images = []\n",
    "all_true_midpoints = []\n",
    "all_pred_midpoints = []\n",
    "\n",
    "# Loop through each batch in the training dataset, predict, and collect results\n",
    "for i, (data_batch, midpoints_batch) in enumerate(train_dataset):\n",
    "    print(f\"Processing batch {i + 1}, batch shape: {data_batch.shape}\")\n",
    "    \n",
    "    # Get the model predictions\n",
    "    predictions = model_builder.model.predict(data_batch)\n",
    "\n",
    "    # Extend the lists to store data from each batch\n",
    "    all_images.extend(data_batch.numpy())  # Store all images\n",
    "    all_true_midpoints.extend(midpoints_batch.numpy())  # Store all true midpoints\n",
    "    all_pred_midpoints.extend(predictions)  # Store all predicted midpoints\n",
    "\n",
    "# Convert lists to arrays for easier indexing\n",
    "all_images = np.array(all_images)\n",
    "all_true_midpoints = np.array(all_true_midpoints)\n",
    "all_pred_midpoints = np.array(all_pred_midpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_visualize = np.random.randint(0, len(all_images))\n",
    "# Visualize the results for the first sample (you can change the index to visualize others)\n",
    "visualize_midpoints_with_gt(all_images[index_to_visualize ], all_true_midpoints[index_to_visualize ]*np.max(centers), all_pred_midpoints[index_to_visualize ]*np.max(centers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9600, 32, 32), (9600, 1, 13, 2), (9600, 1, 13, 2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape,all_pred_midpoints.shape,all_true_midpoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWMAAAF2CAYAAAC72fnJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAng0lEQVR4nO3de1hUdf4H8PeAzCgCA8j9hxDecNPEXVKWsrQgEMtSa1NxdzEvKWKl3bUnRZ+eKLtbatu2q9uW2upmrm5WSoBLoaXFmpUkhEoJaJYzCAICn98fLCdHbgMOnC/wfj3P98Fzzvec85k59Pb0Pd8ZDSIiICIiXTnpXQARETGMiYiUwDAmIlIAw5iISAEMYyIiBTCMiYgUwDAmIlIAw5iISAEMYyIiBTCMqUMZDAakpqbqXUaLZs6cCTc3t04/74YNG2AwGHDs2LFW+15xxRWYOXNmh9Yzc+ZMXHHFFR16Dmoew1gBhYWFWLhwIYYMGQJXV1e4urriyiuvREpKCg4dOqR3eR1q3LhxMBgMrbbLDfSKigqkpqYiMzPTIXVfrOE1DB48uMntu3fv1l7H1q1bHX5+Fbz33nvK/6Wrul56F9DT7dy5E1OnTkWvXr0wY8YMREREwMnJCUeOHME777yDdevWobCwEKGhoXqX2iEee+wxzJkzR1v+7LPPsHr1aixduhS/+tWvtPUjRoy4rPNUVFRgxYoVAOrD09F69+6N/Px8fPrppxg9erTNtrfeegu9e/dGZWWlzfo//OEPmDZtGkwmk8PraY8///nPqKura9e+7733HtasWcNAvgwMYx0VFBRg2rRpCA0NRXp6OgIDA222P/3001i7di2cnFr+H5jy8nL07du3I0vtMDfddJPNcu/evbF69WrcdNNNLYamaq954MCBqKmpwaZNm2zCuLKyEtu2bcPNN9+Mf/7znzb7ODs7w9nZubNLbZaLi4veJfRoHKbQ0apVq1BeXo7169c3CmIA6NWrF+699170799fW9cwvllQUIAJEybA3d0dM2bMAFAfUA888AD69+8Pk8mE8PBwPPvss7j4i/mOHTsGg8GADRs2NDrfpcMBqampMBgMyM/Px8yZM+Hp6Qmz2Yy77roLFRUVNvtWVVVh8eLF8PX1hbu7O2699VZ8//33l/kO2dbx9ddfIzExEV5eXhgzZgyA+rvcpkL74vHPY8eOwdfXFwCwYsWKZoc+fvjhB0yaNAlubm7w9fXFgw8+iNraWrvrnD59Ot5++22bu8sdO3agoqICd955Z6P+TY0ZiwieeOIJBAcHw9XVFTfccAO++uqrZvfdu3cv5s2bh379+sHDwwN//OMf8fPPPzfqv3btWgwbNgwmkwlBQUFISUnB2bNnbfpcOmbc8Lvy7LPP4rXXXsPAgQNhMpkwatQofPbZZzb7rVmzBgBshpYabN68GZGRkXB3d4eHhweuuuoqvPTSS62+nz0N74x1tHPnTgwaNAhRUVFt2q+mpgbx8fEYM2YMnn32Wbi6ukJEcOuttyIjIwOzZ8/GyJEj8cEHH+Chhx7CDz/8gBdeeKHddd55550ICwtDWloaPv/8c7z++uvw8/PD008/rfWZM2cO3nzzTSQmJuKaa67BRx99hJtvvrnd52zK7373OwwePBhPPvkk2vLNr76+vli3bh2Sk5MxefJkTJkyBYDt0EdtbS3i4+MRFRWFZ599Fnv27MFzzz2HgQMHIjk52a7zJCYmauPSN954IwBg48aNiImJgZ+fn13HWLZsGZ544glMmDABEyZMwOeff464uDhUV1c32X/hwoXw9PREamoq8vLysG7dOhw/fhyZmZlaIKampmLFihWIjY1FcnKy1u+zzz7Dxx9/3Ood8caNG1FWVoZ58+bBYDBg1apVmDJlCr777ju4uLhg3rx5OHnyJHbv3o2///3vNvvu3r0b06dPR0xMjPb78s033+Djjz/GfffdZ9d70mMI6cJisQgAmTRpUqNtP//8s5w+fVprFRUV2rakpCQBII8++qjNPu+++64AkCeeeMJm/R133CEGg0Hy8/NFRKSwsFAAyPr16xudF4AsX75cW16+fLkAkFmzZtn0mzx5svTr109bzs3NFQCyYMECm36JiYmNjtmaLVu2CADJyMhoVMf06dMb9R87dqyMHTu20fqkpCQJDQ3Vlk+fPt1sLQ3v6cqVK23W//rXv5bIyMhWax47dqwMGzZMRESuvvpqmT17tojUX0ej0Sh/+9vfJCMjQwDIli1btP3Wr18vAKSwsFBERE6dOiVGo1Fuvvlmqaur0/otXbpUAEhSUlKjfSMjI6W6ulpbv2rVKgEg27dvtzlmXFyc1NbWav1eeeUVASB//etfm33PGn5X+vXrJz/99JO2fvv27QJAduzYoa1LSUmRpuLkvvvuEw8PD6mpqWn1fezpOEyhE6vVCgBNTqkaN24cfH19tdbwv4AXu/Ru7b333oOzszPuvfdem/UPPPAARAS7du1qd63z58+3Wb7uuutw5swZ7TW89957ANDo3IsWLWr3Oe2pw9Gaep3fffddm46RmJiId955B9XV1di6dSucnZ0xefJku/bds2cPqqurcc8999j8b35L7+Pdd99tc2ebnJyMXr16adek4ZiLFi2yefYwd+5ceHh44N///nerdU2dOhVeXl7a8nXXXQcAdr03np6eKC8vx+7du1vt29MxjHXi7u4OADh37lyjbX/605+we/duvPnmm03u26tXLwQHB9usO378OIKCgrTjNmiYkXD8+PF21xoSEmKz3PAfZsPY5PHjx+Hk5ISBAwfa9AsPD2/3OZsSFhbm0ONdrHfv3tq4cgMvL68mx19bMm3aNFgsFuzatQtvvfUWbrnllkbXpDkN1+jSKXK+vr42YXixS/u6ubkhMDBQG4duOOal18JoNGLAgAF2/V60dv1bsmDBAgwZMgQJCQkIDg7GrFmz8P7777e6X0/EMNaJ2WxGYGAgDh8+3GhbVFQUYmNjce211za5r8lkanWGRXMuvuO6WEsPqpp74i+d/C929enTp9G69ryepjhqVkNgYCDGjRuH5557Dnv37kViYqJDjquny7n+fn5+yM3Nxb/+9S/tmUZCQgKSkpIcXWaXxzDW0c0336zNTb1coaGhOHnyJMrKymzWHzlyRNsO/HJXc+mT9Mu5cw4NDUVdXR0KCgps1ufl5bX7mPby8vJq9FqAxq+nudDuCImJifjPf/4DDw8PTJgwwe79Gq7R0aNHbdafPn262bvQS/ueO3cOxcXF2qyIhmNeei2qq6sdOn+9pffXaDRi4sSJWLt2LQoKCjBv3jy88cYbyM/Pd8i5uwuGsY4efvhhuLq6YtasWSgtLW20vS13nhMmTEBtbS1eeeUVm/UvvPACDAYDEhISAAAeHh7w8fHB3r17bfqtXbu2Ha+gXsOxV69ebbP+xRdfbPcx7TVw4EAcOXIEp0+f1tb997//xccff2zTz9XVFUDjv4Q6wh133IHly5dj7dq1MBqNdu8XGxsLFxcXvPzyyzbXvqX38bXXXsOFCxe05XXr1qGmpka7JrGxsTAajVi9erXNMf/yl7/AYrE4bMZLw5zvS9/fM2fO2Cw7OTlps1iqqqoccu7uglPbdDR48GBs3LgR06dPR3h4uPYJPBFBYWEhNm7cCCcnp0bjw02ZOHEibrjhBjz22GM4duwYIiIi8OGHH2L79u1YtGiRzXjunDlz8NRTT2HOnDm4+uqrsXfvXnz77bftfh0jR47E9OnTsXbtWlgsFlxzzTVIT0/vlDufWbNm4fnnn0d8fDxmz56NU6dO4dVXX8WwYcO0B4xA/RDHlVdeibfffhtDhgyBt7c3hg8fjuHDhzu8JrPZ3K5PojXMbU5LS8Mtt9yCCRMm4IsvvsCuXbvg4+PT5D7V1dWIiYnBnXfeiby8PKxduxZjxozBrbfeqh1zyZIlWLFiBcaPH49bb71V6zdq1Cj8/ve/v5yXqomMjARQ/xA3Pj4ezs7OmDZtGubMmYOffvoJN954I4KDg3H8+HG8/PLLGDlypM0nLAmc2qaC/Px8SU5OlkGDBknv3r2lT58+MnToUJk/f77k5uba9E1KSpK+ffs2eZyysjJZvHixBAUFiYuLiwwePFieeeYZm2lSIiIVFRUye/ZsMZvN4u7uLnfeeaecOnWq2altp0+fttn/0ilZIiLnz5+Xe++9V/r16yd9+/aViRMnSlFRkUOntl1aR4M333xTBgwYIEajUUaOHCkffPBBo2laIiKffPKJREZGitFotKmrufe04bytuXhqW3PsmdomIlJbWysrVqyQwMBA6dOnj4wbN04OHz4soaGhTU5ty8rKkrvvvlu8vLzEzc1NZsyYIWfOnGl0/ldeeUWGDh0qLi4u4u/vL8nJyfLzzz/b9GluatszzzzT6HiXXteamhq55557xNfXVwwGg/a+bd26VeLi4sTPz0+MRqOEhITIvHnzpLi4uMX3qycyiHTyUxgiumwbNmzAXXfdhc8++wxXX3213uWQA3DMmIhIAQxjIiIFMIyJiBTAMWMiIgXwzpiISAEMYyIiBSj3oY+6ujqcPHkS7u7unfoRViIiRxMRlJWVISgoqNXvk1EujE+ePGnzL1sQEXV1RUVFrX6StsOGKdasWYMrrrgCvXv3RlRUlN1fhmPv1w0SEXUV9uRah4Tx22+/jfvvvx/Lly/H559/joiICMTHx+PUqVOt7suhCSLqbuzKtY74jPXo0aMlJSVFW66trZWgoCBJS0trdd+Gf46IjY2Nrbs0i8XSavY5/M64uroaBw8eRGxsrLbOyckJsbGxyMnJadS/qqoKVqvVphER9TQOD+Mff/wRtbW18Pf3t1nv7++PkpKSRv3T0tJgNpu1xod3RNQT6T7PeMmSJbBYLForKirSuyQiok7n8KltPj4+cHZ2bvQvV5SWliIgIKBRf5PJBJPJ5OgyiIi6FIffGRuNRkRGRiI9PV1bV1dXh/T0dERHRzv6dERE3UKHfOjj/vvvR1JSEq6++mqMHj0aL774IsrLy3HXXXd1xOmIiLq8DgnjqVOn4vTp01i2bBlKSkowcuRIvP/++40e6hERUT3lvkLTarXCbDbrXQYRkcNYLBZ4eHi02Ef32RRERMQwJiJSAsOYiEgBDGMiIgUwjImIFMAwJiJSAMOYiEgBDGMiIgUwjImIFMAwJiJSAMOYiEgBDGMiIgUwjImIFMAwJiJSAMOYiEgBDGMiIgUwjImIFMAwJiJSAMOYiEgBDGMiIgUwjImIFMAwJiJSAMOYiEgBDGMiIgUwjImIFMAwJiJSAMOYiEgBDGMiIgUwjImIFMAwJiJSAMOYiEgBDGMiIgUwjImIFMAwJiJSAMOYiEgBDGMiIgUwjImIFODwME5NTYXBYLBpQ4cOdfRpiIi6lV4dcdBhw4Zhz549v5ykV4echoio2+iQlOzVqxcCAgI64tBERN1Sh4wZHz16FEFBQRgwYABmzJiBEydONNu3qqoKVqvVphER9TQOD+OoqChs2LAB77//PtatW4fCwkJcd911KCsra7J/WloazGaz1vr37+/okoiIlGcQEenIE5w9exahoaF4/vnnMXv27Ebbq6qqUFVVpS1brVYGMhF1KxaLBR4eHi326fAna56enhgyZAjy8/Ob3G4ymWAymTq6DCIipXX4PONz586hoKAAgYGBHX0qIqIuy+Fh/OCDDyIrKwvHjh3DJ598gsmTJ8PZ2RnTp0939KmIiLoNhw9TfP/995g+fTrOnDkDX19fjBkzBvv27YOvr6+jT0VE1G10+AO8trJarTCbzXqXQUTkMPY8wON3UxARKYBhTESkAIYxEZECGMZERApgGBMRKYBhTESkAIYxEZECGMZERApgGBMRKYBhTESkAIYxEZECGMZERApgGBMRKYBhTESkAIYxEZECGMZERApgGBMRKYBhTESkAIYxEZECGMZERApgGBMRKYBhTESkAIYxEZECGMZERApgGBMRKYBhTESkAIYxEZECGMZERApgGBMRKYBhTESkAIYxEZECGMZERApgGBMRKYBhTESkAIYxEZECGMZERApgGBMRKaDNYbx3715MnDgRQUFBMBgMePfdd222iwiWLVuGwMBA9OnTB7GxsTh69Kij6iUi6pbaHMbl5eWIiIjAmjVrmty+atUqrF69Gq+++ir279+Pvn37Ij4+HpWVlZddLBFRtyWXAYBs27ZNW66rq5OAgAB55plntHVnz54Vk8kkmzZtsuuYFotFALCxsbF1m2axWFrNPoeOGRcWFqKkpASxsbHaOrPZjKioKOTk5DS5T1VVFaxWq00jIuppHBrGJSUlAAB/f3+b9f7+/tq2S6WlpcFsNmutf//+jiyJiKhL0H02xZIlS2CxWLRWVFSkd0lERJ3OoWEcEBAAACgtLbVZX1paqm27lMlkgoeHh00jIuppHBrGYWFhCAgIQHp6urbOarVi//79iI6OduSpiIi6lV5t3eHcuXPIz8/XlgsLC5Gbmwtvb2+EhIRg0aJFeOKJJzB48GCEhYXh8ccfR1BQECZNmuTIuomIupe2TmfLyMhocupGUlKSNr3t8ccfF39/fzGZTBITEyN5eXl2H59T29g6q9lL7zrZun6zZ2qb4X+/bMqwWq0wm816l0E9gL2/+gaDoYMroe7OYrG0+jxM99kURETEMCaqV1MDrFwJxMXV/6yp0bsi6mHa/ACPqFt68kkgNRUQAfbsqV+3bJmuJVHPwjtjIgDIzq4PYqD+Z3a2vvVQj8MwJgKAMWOAhgd1BkP9MlEn4jAFEQAsXVr/Mzu7Pogblok6Cae2UY/FqW3UWeyZ2sY7Y+qxGLKkEo4ZExEpgGFMRKQAhjERkQIYxkRECmAYExEpgGFMRKQAhjERkQIYxkRECmAYExEpgGFMRKQAhjERkQIYxkRECmAYExEpgGFMRKQAhjERkQIYxkRECmAYExEpgGFMRKQAhjERkQIYxkRECmAYExEpgGFMRKQAhjERkQIYxkRECmAYExEpgGFMRKQAhjERkQIYxkRECmAYExEpoM1hvHfvXkycOBFBQUEwGAx49913bbbPnDkTBoPBpo0fP95R9RIRdUttDuPy8nJERERgzZo1zfYZP348iouLtbZp06bLKpKIqLvr1dYdEhISkJCQ0GIfk8mEgICAdhdFRNTTdMiYcWZmJvz8/BAeHo7k5GScOXOm2b5VVVWwWq02jYiop3F4GI8fPx5vvPEG0tPT8fTTTyMrKwsJCQmora1tsn9aWhrMZrPW+vfv7+iSiIjUJ5cBgGzbtq3FPgUFBQJA9uzZ0+T2yspKsVgsWisqKhIAbGxsbN2mWSyWVvO0w6e2DRgwAD4+PsjPz29yu8lkgoeHh00jIuppOjyMv//+e5w5cwaBgYEdfSoioi6rzbMpzp07Z3OXW1hYiNzcXHh7e8Pb2xsrVqzA7bffjoCAABQUFODhhx/GoEGDEB8f79DCiYi6lbaOE2dkZDQ5JpKUlCQVFRUSFxcnvr6+4uLiIqGhoTJ37lwpKSmx+/gWi0X38R02NjY2RzZ7xowNIiJQiNVqhdls1rsMIiKHsVgsrT4P43dTEBEpgGFMRKQAhjERkQIYxkRECmAYExEpgGFMRKQAhjERkQIYxkRECmAYExEpgGFMRKQAhjERkQIYxkRECmAYExEpgGFMRKQAhjERkQIYxkRECmAYExEpgGFMRKQAhjERkQIYxkRECmAYExEpgGFMRKQAhjERkQIYxkRECmAYExEpgGFMRKQAhjERkQJ66V0AEVFLRKTVPgaDoRMq6Vi8MyYiUgDDmIhIAQxjIuo6amqAlSuBuLj6nzU1elfkMBwzJqKu48kngdRUQATYs6d+3bJlupbkKLwzJqKuIzu7PoiB+p/Z2frW40AMYyLqOsaMARpmThgM9cvdBIcpiKjrWLq0/md2dn0QNyx3AwaxZxJfJ7JarTCbzXqXQUSK6A7zjC0WCzw8PFrswztjIlKa6kHrKG0aM05LS8OoUaPg7u4OPz8/TJo0CXl5eTZ9KisrkZKSgn79+sHNzQ233347SktLHVo0EVF306YwzsrKQkpKCvbt24fdu3fjwoULiIuLQ3l5udZn8eLF2LFjB7Zs2YKsrCycPHkSU6ZMcXjhRETdilyGU6dOCQDJysoSEZGzZ8+Ki4uLbNmyRevzzTffCADJycmx65gWi0UAsLGxsXWbZrFYWs2+y5raZrFYAADe3t4AgIMHD+LChQuIjY3V+gwdOhQhISHIycm5nFMREXVr7X6AV1dXh0WLFuHaa6/F8OHDAQAlJSUwGo3w9PS06evv74+SkpImj1NVVYWqqipt2Wq1trckIqIuq913xikpKTh8+DA2b958WQWkpaXBbDZrrX///pd1PCKirqhdYbxw4ULs3LkTGRkZCA4O1tYHBASguroaZ8+etelfWlqKgICAJo+1ZMkSWCwWrRUVFbWnJCKirq0tD+zq6uokJSVFgoKC5Ntvv220veEB3tatW7V1R44cEYAP8NjY2Hpus+cBXpvCODk5Wcxms2RmZkpxcbHWKioqtD7z58+XkJAQ+eijj+TAgQMSHR0t0dHRdp+DYczGxtbdmsPDuLkTrV+/Xutz/vx5WbBggXh5eYmrq6tMnjxZiouLGcZsbGw9ttkTxvxuCiKiDmbPd1PwKzSJiBTAMCYiUgDDmIhIAQxjIiIFMIyJiBTAMCYiUgDDmIhIAQxjIiIFMIyJiBTAMCYiUgDDmIhIAQxjIiIFMIyJiBTAMCYiUgDDmIhIAQxjIiIFMIyJiBTAMCYiUgDDmIhIAQxjIiIFMIyJiBTAMCYiUgDDmIhIAQxjIiIFMIyJiBTAMCYiUgDDmIhIAb30LoCIqLOIiF39DAZDB1fSGO+MiYgUwDAmIlIAw5iIeqaaGmDlSiAurv5nTY2u5XDMmIh6piefBFJTARFgz576dcuW6VYO74yJqGfKzq4PYqD+Z3a2ruUwjImoZxozBmiYNWEw1C/riMMURNQzLV1a/zM7uz6IG5Z1YhB7J951EqvVCrPZrHcZRNQN6TXP2GKxwMPDo8U+HKYgIlJAm8I4LS0No0aNgru7O/z8/DBp0iTk5eXZ9Bk3bhwMBoNNmz9/vkOLJiK6mIjY1S7NpuaaHtoUxllZWUhJScG+ffuwe/duXLhwAXFxcSgvL7fpN3fuXBQXF2tt1apVDi2aiKi7adMDvPfff99mecOGDfDz88PBgwdx/fXXa+tdXV0REBDgmAqJiHqAyxoztlgsAABvb2+b9W+99RZ8fHwwfPhwLFmyBBUVFZdzGiKitlHs03X2aPfUtrq6OixatAjXXnsthg8frq1PTExEaGgogoKCcOjQITzyyCPIy8vDO++80+RxqqqqUFVVpS1brdb2lkREVE+xT9fZRdpp/vz5EhoaKkVFRS32S09PFwCSn5/f5Pbly5cLADY2NrZ2t0ZuukkE+KXddJOIiG71WSyWVjO1XcMUCxcuxM6dO5GRkYHg4OAW+0ZFRQEA8vPzm9y+ZMkSWCwWrRUVFbWnJCKiXyj26Tp7tGmYQkRwzz33YNu2bcjMzERYWFir++Tm5gIAAgMDm9xuMplgMpnaUgYRUcsU+3SdPdr0CbwFCxZg48aN2L59O8LDw7X1ZrMZffr0QUFBATZu3IgJEyagX79+OHToEBYvXozg4GBkZWXZdQ5+Ao+I2sreGNNrDrE9n8Br05gxmhkPWb9+vYiInDhxQq6//nrx9vYWk8kkgwYNkoceesiu8ZIGFotF9/EnNjY2Nkc2ezKQ301BRNTB+N0URERdBMOYiEgBDGMiIgUwjImIFMAwJiJSAMOYiEgBDGMiIgUwjImIFMAwJiJSAMOYiEgBDGMiIgUwjImIFMAwJiJSAMOYiEgBDGMiIgUwjImIFMAwJiJSAMOYiEgBDGMiIgUwjImIFMAwJiJSAMOYiEgBDGMiIgUwjImIFMAwJiJSAMOYiEgBDGMiIgX00rsAIupYItJqH4PB0AmVUEt4Z0xEpACGMRGRAhjGRD1JTQ2wciUQF1f/s6ZG74rofzhmTNSTPPkkkJoKiAB79tSvW7ZM15KoHu+MiXqS7Oz6IAbqf2Zn61sPaRjGRD3JmDFAw8wJg6F+mZTAYQqinmTp0vqf2dn1QdywTLoziD2TEDuR1WqF2WzWuwyiboPzjPVnsVjg4eHRYh8OUxARKaBNYbxu3TqMGDECHh4e8PDwQHR0NHbt2qVtr6ysREpKCvr16wc3NzfcfvvtKC0tdXjRRGQ/g8HQaiP9tSmMg4OD8dRTT+HgwYM4cOAAbrzxRtx222346quvAACLFy/Gjh07sGXLFmRlZeHkyZOYMmVKhxRORNStyGXy8vKS119/Xc6ePSsuLi6yZcsWbds333wjACQnJ8fu41ksFgHAxsbG1m2axWJpNfvaPWZcW1uLzZs3o7y8HNHR0Th48CAuXLiA2NhYrc/QoUMREhKCnJyc9p6GiKhHaPPUti+//BLR0dGorKyEm5sbtm3bhiuvvBK5ubkwGo3w9PS06e/v74+SkpJmj1dVVYWqqipt2Wq1trUkIqIur813xuHh4cjNzcX+/fuRnJyMpKQkfP311+0uIC0tDWazWWv9+/dv97GIiLqqy55nHBsbi4EDB2Lq1KmIiYnBzz//bHN3HBoaikWLFmHx4sVN7t/UnTEDmYi6k06ZZ1xXV4eqqipERkbCxcUF6enp2ra8vDycOHEC0dHRze5vMpm0qXINjYiop2nTmPGSJUuQkJCAkJAQlJWVYePGjcjMzMQHH3wAs9mM2bNn4/7774e3tzc8PDxwzz33IDo6Gr/97W87qn4iou6hLdPYZs2aJaGhoWI0GsXX11diYmLkww8/1LafP39eFixYIF5eXuLq6iqTJ0+W4uLitpyCU9vY2Ni6XbNnahu/m4KIqIPxuymIiLoIhjERkQIYxkRECmAYExEpgGFMRKQAhjERkQIYxkREClAujBWb9kxEdNnsyTXlwrisrEzvEoiIHMqeXFPuE3h1dXU4efIk3N3dtX+bq+Gb3IqKirrkFwmxfv119dfA+vXV3vpFBGVlZQgKCoKTU8v3vm3+cvmO5uTkhODg4Ca3dfVvdWP9+uvqr4H166s99dv79Q7KDVMQEfVEDGMiIgV0iTA2mUxYvnw5TCaT3qW0C+vXX1d/DaxfX51Rv3IP8IiIeqIucWdMRNTdMYyJiBTAMCYiUgDDmIhIAV0ijNesWYMrrrgCvXv3RlRUFD799FO9S7JLamoqDAaDTRs6dKjeZTVr7969mDhxIoKCgmAwGPDuu+/abBcRLFu2DIGBgejTpw9iY2Nx9OhRfYptQmv1z5w5s9H1GD9+vD7FNiEtLQ2jRo2Cu7s7/Pz8MGnSJOTl5dn0qaysREpKCvr16wc3NzfcfvvtKC0t1aliW/bUP27cuEbXYP78+TpVbGvdunUYMWKE9sGO6Oho7Nq1S9ve0e+98mH89ttv4/7778fy5cvx+eefIyIiAvHx8Th16pTepdll2LBhKC4u1lp2drbeJTWrvLwcERERWLNmTZPbV61ahdWrV+PVV1/F/v370bdvX8THx6OysrKTK21aa/UDwPjx422ux6ZNmzqxwpZlZWUhJSUF+/btw+7du3HhwgXExcWhvLxc67N48WLs2LEDW7ZsQVZWFk6ePIkpU6boWPUv7KkfAObOnWtzDVatWqVTxbaCg4Px1FNP4eDBgzhw4ABuvPFG3Hbbbfjqq68AdMJ73+q/H62z0aNHS0pKirZcW1srQUFBkpaWpmNV9lm+fLlEREToXUa7AJBt27Zpy3V1dRIQECDPPPOMtu7s2bNiMplk06ZNOlTYskvrFxFJSkqS2267TZd62uPUqVMCQLKyskSk/v12cXGRLVu2aH2++eYbASA5OTl6ldmsS+sXERk7dqzcd999+hXVRl5eXvL66693ynuv9J1xdXU1Dh48iNjYWG2dk5MTYmNjkZOTo2Nl9jt69CiCgoIwYMAAzJgxAydOnNC7pHYpLCxESUmJzbUwm82IiorqMtcCADIzM+Hn54fw8HAkJyfjzJkzepfULIvFAgDw9vYGABw8eBAXLlywuQZDhw5FSEiIktfg0vobvPXWW/Dx8cHw4cOxZMkSVFRU6FFei2pra7F582aUl5cjOjq6U9575b4o6GI//vgjamtr4e/vb7Pe398fR44c0akq+0VFRWHDhg0IDw9HcXExVqxYgeuuuw6HDx+Gu7u73uW1SUlJCQA0eS0atqlu/PjxmDJlCsLCwlBQUIClS5ciISEBOTk5cHZ21rs8G3V1dVi0aBGuvfZaDB8+HED9NTAajfD09LTpq+I1aKp+AEhMTERoaCiCgoJw6NAhPPLII8jLy8M777yjY7W/+PLLLxEdHY3Kykq4ublh27ZtuPLKK5Gbm9vh773SYdzVJSQkaH8eMWIEoqKiEBoain/84x+YPXu2jpX1TNOmTdP+fNVVV2HEiBEYOHAgMjMzERMTo2NljaWkpODw4cNKP2NoSXP133333dqfr7rqKgQGBiImJgYFBQUYOHBgZ5fZSHh4OHJzc2GxWLB161YkJSUhKyurU86t9DCFj48PnJ2dGz2xLC0tRUBAgE5VtZ+npyeGDBmC/Px8vUtps4b3u7tcCwAYMGAAfHx8lLseCxcuxM6dO5GRkWHzdbIBAQGorq7G2bNnbfqrdg2aq78pUVFRAKDMNTAajRg0aBAiIyORlpaGiIgIvPTSS53y3isdxkajEZGRkUhPT9fW1dXVIT09HdHR0TpW1j7nzp1DQUEBAgMD9S6lzcLCwhAQEGBzLaxWK/bv398lrwUAfP/99zhz5owy10NEsHDhQmzbtg0fffQRwsLCbLZHRkbCxcXF5hrk5eXhxIkTSlyD1upvSm5uLgAocw0uVVdXh6qqqs557x3yGLADbd68WUwmk2zYsEG+/vprufvuu8XT01NKSkr0Lq1VDzzwgGRmZkphYaF8/PHHEhsbKz4+PnLq1Cm9S2tSWVmZfPHFF/LFF18IAHn++efliy++kOPHj4uIyFNPPSWenp6yfft2OXTokNx2220SFhYm58+f17nyei3VX1ZWJg8++KDk5ORIYWGh7NmzR37zm9/I4MGDpbKyUu/SRUQkOTlZzGazZGZmSnFxsdYqKiq0PvPnz5eQkBD56KOP5MCBAxIdHS3R0dE6Vv2L1urPz8+XlStXyoEDB6SwsFC2b98uAwYMkOuvv17nyus9+uijkpWVJYWFhXLo0CF59NFHxWAwyIcffigiHf/eKx/GIiIvv/yyhISEiNFolNGjR8u+ffv0LskuU6dOlcDAQDEajfJ///d/MnXqVMnPz9e7rGZlZGQIgEYtKSlJROqntz3++OPi7+8vJpNJYmJiJC8vT9+iL9JS/RUVFRIXFye+vr7i4uIioaGhMnfuXKX+Um+qdgCyfv16rc/58+dlwYIF4uXlJa6urjJ58mQpLi7Wr+iLtFb/iRMn5Prrrxdvb28xmUwyaNAgeeihh8Risehb+P/MmjVLQkNDxWg0iq+vr8TExGhBLNLx7z2/QpOISAFKjxkTEfUUDGMiIgUwjImIFMAwJiJSAMOYiEgBDGMiIgUwjImIFMAwJiJSAMOYiEgBDGMiIgUwjImIFMAwJiJSwP8DsxP3shDunGwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select an index to visualize from the entire dataset\n",
    "index_to_visualize = np.random.randint(0, len(all_images))\n",
    "\n",
    "# index_to_visualize = 11548\n",
    "# Visualize the selected image with predicted and true midpoints\n",
    "visualize_midpoints(all_images[index_to_visualize], all_pred_midpoints[index_to_visualize, 0, :, :] * np.max(centers), title=\"Predicted Midpoints\")\n",
    "visualize_midpoints(all_images[index_to_visualize], all_true_midpoints[index_to_visualize, 0, :, :] * np.max(centers), title=\"Ground Truth Midpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.843155e-06, 30.997658)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_pred_midpoints)*np.max(centers),np.max(all_pred_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 31.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_true_midpoints)*np.max(centers),np.max(all_true_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 31.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_images), np.max(train_images), np.min(train_midpoints)*np.max(centers), np.max(train_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 4.2590027,  3.908059 ],\n",
       "         [27.263153 ,  4.3831873],\n",
       "         [ 5.8743353,  6.6574388],\n",
       "         [14.020337 ,  8.760142 ],\n",
       "         [ 4.1754484, 10.7192545],\n",
       "         [ 4.123699 , 11.2907295],\n",
       "         [22.326601 , 11.401616 ],\n",
       "         [ 7.203351 , 12.493043 ],\n",
       "         [ 5.814977 , 12.613149 ],\n",
       "         [21.202332 , 14.556165 ],\n",
       "         [ 8.0557995, 17.444569 ],\n",
       "         [ 8.055367 , 18.544151 ],\n",
       "         [ 5.2744675, 26.596989 ]]], dtype=float32),\n",
       " array([[[ 4.,  3.],\n",
       "         [28.,  6.],\n",
       "         [ 6.,  7.],\n",
       "         [14.,  9.],\n",
       "         [ 4., 10.],\n",
       "         [ 4., 10.],\n",
       "         [22., 11.],\n",
       "         [ 7., 12.],\n",
       "         [ 6., 14.],\n",
       "         [21., 15.],\n",
       "         [ 8., 17.],\n",
       "         [ 8., 18.],\n",
       "         [ 5., 28.]]], dtype=float32))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred_midpoints[2]*np.max(centers),all_true_midpoints[2]*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1., 35., 12.],\n",
       "        [ 1., 63., 52.],\n",
       "        [ 1., 11., 43.],\n",
       "        ...,\n",
       "        [ 1., 10., 33.],\n",
       "        [ 1., 11., 48.],\n",
       "        [ 1., 59., 49.]],\n",
       "\n",
       "       [[ 1.,  5., 24.],\n",
       "        [ 1., 34., 55.],\n",
       "        [ 1., 42., 29.],\n",
       "        ...,\n",
       "        [ 1.,  2., 55.],\n",
       "        [ 1., 13., 17.],\n",
       "        [ 1., 45.,  8.]],\n",
       "\n",
       "       [[ 1., 38., 36.],\n",
       "        [ 1., 11., 33.],\n",
       "        [ 1., 40., 40.],\n",
       "        ...,\n",
       "        [ 1., 45.,  5.],\n",
       "        [ 1.,  8.,  7.],\n",
       "        [ 1., 55., 37.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1., 50., 18.],\n",
       "        [ 1., 20., 19.],\n",
       "        [ 1., 63.,  8.],\n",
       "        ...,\n",
       "        [ 1., 32., 44.],\n",
       "        [ 1., 63., 24.],\n",
       "        [ 1., 51., 52.]],\n",
       "\n",
       "       [[ 1.,  6., 33.],\n",
       "        [ 1., 23., 59.],\n",
       "        [ 1., 13., 48.],\n",
       "        ...,\n",
       "        [ 1., 26., 62.],\n",
       "        [ 1., 20., 42.],\n",
       "        [ 1., 53.,  2.]],\n",
       "\n",
       "       [[ 1., 24., 40.],\n",
       "        [ 1., 30., 43.],\n",
       "        [ 1., 38., 55.],\n",
       "        ...,\n",
       "        [ 1., 31., 56.],\n",
       "        [ 1., 21., 50.],\n",
       "        [ 1., 15.,  6.]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[2],)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables to track the min and max MSE\n",
    "min_mse = float('inf')\n",
    "max_mse = float('-inf')\n",
    "min_mse_index = -1\n",
    "max_mse_index = -1\n",
    "\n",
    "# Loop through each prediction to calculate the MSE\n",
    "for i in range(len(all_pred_midpoints)):\n",
    "    mse = np.mean((all_pred_midpoints[i] - all_true_midpoints[i]) **2)\n",
    "    \n",
    "    if mse < min_mse:\n",
    "        min_mse = mse\n",
    "        min_mse_index = i\n",
    "    \n",
    "    if mse > max_mse:\n",
    "        max_mse = mse\n",
    "        max_mse_index = i\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot an image with its centers\n",
    "def plot_image_with_centers(image, true_center, predicted_center, title):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  # Display the image\n",
    "\n",
    "    # Plot the actual center (Groundtruth)\n",
    "    plt.scatter(true_center[:, 0], true_center[:, 1], color='green', label='Groundtruth', s=10)\n",
    "\n",
    "    # Plot the predicted center\n",
    "    plt.scatter(predicted_center[:, 0], predicted_center[:, 1], color='red', label='Predictions', s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the image with the least MSE\n",
    "plot_image_with_centers(all_images[min_mse_index],\n",
    "                        all_true_midpoints[min_mse_index][0] * np.max(centers),  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[min_mse_index][0] * np.max(centers),  # Adjust for scaling if needed\n",
    "                        f'Image with Least MSE. MSE: {min_mse:.4f}')\n",
    "\n",
    "# Plotting the image with the largest MSE\n",
    "plot_image_with_centers(all_images[max_mse_index],\n",
    "                        all_true_midpoints[max_mse_index][0] * np.max(centers),  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[max_mse_index][0] * np.max(centers),  # Adjust for scaling if needed\n",
    "                        f'Image with Largest MSE. MSE: {max_mse:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5266"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mse_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
